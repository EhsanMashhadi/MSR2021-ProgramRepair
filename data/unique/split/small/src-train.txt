public DerivedBuilder setUserAgent(String userAgent){   configBuilder.setUserAgent(userAgent);   return this; } 
GL11.glGetTexParameter(target,pname,params)
ticket.notify()
expectedValue.equals(oldValue)
new Neo4jGraph(database.graph)
id=15855
engine.execute(query).toString()
config.getIdleConnectionTimeoutInMs() > 0
statistics.addGetTimeNano(System.nanoTime() - start)
b.getBroadcasterConfig().applyFilters(r,cachedMessages)
id=52
Assert.assertEquals("Recall outside target range",0.6924,r,0.001)
simple.getFromSentDate()
new DeserializationException(e)
toJSON(entry.getValue())
WebAppUtils.getResolvedRMWebAppURLWithoutScheme(conf)
setMode(mode)
pool != null & pool.getDataSource().getClass().isAssignableFrom(iface)
ours=theirIterator.next()
id=17
new MalformedException("Unrecognized message placeholder referenced: " + phName,objLitNode)
streamTokenizer.ttype == StreamTokenizer.TT_WORD
testSame("asdf;","var asdf;",VarCheck.NAME_REFERENCE_IN_EXTERNS_ERROR,true)
hashFunction.hashBytes(littleEndian)
sExecutorService.shutdown()
assertEquals(8,set.size())
isAllFiles()
buffer.put(indices)
VARCHAR.createBlockBuilder(new BlockBuilderStatus(),1)
loadRunnable instanceof LongTask
public Integer getOlderThan(){   return olderThan; } 
/**   * Signal the maps/reduces to start.  */ static void signalTasks(MiniDFSCluster dfs,FileSystem fileSys,boolean isMap,String mapSignalFile,String reduceSignalFile) throws IOException {   writeFile(dfs.getNameNode(),fileSys.getConf(),isMap ? new Path(mapSignalFile) : new Path(reduceSignalFile),(short)1); } 
twitter1.checkUserListMembership(id1.screenName,id2.id,userList.getId())
annotation == OriginalType.MAP
EnterpriseMapPublisherCreateWithValueCodec.decodeResponse(response).entries
group.shutdownGracefully()
size=1f
postAgg.getName().equals(topNMetricName)
from("direct:start").multicast(new AggregationStrategy(){   public Exchange aggregate(  Exchange oldExchange,  Exchange newExchange){     if (oldExchange == null) {       return newExchange;     }     String body=oldExchange.getIn().getBody(String.class);     oldExchange.getIn().setBody(body + newExchange.getIn().getBody(String.class));     return oldExchange;   } } ).parallelProcessing().timeout(2000)
page.getSizeInBytes()
((VarcharType)type).getLength()
assertThat(context.getBeansOfType(WebServerFactoryCustomizer.class)).hasSize(1)
id=30
(short)777
addGroupedInterceptor(filter,interceptorClassName,group,executionPolicy)
detailNode != null
v.getCreationTime() + timeToLive > now
converter.convertTo(leftValue.getClass(),rightValue)
Multiset<String>
cacheConfig.isPopulateCache()
restEnableGzip=false
logger.debug("NODE {}: Retry timout: Advancing")
@Override public ResponseImpl header(String name,Property property){   addHeader(name,property);   return this; } 
assertThat(xml).isEqualTo(expectedContent)
{14,3.0f}
/**   * Gets the exception thrown (if any) by the method called in  {@link #run()}  * @return the thrown exception (if any).  */ public Throwable getExceptionThrown(){   return exceptionThrown; } 
columnType.equalsIgnoreCase("date")
fields.contains(name)
callTimeoutMs=5000
CONCURRENT_THREAD_COUNT=300
new Exception()
id=20
typeTmp.get(0)
getStreamNode(iterationHead)
new DynamicAwareEntry("https4://localhost/test",null,null)
new Path(tblDesc.getLocation())
new NullOutputOperatorFactory(operatorId,sourceType)
DEFAULT_ROW_FLUSH_BOUNDARY=500000
new ArrayList<Object>()
touchEventPool.free(touchEvents)
LOG.warn("Requesting paths for query services failed.",throwable)
UnsupportedOperationException.class
_barrier.waitFor(nextSequence,10,TimeUnit.MILLISECONDS)
mTfs.getFile(fileId)
new UnsupportedOperationException("Command not found in bolt message: " + shellMsg)
Status.constructStatuses(get(getBaseURL() + "statuses/user_timeline/" + id+ ".json",null,paging.asPostParameterList(),http.isAuthenticationEnabled()))
JSError.make(callNode,NOT_UNIQUE_INSTANTIATION,funType.toString(),UniqueNameGenerator.getOriginalName(typeParam),types.toString())
"Segment initialized with too large address: " + address + " ; Max allowed address is "+ (Long.MAX_VALUE - Integer.MAX_VALUE - 1)
new PoolBagEntry(null,TestElf.getPool(ds))
DefaultManagementAgent.class
JavaDocTagContinuationIndentationCheck.class
GL20.glUniform4(location,v)
logger.info("Parsing Dep: " + filePath)
/**   * Gets the key of bind hostname.  * @return key of bind hostname  */ public String getBindHostKey(){   return mBindHostKey; } 
new File(ctx.getCurrentDir(),resourceArr[i])
interceptors.addFirst(newAInterceptor(a))
Assert.assertEquals(20,as.getAllGlobalProperties().size())
paused.get()
new GrammaticalRelation(Language.UniversalChinese,"nummod","numeric modifier",MODIFIER,"QP|NP|DP",tregexCompiler,"NP|QP < ( QP  =target << M $++ NN|NP|QP)","NP|QP < ( DNP=target < (QP < CD !< OD) !< JJ|ADJP $++ NP|QP )")
TEST_UTIL.waitTableEnabled(TEST_TABLE.getTableName())
probeParentLoaderLast=true
@GwtIncompatible("ObjectInputStream") public void restoreState(InputStream inputStream) throws Exception {   try (final ObjectInputStream objectInputStream=new ObjectInputStream(inputStream)){     CompilerState compilerState=runInCompilerThread(new Callable<CompilerState>(){       @Override public CompilerState call() throws Exception {         return (CompilerState)objectInputStream.readObject();       }     } );     externs=compilerState.externs;     inputs=compilerState.inputs;     inputsById.clear();     inputsById.putAll(compilerState.inputsById);     typeRegistry=compilerState.typeRegistry;     externAndJsRoot=compilerState.externAndJsRoot;     externsRoot=compilerState.externsRoot;     jsRoot=compilerState.jsRoot;     mostRecentTypechecker=compilerState.mostRecentTypeChecker;     synthesizedExternsInput=compilerState.synthesizedExternsInput;     synthesizedExternsInputAtEnd=compilerState.synthesizedExternsInputAtEnd;     injectedLibraries.clear();     injectedLibraries.putAll(compilerState.injectedLibraries);     lastInjectedLibrary=compilerState.lastInjectedLibrary;     globalRefMap=compilerState.globalRefMap;     symbolTable=compilerState.symbolTable;     hasRegExpGlobalReferences=compilerState.hasRegExpGlobalReferences;     typeValidator=compilerState.typeValidator;     setLifeCycleStage(compilerState.lifeCycleStage);     externProperties=compilerState.externProperties;   }    initWarningsGuard(options.getWarningsGuard());   maybeSetTracker(); } 
targetDirectory.directory("unwritable")
soundLocation.add(deltaX / delta,deltaY / delta,deltaZ / delta)
version > 0
sorted_files.get(i).createReader()
ch == '&'
entry.getHeader().getEventLength() * 3
ModelVersion.create(3,0,0)
return 30; 
public Integer getRequestRequiredAcks(){   return configuration.getRequestRequiredAcks(); } 
z.next_in[z.next_in_index++] == 0
new ClusterConfiguration(name,logging.getMessagesLog(ClusterConfiguration.class),Collections.singleton(boundAt))
ServiceLoader.load(WorkerFactory.class)
(short)0644
new WordToSentenceProcessor<IN>()
AdviceWithTasks.afterByToString(route,toString,answer,selectLast,selectFirst,selectFrom,selectTo,maxDeep)
mPersistedFiles.removeAll(mPersistedFiles)
Thread.sleep(100)
position < mSrcDragPos
out.write(this.connectionAddress.getPort())
Ordered.LOWEST_PRECEDENCE - 1
EnumValidator.create(Target.class,false,false)
LOG.error(result.getDescription())
DEFAULT_RM_ACL_ENABLE=false
Status.constructStatuses(get(getBaseURL() + "statuses/user_timeline.json",true))
mMethod.invoke(MenuInflater.this,params)
cache.remove(key,null)
runPartialSorter(sorter,NUM_RECORDS,28)
this.traceHandlers.add(traceHandler)
value.doubleValue()
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class RingbufferBasicDistributedTest extends RingbufferBasicTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(2).newInstances(config);   } } 
new GdxRuntimeException("Error during Vorbis decoding.")
ImmutableList.of(qmark,bang)
this.cli.jar("secure.groovy")
type == VertexDataType.VertexBufferObject
alpha=1
format("RowBlock{SingleRowBlockWriter=%d, fieldBlockBuilderReturned=true}")
itemActionLayout >= 0
/**   */ class SctpClientPipelineSink extends AbstractScptChannelSink {   static final InternalLogger logger=InternalLoggerFactory.getInstance(SctpClientPipelineSink.class);   final Executor bossExecutor;   private final Boss boss=new Boss();   private final SctpWorker[] workers;   private final AtomicInteger workerIndex=new AtomicInteger();   SctpClientPipelineSink(  Executor bossExecutor,  Executor workerExecutor,  int workerCount){     this.bossExecutor=bossExecutor;     workers=new SctpWorker[workerCount];     for (int i=0; i < workers.length; i++) {       workers[i]=new SctpWorker(workerExecutor);     }   }   @Override public void eventSunk(  ChannelPipeline pipeline,  ChannelEvent e) throws Exception {     if (e instanceof ChannelStateEvent) {       ChannelStateEvent event=(ChannelStateEvent)e;       SctpClientChannel channel=(SctpClientChannel)event.getChannel();       ChannelFuture future=event.getFuture();       ChannelState state=event.getState();       Object value=event.getValue(); switch (state) { case OPEN:         if (Boolean.FALSE.equals(value)) {           channel.worker.close(channel,future);         }       break; case BOUND:     if (value != null) {       bind(channel,future,(SocketAddress)value);     }  else {       channel.worker.close(channel,future);     }   break; case CONNECTED: if (value != null) {   connect(channel,future,(SocketAddress)value); }  else {   channel.worker.close(channel,future); } break; case INTEREST_OPS: if (event instanceof SctpBindAddressEvent) { SctpBindAddressEvent bindAddressEvent=(SctpBindAddressEvent)event; bindAddress(channel,bindAddressEvent.getFuture(),bindAddressEvent.getValue()); }  else if (event instanceof SctpUnbindAddressEvent) { SctpUnbindAddressEvent unbindAddressEvent=(SctpUnbindAddressEvent)event; unbindAddress(channel,unbindAddressEvent.getFuture(),unbindAddressEvent.getValue()); }  else { channel.worker.setInterestOps(channel,future,((Integer)value).intValue()); } break; } }  else if (e instanceof MessageEvent) { MessageEvent event=(MessageEvent)e; SctpChannelImpl channel=(SctpChannelImpl)event.getChannel(); boolean offered=channel.writeBuffer.offer(event); assert offered; channel.worker.writeFromUserCode(channel); } } private void bind(SctpClientChannel channel,ChannelFuture future,SocketAddress localAddress){ try { channel.channel.bind(localAddress); channel.boundManually=true; channel.setBound(); future.setSuccess(); fireChannelBound(channel,channel.getLocalAddress()); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void bindAddress(SctpClientChannel channel,ChannelFuture future,InetAddress localAddress){ try { channel.channel.bindAddress(localAddress); future.setSuccess(); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void unbindAddress(SctpClientChannel channel,ChannelFuture future,InetAddress localAddress){ try { channel.channel.unbindAddress(localAddress); future.setSuccess(); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void connect(final SctpClientChannel channel,final ChannelFuture cf,SocketAddress remoteAddress){ try { if (channel.channel.connect(remoteAddress)) { channel.worker.register(channel,cf); }  else { channel.getCloseFuture().addListener(new ChannelFutureListener(){ @Override public void operationComplete(ChannelFuture f) throws Exception { if (!cf.isDone()) { cf.setFailure(new ClosedChannelException()); } } } ); cf.addListener(ChannelFutureListener.CLOSE_ON_FAILURE); channel.connectFuture=cf; boss.register(channel); } }  catch (Throwable t) { cf.setFailure(t); fireExceptionCaught(channel,t); channel.worker.close(channel,succeededFuture(channel)); } } SctpWorker nextWorker(){ return workers[Math.abs(workerIndex.getAndIncrement() % workers.length)]; } private final class Boss implements Runnable { volatile Selector selector; private boolean started; private final AtomicBoolean wakenUp=new AtomicBoolean(); private final Object startStopLock=new Object(); private final Queue<Runnable> registerTaskQueue=QueueFactory.createQueue(Runnable.class); Boss(){ super(); } void register(SctpClientChannel channel){ Runnable registerTask=new RegisterTask(this,channel); Selector selector; synchronized (startStopLock) { if (!started) { try { this.selector=selector=Selector.open(); }  catch (Throwable t) { throw new ChannelException("Failed to create a selector.",t); } boolean success=false; try { DeadLockProofWorker.start(bossExecutor,this); success=true; }   finally { if (!success) { try { selector.close(); }  catch (Throwable t) { logger.warn("Failed to close a selector.",t); } this.selector=selector=null; } } }  else { selector=this.selector; } assert selector != null && selector.isOpen(); started=true; boolean offered=registerTaskQueue.offer(registerTask); assert offered; } if (wakenUp.compareAndSet(false,true)) { selector.wakeup(); } } @Override public void run(){ boolean shutdown=false; Selector selector=this.selector; long lastConnectTimeoutCheckTimeNanos=System.nanoTime(); for (; ; ) { wakenUp.set(false); try { int selectedKeyCount=selector.select(500); if (wakenUp.get()) { selector.wakeup(); } processRegisterTaskQueue(); if (selectedKeyCount > 0) { processSelectedKeys(selector.selectedKeys()); } long currentTimeNanos=System.nanoTime(); if (currentTimeNanos - lastConnectTimeoutCheckTimeNanos >= 500 * 1000000L) { lastConnectTimeoutCheckTimeNanos=currentTimeNanos; processConnectTimeout(selector.keys(),currentTimeNanos); } if (selector.keys().isEmpty()) { if (shutdown || bossExecutor instanceof ExecutorService && ((ExecutorService)bossExecutor).isShutdown()) { synchronized (startStopLock) { if (registerTaskQueue.isEmpty() && selector.keys().isEmpty()) {   started=false;   try {     selector.close();   }  catch (  IOException e) {     if (logger.isWarnEnabled()) {       logger.warn("Failed to close a selector.",e);     }   }  finally {     this.selector=null;   }   break; }  else {   shutdown=false; } } }  else { shutdown=true; } }  else { shutdown=false; } }  catch (Throwable t) { if (logger.isWarnEnabled()) { logger.warn("Unexpected exception in the selector loop.",t); } try { Thread.sleep(1000); }  catch (InterruptedException e) { } } } } private void processRegisterTaskQueue(){ for (; ; ) { final Runnable task=registerTaskQueue.poll(); if (task == null) { break; } task.run(); } } private void processSelectedKeys(Set<SelectionKey> selectedKeys){ for (Iterator<SelectionKey> i=selectedKeys.iterator(); i.hasNext(); ) { SelectionKey k=i.next(); i.remove(); if (!k.isValid()) { close(k); continue; } if (k.isConnectable()) { connect(k); } } } private void processConnectTimeout(Set<SelectionKey> keys,long currentTimeNanos){ ConnectException cause=null; for (SelectionKey k : keys) { if (!k.isValid()) { continue; } SctpClientChannel ch=(SctpClientChannel)k.attachment(); if (ch.connectDeadlineNanos > 0 && currentTimeNanos >= ch.connectDeadlineNanos) { if (cause == null) { cause=new ConnectException("connection timed out"); } ch.connectFuture.setFailure(cause); fireExceptionCaught(ch,cause); ch.worker.close(ch,succeededFuture(ch)); } } } private void connect(SelectionKey k){ SctpClientChannel ch=(SctpClientChannel)k.attachment(); try { if (ch.channel.finishConnect()) { k.cancel(); ch.worker.register(ch,ch.connectFuture); } }  catch (Throwable t) { ch.connectFuture.setFailure(t); fireExceptionCaught(ch,t); k.cancel(); ch.worker.close(ch,succeededFuture(ch)); } } private void close(SelectionKey k){ SctpClientChannel ch=(SctpClientChannel)k.attachment(); ch.worker.close(ch,succeededFuture(ch)); } } private static final class RegisterTask implements Runnable { private final Boss boss; private final SctpClientChannel channel; RegisterTask(Boss boss,SctpClientChannel channel){ this.boss=boss; this.channel=channel; } @Override public void run(){ try { channel.channel.register(boss.selector,SelectionKey.OP_CONNECT,channel); }  catch (ClosedChannelException e) { channel.worker.close(channel,succeededFuture(channel)); } int connectTimeout=channel.getConfig().getConnectTimeoutMillis(); if (connectTimeout > 0) { channel.connectDeadlineNanos=System.nanoTime() + connectTimeout * 1000000L; } } } } 
Color.fromRGB(0x253192)
final PkgControl root=ImportControlLoader.load(new File(getPath("import-control_complete.xml")).toURI()); 
DirectMessage.constructDirectMessages(get(getBaseURL() + "direct_messages.json",null,paging.asPostParameterList(),true))
new S3DataSegmentMover(mockS3Client)
webSocketProcessorName.equalsIgnoreCase(WebSocketProcessor.class.getName())
fail()
level <= RF_STATUS_FULL_SIGNAL
new GatherGettersAndSetterProperties(compiler)
context.reloadRequired()
form instanceof IObj && ((IObj)form).meta() != null
GL20.glUniform1(location,v)
List<Object>
operation.get(ROLLBACK_ON_RUNTIME_FAILURE)
attribute.split("\\.")
new GdxRuntimeException("Failure reading Vorbis.")
Validate.configurationDirectoryExists(javaHome,"controllerJavaHome must exist at " + controllerJavaHome)
RawUDPInput.class
Bukkit.getOfflinePlayers()
timeout=3000
resetTimeInSeconds * 1000
configure(COMPONENT)
registry.put("groovyShellFactory",groovyShellFactory)
messageHandler.serverResponder()
new ArrayList<Data>()
mock.expectedBodiesReceived("Hello World")
mTfs.delete(mTfs.open(new TachyonURI(dirPath)))
bagEntry != null & bagEntry.state().compareAndSet(STATE_NOT_IN_USE,STATE_IN_USE)
id=15859
lastUpdateTime2 > lastUpdateTime
target != null
config.getIdleConnectionTimeoutInMs()
logger.info("Return Object {} now at size {}",b,count.getAndDecrement())
matcher.groupCount() > 0
CreateFileOptions.defaults().setBlockSizeBytes(Constants.KB).setRecursive(true).setTtl(1)
NUMBER_OF_IDS_PER_THREAD=400001
in.readObject()
conf.getInt(Constants.TFS_PERMISSIONS_UMASK_KEY,Constants.DEFAULT_TFS_PERMISSIONS_UMASK)
absEdge.getTarget()
new DescribeInstances(awsConfig).execute(endpoint)
new ModelNode().set(1L)
fields.put(PERMISSIONS,permissions)
Assert.assertEquals(e.getCause().getMessage(),getNotAllowedExceptionMessage("helloForNone"))
expiresOn.getTime()
new byte[9]
MAX_CACHED_HBASE_INSTANCES=31
MD5Loader.loadModel(Gdx.files.internal("data/zfat.md5mesh").read())
layout.createSequentialGroup().addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.RELATED).addComponent(availableStrategiesComboBox,0,232,Short.MAX_VALUE)
buffer.nextOneRow(changeColumns)
Assert.assertEquals(2,json.size())
setTimeToLiveSeconds(Long.valueOf((String)cacheSettings.get("diskExpiryThreadIntervalSeconds")).longValue())
r.getRequest()
read(buffer)
Preconditions.checkNotNull(hostname)
mUfs.create(testFile)
i=4
Executors.newCachedThreadPool(new ThreadFactory(){   private AtomicInteger count=new AtomicInteger();   @Override public Thread newThread(  final Runnable runnable){     return new Thread(runnable,"Atmosphere-BroadcasterConfig-" + count.getAndIncrement());   } } )
logger.info("Recording function information")
group == null
getMockEndpoint("mock:event").expectedMessageCount(5)
waitUntil(() -> pongsReceived.get() == NODE_COUNT * NODE_COUNT * ADDRESSES_COUNT,30_000)
new ConsoleRenderer(context,"start.ftl")
id=15842
robotstxtServer.allows(webURL)
id=15860
DeploymentDescription.getDeployDeploymentOperation(locale)
waitForJobExecutorToProcessAllJobsAndExecutableTimerJobs(10000,200)
converter.convertTo(rightValue.getClass(),leftValue)
connection.pexpire(key,millisecondsTimestamp)
JavaConversions.asIterable(logManager.allLogs())
new UnsupportedOperationException("Command not found in spout message: " + shellMsg)
graphModel.getDirectedGraph()
ufsPath.getPath()
endFunction("get_column_statistics_by_table: ",statsObj != null)
newName.putProp(Node.ORIGINALNAME_PROP,rhsValue)
i < 20
new LinkedHashMap<String,JdbcSqlStat>(maxSize,0.75f,true)
minZ != 0f && maxZ != 0f
Thread.sleep(200)
verify(collector)
new SemanticException(generateErrorMessage(tabref,"Schema of both sides of union should match: field " + field + ":"+ " appears on the left side of the UNION at column position: "+ getPositionFromInternalName(lInfo.getInternalName())+ ", and on the right side of the UNION at column position: "+ getPositionFromInternalName(rInfo.getInternalName())+ ". Column positions should match for a UNION"))
WildcardType maybeWildcardType
relationship(18,c,"KNOWS",d)
LOG.info("Finding all components using class resolver: {} -> {}",new Object[]{resolver})
ctx.write("Your session is protected by " + ctx.pipeline().get(SslHandler.class).engine().getSession().getCipherSuite() + " cipher suite.\n")
expiresOn == null
x instanceof ISeq
HttpTransport.class
SimpleAttributeDefinitionBuilder.create("max-backup-index",ModelType.INT)
new EnumValidator<Mode>(Mode.class,true,false)
waitForJobExecutorToProcessAllJobs(3000,500)
Newer
private final String mHostNameKey; 
case READ_UNCOMMITED: 
JSError.make(declNode,TypeCheck.CONFLICTING_SHAPE_TYPE,className,"dict","dict")
routes.InputsResource()
c.getName()
return EOF_BLOCK_ID; 
body[0][0][0]
preloadQueue.size == 0
version == null
KBP_MINIMUM_SCORE=.445
events == null
WebAppResource.class
cache.put(new Element(key,element),true)
ar.cause()
containedToken.get(TokenizerBenchmarkTestCase.MWTTokenCharacterOffsetBeginAnnotation.class)
new RagManager(tm)
Arrays.asList("spring-boot-starter-jetty-","jetty-continuation","jetty-util-","javax.servlet-","jetty-io-","jetty-http-","jetty-server-","jetty-security-","jetty-servlet-","jetty-servlets","jetty-webapp-","websocket-api","javax.annotation-api","jetty-plus","javax-websocket-server-impl-","asm-","javax.websocket-api-","asm-tree-","asm-commons-","websocket-common-","jetty-annotations-","javax-websocket-client-impl-","websocket-client-","websocket-server-","jetty-jndi-","jetty-xml-","websocket-servlet-")
id=45
collection(StreamImpl.class).update(match,modify)
colorModeClass.equals("ProportionalSizeMode")
this.assignmentManager.isRegionInTransition(regionInfo) == null
3 < buf.length - count
distinctValues.put(distinct,distinct)
BOLD
original.getScreenName().endsWith("new")
Math.min(1000L,connectionTimeout)
"source".equals(key) || "target".equals(key) || "value".equals(key)|| "label".equals(key)
response.getStatus().getCode() / 200
IOUtils.toString(stencilsetStream)
JmxReporter.class
new Exception("File " + file.getPath() + " should not exist")
getPath(tFile).startsWith(MASTER_CONF.TEMPORARY_FOLDER)
input.size()
exported
FileUtil.compactPath(path)
Assert.assertEquals(masterAddress,new InetSocketAddress("RemoteMaster1",10000))
qp.getExclusiveMaximum()
checkArgument(!"/".equals(resourcePath),"%s is the classpath root")
new RequestManager(testTimer,300)
assertThat(context).getBeans(HandlerMapping.class).hasSize(7)
rackIdToNodes.get(rid)
MoreObjects.toStringHelper(this).add("user",getUser()).add("timeZoneKey",timeZoneKey).add("locale",locale).add("startTime",startTime).add("properties",properties)
new BadRequestException()
yz*=ly
logger.warn("NODE {}: BATTERY LOW!",this.getNode().getNodeId())
LOG.warn(e.getMessage())
ImmutableSortedSet.of("a","abbr","acronym","address","area","b","bdo","big","blockquote","br","caption","cite","code","colgroup","dd","del","div","dfn","dl","dt","em","fieldset","font","h1","h2","h3","h4","h5","h6","hr","i","img","ins","kbd","li","ol","p","pre","q","samp","small","span","strong","style","sub","sup","table","tbody","td","tfoot","th","thead","tr","tt","u","ul")
assertEquals(actualTables,expectedTables)
Character.isSpaceChar(origText.charAt(i))
DEFAULT_ALLOW_SPILLING=false
ReflectiveOperationException e
type != REPARTITION
String.valueOf(0.02)
soLingerTime.toSeconds()
96.0 / 160
assertNotNull(savepointPath,"Failed to trigger savepoint")
testSame("var foo = function (a) {}; foo.call(this, 1);","var foo = function () {var a$jscomp$1 = 1;}; foo.call(this);")
decodeAttribute(nameAttribute.getValue(),charset)
id=15866
bindings.get()
(Source)src
delta < 9000
CamelCloudServiceCallConfiguration.class
(byte)0xdf
runOTIafterNTI=false
promise.setFailure(cause)
DruidDataSourceUtils.isRemoveAbandoned(datasource)
manualClock.addTimeMs(1020)
(short)0755
log.info("Performing lookup: %s --> %s",ips,retVal)
JSError.make(AbstractCompiler.READ_ERROR,getName())
message + END
sections.remove(section)
assertEquals(expectedPlan,actualPlan)
Thread.sleep(200)
m.isCacheValue()
LOG.debug("Retrieving location for state={} of job={} from the cache.",jobId,queryableStateName)
maxSize > (used / 1024 / 1024)
layout.setRefreshingLabel(label)
ctx.writeAndFlush(msg,promise)
sendCommand(CLIENT_SETNAME)
{@link PkgControl}
existing.getState()
assertEquals(q.toString(),"[]")
lc + pb
Long.valueOf(args[2])
id=5
URIStatus::getBlockSizeBytes
isDistinct(child)
lights.shadowMap != null
floatBuffer.clear()
-1
/**   * @see ConceptService#getCountOfConceptReferenceTerms(String,ConceptSource,boolean)  */ public Integer getCountOfConceptReferenceTerms(String query,ConceptSource conceptSource,boolean includeRetired) throws DAOException ; 
logger.warn("Failed to set channel option '{}' with value '{}' for channel '{}'",option,channel,channel,t)
mWorkerId + BASE_FILE_NUMBER
Arrays.asList("Java","CSharp")
-1L
new DynamicAwareEntry("http4://localhost/test",null,null)
DiagnosticType.error("JSC_REDECLARED_VARIABLE","Redeclared variable: {0}")
byteBuf.readable()
m_data.rewind().forward((int)key_offset).getFixString((int)key_length)
final Object firstLineKey=lines.firstKey(); 
getFirstByType(type,withProxy)
this(host,port,threadName,queueSize,timeout,SEND_BUFFER_SIZE,DEFAULT_BUFFER_SIZE); 
assertTrueEventually(new AssertTask(){   @Override public void run(){     getStats(client,clientEngine);   } } ,STATS_PERIOD_SECONDS * 3)
ZWaveSwithcAllCommandClass.class
mViewAbove.setCurrentItem(2,animate)
LOG.info("Syslog message is missing date or date could not be parsed. (Possibly set {} to true) " + "Not further handling. Message was: {}",SyslogInputBase.CK_ALLOW_OVERRIDE_DATE,new String(msg.getRaw()))
Assert.assertEquals(expected,values)
position == buffer.length
entry.getName().startsWith(BOOT_INF_CLASSES)
Assert.assertEquals("Message key '" + retrievedMessage + "' is not valid",retrievedMessage,"unable.open.cause")
r.getUri().toString()
getCompletePredicate()
bodyParts != null
that.getDomain() == null
JSError.make(currentStatement,Es6ToEs3Converter.CANNOT_CONVERT_YET,"Case statements that contain yields")
new MockQueryExecution(1)
buffer.indexOf(partToMatch)
value == 0
this.setAutoCommitOnClose(false)
LOG.debug("Error while deserializing payload",e)
1000 * 5
id=15833
Setting<Long>
new SimpleDateFormat(format)
new LwjglPreferences(name)
getConnectionFactory()
Context.getPersonService().getRelationships(Context.getPersonService().getPerson(personId))
SocketUtils.findAvailableTcpPort(40000)
logger.info("Collapsed " + numRenamedPropertyNames + " properties into "+ numNewPropertyNames+ " and skipped renaming "+ numSkippedPropertyNames+ " properties.")
id=15850
BitSetUtils.class
IOException.class
new UnsafeBasedStringCharProvider(UNSAFE,stringValueFieldOffset,str)
response.set(ROLLED_BACK)
new IntRangeValidator(1,true)
failureDesc.contains("14807") || failureDesc.contains("14883") || failureDesc.contains("13456")
GL20.glUniformMatrix3(location,transpose,value)
@RunWith(HazelcastSerialClassRunner.class) @Category(QuickTest.class) public class UserCodeDeploymentPermissionTest extends AbstractGenericPermissionTest {   @Override protected Permission createPermission(  String name,  String... actions){     return new CardinalityEstimatorPermission(name,actions);   }   @Test public void checkDeployPermission_whenAll(){     new CheckPermission().of("deploy").against("deploy").expect(true).run();   }   @Test public void checkDeployPermission(){     new CheckPermission().of("deploy").against("all").expect(true).run();   }   @Test public void checkAllPermission_whenDeploy(){     new CheckPermission().of("all").against("deploy").expect(false).run();   } } 
ChannelBuffers.copiedBuffer(bytes,0,length)
id=15853
is(4)
promise.setFailure(new ClosedChannelException())
log.warn("Annotation scanning mode loaded {} type converters. Its recommended to migrate to @Converter(loader = true) for fast type converter mode.")
Thread.sleep(10)
assertEquals(1,historyService.createHistoricActivityInstanceQuery().processDefinitionId(processInstance.getProcessDefinitionId()).list().size())
factory.get(sResponseWildcard,NO_ANNOTATIONS,retrofit)
to("direct:foo")
id=29
Color.fromRGB(0xF0F0F0)
Preconditions.checkNotNull(path)
(BeanDefinitionRegistry)context
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class CountDownLatchBasicLocalTest extends CountDownLatchBasicTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(1).newInstances();   } } 
new ClusterConfiguration("clusterName",StringLogger.DEV_NULL,initialHosts)
!calculatePositionAndValue(x,y)
new IllegalArgumentException("Expected a proto but was: " + body.mimeType())
NumberFormatException nfe
attributeMap.put(attributeName,value)
MAX_USER_NAME_LENGTH=20
new IllegalStateException()
tiled != null
columnType.equalsIgnoreCase("string")
ENTER_PORTAL_FRAME(120)
xmlDocAnnotation.get(CoreAnnotations.TokensAnnotation.class).get(554)
assertTrue(jmsTemplate.isPubSubDomain())
obj1.isLoose || obj2.isLoose
legacyModel.isDefined()
TestSuiteEnvironment.getServerAddress()
LOG.info("Creating netty input stream for block {} @ {} from client {}",blockId,address,NetworkAddressUtils.getClientHostName())
@Override protected BlockBuilder getBlock(){   return blockBuilder; } 
@Path(PATH_NODE_INDEX_ID)
mail.getClass().getName()
LOG.info("Date could not be parsed. Was set to NOW because {} is true.",SyslogInputBase.CK_ALLOW_OVERRIDE_DATE)
javaClass.addNestedType().setPublic()
outputFile.lastModified() < grammarFile.lastModified()
Assert.assertEquals(select.size(),1)
(long)y & 0xFFFFFFFL
channelIdle(ctx,IdleState.WRITER_IDLE,lastReadTime)
new ResultPrinter(new PrintStream(output)){   public void printErrors(  TestResult result){     getWriter().println("Errors here");   } } 
new PoolBagEntry(null,pool)
commandLineArguments.isLocal()
collisionPoints.get(2)
id=15807
ProtobufUtil.createSnapshotDesc(reqSnapshot)
(t instanceof MetaException) && t.getMessage().matches("(?s).*(JDO[a-zA-Z]*|TProtocol|TTransport)Exception.*")
UnmodifiableIterable<T>
log.tracef("%s finished request %d",ManagementChannel.this)
filteredData.addAccessRestrictedResource(absoluteChildAddr)
RedisOperations<Object,Object>
graphModel.getGraph().getEdgeCount()
resultEndpoint.expectedMessageCount(2)
final DeletionRetentionStrategy deletionRetentionStrategy=clusterConfigService.get(DeletionRetentionStrategy.class); 
doMethod("GET","/books/" + bookId,null)
items[33]
id=15834
format(conf,true)
new Duration(10,TimeUnit.SECONDS)
compressedProto.length < 340000
newroot.length == 1
@RunWith(HazelcastSerialClassRunner.class) @Category(QuickTest.class) public class ReplicatedMapTest extends ReplicatedMapBaseTest {   @Test public void testEmptyMapIsEmpty() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance=nodeFactory.newHazelcastInstance();     ReplicatedMap<Integer,Integer> map=instance.getReplicatedMap(randomName());     assertTrue("map should be empty",map.isEmpty());   }   @Test public void testNonEmptyMapIsNotEmpty() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance=nodeFactory.newHazelcastInstance();     ReplicatedMap<Integer,Integer> map=instance.getReplicatedMap(randomName());     map.put(1,1);     assertFalse("map should not be empty",map.isEmpty());   }   @Test(expected=IllegalArgumentException.class) public void testNegativeTtlThrowsException() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance=nodeFactory.newHazelcastInstance();     ReplicatedMap<Integer,Integer> map=instance.getReplicatedMap(randomName());     map.put(1,1,-1,TimeUnit.DAYS);   }   @Test public void testAddObject() throws Exception {     testAdd(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testAddBinary() throws Exception {     testAdd(buildConfig(InMemoryFormat.BINARY));   }   private void testAdd(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );   }   @Test public void testPutAllObject() throws Exception {     testPutAll(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testPutAllBinary() throws Exception {     testPutAll(buildConfig(InMemoryFormat.BINARY));   }   private void testPutAll(  Config config) throws TimeoutException {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     final Map<String,String> mapTest=new HashMap<String,String>();     for (    String key : keys) {       mapTest.put(key,"bar");     }     map1.putAll(mapTest);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );   }   @Test public void testClearObject() throws Exception {     testClear(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testClearBinary() throws Exception {     testClear(buildConfig(InMemoryFormat.BINARY));   }   private void testClear(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );     map1.clear();     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(0,map1.size());         assertEquals(0,map2.size());       }     } );   }   @Test public void testAddTtlObject() throws Exception {     testAddTtl(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testAddTtlBinary() throws Exception {     testAddTtl(buildConfig(InMemoryFormat.BINARY));   }   private void testAddTtl(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar",10,TimeUnit.MINUTES);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           ReplicatedRecord<String,String> record=getReplicatedRecord(map1,key);           assertNotNull(record);           assertNotEquals(0,record.getTtlMillis());         }       }     } );     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map2.get(key));           ReplicatedRecord<String,String> record=getReplicatedRecord(map2,key);           assertNotNull(record);           assertNotEquals(0,record.getTtlMillis());         }       }     } );   }   @Test public void testUpdateObject() throws Exception {     testUpdate(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testUpdateBinary() throws Exception {     testUpdate(buildConfig(InMemoryFormat.BINARY));   }   private void testUpdate(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );     for (    String key : keys) {       map2.put(key,"bar2");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar2",map1.get(key));           assertEquals("bar2",map2.get(key));         }       }     } );   }   @Test public void testUpdateTtlObject() throws Exception {     testUpdateTtl(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testUpdateTtlBinary() throws Exception {     testUpdateTtl(buildConfig(InMemoryFormat.BINARY));   }   private void testUpdateTtl(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );     for (    String key : keys) {       map2.put(key,"bar2",10,TimeUnit.MINUTES);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar2",map1.get(key));           ReplicatedRecord<String,String> record=getReplicatedRecord(map1,key);           assertNotNull(record);           assertTrue(record.getTtlMillis() > 0);         }       }     } );     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar2",map2.get(key));           ReplicatedRecord<String,String> record=getReplicatedRecord(map2,key);           assertNotNull(record);           assertTrue(record.getTtlMillis() > 0);         }       }     } );   }   @Test public void testRemoveObject() throws Exception {     testRemove(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testRemoveBinary() throws Exception {     testRemove(buildConfig(InMemoryFormat.BINARY));   }   @Test public void testContainsKey_returnsFalse_onRemovedKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     map.remove(1);     assertFalse(map.containsKey(1));   }   @Test public void testContainsKey_returnsFalse_onNonexistentKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     assertFalse(map.containsKey(1));   }   @Test public void testContainsKey_returnsTrue_onExistingKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     assertTrue(map.containsKey(1));   }   @Test public void testKeySet_notIncludes_removedKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     final ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     map.put(2,Integer.MIN_VALUE);     map.remove(1);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         Set<Integer> keys=new HashSet<Integer>(map.keySet());         assertFalse(keys.contains(1));       }     } ,20);   }   @Test public void testEntrySet_notIncludes_removedKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     final ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     map.put(2,Integer.MIN_VALUE);     map.remove(1);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         Set<Entry<Integer,Integer>> entries=map.entrySet();         for (        Entry<Integer,Integer> entry : entries) {           if (entry.getKey().equals(1)) {             fail(String.format("We do not expect an entry which's key equals to %d in entry set",1));           }         }       }     } ,20);   }   private void testRemove(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );     for (    String key : keys) {       map2.remove(key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertFalse(map1.containsKey(key));           assertFalse(map2.containsKey(key));         }       }     } );   }   @Test public void testSizeObject() throws Exception {     testSize(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testSizeBinary() throws Exception {     testSize(buildConfig(InMemoryFormat.BINARY));   }   private void testSize(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     final SimpleEntry<String,String>[] testValues=buildTestValues(keys);     int half=testValues.length / 2;     for (int i=0; i < testValues.length; i++) {       final ReplicatedMap<String,String> map=i < half ? map1 : map2;       final SimpleEntry<String,String> entry=testValues[i];       map.put(entry.getKey(),entry.getValue());     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(keys.size(),map1.size());         assertEquals(keys.size(),map2.size());       }     } );   }   @Test public void testContainsKeyObject() throws Exception {     testContainsKey(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testContainsKeyBinary() throws Exception {     testContainsKey(buildConfig(InMemoryFormat.BINARY));   }   private void testContainsKey(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertTrue(map1.containsKey(key));           assertTrue(map2.containsKey(key));         }       }     } );   }   @Test public void testContainsValue_returnsFalse_onNonexistentValue() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     assertFalse(map.containsValue(1));   }   @Test public void testContainsValueObject() throws Exception {     testContainsValue(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testContainsValueBinary() throws Exception {     testContainsValue(buildConfig(InMemoryFormat.BINARY));   }   private void testContainsValue(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     int half=keys.size() / 2, i=0;     for (    String key : keys) {       final ReplicatedMap<String,String> map=i++ < half ? map1 : map2;       map.put(key,key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertTrue(map1.containsValue(key));           assertTrue(map2.containsValue(key));         }       }     } );   }   @Test public void testValuesWithComparator() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance=nodeFactory.newHazelcastInstance();     ReplicatedMap<Integer,Integer> map=instance.getReplicatedMap(randomName());     for (int i=0; i < 100; i++) {       map.put(i,i);     }     Collection<Integer> values=map.values(new DescendingComparator());     int v=100;     for (    Integer value : values) {       assertEquals(--v,(int)value);     }   }   @Test public void testValuesObject() throws Exception {     testValues(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testValuesBinary() throws Exception {     testValues(buildConfig(InMemoryFormat.BINARY));   }   private void testValues(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     int half=keys.size() / 2, i=0;     for (    String key : keys) {       final ReplicatedMap<String,String> map=i++ < half ? map1 : map2;       map.put(key,key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(keys,new HashSet<String>(map1.values()));         assertEquals(keys,new HashSet<String>(map2.values()));       }     } );   }   @Test public void testKeySetObject() throws Exception {     testKeySet(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testKeySetBinary() throws Exception {     testKeySet(buildConfig(InMemoryFormat.BINARY));   }   private void testKeySet(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     int half=keys.size() / 2, i=0;     for (    String key : keys) {       final ReplicatedMap<String,String> map=i++ < half ? map1 : map2;       map.put(key,key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(keys,new HashSet<String>(map1.keySet()));         assertEquals(keys,new HashSet<String>(map2.keySet()));       }     } );   }   @Test public void testEntrySetObject() throws Exception {     testEntrySet(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testEntrySetBinary() throws Exception {     testEntrySet(buildConfig(InMemoryFormat.BINARY));   }   private void testEntrySet(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     int half=keys.size() / 2, i=0;     for (    String key : keys) {       final ReplicatedMap<String,String> map=i++ < half ? map1 : map2;       map.put(key,key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         List<Entry<String,String>> entrySet1=new ArrayList<Entry<String,String>>(map1.entrySet());         List<Entry<String,String>> entrySet2=new ArrayList<Entry<String,String>>(map2.entrySet());         assertEquals(keys.size(),entrySet1.size());         assertEquals(keys.size(),entrySet2.size());         for (        Entry<String,String> e : entrySet1) {           assertTrue(keys.contains(e.getKey()));         }         for (        Entry<String,String> e : entrySet2) {           assertTrue(keys.contains(e.getKey()));         }       }     } );   }   @Test public void testAddListenerObject() throws Exception {     testAddEntryListener(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testAddListenerBinary() throws Exception {     testAddEntryListener(buildConfig(InMemoryFormat.BINARY));   }   private void testAddEntryListener(  Config config) throws TimeoutException {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     SimpleEntryListener listener=new SimpleEntryListener(1,0);     map2.addEntryListener(listener,keys.iterator().next());     for (    String key : keys) {       map1.put(key,"bar");     }     assertOpenEventually(listener.addLatch);   }   @Test public void testEvictionObject() throws Exception {     testEviction(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testEvictionBinary() throws Exception {     testEviction(buildConfig(InMemoryFormat.BINARY));   }   private void testEviction(  Config config) throws TimeoutException {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     SimpleEntryListener listener=new SimpleEntryListener(0,100);     map2.addEntryListener(listener);     SimpleEntryListener listenerKey=new SimpleEntryListener(0,1);     map1.addEntryListener(listenerKey,keys.iterator().next());     for (    String key : keys) {       map1.put(key,"bar",3,TimeUnit.SECONDS);     }     assertOpenEventually(listener.evictLatch);     assertOpenEventually(listenerKey.evictLatch);   } private class SimpleEntryListener extends EntryAdapter<String,String> {     CountDownLatch addLatch;     CountDownLatch evictLatch;     SimpleEntryListener(    int addCount,    int evictCount){       addLatch=new CountDownLatch(addCount);       evictLatch=new CountDownLatch(evictCount);     }     @Override public void entryAdded(    EntryEvent event){       addLatch.countDown();     }     @Override public void entryEvicted(    EntryEvent event){       evictLatch.countDown();     }   }   @Test(expected=IllegalArgumentException.class) public void putNullKey() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap("default");     map1.put(null,1);   }   @Test(expected=IllegalArgumentException.class) public void removeNullKey() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap("default");     map1.remove(null);   }   @Test public void removeEmptyListener() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap("default");     assertFalse(map1.removeEntryListener("2"));   }   @Test(expected=IllegalArgumentException.class) public void removeNullListener() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap("default");     map1.removeEntryListener(null);   }   @Test public void testSizeAfterRemove() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     map.remove(1);     assertTrue(map.size() == 0);   }   @Test public void testDestroy() throws Exception {     HazelcastInstance instance=createHazelcastInstance();     ReplicatedMap<Object,Object> replicatedMap=instance.getReplicatedMap(randomName());     replicatedMap.put(1,1);     replicatedMap.destroy();     Collection<DistributedObject> objects=instance.getDistributedObjects();     assertEquals(0,objects.size());   } class DescendingComparator implements Comparator<Integer> {     @Override public int compare(    Integer o1,    Integer o2){       return o1 == o2 ? 0 : o1 > o2 ? -1 : 1;     }   } } 
Double.isNaN(rate)
AnnotatedElementUtils.isAnnotated(type,Validated.class)
nodeString()
initial(rand)
String[]
request.getTaskDefinitionKey()
new RuntimeException(e)
xAmount > 0
Pattern.compile("(--?[a-zA-Z_]+)=(.*)")
notifier.getConfiguration().setPort(25667)
Ints.min(startedSplits.get(),completedSplits.get(),splits)
toJSON(item)
test(externs,js,(String)null,ConstCheck.CONST_REASSIGNED_VALUE_ERROR,null)
prevNerEndIndex != (start - 1) || nextNerStartIndex != end
new RetryDriver(maxRetryAttempts,minSleepTime,maxSleepTime,scaleFactor,maxRetryTime,exceptionWhiteList)
ret == null
!clusterVersion.onOrAfter(MINIMUM_ES_VERSION) && !clusterVersion.onOrBefore(MAXIMUM_ES_VERSION)
report(SHIFT_AMOUNT_OUT_OF_BOUNDS,right)
bar.setResultWaitTime(1000)
Iterable<ManyValues>
ClusterLeaveReelectionListener.class
log.warn(e,"Graceful shutdown of task[%s] aborted with exception.")
(Long)strategy.getOrNull("test",third)
dbCollection.save(clusterEvent)
MAX_LENGTH=100
FSImageFormatProtobuf.class
socket == null
LOG.warn("Failed to write into TachyonStorage, the block " + getCurrentBlockId() + " will not be in TachyonStorage",ioe)
instance2.getLifecycleService().terminate()
if (mCheckUnusedThrows) {   processImport(aAST); } 
In.valueOf(apiKeyAuthConfig.in().toValue())
y / vz
LOG.info("Creating short circuit input stream for block {} @ {}",blockId,address)
SecurityActions.getModuleClassLoader(JACC_MODULE)
id=14
generator.generateX509Certificate(signedByKeyPair.getPrivate())
mFixedExecutionService.shutdown()
new PeepholeSubstituteAlternateSyntax(false)
s.count()
new ModelNode().set(1)
jarName.endsWith(".jar")
id=11
webSocket.isOpen()
CompletableFuture<Boolean>
potentialResponse == null
token.substring(0,p).trim().toLowerCase()
ArrayNodeBaseTest<LazyTailArrayNode>
proxy == null
log.error(error,cause)
spanEvent.getNextSpanId() == -1
DIODE(100)
1 < user.getListedCount()
s != null
getPath("InputPackageDeclarationDiffDirectoryAtSubpackage.java")
DirectMessage.constructDirectMessages(get(getBaseURL() + "direct_messages/sent.json",new PostParameter[0],paging.asPostParameterList(),true))
PROTOCOL_VERSION=1
attributeModel != null
request.getTaskDefinitionKey()
i < maxIndex
List<PersistentLocalScope>
BlockingQueue<BodyChunk>
public static XQueryBuilder xquery(File file,String characterSet) throws FileNotFoundException {   return xquery(IOConverter.toInputStream(file),characterSet); } 
addKeys(externalClasses,DATE_TIME,"org.joda.time.DateTime","org.joda.time.ReadableDateTime","javax.xml.datatype.XMLGregorianCalendar")
assertEquals(mock.getExchanges().get(0).getIn().getBody(String.class),"val-1")
docData.charAt(0) == 65279
attribute.getDefinition().getAttributeMarshaller()
cSet.getConcept()
map.set(key,"value",1,TimeUnit.SECONDS)
graphStack.push(tx)
Assert.assertEquals(20,Context.getAdministrationService().getAllGlobalProperties().size())
getCode().split("\n")
typeSerializer.getClass()
new LocalTachyonClusterResource(Constants.GB,Constants.KB,BLOCK_SIZE,Constants.KEY_VALUE_ENABLED,"true",Constants.KEY_VALUE_PARTITION_SIZE_BYTES_MAX,Integer.toString(KEY_VALUE_PARTITION_SIZE))
Assert.assertEquals(masterAddress,new InetSocketAddress(defaultHostname,20000))
new JedisClusterCommand<Long>(connectionHandler,timeout,maxRedirections){   @Override public Long execute(  Jedis connection){     return connection.persist(key);   } } 
assertEquals(2,historyService.createHistoricActivityInstanceQuery().processInstanceId(processInstance.getId()).count())
new ConnectorTableLayout(handle)
new PkgControl(stack.peek(),name,regex)
new NodeHistogram(application,range)
ArrayList<EntryListener<?,?>>
bar.expectedMinimumMessageCount(1)
nodeId.equals(message.getToNode())
mock(ExampleService.class,MockReset.before())
r.locals.ast=returns
GatherGettersAndSetterProperties.update(compiler,externsRoot,mainRoot)
LOG.info("Creating netty output stream for block {} @ {} from client {}",blockId,address,NetworkAddressUtils.getClientHostName())
arguments == null
new RefProperty(existing)
wrapRequest
new RuntimeException("Could not create TypeInformation for type " + data[0].getClass().getName() + "; please specify the TypeInformation manually via "+ "ExecutionEnvironment#fromElements(Collection, TypeInformation)")
Utils.deserialize(_boltSer,IBatchBolt.class)
DEFAULT_SHUFFLE_PORT=11000
registry.put("myManager",cacheManager)
List<SuggestedFix>
entry.getOriginalUri()
HiveConf.setLongVar(conf,HiveConf.ConfVars.MAPREDMINSPLITSIZE,preferredSplitSize)
new ClosedByInterruptException("Interrupted while reading.")
endpoint.getBus().getInInterceptors().size() == 1
this.applicationContext.register(RootConfig.class,PropertyPlaceholderAutoConfiguration.class,ManagementServerPropertiesAutoConfiguration.class,ServerPropertiesAutoConfiguration.class,EmbeddedServletContainerAutoConfiguration.class,DispatcherServletAutoConfiguration.class,WebMvcAutoConfiguration.class,EndpointWebMvcAutoConfiguration.class)
new CacheCreateConfigOperation(cacheConfig,create,false)
GL11.glGetInteger(pname,params)
error("Unable to connect due to unrecognised server certificate")
ExceptionInInitializerError|ClassNotFoundException
testSame("var foo = function (a) {}; foo.call(null, 1);","var foo = function () {var a$jscomp$1 = 1;}; foo.call(null);")
max=20
SimpleAttributeDefinitionBuilder.create("new-level",ModelType.STRING)
cs.getString(columnIndex)
id=15854
Collection<Data>
new HazelcastProperty("hazelcast.invalidation.reconciliation.interval.seconds",1,SECONDS)
DATABASE_TYPE_MYSQL.equals(databaseType)
new InMemoryMessageRespository()
config.getBroadcasterFactory().lookup(a.broadcaster(),true)
timeout=120000
beansXml.createAlternatives()
Entry<Url,Channel>
Assert.assertTrue("Was not expecting this output " + acc,System.currentTimeMillis() - now < 5000)
String.format("NODE %d: Already in or beyond node stage, ignoring. current = %s, requested = %s",this.node.getNodeStage().getLabel(),targetStage.getLabel())
ResponseImpl description(String description); 
minor < 5
isHandshaking(clientResult) && isHandshaking(serverResult)
NETHER_WATER(115)
QUEUE_TRANSACTION_LOG_RECORD=43
new HazelcastProperty("hazelcast.invalidation.min.reconciliation.interval.seconds",1,SECONDS)
ExceptionUtils.firstOrSuppressed(collectedExceptions,e)
cppFile.writeString(buffer.toString(),false)
StringUtils.subString(url,"weburi-",".json")
Assert.assertEquals(workerAddress,new InetSocketAddress(defaultHostname,defaultPort))
getDatabaseSchema() != null
DiagnosticType.warning("JSC_BAD_PRIVATE_GLOBAL_ACCESS","Access to private variable {0} not allowed outside file {1}.")
f.cancel(true)
capacity > 1 << 30
patientExitObs != null
new PrestoException(HIVE_FILESYSTEM_ERROR,e)
basicGraph.getShortestPath(root,t,true)
message.contains("14807") || message.contains("14883")
public IMetric registerMetric(String name,ICombiner combiner,int timeBucketSizeInSecs){   return _topoContext.registerMetric(name,new CombinedMetric(combiner),timeBucketSizeInSecs); } 
ps.createRelationship(rel)
Attribute attribute=(Attribute)o; 
builder(SingleSignOnDefinition.INSTANCE).addAttributes(SingleSignOnDefinition.DOMAIN,SingleSignOnDefinition.PATH,SingleSignOnDefinition.HTTP_ONLY,SingleSignOnDefinition.SECURE)
Map.class
assertOpenEventually(countDownLatch,50)
id=15846
toShortUnsafe(bytes,0)
HIVE_PARTITION_OFFLINE(6,EXTERNAL)
mapJoinTables != null
remoteAddressAliases != null
public DerivedBuilder setRealmScheme(Realm.AuthScheme scheme){   realm().setScheme(scheme);   return this; } 
combine(getDefaultCamelKarafOptions(),provision(TinyBundles.bundle().add("META-INF/persistence.xml",BlobStoreBlueprintRouteTest.class.getResource("/META-INF/persistence.xml")).add("OSGI-INF/blueprint/test.xml",BlobStoreBlueprintRouteTest.class.getResource("blueprintCamelContext.xml")).set(Constants.BUNDLE_SYMBOLICNAME,"CamelBlueprintJcloudsTestBundle").set(Constants.DYNAMICIMPORT_PACKAGE,"*").set("Meta-Persistence","META-INF/persistence.xml").build()),bundle(TinyBundles.bundle().add("OSGI-INF/blueprint/test.xml",BlobStoreBlueprintRouteTest.class.getResource("blueprintBlobStoreService.xml")).set(Constants.BUNDLE_SYMBOLICNAME,"org.apache.camel.jclouds.blobstore.service").set(Constants.BUNDLE_VERSION,"1.0.0").set(Constants.DYNAMICIMPORT_PACKAGE,"*").build()).start(),loadCamelFeatures("camel-blueprint","camel-jclouds"),workingDirectory("target/paxrunner/"),felix())
SSEAtmosphereInterceptor.class
items[23]
encoding=options.get(ELEMENT_NAME)
endTrack("main")
document.tokens().get(10)
mTfs.delete(mTfs.open(path))
type.createDataFormat(routeContext)
this.vertices.containsKey(node) || this.chainedTasks.containsKey(node)
trimmedLine.endsWith(delimiter)
computeSemiJoin(inputStatistics,inputStatistics,unknown,u)
reg.put("localhost:" + port,env)
LOG.warn("calculatedMaxSteps:{} for loadbalancer's stochastic walk is larger than " + "maxSteps:{}. Hence load balancing may not work well. Setting parameter " + "\"hbase.master.balancer.stochastic.runMaxSteps\" to true can overcome this issue."+ "(This config change does not require service restart)",calculatedMaxSteps,maxRunningTime)
UnderFileSystem.get(tmpFolder)
bits2[1] == false
1 / 5
@Override public Cell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   if (clonedBaseCell instanceof ByteBufferCell) {     return new ValueAndTagRewriteByteBufferCell((ByteBufferCell)clonedBaseCell,this.value,this.tags);   }   return new ValueAndTagRewriteCell(clonedBaseCell,this.value,this.tags); } 
totalTime / curTime == curOps
"Invalid modules directory: " + modulesDir
result.addEnchantment(enchantment,(Integer)entry.getValue())
Long.valueOf(args[1])
addProperty(firstNode,"band","The Clash")
Integer.class
isDirect=false
Parameter.forConstructor(errorHandler,fastConstructor)
return r; 
new AnnotationNode()
getSSLContext().getSocketFactory().createSocket()
len > bits.length
size() >= this.capacity
serverEnvironment == null
sb.toString()
bundleContext.getBundle().getEntry(uri)
Throwable e
-1
WebSocketEventListener.class.cast(l).onMessage(event)
endpoint.setDataSource(ds)
"Using bind address: " + publicAddress
getGlobalProperty(OpenmrsConstants.GLOBAL_PROPERTY_LOCALE_ALLOWED_LIST)
LOG.warn("clear parameter error",ex)
args.length == 3
primitiveToWrappers.put(wrapperType,primitiveType)
new StringInputRowParser(dataSpec == null ? null : dataSpec.toParseSpec(timestampSpec,dimensionExclusions),null,null,null)
Vector<>
KeyValueStoreTest.class
assertEquals(mock.getExchanges().get(1).getIn().getHeader(ChronicleEngineConstants.MAP_EVENT_TYPE),ChronicleEngineMapEventType.REMOVE)
buffer.append(KEY_NODE_ID + "=").append(id)
1000 * 1
/**   * Retrieves X.  * @return a value  */ public T getX(){   return null; } 
status.getCreationTimeMs()
config.getInputShipStrategy(0)
SchematronProcessorFactory.newScehamtronEngine(endpoint.getRules())
BufferUtils.freeMemory(bytebuffer)
Foundation.NSLog("[info] " + tag + ": "+ message)
BlockingIOCometSupport.class
mTfs.mkdirs(path)
return false; 
constructor.getTypeParameters()
Assert.assertEquals(e.getCause().getMessage(),getNotAllowedExceptionMessage("helloForRole"))
this.connectTo(vertex,channelType,compressionLevel,-1,-1,DistributionPattern.BIPARTITE,false)
deployments.get(uniqueName)
/**   * <code>CONCAT_AGG</code> aggregate function.  */ public static final SqlConcatAggFunction CONCAT_AGG=new SqlConcatAggFunction(); 
binder.bindConstant().annotatedWith(Names.named("tlsServicePort")).to(8091)
@Override public Object getValue(){   return getThreadCount(state); } 
Iterable<TypedVar>
new StringInputRowParser(new JSONParseSpec(new TimestampSpec("timestamp","auto"),new DimensionsSpec(Arrays.asList("dim1","dim2"),null,null)),null,null,null)
future.get(30,TimeUnit.SECONDS)
assertThat(child.getBeansOfType(ExampleBean.class)).hasSize(1)
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
additionalProperties.remove(DATE_FORMAT)
headerHandled=false
Color.fromRGB(0xD88198)
model.getEnum().size() == 2
getSrcPath("checks/javadoc/Input_03.java")
mSizeOnTier.containsKey(tierAlias) ? mSizeOnTier.get(tierAlias) : 0
mFileLength - mPos < mBlockSize
new AMQPProducer(configuration,metricRegistry)
reg.getCounters(transformFilter(filter))
tx == null
new GZIPOutputStream(outputStream,true)
war.addAsWebInfResource(ClusteredWebTestCase.class.getPackage(),"web.xml")
"A task is in the ABORTED state but stage is " + stageState
raw.getParameters()
{189084,192250.913,195456.774,198696.946,201977.762,205294.444,208651.754,212042.099,215472.269,218941.91,222443.912,225996.845,229568.199,233193.568,236844.457,240543.233,244279.475,248044.27,251854.588,255693.2,259583.619,263494.621,267445.385,271454.061,275468.769,279549.456,283646.446,287788.198,291966.099,296181.164,300431.469,304718.618,309024.004,313393.508,317760.803,322209.731,326675.061,331160.627,335654.47,340241.442,344841.833,349467.132,354130.629,358819.432,363574.626,368296.587,373118.482,377914.93,382782.301,387680.669,392601.981,397544.323,402529.115,407546.018,412593.658,417638.657,422762.865,427886.169,433017.167,438213.273,443441.254,448692.421,453937.533,459239.049,464529.569,469910.083,475274.03,480684.473,486070.26,491515.237,496995.651,502476.617,507973.609,513497.19,519083.233,524726.509,530305.505,535945.728,541584.404,547274.055,552967.236,558667.862,564360.216,570128.148,575965.08,581701.952,587532.523,593361.144,599246.128,605033.418,610958.779,616837.117,622772.818,628672.04,634675.369,640574.831,646585.739,652574.547,658611.217,664642.684,670713.914,676737.681,682797.313,688837.897,694917.874,701009.882,707173.648,713257.254,719415.392,725636.761,731710.697,737906.209,744103.074,750313.39,756504.185,762712.579,768876.985,775167.859,781359,787615.959,793863.597,800245.477,806464.582,812785.294,819005.925,825403.057,831676.197,837936.284,844266.968,850642.711,856959.756,863322.774,869699.931,876102.478,882355.787,888694.463,895159.952,901536.143,907872.631,914293.672,920615.14,927130.974,933409.404,939922.178,946331.47,952745.93,959209.264,965590.224,972077.284,978501.961,984953.19,991413.271,997817.479,1004222.658,1010725.676,1017177.138,1023612.529,1030098.236,1036493.719,1043112.207,1049537.036,1056008.096,062476.184,1068942.337,1075524.95,1081932.864,1088426.025,1094776.005,1101327.448,1107901.673,1114423.639,1120884.602,1127324.923,1133794.24,1140328.886,1146849.376,1153346.682,1159836.502,1166478.703,1172953.304,1179391.502,1185950.982,1192544.052,1198913.41,1205430.994,1212015.525,1218674.042,1225121.683,1231551.101,1238126.379,1244673.795,1251260.649,1257697.86,1264320.983,1270736.319,1277274.694,1283804.95,1290211.514,1296858.568,1303455.691}
connection.search(searchBase,filter,SearchScope.SUBTREE,groupIdAttribute,displayNameAttribute,"dn","uid","userPrincipalName","mail","rfc822Mailbox","memberOf")
Multimap<Feature<?>,Feature<?>>
tableMetadataBuilder(TPCH_SCHEMA_NAME,TPCH_ORDERS_NAME).column("orderkey",LONG).column("custkey",LONG).column("orderstatus",STRING).column("totalprice",DOUBLE).column("orderdate",STRING).column("orderpriority",STRING).column("clerk",STRING).column("shippriority",STRING)
id=40
config.get(CONFIG_KEY_READ_TIMEOUT)
target.setField(0,val2)
res.sendError(202,"Websocket protocol not supported")
checkForMisplacedBindingAnnotations(method,errors) | !isValidMethod(injectableMethod,errors)
body.endsWith("6")
entries.remove(key)
exchange.addRequestHeader(HttpHeaders.AUTHORIZATION,"OAuth " + accessToken)
@UriParam
new DirectDruidClient(warehose,smileMapper,httpClient,server.getHost())
JSError.make(ModuleLoader.MODULE_CONFLICT,"my/js.js")
new FeaturesConfig().setExperimentalSyntaxEnabled(true).setDistributedIndexJoinsEnabled(true).setDistributedJoinsEnabled(false).setRedistributeWrites(false).setOptimizeMetadataQueries(true).setOptimizeHashGeneration(false).setOptimizeSingleDistinct(false).setPushTableWriteThroughUnion(true)
toPreCompute.size()
results.expectedMessageCount(2)
resultEndpoint.expectedBodiesReceived("one","two","three")
julianDateFloor(range,(int)date + EPOCH_JULIAN,true)
pixmap.drawCircle(x,y,radius,color)
buffer.getInt8()
outputBatchSize=5000
littleEndian.order()
Preconditions.checkNotNull(location)
new GeoLocation(array.getDouble(0),array.getDouble(1))
AsynchronousCloseException e
funType.toString()
id=15862
Files.delete(file.toPath())
id=21
in.readShortx()
when(rs.wasNull()).thenReturn(false)
seenServiceNames.contains(serviceName)
next.getField(0)
!(topicParts.length > 2) && !topicParts[0].equals(TOPIC_PREFIX)
createNextExchange(processor,exchange)
logger.trace("{} is already cancelled",impl.uuid())
hz.getCluster().getLocalMember().isSuperClient()
0.5f
id=19903
mWorkerId + BASE_FILE_NUMBER
GenericUDFEnforceNotNullConstraint.class
Services.deploymentUnitName(deploymentUnit.getParent().getName(),deploymentUnit.getName(),nextPhase)
@Override public Cell deepClone(){   byte[] copy=new byte[this.length];   ByteBufferUtils.copyFromBufferToArray(copy,this.buf,this.offset,0,this.length);   KeyValue kv=new NoTagsKeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } 
new GoogleCodeRemoval(compiler)
id=15801
new ReadonlyMapELResolver(beans)
this.instanceName.equals(singleInstanceProfilingEvent.getInstanceName())
addOrGetIndex(definition.getKey(),definition.getValue())
time.put(delta)
ArrayList<TaggedWord>
logger.debug("NODE {}: App version requested but Version class not supported",this.getNodeId())
new Argument().setIndex(0)
serialNumber.equals(null)
new PercentType(precent)
private Actor actor; 
JSError.make(ref.source.getName(),ref.node,NAME_DEFINED_LATE_WARNING,parent.fullName())
config.getClass().toString()
case REPLACE_IS_SAME: 
checkNotNull(getPropDefFromClass(superType,pname))
new Packet(ioService.getPortableContext())
ChannelBuffers.dynamicBuffer()
GnomeEngineeringManager manager=new GnomeEngineeringManager(); 
synchronized (mLostBlocks) {   return ImmutableSet.copyOf(mLostBlocks); } 
new FunctionCall("substring",new PathExpression(new ObjectAccess("addresses"),new ArrayAccess(0),new ObjectAccess("zipCode")))
node.executorManager.executeLocaly(new Runnable(){   public void run(){     MembershipEvent membershipEvent=new MembershipEvent(ClusterImpl.this,dummy,MembershipEvent.MEMBER_ADDED);     for (    MembershipListener listener : listenerSet) {       listener.memberAdded(membershipEvent);     }   } } )
synchronized (threadCount) {   ++threadCount;   if (session == null) {     try {       options=BigtableOptionsFactory.fromConfiguration(CONFIG);       session=new BigtableSession(options);       client=session.getDataClient();     }  catch (    IOException e) {       throw new DBException("Error loading options from config: ",e);     }   }  else {     client=session.getDataClient();   }   if (clientSideBuffering) {     heapSizeManager=new HeapSizeManager(Long.parseLong(getProperties().getProperty(ASYNC_MUTATOR_MAX_MEMORY,Long.toString(AsyncExecutor.ASYNC_MUTATOR_MAX_MEMORY_DEFAULT))),Integer.parseInt(getProperties().getProperty(ASYNC_MAX_INFLIGHT_RPCS,Integer.toString(AsyncExecutor.MAX_INFLIGHT_RPCS_DEFAULT))));     asyncExecutor=new AsyncExecutor(client,heapSizeManager);   } } 
promise.setSuccess(null)
(ArrayInitHandler)getParent()
FloatBuffer target
public DerivedBuilder setRealmPassword(String password){   realm().setPassword(password);   return this; } 
dstPath.getValue()
assertThat(request.getBody().readUtf8()).isEqualTo("<my-object><message>hello world</message><count>10</count></my-object>")
!method.getName().equals(methodToSearch) || !method.getReturnType().isAssignableFrom(methodToFind.getReturnType())
KafkaEightDruidModule.class
Assert.assertEquals(1457,details.get(6).getAbsolutePosition())
new LogVersionMismatchRequest()
new IOException(badLine)
compressedProto.length < 330000
return 18; 
Cloud.class
DEFAULT_MAX_QUERIES=3
assertThat(this.context.getBean(FilterChainProxy.class).getFilterChains()).hasSize(5)
Boolean ignored
calendar.set(Calendar.YEAR,2200)
Preconditions.checkNotNull(uri)
new StringBuilder(247)
new BasicAWSSessionCredentials(accessKey,secretKey,sessionToken)
HazelcastInstanceFactory.terminateAll()
Status.constructStatuses(get(getBaseURL() + "statuses/home_timeline.json",true))
id=55
200000 * 4 * 4
Thread.sleep(600)
targetDescription.getClassName()
(o instanceof Record)
partitionContainer.getRecordStore(name)
FILES_BYTES * 1000L
request.getRelaxLocality() == false
new BuildSecondHashMatchIterator(this.inputs[0],this.inputs[1],keyPositions1,keyPositions2,keyClasses,memoryManager,ioManager,this,availableMemory)
Generics.newHashMap()
assertOpenEventually(countDownLatch,30)
public DerivedBuilder setSSLEngineFactory(SSLEngineFactory sslEngineFactory){   configBuilder.setSSLEngineFactory(sslEngineFactory);   return this; } 
log.info("Worker nodes %s do not have capacity to run any more tasks!",zkWorkers.values())
TypeScriptNodeClientCodegen.class
connection.subscribe(jedisPubSub,patterns)
Preconditions.checkState(hasInstanceType())
public DerivedBuilder setProxyPort(int port){   this.proxyPort=port;   return this; } 
Mockito.doThrow(EXCEPTION).when(mFileSystemMasterClient).mount(alluxioPath,ufsPath)
id=16
logger.info(name)
new DynamicAwareEntry("http://localhost:8080/test",null,null)
new StringBuilder(639)
response == null
Integer requestRequiredAcks
HashSet<String>
new byte[10]
Context.getEncounterService().createEncounter(encounter)
configMonitor.init(this)
assertEquals(2,historyService.createHistoricActivityInstanceQuery().executionId(processInstance.getId()).list().size())
KeyType
new RuntimeException("Could not create TypeInformation for type " + type.getName() + "; please specify the TypeInformation manually via "+ "StreamExecutionEnvironment#fromElements(Collection, TypeInformation)")
cam.near=0.1f
cache.setRecord(key,record)
new AuthenticationException("Error validating LDAP user")
mock.expectedMessageCount(3)
from("seda:foo").startupOrder(1).delay(1000)
DiagnosticType.disabled("AMBIGUOUS_FUNCTION_DECL","Ambiguous use of a named function: {0}.")
factory.getSemaphore(packet.name)
EnterpriseMapPublisherCreateCodec.decodeResponse(response).list
javaWriter.emitSingleLineCOmment("foo")
sizeNeeded >= items.length
this.nameDefinitionMultimap.remove(name,node)
private final ReplayingDecoderBuffer replayable=new ReplayingDecoderBuffer(); 
new HazelcastInstance[count]
new DefaultAgentOption(agentArgs,instrumentation,profilerConfig,pluginJars,bootStrapJarPath,serviceTypeRegistryService,annotationKeyRegistryService)
LOG.warn("Unable to close socket selector",ex)
(color & 0x00FFFFFF) & (alpha << 24)
assertClusterSize(2,nodes[0])
assertEquals(id3,new Twitter(id3,pass3).verifyCredentials().getName())
group.getId()
IllegalArgumentException.class
incomingMessage.setTransActionCanceled(true)
amq.getConfiguration().getConnectionFactory()
julLogger.info("Hello world")
logger.error(message)
Map<Integer,Object>
Integer.MIN_VALUE + 11
0 == CheckUtils.parseFloat(text,type)
Status.constructStatuses(get(getBaseURL() + "statuses/home_timeline.json",null,paging.asPostParameterList(),true))
connection.zrangeByLex(key,max,min)
"Refreshing storefiles of region " + regionToFlush + " due to global heap pressure. memstore size="+ StringUtils.humanReadableInt(server.getRegionServerAccounting().getGlobalMemstoreSize())
assertThat(connector.getSoLingerTime()).isEqualTo(30)
new TezTaskRunner2(conf,taskUgi,fragmentInfo.getLocalDirs(),taskSpec,request.getAppAttemptNumber(),serviceConsumerMetadata,envMap,startedInputsMap,taskReporter,executor,objectRegistry,pid,executionContext,memoryAvailable)
doAnswer(new Answer<Object>(){   @Override public Object answer(  InvocationOnMock invocation) throws Throwable {     sem.release();     return null;   } } ).when(loggerMock).warn(anyString(),any(Exception.class))
incomingMessage.getMessagePayloadByte(0)
mFixedExecutionService.shutdown()
T
"true".equalsIgnoreCase(value)
testTLS(Cert.CLIENT_PEM_ROOT_CA,Trust.SERVER_JKS,Cert.SERVER_JKS,Trust.CLIENT_PEM_ROOT_CA).requiresClientAuth().clientUsesCrl()
classResolver.resolveClass(type)
attribute.startsWith(keyPrefix) & attribute.length() > keyPrefix.length()
json.length() - 2
public class XpathRegressionMultipleVariableDeclarationsTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=MultipleVariableDeclarationsCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionMultipleVariableDeclarationOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(MultipleVariableDeclarationsCheck.class);     final String[] expectedViolation={"4:5: " + getCheckMessage(MultipleVariableDeclarationsCheck.class,MultipleVariableDeclarationsCheck.MSG_MULTIPLE_COMMA)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='i']","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='i']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='i']/TYPE","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='i']/TYPE/LITERAL_INT","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='j']","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='j']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='j']/TYPE","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='j']/TYPE/LITERAL_INT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=MultipleVariableDeclarationsCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionMultipleVariableDeclarationTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(MultipleVariableDeclarationsCheck.class);     final String[] expectedViolation={"4:5: " + getCheckMessage(MultipleVariableDeclarationsCheck.class,MultipleVariableDeclarationsCheck.MSG_MULTIPLE)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='i1']","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='i1']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='i1']/TYPE","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='i1']/TYPE/LITERAL_INT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
"access-control/default is missing operations: " + accessControl
setColor(color)
type == TokenTypes.CLASS_DEF
declaredIntentionToWrite.getMode() != DIRECT_TO_TARGET_NEW_DIRECTORY
this.logFactory
id=15839
mTfs.mkdirs(new TachyonURI(dirPath))
new Version(1,0,0)
lines("Function.prototype.inherits = function(parentCtor) {","  function tempCtor() {};","  tempCtor.prototype = parentCtor.prototype;","  this.superClass_ = parentCtor.prototype;","  this.prototype = new tempCtor();","  this.prototype.constructor = this;","};")
applicationStatistics.incrUpdateUserTimes()
mTableInfo.getTableName()
logger.warn("{} {}",errorCode,message)
tJvmGcDetailed.getJvmGcNewCount()
new NagiosNscaStub(25667,"secret")
registered.add(objectName)
InputProcessor[]
endpointId <= result.getInstances()
LOG.error(e,"Unexpected failure when handling parsing error. This is likely a bug in the implementation")
!plugin.isEnabled()
type=200
id=19907
assertEquals(2,possibleOutcomes.size())
to("bar")
this.isDefaultAutoCommit()
new FileInputStream(props)
/**   * Exception thrown if the session-type of a session bean is not specified  */ @Message(id=14551,value="<session-type> not specified for ejb %s. This must be present in ejb-jar.xml") IllegalStateException sessionTypeNotSpecified(String bean); 
LOGGER.warn("{} - Failed to execute isValid() for connection, configure connection test query. ({})",poolName,e.getMessage())
dis.read(serializedData,0,length)
new IOException(msg)
LOG.trace("No binding to service interface as @Body,@Header,@ExchangeProperty not detected. Using BeanInvocation as message body when calling proxy method: {}")
zk.exists(znode,false) != null
id=1
GL.glCopyTexSubImage2DEXT(target,level,xoffset,yoffset,x,y,width,height)
public DerivedBuilder setProxyPrincipal(String principal){   this.proxyPrincipal=principal;   return this; } 
level <= RF_STATUS_HIGH_SIGNAL
public DerivedBuilder setMaximumNumberOfRedirects(int maxDefaultRedirects){   configBuilder.setMaximumNumberOfRedirects(maxDefaultRedirects);   return this; } 
wizardModel.databaseConnection.contains("localhost")
MD5Loader.loadModel(Gdx.files.internal("data/zfat.md5mesh").read(),false)
new RuntimeException("error initializing deserializer: " + deserializer.getClass().getName())
new InputStreamReader(fileObject.getInputStream())
id=33
mStack.size() > 2
REPLACE_IS_SAME(7)
StringBuffer result
HttpAuthenticationFactory.class
new Tag(line,column,text,on)
channelIdle(ctx,IdleState.ALL_IDLE,lastReadTime)
clockSource.elapsedMillis(startTime,now)
prev.getPrevProp()
closedChannelException != null
field.set(instanceRef,value)
worldVertices.length < localVertices.length
id=51
compactionStarted.getAndSet(true)
Integer.valueOf(options.getMaxKeys())
Assert.assertEquals(stringNumber,0)
row("p_comment",null,1.0,0.0,null,null,null)
util.getDataTestDir(table)
clientConfig.property(ClientProperties.READ_TIMEOUT,1000)
processInstance.getId()
logger.debug("NODE {}: Retry timout: Can't advance")
assertThat(page1.pagination().getGlobalTotal()).isEqualTo(7)
return 400; 
TABLE_COMMIT
route.setDelay(5)
/**   * Make sure we don't attempt to recover inline; if the parser successfully recovers, it won't throw an exception.  */ @Override public Symbol recoverInline(BaseRecognizer recognizer) throws RecognitionException {   throw new RuntimeException(new InputMismatchException(recognizer)); } 
Gauge<Object>
peekNode()
sourceNodeData != null
new SensitivityClassification(SUBSYSTEM_NAME,"web-connector",true,false,false)
AtmosphereResponse.create()
maxSize > (used / total)
id=17
region.checkAndMutate(row1,fam1,qf1,CompareOp.EQUAL,new BinaryComparator(val1),put,true)
/**   * Returns messages newer than the message ID specified as a numeric string. This should be used when polling for new messages. If you're looking at messages, and the most recent message returned is 3516, you can make a request with the parameter "?newerThan=3516 to ensure that you do not get duplicate copies of messages already on your page.  */ private Integer newerThan=-1; 
saveTask(taskDefinition)
new MultitouchTest()
invocation.logger.warning("Asking if operation execution has been started: " + invocation)
sshd.stop()
lock.lock(1000,TimeUnit.MILLISECONDS)
inputProcessor.touchDown(event.x,event.y,event.pointer,Buttons.LEFT)
createService(apiKey,apiSecret,callback,defaultScope,responseType,userAgent,httpClientConfig,httpClient)
logger.info("Aliasing common strings")
i < count
nameLength > maxHeadersLength - headersLength
SpringApplication.class
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class QueueBasicDistributedTest extends QueueBasicTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(2).newInstances(config);   } } 
msgType <= values.length
LOG.error("Ignoring duplicate class " + className)
statistics.addRemoveTimeNano(System.nanoTime() - start)
mBuffer.remaining() > toRead
GatherGettersAndSetterProperties.gather(compiler,mainRoot)
!handler.isDifferent(existing)
new HttpDigestAuthFilter(DIGEST_TEST_LOGIN,DIGEST_TEST_INVALIDPASS,1)
privObj.getObjectName().equals("masking_acid_no_masking")
items[29]
setNetworkTimeout(connection,networkTimeout)
new ModelNode().set(10)
Map<String,Integer>
new ModelNode(10)
public static XQueryBuilder xquery(File file) throws FileNotFoundException {   return xquery(IOConverter.toInputStream(file),ObjectHelper.getDefaultCharacterSet()); } 
mapServiceContext.hasRegisteredListener(mapName)
string.length() >= 0
HashMap<Object,AggregationStrategy>
ti > 0
new RuntimeException(String.format("File \"%1$s\" has no indentation comment or its format " + "malformed. Error on line: %2$d(%3$s)",aFileName,lineNumber,line))
UnderFileSystemUtils.deleteFileIfExists(mUfs,mCheckpointPath)
id=15867
new RuntimeException(msg.getMessage())
mTfs.delete(mTfs.open(new TachyonURI(filePath)))
/**   * Loads the import control file from a  {@link InputSource}.  * @param source the source to load from.  * @param uri uri of the source being loaded.  * @return the root {@link PkgControl} object.  * @throws CheckstyleException if an error occurs.  */ private static PkgControl load(final InputSource source,final URI uri) throws CheckstyleException {   try {     final ImportControlLoader loader=new ImportControlLoader();     loader.parseInputSource(source);     return loader.getRoot();   }  catch (  final ParserConfigurationException|SAXException ex) {     throw new CheckstyleException("unable to parse " + uri + " - "+ ex.getMessage(),ex);   } catch (  final IOException ex) {     throw new CheckstyleException("unable to read " + uri,ex);   } } 
factory.get(sResultWildcard,NO_ANNOTATIONS,retrofit)
this.logger.isWarnEnabled()
period < MINIMAL_POLL_PERIOD
id=15849
getRegistry().put("hb",hb)
new RunnableAdapter<T>(task,result)
input.getDouble(0) < 10.0
invoke(args)
8 * 60000
String.format("<?xml version=\"1.0\" encoding=\"UTF-8\"?>%n" + "<checkstyle version=\"" + version + "\">%n"+ "<file name=\""+ expectedPath+ "\">%n"+ "</file>%n"+ "</checkstyle>%n")
propMember.getType(beanDesc.bindingsForBeanType())
i == -1
SSL.getErrorString(err)
User.createCursorSupportUserList(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/statuses/followers/T4J_hudson.json"))
testWarning(LINE_JOINER.join("goog.require('a.c');","/** @suppress {extraRequire} */","goog.require('a.b')"),REQUIRES_NOT_SORTED,LINE_JOINER.join("goog.require() statements are not sorted. The correct order is:","","/**"," @suppress {extraRequire}"," */","goog.require('a.b');","goog.require('a.c');","",""))
oldestNode == null
names[2]
DSVHTTPDataAdapter.Config.builder().type(NAME).url("https://example.org/table.csv").separator(",").lineSeparator("\n").quotechar("\"").ignorechar("#").keyColumn(1)
ar.cause()
objectMapper.readerFor(DataSegment.class)
timeout=120000
maxInvocationCountObservedDuringWarmup * 1.2
runningTasks.get(assignedTask)
expirationTime == Long.MAX_VALUE && expirationTime < 0
req.getRequestURI()
r.destination != null
/**   * Represents black  */ BLACK('0',0x01)
val.get(key)
setEternal(Boolean.valueOf((String)cacheSettings.get("diskPersistent")))
loadResourceAsURL(name)
context.setDelayer(2000)
LOG.error("delete failed: {}",e.getMessage())
CommonUtils.randomString(random.nextInt(10))
logger.debug("NODE {}: App version requested but version is unknown",this.getNodeId())
getSsl(ClientAuth.NEED,"password","src/test/resources/test.jks")
Arrays.asList(RFXComValueSelector.RAW_DATA,RFXComValueSelector.SIGNAL_LEVEL,RFXComValueSelector.COMMAND,RFXComValueSelector.MOOD,RFXComValueSelector.DIMMING_LEVEL)
assertTrue(isBufferCopyNeededForWrite(byteBuf.asReadOnly()))
CachingConnectionFactory connectionFactory
this.context.getLogAggregationStatusForApps().add(report)
handler instanceof ChannelInboundHandler
Configuration.getLong(PropertyKey.USER_NETWORK_NETTY_TIMEOUT_MS)
public class XpathRegressionRequireThisTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=RequireThisCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRequireThisOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RequireThisCheck.class);     moduleConfig.addAttribute("validateOnlyOverlapping","false");     final String[] expectedViolation={"7:9: " + getCheckMessage(RequireThisCheck.class,RequireThisCheck.MSG_VARIABLE,"age","")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRequireThisOne']/OBJBLOCK" + "/METHOD_DEF[@text='changeAge']/SLIST/EXPR/ASSIGN[@text='age']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=RequireThisCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRequireThisTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RequireThisCheck.class);     moduleConfig.addAttribute("validateOnlyOverlapping","false");     final String[] expectedViolation={"9:9: " + getCheckMessage(RequireThisCheck.class,RequireThisCheck.MSG_METHOD,"method1","")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRequireThisTwo']/OBJBLOCK" + "/METHOD_DEF[@text='method2']/SLIST/EXPR/METHOD_CALL[@text='method1']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
INVISIBILTY(14,PotionEffectType.INVISIBILITY,1)
uri.toASCIIString()
sanitizedName(name)
config().getSoLinger() > 0
this.connectTo(vertex,channelType,compressionLevel,-1,-1,distributionPattern,false)
Set<Key<?>>
getPath("InputPackageDeclarationDiffDirectory.java")
fileInfo.getPath()
CONFIG_REFRESH.equals(configKey) || "service.pid".equals(configKey)
userGroupMember.getMemberId()
consumer.endpoint.isAutoAck()
Status.constructStatuses(get(getApiBaseURL() + V1 + user+ "/lists/"+ id+ "/statuses.json",new PostParameter[0],paging.asPostParameterList(Paging.SMCP,Paging.PER_PAGE),true))
(Object)y
assertEquals(1,scheduler.getQueueManager().getQueues().size())
!isClosed.get()
T
offset >= 0
SimpleAttributeDefinitionBuilder.create("file",ModelType.OBJECT,true)
invoke(agentInfo,payload,DEFUALT_FUTURE_TIMEOUT)
memoryMap.getInt("mappedWithJournal")
table.getParameters()
JavaConversions.asMap(logManager.logsByTopicPartition())
Thread.sleep(10)
getUrl().getMethodParameter(methodName,TIMEOUT_KEY,DEFAULT_TIMEOUT)
getData() ^ 0x8
sliceInput.length()
HttpRequest.put("http://localhost:8080/ejbws-example/SingletonEndpoint",message,10,SECONDS)
4 * (float)Math.sqrt(radius)
(new Path(testBucket.getParent(),".test.inprogress")).toString()
timeLeft >= 0
@PATCH
REMOVALS_UPDATER.compareAndSet(this,nanos,nanos + duration)
SingleMapBlockWriter.class
logger.debug("Requsting URL {}",url)
assertEquals(3,map2.keySet().size())
QuotaCache.this.tableQuotaCache.contains(table)
stop < start
Status.constructStatuses(get(getBaseURL() + "statuses/retweets/" + statusId+ ".json",true))
100 * 1000
bulkInsertableMap.get(persistentObjectClass)
128 * 1024
id=15863
FileInStream.create(status,options.toInStreamOptions(),mContext)
this.getLimit()
assertThat(page3.pagination().getGlobalTotal()).isEqualTo(7)
eq(true)
VertexAttribute.Color()
mLineageStore.requestFilePersistence(fileId)
Mono.just(entry.getKey()).and(entry.getValue().health().compose(this.timeoutCompose))
emptyCheck.log(0,"msgKey",null)
id=15851
public ByteBuf getBufferFor(int index) throws IOException {   if (index < 0 || index > capacity()) {     throw new IndexOutOfBoundsException("Invalid index: " + index + " - Bytes needed: "+ (index)+ ", maximum is "+ capacity());   }   int componentId=componentId(index);   return components[componentId].duplicate(); } 
registry.put("firehoseClient",amazonKinesisFirehoseClient)
repo.setRecoveryInterval(500,TimeUnit.MILLISECONDS)
scanFeatures(getKarafFeatureUrl(),"spring","spring-dm","jetty")
doTestNegative(301,false)
Thread.sleep(50)
deserialze(parser,type,fieldName,null,0,null)
c * b
@Override public Integer call() throws Exception {   MessageCountResponse response=api.get(MessageCountResponse.class).path("/count/total").execute();   return response.events; } 
logger.error("Error getting value for expression " + expressionField.getExpression() + " "+ e.getMessage())
resultEndpoint.assertIsSatisfied(5000)
getTablename().getBytes()
this.setSortParamsByRequiredFlag(Boolean.valueOf(additionalProperties.get(CodegenConstants.REMOVE_OPERATION_ID_PREFIX).toString()))
id=25
c.getSimpleName()
List<SourceFile>
waitLatch.await(25,TimeUnit.MILLISECONDS)
Arrays.asList("ls","pwd")
val=1
n.getNodeData().x()
@InputIntMethodAnnotation(-44)
items[31]
DirectMessage.constructDirectMessages(get(getBaseURL() + "direct_messages.json",true))
ChannelInboundHandlerAdapter handler=new ChannelDuplexHandler(){   @Override public void channelActive(  ChannelHandlerContext ctx) throws Exception {     ctx.fireChannelActive();     peerRef.exchange(ctx.channel(),1L,SECONDS);   }   @Override public void channelRead(  ChannelHandlerContext ctx,  Object msg){     latch.countDown();     ctx.read();   }   @Override public void exceptionCaught(  ChannelHandlerContext ctx,  Throwable cause){     causeRef.set(cause);   } } ; 
(strLine=br.readLine()) != null
excludesPattern == null
id=14
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
clazz.getConstructor(ConstantsAndVariables.class,PatternScoring.class,String.class,TwoDimensionalCounter.class,TwoDimensionalCounter.class,TwoDimensionalCounter.class,TwoDimensionalCounter.class,TwoDimensionalCounter.class)
DEFAULT_ROW_FLUSH_BOUNDARY=80000
LOG.error("Async Kafka commit failed.",cause)
log.debug("PID contains identifier with no assigning authority")
rs.getString(columnIndex)
InvalidPathException.class
getJSDocTypeWithBraces(operation)
mock.expectedBodiesReceived("Hello World 2")
mFileLength < mBlockSize
target.directory("zk" + id + "data")
twitter4j.List.constructListOfLists(get(getApiBaseURL() + V1 + user+ "/lists/memberships.json?cursor="+ cursor,true))
pti.getTotalFields()
sendCommand(CLIENT_GETNAME)
success
acceptor.getFilterChain()
!StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"flush") && !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"grant")
id=15868
nodeEngine.getPartitionService()
writer.write(line)
new MethodInjectionTarget(methodName,methodInfo.declaringClass().name().toString(),methodInfo.returnType().name().toString())
suiteMethod.invoke(null,(Object[])new Class[0])
edge.setType(EdgeDirection.DIRECTED)
flags.length == 0
new HashSet<RecordReplicationInfo>(recordStore.size())
app.getAudio().newAudioRecoder(22050,true)
BlockMasterClient.class
builder.addDependency(RegistryInstallerService.SERVICE_NAME)
IOConverter.toString(out)
views.html.search.noresults.render(currentUser(),q,searchResult)
clients.inMemory().withClient("my-trusted-client").authorizedGrantTypes("password","authorization_code","refresh_token","implicit").authorities("ROLE_CLIENT","ROLE_TRUSTED_CLIENT").scopes("read","write","trust").accessTokenValiditySeconds(60).additionalInformation("foo:bar","spam:bucket")
this(true,true); 
id=15
new KafkaComponent()
getBooleanValue(ASYNC_CLIENT + "acceptAnyCertificate",false)
jmsManager.destroyQueue(queueName)
Size.kilobytes(3)
JSError.make(SourceMapInput.SOURCEMAP_PARSE_FAILED,sourceMapPath)
jedis.sadd(getSetKey(task),request.getUrl()) > 0
Class.forName(className.replace('/','.'))
cursor.getPosition()
execution.getJobs().remove(this)
var.setValue(guessType(value))
/**   * Executes the given task in a new thread that is authenticated as the daemon user. <br/> <br/> This can only be called from  {@link TimerSchedulerTask} during actual task execution  * @param task the task to run  * @should not be called from other methods other than TimerSchedulerTask  * @should not throw error if called from a TimerSchedulerTask class  */ public static void executeScheduledTask(final Task task) throws Throwable {   Class<?> callerClass=new OpenmrsSecurityManager().getCallerClass(0);   if (!TimerSchedulerTask.class.isAssignableFrom(callerClass)) {     throw new APIException("This method can only be called from the TimerSchedulerTask class, not " + callerClass.getName());   }   DaemonThread executeTaskThread=new DaemonThread(){     @Override public void run(){       isDaemonThread.set(true);       try {         Context.openSession();         TimerSchedulerTask.execute(task);       }  catch (      Exception e) {         exceptionThrown=e;       }  finally {         Context.closeSession();       }     }   } ;   executeTaskThread.start();   try {     executeTaskThread.join();   }  catch (  InterruptedException e) {   }   if (executeTaskThread.exceptionThrown != null) {     throw executeTaskThread.exceptionThrown;   } } 
Column::toString
public DerivedBuilder setAllowPoolingConnection(boolean allowPoolingConnection){   configBuilder.setAllowPoolingConnection(allowPoolingConnection);   return this; } 
assertEquals(70011,exchange.getIn().getBody().toString().length())
new DynamicAwareEntry("https://localhost/test",null,null)
uncompressedProto.length < 2550000
new RuntimeException()
getRegistry().put("myTable",ht)
Tuple2.of(timeoutPattern2,13L)
logger.info("Moving functions + variable into deeper modules")
Assert.assertEquals("Invalid selection end",280,selector.getSelectionEnd())
SortedMap<Integer,Integer>
binder.bindConstant().annotatedWith(Names.named("servicePort")).to(8081)
replicatedMapService.getReplicatedRecordStore(mapName,false)
tokens.toString()
new JSONParseSpec(new TimestampSpec("timestamp","auto"),new DimensionsSpec(Arrays.asList("dim1","dim2"),null,null),JSONParseSpec.JSON)
mesh.getNumVertices() / 2
log.error("Multiple nodes are set, but execute() was called. This is most likely a bug and you meant to call executeOnAll()!")
currentPath.isEmpty()
current.getLabel().startsWith("nt") && !pre.getLabel().startsWith("nt")
_maxTransactionActive=0
parameter.toString()
uri.getPort() == -1
findState != 0
Color.rgb888ToColor(color,colorInt)
mapEntry.getValue().isSame(source)
entry.getValue().getManagementInterfaceMinorVersion()
-120
scheduler.scheduleRecurring(indexPopulation,countInvocationsJob,1,MILLISECONDS)
handshakeFuture != null
c < values.length()
String text
assertMockEndpointsSatisifed()
id=15858
program.getProgramId()
Context.getProviderService().getAllProviderAttributeTypes(false)
numKeys > 1
createPermissionsXmlAsset(new SocketPermission("*:10389","connect,resolve"))
twitter.getHomeTimeline()
i > 0
pixmap.getHeight() - yHotspot - 4
GL20.glUniformMatrix2(location,transpose,toFloatBuffer(value,offset,count << 2))
String pattern=this.prefix; 
zoneId.equals("+00:00") | zoneId.equals("-00:00")
new LinkedHashMap<String,Object>(whileListMaxSize,0.75f,true)
connectionTimeout / 2
showTooltip == null
closeCode < 1001
complexColumnCache.values()
Integer.valueOf(tokens[3])
TEST_UTIL.getHBaseAdmin()
UrlUtils.getIdleTimeout(getUrl())
new DefaultAsyncHttpClient()
1
obj.getAcceptableTokens()
new JGroupsFilter(bc,event.getAtmosphereConfig().getWebServerName())
super.equals(obj)
state.isGloballyTerminalState()
FISHING_ROD(346,1,64)
idx[j] >= 0
from("direct:start").recipientList(header("slip")).aggregationStrategy(new AggregationStrategy(){   public Exchange aggregate(  Exchange oldExchange,  Exchange newExchange){     if (oldExchange == null) {       return newExchange;     }     String body=oldExchange.getIn().getBody(String.class);     oldExchange.getIn().setBody(body + newExchange.getIn().getBody(String.class));     return oldExchange;   } } ).parallelProcessing().timeout(2000)
headerRow != null
RaftJournalSystem.class
registration.registerOperationHandler(CommonAttributes.ENABLE_CONTEXT,ModClusterEnableContext.INSTANCE,enableContext,false)
result.expectedMessageCount(0)
mFs.mkdirs(new Path(path),null)
size=500
/**   * t1.g4 -> t2.g4 -> t3.g4 ->t1.g4   */ CIRCULAR_DEPENDENCY(130,"your grammars contain a circular dependency and cannot be sorted into a valid build order",ErrorSeverity.ERROR)
error.expectedMessageCount(2)
logger.info("Calimero library version {}",Settings.getLibraryVersion())
id=15850
latch.await(100,TimeUnit.SECONDS)
GL20.glUniform1(location,v)
DefaultBroadcaster.class.cast(resource.getBroadcaster()).broadcasterCache.retrieveFromCache(resource)
getApprovalParameters()
public class XpathRegressionFallThroughTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=FallThroughCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(FallThroughCheck.class);     final String[] expectedViolation={"11:13: " + getCheckMessage(FallThroughCheck.class,FallThroughCheck.MSG_FALL_THROUGH)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP","/CLASS_DEF[@text='SuppressionXpathRegressionExplicitOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP/LITERAL_CASE");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=FallThroughCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(FallThroughCheck.class);     moduleConfig.addAttribute("checkLastCaseGroup","true");     final String[] expectedViolation={"10:17: " + getCheckMessage(FallThroughCheck.class,FallThroughCheck.MSG_FALL_THROUGH_LAST)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitTwo']/OBJBLOCK" + "/METHOD_DEF[@text='methodFallThruCustomWords']/SLIST/LITERAL_WHILE/SLIST" + "/LITERAL_SWITCH/CASE_GROUP","/CLASS_DEF[@text='SuppressionXpathRegressionExplicitTwo']/OBJBLOCK" + "/METHOD_DEF[@text='methodFallThruCustomWords']/SLIST/LITERAL_WHILE/SLIST" + "/LITERAL_SWITCH/CASE_GROUP/LITERAL_DEFAULT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
meta.setContentEncoding(Mimetypes.MIMETYPE_OCTET_STREAM)
getClusterMap().put(buildAttributeName(name),value)
op.getIDLName()
nextRequest(request,future)
this(false,16,arrayType); 
status == 400
batteryVp >= low
assertEquals(failures.size(),1)
op.getResultAsObject()
request.getTaskDefinitionKey()
assertEquals(counter,1)
req.getSession().getMaxInactiveInterval() * 1000
ImmutableList<String>
new NullPointerException("the name is null")
assertNotPresent(GsonConverter.class)
processEngineConfiguration.getCommandExecutorTxRequiresNew()
app.configuration().getString("timezone")
5 * 60 * 100
principalCookieName != null
getTokenNames()
ConfigUtils.absoluteHealthCheckDir(stormConf)
assertEquals(7,LambdaOperations.values().length)
new NetAddress(resolvedHost,resolvedPort,-1)
new RuntimeException(String.format("File \"%1$s\" has no indentation comment or its format " + "malformed. Error on line: %2$d",aFileName,lineNumber))
fields.get("last_seen")
AtmosphereResourceEventListener.class
proxy.getHostText()
items[16]
propertiesComponent.isDefaultCreated()
"Content-Type".equals(name)
DiagnosticType.disabled("JSC_MISPLACED_TYPE_ANNOTATION","Type annotations are not allowed here. " + "Are you missing parentheses?")
maxRelError=1e-4
(ChronicleEngineEnpoint)getEndpoint()
ppcY / 2.54f
length % dictionarySize
"memberOf".equalsIgnoreCase(attribute.getId())
AttributeUtils.getDefault().getMin(column,valuesArray)
DEFAULT_CAPACITY=4000
compressedProto.length < 390000
log.debug("Unexpected exception on closing transaction.  Cause: " + e)
inputPath=args[1]
new PrestoException(INVALID_CAST_ARGUMENT,e)
IllegalArgumentException iae
DiagnosticGroups.registerGroup("oldCheckTypes",TypeValidator.ALL_DIAGNOSTICS,TypeCheck.ALL_DIAGNOSTICS)
cache.flush()
properties.length > 3
new DefaultRouteContext(route,null,list)
log.error(throwable,"Query %s failed",queryId)
NoopChatHandlerProvider.class
ImmutableList.of("es3.js","es5.js","w3c_event.js","w3c_event3.js","gecko_event.js","ie_event.js","webkit_event.js","w3c_dom1.js","w3c_dom2.js","w3c_dom3.js","gecko_dom.js","ie_dom.js","webkit_dom.js","w3c_css.js","gecko_css.js","ie_css.js","webkit_css.js","google.js","deprecated.js","fileapi.js","flash.js","gears_symbols.js","gears_types.js","gecko_xml.js","html5.js","ie_vml.js","iphone.js","webstorage.js","w3c_css3d.js","w3c_elementtraversal.js","w3c_geolocation.js","w3c_indexeddb.js","w3c_range.js","w3c_selectors.js","w3c_xml.js","window.js","webkit_notifications.js")
assertEquals(6,set.size())
USER_UFS_DELEGATION_ENABLED(Name.USER_UFS_DELEGATION_ENABLED,false)
this.posColumn=posColumn
preDestroys != null
new ResultSetIterator(rs,getEndpoint().isUseJDBC4ColumnNameAndLabelSemantics())
shouldBackup=false
new BinaryWebSocketFrame(payload)
(short)600
FilterAndProjectOperator.class
new GeneralDataCoding(false,false,MessageClass.CLASS1,Alphabet.ALPHA_DEFAULT)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class IdGeneratorBasicLocalTest extends IdGeneratorBasicTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(1).newInstances();   } } 
TIMEOUT=20000L
ObjectStore.isCurrentStatsValidForTheQuery(conf,db,tbl,params,statsWriteId,writeIdString,false)
parameters.getPositions().get(0)
log.warn("Could not annotate via server! Trying to annotate locally...",t)
saHooks != null
id=19
routes.UsersController.index()
assertMockEndpointsSatisfied()
id == null
pool.dealloc()
id=47
from("timer://foo?fixedRate=true&delay=0&period=500").to("bean:myBean")
id=38
GL11.glTexParameter(target,pname,params)
test("var foo = function () {var module = {};module.exports = {};};" + "module.exports = foo;","goog.provide('module$test');" + "var foo$$module$test=function(){var module={};module.exports={}};" + "var module$test=foo$$module$test")
assertEquals(0,counter.get())
Arrays.asList(RFXComValueSelector.RAW_DATA,RFXComValueSelector.SIGNAL_LEVEL,RFXComValueSelector.COMMAND)
AuditEvemtFormatter messageFormatter
rSocketMessageHandler.serverResponder()
/**   * Tests for  {@link ClosureSortedDependencies}  */ public class ClosureSortedDependenciesTest extends SortedDependenciesTest {   @Override public SortedDependencies<SimpleDependencyInfo> createSortedDependencies(  List<SimpleDependencyInfo> shuffled) throws CircularDependencyException {     return new ClosureSortedDependencies<>(shuffled);   }   @Override public boolean handlesCycles(){     return false;   } } 
id=19906
expression.length() - 2
rs.getString(columnName)
GL.glGenTexturesEXT(n,toBuffer(textures,offset),0)
super.getClass()
allDefinitions != null
t.st == ST.LABEL
ImmutableList.of(modules)
ImmutableList.of(listeners)
this.fs.delete(filePath,false)
active=true
id=15841
cachedMemoryUsageBytes < softMemoryLimitBytes
mock.expectedFileExists("target/failed/error/bye.txt","Kabom")
lexer.token == Token.HINT
pushExecutor.submit(new NamedRunnable("OkHttp %s Push Reset[%s]",hostName,streamId){   @Override public void execute(){     pushObserver.onReset(streamId,errorCode); synchronized (SpdyConnection.this) {       currentPushRequests.remove(streamId);     }   } } )
TestMapUsingMapStoreBuilder.create().mapName(mapName).withMapStore(mapStore).withNodeCount(nodeCount).withBackupCount(2)
inner.innerSetException((Throwable)result)
locator.getRegionLocation(regionName)
aliases.size() > 0
redirectUri == null
new NullPointerException("ClassInfo's name should be non-null")
0 - originY
mTfs.free(mTfs.open(path))
synchronized (conn) {   this.conn=conn;   this.stream=stream;   stream.beginRequest(this);   if (pendingMaxSize != -1) {     this.stream.doSetWriteQueueMaxSize(pendingMaxSize);   }   if (pendingChunks != null) {     ByteBuf pending=pendingChunks;     pendingChunks=null;     if (completed) {       writeHeadWithContent(pending,true);       conn.reportBytesWritten(written);       if (respHandler != null) {         this.stream.endRequest();       }     }  else {       writeHeadWithContent(pending,false);       if (headersCompletionHandler != null) {         headersCompletionHandler.handle(stream.version());       }     }   }  else {     if (completed) {       writeHeadWithContent(Unpooled.EMPTY_BUFFER,true);       conn.reportBytesWritten(written);       if (respHandler != null) {         this.stream.endRequest();       }     }  else {       if (writeHead) {         writeHead();         if (headersCompletionHandler != null) {           headersCompletionHandler.handle(stream.version());         }       }     }   } } 
Thread.sleep(1200)
timeout=30000
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
REAL_DRIVER.close()
QuotaCache.this.namespaceQuotaCache.contains(ns)
AstUtils.hasLeastOneAnnotation(classNode,"MessageEndpoint","EnableIntegrationPatterns")
new DatabaseFormatterOracle()
logger.info("fail-mock: " + invocation.getMethodName() + " fail-mock enabled , url : "+ directory.getUrl(),e)
/**   * Represents the default formatter for log message. Default log message format is: [SEVERITY LEVEL] filePath:lineNo:columnNo: message. [CheckName]  * @author Andrei Selkin  */ public class AuditEventDefaultFormatter implements AuditEvemtFormatter {   /**   * Length of all separators.   */   private static final int LENGTH_OF_ALL_SEPARATORS=10;   /**   * Suffix of module names like XXXXCheck.   */   private static final String SUFFIX="Check";   @Override public String format(  AuditEvent event){     final String fileName=event.getFileName();     final String message=event.getMessage();     final SeverityLevel severityLevel=event.getSeverityLevel();     final String severityLevelName;     if (severityLevel == SeverityLevel.WARNING) {       severityLevelName="WARN";     }  else {       severityLevelName=severityLevel.getName().toUpperCase(Locale.US);     }     final int bufLen=calculateBufferLength(event,severityLevelName.length());     final StringBuilder sb=new StringBuilder(bufLen);     sb.append('[').append(severityLevelName).append("] ").append(fileName).append(':').append(event.getLine());     if (event.getColumn() > 0) {       sb.append(':').append(event.getColumn());     }     sb.append(": ").append(message);     final String checkShortName=getCheckShortName(event);     sb.append(" [").append(checkShortName).append(']');     return sb.toString();   }   /**   * Returns the length of the buffer for StringBuilder. bufferLength = fileNameLength + messageLength + lengthOfAllSeparators + + severityNameLength + checkNameLength.  * @param event audit event.  * @param severityLevelNameLength length of severity level name.  * @return the length of the buffer for StringBuilder.  */   private static int calculateBufferLength(  AuditEvent event,  int severityLevelNameLength){     return LENGTH_OF_ALL_SEPARATORS + event.getFileName().length() + event.getMessage().length()+ severityLevelNameLength+ getCheckShortName(event).length();   }   /**   * Returns check name without 'Check' suffix.  * @param event audit ivent.  * @return check name without 'Check' suffix.  */   private static String getCheckShortName(  AuditEvent event){     final String checkFullName=event.getSourceName();     final String checkShortName;     final int lastDotIndex=checkFullName.lastIndexOf('.');     if (lastDotIndex == -1) {       if (checkFullName.endsWith(SUFFIX)) {         checkShortName=checkFullName.substring(0,checkFullName.lastIndexOf(SUFFIX));       }  else {         checkShortName=checkFullName.substring(0,checkFullName.length());       }     }  else {       if (checkFullName.endsWith(SUFFIX)) {         checkShortName=checkFullName.substring(lastDotIndex + 1,checkFullName.lastIndexOf(SUFFIX));       }  else {         checkShortName=checkFullName.substring(lastDotIndex + 1,checkFullName.length());       }     }     return checkShortName;   } } 
hazelcastFactory.newHazelcastClient()
infos == null | infos.length == 0
sendMessage() == false
c.isEncoded()
i=0
Preconditions.checkNotNull(mBlockIdsOnTiers)
ReplicationMessage event
equalTo(6)
assertTrueEventually(new AssertTask(){   @Override public void run() throws Exception {     Collection<EventRegistration> regs1=eventService1.getRegistrations(MapService.SERVICE_NAME,mapName);     Collection<EventRegistration> regs2=eventService2.getRegistrations(MapService.SERVICE_NAME,mapName);     assertEquals("there should be only one registration",1,regs1.size());     assertEquals("there should be only one registration",1,regs2.size());   } } ,10)
NIO_GROUP.shutdownGracefully()
@Override public Cell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   return new TagRewriteCell(clonedBaseCell,this.tags); } 
LOG.warn("Cannot create the SAXParser XMLReader, due to {}",ex)
graphModel.getUndirectedGraph()
@SuppressWarnings("unused") private final Object strongReference; 
mapConfig.getTotalBackupCount()
Color.fromRGB(0xEB8844)
parent.incrementPrioritizableForTree(amt,oldParent)
runTasks & 0x40
exchange.getPartitioningScheme().isReplicateNulls()
i > stripeStats.size()
id=15853
ResponseImpl headers(Map<String,Property> headers); 
id=2
synchronized (threadCount) {   --threadCount;   if (threadCount <= 0) {     try {       session.close();     }  catch (    IOException e) {       throw new DBException(e);     }   } } 
getLsResultStr("/testRoot/testDir",files[1].getCreationTimeMs(),0,LsCommand.STATE_FOLDER,testUser,testUser,files[1].getPermission(),files[1].isFolder())
is("/home/source")
LOG.debug("Consumer subtask {} is trying to discover new partitions ...")
metric instanceof MetricsRate || metric instanceof MetricsString
IR.name(TMP_ERROR)
fireMessageReceived(ctx,completeMessage)
masterAddress.split(":").length != 2
new ServletException("non-HTTP request or response")
LOGGER.warn("{} - Failed to execute connection test query. ({})",poolName,e.getMessage())
i < 1000
callTimeoutMillis=1000
pm.runMigrationTasks(this,tasks,partitionId,replicaIndex,from)
connectors.put(connectorName,connector)
id=3
ReactiveHelper.scheduleLast(() -> {   if (uow != null) {     uow.afterProcess(processor,exchange,callback,false);   }   if (log.isTraceEnabled()) {     log.trace("Exchange processed and is continued routed asynchronously for exchangeId: {} -> {}",exchange.getExchangeId(),exchange);   } } ,"CamelInternalProcessor - UnitOfWork - afterProcess - " + processor + " - "+ exchange.getExchangeId())
patientState.getState().getId()
s.setMaxVersions()
bufferedBytes >= maxBufferedBytes
assertEquals(8,config.getMapConfigs().size())
providers.size() >= 0
new UnlockHandler(this)
dbCol.findOne()
this.healthMvcEndpointProperties.getMapping() != null
endFunction("get_column_statistics_by_partition: ",statsObj != null)
Pattern.compile(foundAuthor)
items[25]
String.format(SCOPED_AUTHORIZE_URL,formURLEncode(config.getCallback()),formURLEncode(config.getScope()))
LOG.fatal("Could not append. Requesting close of wal",e)
isNotNull(overriderParameters.get(i)) && !(isNullable(overriddenParameters.get(i)) || isNotNull(overriddenParameters.get(i)))
final HColumnDescriptor hcd=htd.getFamily(familyName); 
Dagger_AutoFactoryProcessorComponent.builder()
map.lock(key,4,TimeUnit.SECONDS)
config.setProxyList(modelconf.get(CommonAttributes.ADVERTISE_SECURITY_KEY).asString())
resource.terminate(input.getId(),extractorId)
Throwable ex
new AsyncWriteToken(r,finalMsg,entry.future,entry.originalMessage)
entity instanceof ProcessDefinition
region.getRegionId()
public DerivedBuilder setDefaultThrowableHandler(ThrowableHandler throwableHandler){   this.defaultThrowableHandler=throwableHandler;   return this; } 
ROOT_LOGGER.error(consoleSlot == null ? "main" : consoleSlot)
flushStatements(false)
new InputStreamReader(in)
Values.WEBSOCKET.equalsIgnoreCase(upgrade)
id=7
new GenericAggregationFunction(name,inputTypes,intermediateType,outputType,false,aggregationAnnotation.approximate(),factory)
case JOIN: 
mock.setResultWaitTime(3000)
Site.me().setRetryTimes(3).setSleepTime(0)
fireMessageReceived(ctx,message)
type.equalsIgnoreCase("integer")
config.isAutoRead()
streamCachingStrategy.setSpoolThreshold(1l)
factory.getEmbdeddedServletContainer(exampleServletRegistration(),new FilterRegistrationBean(new ExampleFilter()))
new CSVFilter(columns)
new CardinalityAggregatorFactory(name,Arrays.asList(input),byRow)
new ExchangePatternType(exchangePattern)
assertEquals(expectedResponse,orig.getResponse())
log.makeAlert("Failed to remove segment")
new Entry[0xff]
Arrays.asList(RFXComValueSelector.RAW_DATA,RFXComValueSelector.SIGNAL_LEVEL,RFXComValueSelector.COMMAND,RFXComValueSelector.DIMMING_LEVEL)
assertEquals(model.getProperties().get(COUNT).getType(),"integer")
factory.getProxy()
mkdirs(mBaseDir)
hotDrinkDelay=500
this.referenceId == referenceId
UserGroupInformation.getLoginUser().reloginFromKeytab()
Assert.assertEquals(configs.size(),1)
c.getDomain() == null
public abstract class AbstractHikariConfig implements HikariConfigMBean {   private static final Logger LOGGER=LoggerFactory.getLogger(HikariConfig.class);   private static final long CONNECTION_TIMEOUT=TimeUnit.SECONDS.toMillis(30);   private static final long VALIDATION_TIMEOUT=TimeUnit.SECONDS.toMillis(5);   private static final long IDLE_TIMEOUT=TimeUnit.MINUTES.toMillis(10);   private static final long MAX_LIFETIME=TimeUnit.MINUTES.toMillis(30);   private static int poolNumber;   private static boolean unitTest;   private volatile long connectionTimeout;   private volatile long validationTimeout;   private volatile long idleTimeout;   private volatile long leakDetectionThreshold;   private volatile long maxLifetime;   private volatile int maxPoolSize;   private volatile int minIdle;   private String catalog;   private String connectionCustomizerClassName;   private String connectionInitSql;   private String connectionTestQuery;   private String dataSourceClassName;   private String dataSourceJndiName;   private String driverClassName;   private String jdbcUrl;   private String password;   private String poolName;   private String transactionIsolationName;   private String username;   private boolean isAutoCommit;   private boolean isReadOnly;   private boolean isInitializationFailFast;   private boolean isIsolateInternalQueries;   private boolean isRegisterMbeans;   private boolean isAllowPoolSuspension;   private DataSource dataSource;   private Properties dataSourceProperties;   private IConnectionCustomizer customizer;   private ThreadFactory threadFactory;   private Object metricRegistry;   private Object healthCheckRegistry;   private Properties healthCheckProperties;   /**   * Default constructor  */   public AbstractHikariConfig(){     dataSourceProperties=new Properties();     healthCheckProperties=new Properties();     connectionTimeout=CONNECTION_TIMEOUT;     validationTimeout=VALIDATION_TIMEOUT;     idleTimeout=IDLE_TIMEOUT;     isAutoCommit=true;     isInitializationFailFast=true;     minIdle=-1;     maxPoolSize=10;     maxLifetime=MAX_LIFETIME;     customizer=new IConnectionCustomizer(){       @Override public void customize(      Connection connection) throws SQLException {       }     } ;     String systemProp=System.getProperty("hikaricp.configurationFile");     if (systemProp != null) {       loadProperties(systemProp);     }   }   /**   * Construct a HikariConfig from the specified properties object.  * @param properties the name of the property file  */   public AbstractHikariConfig(  Properties properties){     this();     PropertyBeanSetter.setTargetFromProperties(this,properties);   }   /**   * Construct a HikariConfig from the specified property file name.  <code>propertyFileName</code> will first be treated as a path in the file-system, and if that fails the  ClassLoader.getResourceAsStream(propertyFileName) will be tried.  * @param propertyFileName the name of the property file  */   public AbstractHikariConfig(  String propertyFileName){     this();     loadProperties(propertyFileName);   }   /**   * Get the default catalog name to be set on connections.  * @return the default catalog name  */   public String getCatalog(){     return catalog;   }   /**   * Set the default catalog name to be set on connections.  * @param catalog the catalog name, or null  */   public void setCatalog(  String catalog){     this.catalog=catalog;   }   /**   * Get the name of the connection customizer class to instantiate and execute on all new connections.  * @return the name of the customizer class, or null  */   @Deprecated public String getConnectionCustomizerClassName(){     return connectionCustomizerClassName;   }   /**   * Set the name of the connection customizer class to instantiate and execute on all new connections.  * @param connectionCustomizerClassName the name of the customizer class  */   @Deprecated public void setConnectionCustomizerClassName(  String connectionCustomizerClassName){     this.connectionCustomizerClassName=connectionCustomizerClassName;     LOGGER.warn("The connectionCustomizerClassName property has been deprecated and may be removed in a future release");   }   /**   * Get the customizer instance specified by the user.  * @return an instance of IConnectionCustomizer  */   @Deprecated public IConnectionCustomizer getConnectionCustomizer(){     return customizer;   }   /**   * Set the connection customizer to be used by the pool.  * @param customizer an instance of IConnectionCustomizer  */   @Deprecated public void setConnectionCustomizer(  IConnectionCustomizer customizer){     this.customizer=customizer;     LOGGER.warn("The connectionCustomizer property has been deprecated and may be removed in a future release");   }   /**   * Get the SQL query to be executed to test the validity of connections.  * @return the SQL query string, or null   */   public String getConnectionTestQuery(){     return connectionTestQuery;   }   /**   * Set the SQL query to be executed to test the validity of connections. Using the JDBC4 <code>Connection.isValid()</code> method to test connection validity can be more efficient on some databases and is recommended.  See  {@link HikariConfig#setJdbc4ConnectionTest(boolean)}.  * @param connectionTestQuery a SQL query string  */   public void setConnectionTestQuery(  String connectionTestQuery){     this.connectionTestQuery=connectionTestQuery;   }   /**   * Get the SQL string that will be executed on all new connections when they are created, before they are added to the pool.  * @return the SQL to execute on new connections, or null  */   public String getConnectionInitSql(){     return connectionInitSql;   }   /**   * Set the SQL string that will be executed on all new connections when they are created, before they are added to the pool.  If this query fails, it will be treated as a failed connection attempt.  * @param connectionInitSql the SQL to execute on new connections  */   public void setConnectionInitSql(  String connectionInitSql){     this.connectionInitSql=connectionInitSql;   }   /**   * {@inheritDoc}   */   @Override public long getConnectionTimeout(){     return connectionTimeout;   }   /**   * {@inheritDoc}   */   @Override public void setConnectionTimeout(  long connectionTimeoutMs){     if (connectionTimeoutMs == 0) {       this.connectionTimeout=Integer.MAX_VALUE;     }  else     if (connectionTimeoutMs < 1000) {       throw new IllegalArgumentException("connectionTimeout cannot be less than 1000ms");     }  else {       this.connectionTimeout=connectionTimeoutMs;     }   }   /**   * {@inheritDoc}   */   @Override public long getValidationTimeout(){     return validationTimeout;   }   /**   * {@inheritDoc}   */   @Override public void setValidationTimeout(  long validationTimeoutMs){     if (validationTimeoutMs < 1000) {       throw new IllegalArgumentException("validationTimeout cannot be less than 1000ms");     }  else {       this.validationTimeout=validationTimeoutMs;     }   }   /**   * Get the  {@link DataSource} that has been explicitly specified to be wrapped by thepool.  * @return the {@link DataSource} instance, or null  */   public DataSource getDataSource(){     return dataSource;   }   /**   * Set a  {@link DataSource} for the pool to explicitly wrap.  This setter is notavailable through property file based initialization.  * @param dataSource a specific {@link DataSource} to be wrapped by the pool  */   public void setDataSource(  DataSource dataSource){     this.dataSource=dataSource;   }   public String getDataSourceClassName(){     return dataSourceClassName;   }   public void setDataSourceClassName(  String className){     this.dataSourceClassName=className;   }   public void addDataSourceProperty(  String propertyName,  Object value){     dataSourceProperties.put(propertyName,value);   }   public String getDataSourceJNDI(){     return this.dataSourceJndiName;   }   public void setDataSourceJNDI(  String jndiDataSource){     this.dataSourceJndiName=jndiDataSource;   }   public Properties getDataSourceProperties(){     return dataSourceProperties;   }   public void setDataSourceProperties(  Properties dsProperties){     dataSourceProperties.putAll(dsProperties);   }   public String getDriverClassName(){     return driverClassName;   }   public void setDriverClassName(  String driverClassName){     try {       Class<?> driverClass=this.getClass().getClassLoader().loadClass(driverClassName);       driverClass.newInstance();       this.driverClassName=driverClassName;     }  catch (    Exception e) {       throw new RuntimeException("driverClassName specified class '" + driverClassName + "' could not be loaded",e);     }   }   /**   * {@inheritDoc}   */   @Override public long getIdleTimeout(){     return idleTimeout;   }   /**   * {@inheritDoc}   */   @Override public void setIdleTimeout(  long idleTimeoutMs){     if (idleTimeoutMs < 0) {       throw new IllegalArgumentException("idleTimeout cannot be negative");     }     this.idleTimeout=idleTimeoutMs;   }   public String getJdbcUrl(){     return jdbcUrl;   }   public void setJdbcUrl(  String jdbcUrl){     this.jdbcUrl=jdbcUrl;   }   /**   * Get the default auto-commit behavior of connections in the pool.  * @return the default auto-commit behavior of connections  */   public boolean isAutoCommit(){     return isAutoCommit;   }   /**   * Set the default auto-commit behavior of connections in the pool.  * @param isAutoCommit the desired auto-commit default for connections  */   public void setAutoCommit(  boolean isAutoCommit){     this.isAutoCommit=isAutoCommit;   }   /**   * Get the pool suspension behavior (allowed or disallowed).  * @return the pool suspension behavior  */   public boolean isAllowPoolSuspension(){     return isAllowPoolSuspension;   }   /**   * Set whether or not pool suspension is allowed.  There is a performance impact when pool suspension is enabled.  Unless you need it (for a redundancy system for example) do not enable it.  * @param isAllowPoolSuspension the desired pool suspension allowance  */   public void setAllowPoolSuspension(  boolean isAllowPoolSuspension){     this.isAllowPoolSuspension=isAllowPoolSuspension;   }   /**   * Get whether or not the construction of the pool should throw an exception if the minimum number of connections cannot be created.  * @return whether or not initialization should fail on error immediately  */   public boolean isInitializationFailFast(){     return isInitializationFailFast;   }   /**   * Set whether or not the construction of the pool should throw an exception if the minimum number of connections cannot be created.  * @param failFast true if the pool should fail if the minimum connections cannot be created  */   public void setInitializationFailFast(  boolean failFast){     isInitializationFailFast=failFast;   }   public boolean isIsolateInternalQueries(){     return isIsolateInternalQueries;   }   public void setIsolateInternalQueries(  boolean isolate){     this.isIsolateInternalQueries=isolate;   }   @Deprecated public boolean isJdbc4ConnectionTest(){     return false;   }   @Deprecated public void setJdbc4ConnectionTest(  boolean useIsValid){     LOGGER.warn("The jdbcConnectionTest property is now deprecated, see the documentation for connectionTestQuery");   }   /**   * Get the Codahale MetricRegistry, could be null.  * @return the codahale MetricRegistry instance  */   public Object getMetricRegistry(){     return metricRegistry;   }   /**   * Set a Codahale MetricRegistry to use for HikariCP.  * @param metricRegistry the Codahale MetricRegistry to set  */   public void setMetricRegistry(  Object metricRegistry){     if (metricRegistry != null) {       if (metricRegistry instanceof String) {         try {           InitialContext initCtx=new InitialContext();           metricRegistry=(MetricRegistry)initCtx.lookup((String)metricRegistry);         }  catch (        NamingException e) {           throw new IllegalArgumentException(e);         }       }       if (!(metricRegistry instanceof MetricRegistry)) {         throw new IllegalArgumentException("Class must be an instance of com.codahale.metrics.MetricRegistry");       }     }     this.metricRegistry=metricRegistry;   }   /**   * Get the Codahale HealthCheckRegistry, could be null.  * @return the Codahale HealthCheckRegistry instance  */   public Object getHealthCheckRegistry(){     return healthCheckRegistry;   }   /**   * Set a Codahale HealthCheckRegistry to use for HikariCP.  * @param healthCheckRegistry the Codahale HealthCheckRegistry to set  */   public void setHealthCheckRegistry(  Object healthCheckRegistry){     if (healthCheckRegistry != null) {       if (healthCheckRegistry instanceof String) {         try {           InitialContext initCtx=new InitialContext();           healthCheckRegistry=(HealthCheckRegistry)initCtx.lookup((String)healthCheckRegistry);         }  catch (        NamingException e) {           throw new IllegalArgumentException(e);         }       }       if (!(healthCheckRegistry instanceof HealthCheckRegistry)) {         throw new IllegalArgumentException("Class must be an instance of com.codahale.metrics.health.HealthCheckRegistry");       }     }     this.healthCheckRegistry=healthCheckRegistry;   }   public Properties getHealthCheckProperties(){     return healthCheckProperties;   }   public void setHealthCheckProperties(  Properties healthCheckProperties){     this.healthCheckProperties.putAll(healthCheckProperties);   }   public void addHealthCheckProperty(  String key,  String value){     healthCheckProperties.setProperty(key,value);   }   public boolean isReadOnly(){     return isReadOnly;   }   public void setReadOnly(  boolean readOnly){     this.isReadOnly=readOnly;   }   public boolean isRegisterMbeans(){     return isRegisterMbeans;   }   public void setRegisterMbeans(  boolean register){     this.isRegisterMbeans=register;   }   /**   * {@inheritDoc}   */   @Override public long getLeakDetectionThreshold(){     return leakDetectionThreshold;   }   /**   * {@inheritDoc}   */   @Override public void setLeakDetectionThreshold(  long leakDetectionThresholdMs){     this.leakDetectionThreshold=leakDetectionThresholdMs;   }   /**   * {@inheritDoc}   */   @Override public long getMaxLifetime(){     return maxLifetime;   }   /**   * {@inheritDoc}   */   @Override public void setMaxLifetime(  long maxLifetimeMs){     this.maxLifetime=maxLifetimeMs;   }   /**   * {@inheritDoc}   */   @Override public int getMaximumPoolSize(){     return maxPoolSize;   }   /**   * {@inheritDoc}   */   @Override public void setMaximumPoolSize(  int maxPoolSize){     if (maxPoolSize < 1) {       throw new IllegalArgumentException("maxPoolSize cannot be less than 1");     }     this.maxPoolSize=maxPoolSize;   }   /**   * {@inheritDoc}   */   @Override public int getMinimumIdle(){     return minIdle;   }   /**   * {@inheritDoc}   */   @Override public void setMinimumIdle(  int minIdle){     if (minIdle < 0) {       throw new IllegalArgumentException("minimumIdle cannot be negative");     }     this.minIdle=minIdle;   }   /**   * Get the default password to use for DataSource.getConnection(username, password) calls.  * @return the password  */   public String getPassword(){     return password;   }   /**   * Set the default password to use for DataSource.getConnection(username, password) calls.  * @param password the password  */   public void setPassword(  String password){     this.password=password;   }   /**   * {@inheritDoc}   */   @Override public String getPoolName(){     return poolName;   }   /**   * Set the name of the connection pool.  This is primarily used for the MBean to uniquely identify the pool configuration.  * @param poolName the name of the connection pool to use  */   public void setPoolName(  String poolName){     this.poolName=poolName;   }   public String getTransactionIsolation(){     return transactionIsolationName;   }   /**   * Set the default transaction isolation level.  The specified value is the constant name from the <code>Connection</code> class, eg.  <code>TRANSACTION_REPEATABLE_READ</code>.  * @param isolationLevel the name of the isolation level  */   public void setTransactionIsolation(  String isolationLevel){     this.transactionIsolationName=isolationLevel;   }   /**   * Get the default username used for DataSource.getConnection(username, password) calls.  * @return the username  */   public String getUsername(){     return username;   }   /**   * Set the default username used for DataSource.getConnection(username, password) calls.  * @param username the username  */   public void setUsername(  String username){     this.username=username;   }   /**   * Get the thread factory used to create threads.  * @return the thread factory (may be null, in which case the default thread factory is used)  */   public ThreadFactory getThreadFactory(){     return threadFactory;   }   /**   * Set the thread factory to be used to create threads.  * @param threadFactory the thread factory (setting to null causes the default thread factory to be used)  */   public void setThreadFactory(  ThreadFactory threadFactory){     this.threadFactory=threadFactory;   }   public void validate(){     Logger logger=LoggerFactory.getLogger(getClass());     validateNumerics();     if (connectionCustomizerClassName != null) {       try {         getClass().getClassLoader().loadClass(connectionCustomizerClassName);       }  catch (      Exception e) {         logger.warn("connectionCustomizationClass specified class '" + connectionCustomizerClassName + "' could not be loaded",e);         connectionCustomizerClassName=null;       }     }     if (driverClassName != null && jdbcUrl == null) {       logger.error("when specifying driverClassName, jdbcUrl must also be specified");       throw new IllegalStateException("when specifying driverClassName, jdbcUrl must also be specified");     }  else     if (driverClassName != null && dataSourceClassName != null) {       logger.error("both driverClassName and dataSourceClassName are specified, one or the other should be used");       throw new IllegalStateException("both driverClassName and dataSourceClassName are specified, one or the other should be used");     }  else     if (jdbcUrl != null) {     }  else     if (dataSource == null && dataSourceClassName == null) {       logger.error("one of either dataSource, dataSourceClassName, or jdbcUrl and driverClassName must be specified");       throw new IllegalArgumentException("one of either dataSource or dataSourceClassName must be specified");     }  else     if (dataSource != null && dataSourceClassName != null) {       logger.warn("both dataSource and dataSourceClassName are specified, ignoring dataSourceClassName");     }     if (transactionIsolationName != null) {       UtilityElf.getTransactionIsolation(transactionIsolationName);     }     if (poolName == null) {       poolName="HikariPool-" + poolNumber++;     }     if (LOGGER.isDebugEnabled() || unitTest) {       logConfiguration();     }   }   private void validateNumerics(){     Logger logger=LoggerFactory.getLogger(getClass());     if (validationTimeout > connectionTimeout && connectionTimeout != 0) {       logger.warn("validationTimeout is greater than connectionTimeout, setting validationTimeout to connectionTimeout.");       validationTimeout=connectionTimeout;     }     if (minIdle < 0 || minIdle > maxPoolSize) {       minIdle=maxPoolSize;     }     if (maxLifetime < 0) {       logger.error("maxLifetime cannot be negative.");       throw new IllegalArgumentException("maxLifetime cannot be negative.");     }  else     if (maxLifetime > 0 && maxLifetime < TimeUnit.SECONDS.toMillis(30)) {       logger.warn("maxLifetime is less than 30000ms, using default {}ms.",MAX_LIFETIME);       maxLifetime=MAX_LIFETIME;     }     if (idleTimeout != 0 && idleTimeout < TimeUnit.SECONDS.toMillis(10)) {       logger.warn("idleTimeout is less than 10000ms, using default {}ms.",IDLE_TIMEOUT);       idleTimeout=IDLE_TIMEOUT;     }  else     if (idleTimeout > maxLifetime && maxLifetime > 0) {       logger.warn("idleTimeout is greater than maxLifetime, setting to maxLifetime.");       idleTimeout=maxLifetime;     }     if (leakDetectionThreshold != 0 && leakDetectionThreshold < TimeUnit.SECONDS.toMillis(2) && !unitTest) {       logger.warn("leakDetectionThreshold is less than 2000ms, setting to minimum 2000ms.");       leakDetectionThreshold=2000L;     }   }   private void logConfiguration(){     LOGGER.debug("HikariCP pool {} configuration:",poolName);     final Set<String> propertyNames=new TreeSet<String>(PropertyBeanSetter.getPropertyNames(HikariConfig.class));     for (    String prop : propertyNames) {       try {         Object value=PropertyBeanSetter.getProperty(prop,this);         if ("dataSourceProperties".equals(prop)) {           Properties dsProps=PropertyBeanSetter.copyProperties(dataSourceProperties);           dsProps.setProperty("password","<masked>");           value=dsProps;         }         value=(prop.contains("password") ? "<masked>" : value);         LOGGER.debug((prop + "................................................").substring(0,32) + (value != null ? value : ""));       }  catch (      Exception e) {         continue;       }     }   }   abstract protected void loadProperties(  String propertyFileName);   public void copyState(  AbstractHikariConfig other){     for (    Field field : AbstractHikariConfig.class.getDeclaredFields()) {       if (!Modifier.isFinal(field.getModifiers())) {         field.setAccessible(true);         try {           field.set(other,field.get(this));         }  catch (        Exception e) {           throw new RuntimeException("Exception copying HikariConfig state: " + e.getMessage(),e);         }       }     }   } } 
put(TYPES,new MapTypeCaster(),Map.class,Double.class)
Assert.fail()
PathUtils.concatPath(filePath,YML_FILE_DIR)
args.length < 1
telegram.getTimestamp() < currentTime
data.limit()
preserve.toString()
asList(4L)
completionLatch.await(1200,TimeUnit.MILLISECONDS)
compressedSliceInput.length()
private ErrorWrapperEmbeddedServletContainerFactory filter=new ErrorWrapperEmbeddedServletContainerFactory(); 
role.description().get()
/**   * Converts quoted property accesses to dot syntax (a['b'] -> a.b)   */ COVERT_TO_DOTTED_PROPERTIES{   @Override void apply(  CompilerOptions options,  boolean value){     options.setConvertToDottedProperties(value);   }   @Override String getJavaInfo(){     return "options.setConvertToDottedProperties(true)";   } } 
mock.message(0).arrives().between(7,9)
@Override public Cell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   if (clonedBaseCell instanceof ByteBufferCell) {     return new TagRewriteByteBufferCell((ByteBufferCell)clonedBaseCell,this.tags);   }   return new TagRewriteCell(clonedBaseCell,this.tags); } 
configuredScriptEngineNames == null
new LocalizedXStreams(classLoader)
LOG.info("Finding components in url: {}",url)
assertTrue(CompressionTest.testCompression("SNAPPY"))
asyncContext.continueAsyncTraceObject()
target.setField(1,edge)
mMountTable.resolve(getPath(next)).getPath()
executor.submit(new NamedRunnable("OkHttp %s ping %08x%08x",hostName,payload1,payload2){   @Override public void execute(){     try {       writePing(reply,payload1,payload2,ping);     }  catch (    IOException ignored) {     }   } } )
expectQueryToFail("UserWith:Colon",ldapUserPassword,INVALID_CREDENTIALS_ERROR)
new StringInputRowParser(new DelimitedParseSpec(new TimestampSpec("ts","iso"),new DimensionsSpec(Arrays.asList(DIMENSIONS),null,null),"\t",Arrays.asList(COLUMNS)),null,null,null)
factory.get(sBodyWildcard,NO_ANNOTATIONS,retrofit)
from("direct:start").multicast(new MyAggregationStrategy()).parallelProcessing().timeout(2000)
return context; 
logger.info("Strip code")
id=6
content().copy()
grammar.getTokenNames()
id=15861
1024 * 64
functionJSDocInfo != null
Status.constructStatuses(get(getBaseURL() + "statuses/public_timeline.json",false))
handshakeStatus == HandshakeStatus.NOT_HANDSHAKING
Objects.hash(expressions)
pws.getPatientPrograms(patient,program,null,enrollmentDate,completionDate,null,false)
DEFAULT_BLOCK_SIZE=10
ImmutableList.of(sourcesAsStrings)
THREADS_PER_CLIENT=8
EnglishUdLas=84.9873
JMXJsonServlet.class
DiagnosticType.error("JSC_CONSTANT_REASSIGNED_VALUE_ERROR","constant {0} assigned a value more than once.\n" + "Original definition at {1}")
BeanMapper.mapList(books,Book.class,BookDto.class)
public DerivedBuilder setRealmName(String realmName){   realm().setRealmName(realmName);   return this; } 
lineageInfo.getParents()
taken > 190
ensureInChild(parent,FooImpl.class,FooBar.class,Foo.class)
LOG.info("Ignoring duplicate journal entry with SN {} when next SN is {}",newSN,mNextSequenceNumberToRead)
redeliveryDelay > maximumRedeliveryDelay
@Override public ResponseImpl schema(Property property){   this.setSchema(property);   return this; } 
new LazyTailArrayNode(record,schema)
parent.getRegionName()
securityDomain != null
new StringBuilder(730)
super.mySetupMutualAuthServerIsValidException(cause)
SpringBootWebSecurityConfiguration.class
Assert.assertTrue(System.currentTimeMillis() - now < 5000)
queue.size() < 100000
new JSONParseSpec(new TimestampSpec("timestamp","auto"),new DimensionsSpec(null,null,null),JSONParseSpec.JSON)
connections.get(address)
config.getBroadcasterFactory().lookup(m.broadcaster(),true)
-region.getRegionHeight()
createMessageConsumer(session,destinationName,messageSelector,true,null,true)
t=b.getBroadcasterConfig().applyFilters(r,t)
getUrl()
Call<L>
"Interrupted when attempting to close writer for end point: " + ep
4 < buf.length - count
Foundation.NSLog("[debug] " + tag + ": "+ message)
outList.size()
cal.set(1900,1,1,hour,minute,second)
this(type,0); 
new WebSocketServerHandshakerFactory(getWebSocketLocation(req),null,false)
((StringLiteral)literal).getSlice()
map.put(USERNAME_KEY,password)
private static class TestException extends Exception {   private static final long serialVersionUID=1L;   @Override public void printStackTrace(  PrintWriter printWriter){     printWriter.print("stackTrace");   } } 
factory.get(sBodyGeneric,NO_ANNOTATIONS,retrofit)
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
WebSocketEventListener.class.cast(l).onMessage(event)
rj.mapProgress()
timeoutLatch.await(1200,TimeUnit.MILLISECONDS)
/**   * Gets the key of service port.  * @return key of service port  */ public String getPortKey(){   return mPortKey; } 
/**   * Changes the group of a file or directory specified by args recursively.  */ public final class ChgrpRecursiveCommand extends AbstractACLCommand {   public ChgrpRecursiveCommand(  TachyonConf conf,  TachyonFileSystem tfs){     super(conf,tfs);   }   @Override public String getCommandName(){     return "chgrpr";   }   @Override protected int getNumOfArgs(){     return 2;   }   @Override public void run(  String... args) throws IOException {     String group=args[0];     TachyonURI path=new TachyonURI(args[1]);     chgrp(path,group,true);   }   @Override public String getUsage(){     return "chgrpr <group> <path>";   } } 
fLines.add(st.nextToken())
pubSubDomain=true
refreshableViewWrapper.addView(newEmptyView,ViewGroup.LayoutParams.MATCH_PARENT,ViewGroup.LayoutParams.MATCH_PARENT)
routerChain.notifyFullInvokers(groupInvokers,getUrl())
Color.fromRGB(0xC354CD)
GL20.glUniformMatrix4(location,transpose,toFloatBuffer(value,offset,count << 4))
stage.compareTo(currentStage) > 0
localX2 * cos
node1.checkTreeEqualsSilent(node2)
System.getProperty(propName)
assertEquals(1,historyService.createHistoricActivityInstanceQuery().executionId(processInstance.getId()).list().size())
DiagnosticType.warning("JSC_REDECLARED_VARIABLE","Redeclared variable: {0}")
NbPreferences.forModule(DataTableTopComponent.class).getBoolean(DATA_LABORATORY_ONLY_VISIBLE,false)
CamelContextHelper.parseInteger(getCamelContext(),keepAliveTime)
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
logException(id,exception)
options.checkProvides.isOn()
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.BeforeAnnotation.class,CoreAnnotations.AfterAnnotation.class,CoreAnnotations.TokenBeginAnnotation.class,CoreAnnotations.TokenEndAnnotation.class,CoreAnnotations.PositionAnnotation.class,CoreAnnotations.IndexAnnotation.class,CoreAnnotations.OriginalTextAnnotation.class,CoreAnnotations.ValueAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class)
new SimpleDateFormat(format)
GL20.glGetVertexAttrib(index,pname,params)
new CommandFormatException("Communication error",e)
logger.info("Named " + namedCount + " anon functions using "+ bytesUsed+ " bytes")
public final TFAgentStatMappter tFAgentStatMappter=new TFAgentStatMappter(); 
GL.glCopyTexImage2DEXT(target,level,internalformat,x,y,width,height,border)
metastore.getHostText()
ServiceAuthorizationManager.refresh(conf,new HBasePolicyProvider())
id=53
IOConverter.toInputStream(s)
tupleInfo.getMessageId() != null
bean.getCollectionCount()
Objects.isNull(value)
JsonObject.createObjectMapper().getJsonFactory()
mapper.getJsonFactory()
dataSource.setInitExceptionThrow(true)
private final String mPortKey; 
final Command cmd
new CacheCreateConfigOperation(config,true)
assertEquals(avDegree,2.0)
TrustManagerFactory.getDefaultAlgorithm()
engine.execute(cypher).toString()
new DefaultPropertyNamePatternsMatcher(TARGET_NAME_DELIMETERS,this.targetName)
!first
new PkgControl(pkg,regex)
Color.fromRGB(0x7B2FBE)
return handshakeTimeoutMillis; 
new UDFArgumentTypeException(2,"The first and seconds arguments of function NLV should have the same type, " + "but they are different: \"" + arguments[0].getTypeName() + "\" and \""+ arguments[1].getTypeName()+ "\"")
connectionManager.markOwnerAddressAsClosed()
computeSemiJoin(inputStatistics,inputStatistics,x,unknown)
mock.expectedHeaderReceived(CaffeineConstants.ACTION_HAS_RESULT,false)
expectedMinimumCount == -1
Integer.valueOf(patchVersionString)
registration.registerOperationHandler(CommonAttributes.ADD_PROXY,ModClusterAddProxy.INSTANCE,addProxy,false)
lastCompletedOffset != lastCompletedOffset
SOURCE.deref()
DataTypes.TIME(9)
Objects.equals(builtInVersion,configuredVersion)
Assert.assertEquals(e.getCause().getMessage(),getNotAllowedExceptionMessage("helloForRoles"))
factory.get(sResultClass,NO_ANNOTATIONS,retrofit)
serverSocket == null
p > 0
connection.hdel(key)
Configuration.getLong(PropertyKey.USER_FILE_LOAD_TTL)
Bytes.toString(qualifierName)
LOG.trace("Trying to open resource [{}] as a class path resource using the classloader [{}].",this.getClass().getClassLoader())
@RunWith(HazelcastParallelClassRunner.class) @Category(value={QuickTest.class,ParallelTest.class}) public class ReplicatedMapLoadingTest extends ReplicatedMapBaseTest {   @Test public void testAsyncFillUp() throws Exception {     Config config=new Config();     String mapName=randomMapName();     ReplicatedMapConfig replicatedMapConfig=config.getReplicatedMapConfig(mapName);     replicatedMapConfig.setAsyncFillup(true);     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     fillMapsAndAssertMapSizeEventually(nodeFactory,config,mapName);   }   @Test public void testSyncFillUp() throws Exception {     Config config=new Config();     String mapName=randomMapName();     ReplicatedMapConfig replicatedMapConfig=config.getReplicatedMapConfig(mapName);     replicatedMapConfig.setAsyncFillup(false);     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     fillMapsAndAssertMapSizeEventually(nodeFactory,config,mapName);   }   private void fillMapsAndAssertMapSizeEventually(  TestHazelcastInstanceFactory nodeFactory,  Config config,  String mapName){     final int first=1000;     final int second=2000;     final int third=3000;     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<Integer,Integer> map1=instance1.getReplicatedMap(mapName);     fillMap(map1,0,first);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<Integer,Integer> map2=instance2.getReplicatedMap(mapName);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertMapSize("map1",first,map1);         assertMapSize("map2",first,map2);       }     } );     fillMap(map2,first,second);     HazelcastInstance instance3=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<Integer,Integer> map3=instance3.getReplicatedMap(mapName);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertMapSize("map1",second,map1);         assertMapSize("map2",second,map2);         assertMapSize("map3",second,map3);       }     } );     fillMap(map3,second,third);     HazelcastInstance instance4=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<Integer,Integer> map4=instance4.getReplicatedMap(mapName);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertMapSize("map1",third,map1);         assertMapSize("map2",third,map2);         assertMapSize("map3",third,map3);         assertMapSize("map4",third,map4);       }     } );   }   private void fillMap(  ReplicatedMap<Integer,Integer> map,  int start,  int end){     for (int i=start; i < end; i++) {       map.put(i,i);     }   }   private void assertMapSize(  String mapName,  int expectedMapSize,  ReplicatedMap<Integer,Integer> map){     assertEquals(format("%s should contain %d elements",mapName,expectedMapSize),expectedMapSize,map.size());   } } 
shardManager.commitShards(transactionId,tableId,columns,shardNodes,Optional.empty())
ssl.has(CommonAttributes.CIPHER_SUITE)
testComplete()
colorModeClass.equals("ScaledSizeMode")
msg.getType() == Message.Type.error
start.expectedMessageCount(6)
LOG.info("Table {} is disabled, give up reopening its regions")
key.equals(PropertyKey.ZOOKEEPER_ENABLED)
context.getContextPath()
latch.await(10,TimeUnit.MILLISECONDS)
port > 21000
TestSuite testSuite=new TestSuite(testClass); 
System.currentTimeMillis() + WAIT_SECONDS_BEFORE_JOIN + 1000
new ServiceActivatorContextImpl(batchBuilder)
RowingBoat captain=(RowingBoat)beans.get(ROWING_BEAN); 
subProperties.put(subName,value)
Assert.assertEquals(masterAddress,new InetSocketAddress("RemoteMaster3",defaultPort))
id=26
(Long)strategy.getOrNull(third)
from("direct:a").delay(3000)
id=19909
transform.setToRotation(new Vector3(1,0,1).nor(),angle)
new PooledCFAttribute(LOAD_BALANCING_CLASS_NAME,LOAD_BALANCE_POLICY_CLASS_NAME_METHOD)
new DoubleInetAddressDns()
Arrays.asList("dirty","log","serialVersionUID","DATE_TIME_PATTERN","TIME_PATTERN","DATE_PATTERN","FORM_NAMESPACE_PATH_SEPARATOR","FORM_NAMESPACE_PATH_MAX_LENGTH","obsId","groupMembers","uuid","changedBy","dateChanged","voided","voidedBy","voidReason","dateVoided","formNamespaceAndPath")
bindingConfiguration.getSource().getResourceValue(serviceBuilder,phaseContext,service.getManagedObjectInjector())
items[18]
types.length >= Tuple.MAX_ARITY
assertEquals(9,rows.size())
LOG.debug(e)
from(Constants.PARALLEL_LOANBROKER_URI).process(new CreditScoreProcessor(Constants.CREDITAGENCY_ADDRESS)).multicast(new BankResponseAggregationStrategy()).parallelProcessing(true)
hazelcastFactory.newHazelcastInstance()
resultEndpoint.setMinimumResultWaitTime(1000)
oldestInflightEntry != null
invocation.addAttachmentsIfAbsent(context)
part.getDataLocation()
report(n,MISPLACED_ANNOTATION)
setMinHeight(minWidth)
new PrestoException(INVALID_CAST_ARGUMENT,e)
acquiredChannelCount <= maxConnections
new JCacheProducer(this,cacheCnfiguration)
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
delayer != null
tsr.getReturnCode() != AbstractTaskResult.ReturnCode.SUCCESS || tsr.getReturnCode() != AbstractTaskResult.ReturnCode.TASK_NOT_FOUND
factory.lookup(DefaultBroadcaster.class,id)
new DynamicAwareEntry(uri,properties,lenient)
importedClassIndex.isEmpty()
await().atMost(5,TimeUnit.SECONDS)
new MockEnvironment("MockTask",3 * 1024 * 1024,new MockInputSplitProvider(),1024,new Configuration(),new ExecutionConfig(),maxParallelism,numSubtasks,subtaskIndex)
LOG.fatal("Cannot run ThriftServer")
items[21]
LinkedList<>
16 << 10
new IllegalArgumentException()
o instanceof Attribute
shardDao.insertShard(shard,tableId,null,0,0,0)
host.getHostText()
@Override public ResponseImpl headers(Map<String,Property> headers){   this.headers=headers;   return this; } 
connectPromise.setFailure(t)
new TransactionOptions().setDurability(0).setTimeout(10,TimeUnit.SECONDS)
new File(FilenameUtils.getBaseName(file) + "_dex2jar.jar")
isFieldKept(uniqueField,input)
Metric<Integer>
idleConnectionTimeout - nettyResponseFuture.getLastTouch()
@Converter
request.getRequestURI()
id=15830
Status.constructStatuses(get(getBaseURL() + "statuses/retweeted_to_me.json",null,true))
requestFilters.isEmpty()
server.getSegment(segment.getIdentifier()) != null && peon.getSegmentsToLoad().contains(segment)
setAttributeInternal(inodePath,false,entry.getOpTimeMs(),options)
"false".equals(showRelationships)
SemanticGraphFactory.makeFromTree(tree,mode,useExtras ? GrammaticalStructure.Extras.MAXIMAL : GrammaticalStructure.Extras.NONE,true,null)
getRequestMethod == null
Set<String>
defaultMaxRowsInMemory=500000
Math.min(aggregateData.getAvgColLen(),newData.getAvgColLen())
id=19908
removeBlockInternal(sessionId,blockId,BlockStoreLocation.anyTier())
blocked.isDone()
idleTimeout < 30000
@Override protected boolean handleResponse(ChannelHandlerContext ctx,Object response) throws HttpProxyConnectException {   if (response instanceof HttpResponse) {     if (status != null) {       throw new HttpProxyConnectException(exceptionMessage("too many responses"),null);     }     HttpResponse res=(HttpResponse)response;     status=res.status();     inboundHeaders=res.headers();   }   boolean finished=response instanceof LastHttpContent;   if (finished) {     if (status == null) {       throw new HttpProxyConnectException(exceptionMessage("missing response"),inboundHeaders);     }     if (status.code() != 200) {       throw new HttpProxyConnectException(exceptionMessage("status: " + status),inboundHeaders);     }   }   return finished; } 
FsDatasetImpl.LOG.info("Completed checkDirs. Removed " + removedVols.size() + " volumes. Current volumes: "+ this)
i < end
noPendingBlockIteration >= MAX_NO_PENDING_BLOCK_INTERATIONS
id=44
Thread.sleep(500)
endPosition.getPosition() < logfileoffset
Validate.notEmpty("Cookie name must not be empty")
this.transactionsRepository.removeTransaction(this.xidTransactionID)
obj.setContentEncoding(Mimetypes.MIMETYPE_BINARY_OCTET_STREAM)
new KernelStatement(mock(KernelTransactionImplementation.class),mock(IndexReaderFactory.class),scanStore,null,null,null,null)
Context.getVisitService().getAllVisitTypes(true)
Integer.valueOf(p.getProperty(screenName + ".id"))
hgraph.getMutualDegree(n)
registration.registerOperationHandler(CommonAttributes.STOP_CONTEXT,ModClusterStopContext.INSTANCE,stopContext,false)
paused.set(false)
reg.getCounters(transformFilter(filter))
mime == null
logger.debug("Invalid Atmosphere Version {}",javascriptVersion)
/**   * Add a  {@link AtmosphereResource} to the list of item to be notified whenthe  {@link Broadcaster#broadcast} is invoked.  * @param resource an {@link AtmosphereResource}  * @return {@link AtmosphereResource} if added, or null if it was already there.  */ AtmosphereResource addAtmosphereResource(AtmosphereResource resource); 
id=15852
Thread.sleep(1000)
22 * ClassSize.REFERENCE
PostgreSQLConnector.class
new Date(0)
!remoteTableHandle.isPresent()
new GeneralDataCoding(false,false,MessageClass.CLASS1,Alphabet.ALPHA_8_BIT)
DirectMessage.constructDirectMessages(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/statuses/friends/T4J_hudson.json"))
byteBuffer.get((SIZEOFLONG - 1) - i) & 0xff
log.error("Checking bounds key:[{}, {}) & col:[{}, {}) (expect {} keys)",new Object[]{keyStart,keyEnd,startCol,endCol,expected.size()})
id=50
LOG.debug("recovered from " + StringUtils.stringifyException(e))
Short.valueOf(value.toString())
boundary.startsWith("\"")
assertEquals(13,lm.getFields().size())
map.set(key,toStoreValue(value),0,TimeUnit.SECONDS)
LOG.error("PriviledgedActionException as:" + this + " cause:"+ cause)
w.println(padding)
dict.put(words[0],words[2])
Context.getVisitService().getAllVisitTypes()
gl.glDeleteBuffer(depthStencilPackedBufferHandle)
/**   * The root package controller.   */ private PkgControl root; 
minPriority == null ? 1 : minPriority
assertEquals(12,url.getPort())
callback.done(true)
LOG.info("Set the current default database as [{}] in the current default catalog [{}].",currentCatalogName,currentDatabaseName)
public DerivedBuilder setConnectionTimeoutInMs(int connectionTimeuot){   configBuilder.setConnectionTimeoutInMs(connectionTimeuot);   return this; } 
logger.debug("Queue length is {} - deferring HEAL.")
count < 0
id=37
LOG.warn("failed to send {} messages to {}: {}",numMessages,dstAddressPrefixedName,future.getCause())
ShrinkWrap.create(JavaArchive.class).addAsManifestResource(EmptyAsset.INSTANCE,"beans.xml")
getLsNoAclResultStr("/testRoot/testDir",files[1].getCreationTimeMs(),0,LsCommand.STATE_FOLDER)
Arrays.equals(this.element,other.element)
map.tryPut(key,newValue,8,TimeUnit.SECONDS)
client.get(path)
item == null
new LocalTachyonClusterResource(Constants.GB,Constants.KB,BLOCK_SIZE)
waitLatch.await(25,TimeUnit.MILLISECONDS)
boolean injvm() default false; 
yamlFactory.createJsonParser(input)
taskDao.findByUserId(1L,new Sort(Direction.ASC,"id"))
processor.open(w2,request)
new StringBuilder(674)
AdviceWithTasks.removeByToString(route,toString,selectLast,selectFirst,selectFrom,selectTo,maxDeep)
tFAgentStatMappter.map(agentStatBo)
ModuleFactory.stopModule(mod)
HBaseFsck.class
providerConfig.setTimeout(1000)
defaultCamelContext.removeRouteDefinition(id)
logger.trace("Receive queue TAKE: Length={}",recvQueue.size())
assertEquals("One propagated header is expected.",5,headers.toArray().length)
items[26]
getLog().error("register druid-driver mbean error",ex)
j++
id=22
from("jms:queue:order").to("bean:validateOrder").to("mock:validate").threads(20).unmarshal(mySecureDataFormat).delay(100)
outputBatchSize=25
LOG.error("Node " + path + " already exists and this is not a "+ "retry")
requestContext.getUri().getPath()
uuid.equals(NULL)
id=15854
localCache.put(name,NULL_ENTRY)
GL.glDrawArraysEXT(mode,first,count)
super.beginPass(n)
responseCode < OK && MULTIPLE_CHOICES <= responseCode
out.writeObject(entry.getValue())
assertThat(throttledLines(Duration.milliseconds(100))).doesNotHaveDuplicates().haveAtLeast(9,containsApplicationLog).haveAtMost(12,containsApplicationLog)
assertEquals(input.getFieldCount(),3)
StringBuffer text
uiAclHandler.permit(reqContext,op,conf)
checkArgument(partitionColumns.size() == values.size())
Bytes.toBytesBinary(tableOrRegionName)
logger.warn("The GENA Subscription for serviceID {} ended for device {}",subscription.getService().getServiceId(),subscription.getService().getDevice())
ast.atnState != null
c.setLong("hbase.hregion.memstore.flush.size",100000)
isStarted()
1000L * FILE_BYTES
badLine.getMessage()
args[5]
n.isArrayPattern()
Assert.assertEquals(3,visitor.getConditions().size())
ImmutableSet.of("reportUnknownTypes")
id=15862
GL20.glGetActiveAttrib(program,index,256,typeTmp)
testerAnnotation.getClass()
final Prototype testedPrototype
stats.getLastUpdateTime() > lastUpdateTime
assertEquals(service.state(),Service.State.FAILED)
System.currentTimeMillis() + start
new CacheCreateConfigRequest(cacheConfig,true,partitionId)
context.addStep(new NewStepHandler(){   public void execute(  final NewOperationContext context,  final ModelNode operation){     if (context.completeStep() == NewOperationContext.ResultAction.KEEP && context.isModelAffected()) {     }   } } ,NewOperationContext.Stage.VERIFY)
id=13306
System.currentTimeMillis() + 5000
TfsShell.convertMsToDate(files[1].getCreationTimeMs())
mCurrentBlockLeftByte > tLen
LOG.info("Cannot access storage directory " + rootPath)
startTest(getMethodName(),false)
this.connectTo(vertex,null,null,-1,-1,DistributionPattern.BIPARTITE,false)
public void testJobQueues() throws IOException {   JobClient jc=new JobClient(mrCluster.createJobConf());   String expectedQueueInfo="Maximum Tasks Per Job :: 10";   JobQueueInfo[] queueInfos=jc.getQueues();   assertNotNull(queueInfos);   assertEquals(1,queueInfos.length);   assertEquals("default",queueInfos[0].getQueueName());   assertEquals(QueueState.RUNNING.getStateName(),queueInfos[0].getQueueState());   JobConf conf=mrCluster.createJobConf();   FileSystem fileSys=dfsCluster.getFileSystem();   conf=configureWaitingJob(conf);   conf.setJobName("test-job-queue-info-test");   fileSys.delete(SHARE_DIR,true);   RunningJob rJob=jc.submitJob(conf);   while (rJob.getJobState() != JobStatus.RUNNING) {     UtilsForTests.waitFor(10);   }   int numberOfJobs=0;   for (  JobQueueInfo queueInfo : queueInfos) {     JobStatus[] jobStatusList=jc.getJobsFromQueue(queueInfo.getQueueName());     assertNotNull(queueInfo.getQueueName());     assertNotNull(queueInfo.getSchedulingInfo());     assertEquals(expectedQueueInfo,queueInfo.getSchedulingInfo());     numberOfJobs+=jobStatusList.length;     for (    JobStatus status : jobStatusList) {       assertEquals(JOB_SCHEDULING_INFO,status.getSchedulingInfo());     }   }   assertEquals(1,numberOfJobs);   UtilsForTests.signalTasks(dfsCluster,fileSys,getSignalFile(),getSignalFile(),4); } 
comparePartitionOwnership(false,localMember,partition)
new FieldFrame(currentFrame,isStaticInnerType,type,type == TokenTypes.CLASS_DEF || type == TokenTypes.ENUM_DEF ? ast.findFirstToken(TokenTypes.IDENT).getText() : null)
public DerivedBuilder setSSLContext(final SSLContext sslContext){   configBuilder.setSSLContext(sslContext);   return this; } 
LOG.warn("DataNode is out of memory. Will retry in 30 seconds.",ie)
@Override public ResponseImpl example(String type,Object example){   if (examples == null) {     examples=new HashMap<String,Object>();   }   examples.put(type,example);   return this; } 
assertEquals(ex.getCause().getMessage(),"Unable to read 1 bytes, got 0")
/**   * Column number filter.   */ private CSVFilter columnFilter; 
queue.poll(2,TimeUnit.SECONDS)
id=15800
mockRegionInfo.isMetaRegion()
wsdlLocation.length() > 0
LOG.info("Getting asynchronous method stub from channel")
new TaskStatusUpdateEvent(counters,progress,stats)
StringBuffer pattern=new StringBuffer(this.prefix); 
originalValue != null
executor.submit(new NamedRunnable("OkHttp %s ACK Settings",hostName){   @Override public void execute(){     try {       frameWriter.ackSettings(peerSettings);     }  catch (    IOException ignored) {     }   } } )
MapPutParameters.encodeSizeCost(NAME,BYTES_DATA,BYTES_DATA,THE_LONG,THE_LONG,THE_BOOLEAN)
logError(rcurly,"rcurly",expandedTabsColumnNo(rcurly))
targetActor.addCaptureListener(listener)
newState.score()
logger.info("Future response is already set! Current response: " + response + ", Offered response: "+ offeredResponse+ ", Invocation: "+ invocation)
Color.fromRGB(0x3B511A)
Preconditions.checkNotNull("Streaming Job name should not be null.")
bindingConfig != null
logger.info("Creating extern file for exports")
offsetRepository != null
this.alphabet
n <= k
member.getType(beanDesc.bindingsForBeanType())
mHeartbeat != null
executionStats.getSplits()
setPin(file,false)
assertEquals(9,set.size())
@NonNull
/**   * Checkstyle frame model.   */ private final transient CheckstyleFrameModel model=new CheckstyleFrameModel(); 
context.var("long")
new SpringApplicationBuilder(SampleSecureApplication.class).properties("security.basic.enabled=false","security.user.password=password")
/**   * A  {@link ChannelHandler} that is notified when it is added to or removedfrom a  {@link ChannelPipeline}.  Please note that the methods of this handler is called only when the  {@link ChannelPipeline} it belongs to hasbeen  {@linkplain ChannelPipeline#attach(Channel,ChannelSink) attached}.  * @author The Netty Project (netty-dev@lists.jboss.org)  * @author Trustin Lee (tlee@redhat.com)  * @version $Rev$, $Date$  */ public interface LifeCycleAwareChannelHandler extends ChannelHandlerContext {   void beforeAdd(  ChannelHandlerContext ctx) throws Exception ;   void afterAdd(  ChannelHandlerContext ctx) throws Exception ;   void beforeRemove(  ChannelHandlerContext ctx) throws Exception ;   void afterRemove(  ChannelHandlerContext ctx) throws Exception ; } 
ImmutableSet.of(modules)
200000 * 4 * 3
request.charset != null
ssl.has(CommonAttributes.CA_CERTIFICATE_FILE)
Outcome.match("missing database driver " + driverClassName)
new PairPongMsg(getMessageCount(),(byte)0,MaxCulMsgType.PAIR_PONG,(byte)0,this.srcAddr,dstAddr)
registerConsumer(newUUIDString(),newUUIDString(),owner,attributes)
realPointerIndex > AndroidInput.NUM_TOUCHES
HIVE_TABLE_OFFLINE(2,EXTERNAL)
HttpHeaderValues.IDENTITY.equals(targetContentEncoding)
qp.getUniqueItems()
fullName.split("[/@]",2)
new RuntimeException(ex)
this.thrown.equals("File must not be null")
log.error("Metric=[%s] has no StatsD type mapping",statsDMetric)
T resource
(uptime - days) * 60
assertThat(response).isEqualToIgnoringCase("Ok.\n")
pos < len
cs.getMetaData()
waitUntil(() -> clusterManager.getNodes().size() == 2,30_000)
dirtyOutputBuffer()
this.comparator
map.tryPut(key,value,8,TimeUnit.SECONDS)
new CancelJobSupervisorOperation(name,jobId,jobOwner)
return sinkMaxBufferSize; 
b.length() - 1
testError(js,VariableReferenceCheck.REDECLARED_VARIABLE)
return ES5; 
UriBuilder.fromResource(StreamAlertConditionResource.class).path("{conditionId}").build(alertCondition.getId())
Thread.sleep(50)
user.getSystemId() == null
id=15855
mTfs.setPin(mTfs.open(path),true)
config(" ",0)
loadMetadataSuceeded=true
IllegalArgumentException e
mock.expectedBodiesReceived("B+END","A+END")
RuntimeGlue optionalGlue
@ConditionalOnEnablednHealthIndicator("solr")
type.getDeclaredConstructor(String.class)
NONCONFORMING_LR_RULE(165,"rule <arg> is left recursive but doesn't conform to a pattern ANTLR can handle",ErrorSeverity.ERROR)
client.getVertx().setTimer(1,id -> checkExpired())
HELSINKY{   @Override public ServiceNowProducer get(  ServiceNowEndpoint endpoint) throws Exception {     return new HelsinkiServiceNowProducer(endpoint);   } } 
columnType.equalsIgnoreCase("long")
GL20.glUniform2(location,toFloatBuffer(v,offset,count << 1))
lookup(parseName(name))
c.getDeclaredConstructors()
AtmosphereRequest.class.isAssignableFrom(request.getClass())
public class TimesNewRoman extends FontMetrics { {     maxCharHeight=717;     widths[32]=250;     widths[33]=333;     widths[34]=408;     widths[35]=500;     widths[36]=500;     widths[37]=833;     widths[38]=777;     widths[39]=180;     widths[40]=333;     widths[41]=333;     widths[42]=500;     widths[43]=563;     widths[44]=250;     widths[45]=333;     widths[46]=250;     widths[47]=277;     widths[48]=500;     widths[49]=500;     widths[50]=500;     widths[51]=500;     widths[52]=500;     widths[53]=500;     widths[54]=500;     widths[55]=500;     widths[56]=500;     widths[57]=500;     widths[58]=277;     widths[59]=277;     widths[60]=563;     widths[61]=563;     widths[62]=563;     widths[63]=443;     widths[64]=920;     widths[65]=722;     widths[66]=666;     widths[67]=666;     widths[68]=722;     widths[69]=610;     widths[70]=556;     widths[71]=722;     widths[72]=722;     widths[73]=333;     widths[74]=389;     widths[75]=722;     widths[76]=610;     widths[77]=889;     widths[78]=722;     widths[79]=722;     widths[80]=556;     widths[81]=722;     widths[82]=666;     widths[83]=556;     widths[84]=610;     widths[85]=722;     widths[86]=722;     widths[87]=943;     widths[88]=722;     widths[89]=722;     widths[90]=610;     widths[91]=333;     widths[92]=277;     widths[93]=333;     widths[94]=469;     widths[95]=500;     widths[96]=333;     widths[97]=443;     widths[98]=500;     widths[99]=443;     widths[100]=500;     widths[101]=443;     widths[102]=333;     widths[103]=500;     widths[104]=500;     widths[105]=277;     widths[106]=277;     widths[107]=500;     widths[108]=277;     widths[109]=777;     widths[110]=500;     widths[111]=500;     widths[112]=500;     widths[113]=500;     widths[114]=333;     widths[115]=389;     widths[116]=277;     widths[117]=500;     widths[118]=500;     widths[119]=722;     widths[120]=500;     widths[121]=500;     widths[122]=443;     widths[123]=479;     widths[124]=200;     widths[125]=479;     widths[126]=541;   } } 
id=35
provider.isInBound(itemName) && credentialsMatch(provider,itemName,oauthCredentials)
new Thread()
Status.constructStatuses(get(getBaseURL() + "favorites/" + id+ ".json","page",String.valueOf(page),true))
{(byte)this.getNode().getNodeId(),3,(byte)getCommandClass().getKey(),(byte)SWITCH_MULTILEVEL_STOP_LEVEL_CHANGE}
context.getStreamCachingStrategy().getSpoolChiper()
prevNerEndIndex != (start - 1) && nextNerStartIndex != end
new byte[19]
g.tool.errMgr.grammarError(ErrorType.INVALID_RULE_PARAMETER_REF,g.fileName,y,y.getText(),expr)
return 10; 
ChannelBuffers.buffer(length)
HazelcastClient.newHazelcastClient()
IOException ignored
ImmutableList.<PostAggregator>of(new ExpressionPostAggregator("a3","log((\"a1\" + \"a2\"))"))
@Bean @ConditionalOnMissingBean(NamedParameterJdbcOperations.class) public NamedParameterJdbcOperations namedParameterJdbcTemplate(){   return new NamedParameterJdbcTemplate(this.dataSource); } 
d.setMajorVersion(1)
response.getHeader(Exchange.CONTENT_TYPE) != null
report(n,MISPLACED_ANNOTATION)
model.getBoundingBox(bbox)
Exception unexpectedException
id=15840
s.toString().toUpperCase()
visitNode(node,context)
AlluxioWorkerService.class
new CheckPermission().of("all").against("deploy").expect(false)
elements.size() > i
new ScheduledJob(job,jobName,period)
sleepAtLeastMillis(1)
counter + 2
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.BeforeAnnotation.class,CoreAnnotations.AfterAnnotation.class,CoreAnnotations.TokenBeginAnnotation.class,CoreAnnotations.TokenEndAnnotation.class,CoreAnnotations.PositionAnnotation.class,CoreAnnotations.IndexAnnotation.class,CoreAnnotations.OriginalTextAnnotation.class,CoreAnnotations.ValueAnnotation.class)
Double.valueOf(value.toString())
encounter.getObsAtTopLevel(false)
maxLifetime < 120000
11 * ClassSize.REFERENCE
Color.fromRGB(0x434343)
namespace.equals("")
type.toUpperCase(ENGLISH)
new AnnotationRepositoryConfigurationSource(metadata,getAnnotation(),this.environment){   @Override public java.lang.Iterable<String> getBasePackages(){     return AbstractRepositoryConfigurationSourceSupport.this.getBasePackages();   } } 
addKeys(externalClasses,DATE,"org.joda.time.LocalDate")
option.getType()
1024 * 1024
latch.await(100,TimeUnit.MILLISECONDS)
map.put(i,emp,0L,SECONDS,2L,SECONDS)
new RuntimeException("Invalid Column Reference: " + grpbyExpr.dump())
logger.info("Session destroyed")
assertEquals(512f,i,10f)
id=15860
barrier1.await(2,TimeUnit.SECONDS)
selectBoxList.setScrollingDisabled(false,y)
id=56
IDAUTHORITY_RETRY_COUNT_DEFAULT=3
nodeManager.getAllNodes()
MESSAGES.failToReplicateAttribute()
ConditionalOnEnablednHealthIndicator.class
endFunction("delete_column_statistics_by_partition: ",ret != false)
new InputStreamReader(is)
Sets.newHashSet(BUFFERS_READ,FIELDNAMES_READ,INDEXERCLUSTER_READ,INPUTS_READ,JVMSTATS_READ,MESSAGECOUNT_READ,MESSAGES_READ,METRICS_READ,SYSTEM_READ,THROUGHPUT_READ)
new JSONParseSpec(timestampSpec,new DimensionsSpec(dimensions,dimensionExclusions,spatialDimensions),JSONParseSpec.JSON)
uri.getPath()
super.setV(u)
NodeTraversal.traverseEs6(compiler,originalRoot,this)
users.size() > 90
this.contextRunner.withUserConfiguration(TestSecurityConfiguration.class,JwtDecoderConfiguration.class)
this(maxFrameLength,lengthFieldOffset,lengthFieldOffset,lengthAdjustment,initialBytesToStrip,false); 
6 * Bytes.SIZEOF_LONG
traces.set(null)
Object.class
JavaAssistUtils.getParameterType(parameterTypes)
new MD5Renderer(model,true)
AcidUtils.getTableSnapshot(hive.getConf(),tbl,true)
DEFAULT_MAX=1024
new RuntimeException(String.format("File \"%1$s\" has incorrect indentation in comment." + "Line %2$d: comment:%3$d, actual:%4$d.",aFileName,lineNumber,indentInComment,actualIndent))
static public final PowIn fastSlow=pow2In; 
result.expectedMessageCount(2)
EXPLICIT_NO_UNSAFE_CAUSE == null
/**   * Change the permission of a file or directory specified by args.  */ public final class ChmodCommand extends AbstractACLCommand {   public ChmodCommand(  TachyonConf conf,  TachyonFileSystem tfs){     super(conf,tfs);   }   @Override public String getCommandName(){     return "chmod";   }   @Override protected int getNumOfArgs(){     return 2;   }   @Override public void run(  String... args) throws IOException {     String modeStr=args[0];     TachyonURI path=new TachyonURI(args[1]);     chmod(path,modeStr,false);   }   @Override public String getUsage(){     return "chmod <mode> <path>";   } } 
task.cancel()
((Number)s.first()).intValue()
log.error("Both session() and unauthenticated() are set for this request, this is a bug, using session id.")
webSocketConnection.getRemote().sendString(s)
GenericIntegrationTest.class
EmitterProcessor.create(1)
private static final Configuration config=HBaseConfiguration.create(); 
!tmp.exists() && !tmp.isDirectory()
startServer()
mjCtx.getOldMapJoin() == null
"wrong partition, expected: " + getPartitionId() + " but found:"+ op
id=19
monochrome=false
getIndexes().hasIndex() & OBJECT.equals(mapConfig.getInMemoryFormat())
cluster.getTypeFactory().createSqlType(SqlTypeName.DECIMAL,bd.scale(),unscaled.toString().length())
LOG.warn("Failed to get TachyonStore stream, the block " + currentBlockId + " will not be in TachyonStorage",ioe)
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
future.get(10,TimeUnit.SECONDS)
SimpleAttributeDefinitionBuilder.create("max-inclusive",ModelType.BOOLEAN)
getRedeliverDelay()
options.removeUnusedVars
watch.stop()
timePassed >= 1000
vizConfig.isShowArrows() && dataBridge.isDirected()
new CopyableValueComparator(sortOrderAscending,type)
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class)
bLocations[0].getNames()
GatherGettersAndSetterProperties.update(compiler,externs,root)
messageJournalEnabled=false
Mockito.doNothing().when(mFileSystemMasterClient).mount(alluxioPath,ufsPath)
model.getSelectedLayout() != null
TimeUnit.SECONDS.toMillis(4)
getClientConfig().getAddressList()
lastUpdate.after(updated)
items[28]
assertEquals(4933401,received.get(0)[1])
elapsed > config.getConnectionTimeout()
primitiveType != GL10.GL_POINTS
resultEndpoint.setResultWaitTime(1000)
LocalEjbReceiver.clone(invocation.getInvokedMethod().getReturnType(),resultCloner,exception,allowPassByReference)
sX != 0
globalSecurityDomain != null
tableInfo.getType()
new MMUnlockHandler(this)
id=36
a.length >= count()
assertEquals(row.getField(0),2L)
BeforeAfterTester t=new BeforeAfterTester(new DisconnectionBehavior(h2,h1),new MultiCallBuilder(h2)); 
LOG.error("Failed to get files from " + baseDirectory.getAbsolutePath())
body.getData()
new UnilateralSortMerger<TestData.Key,TestData.Value>(memoryManager,ioManager,40 * 1024 * 1024,1024 * 1024 * 1,10,2,keySerialization,valSerialization,keyComparator,reader,parentTask)
new IOException()
line.substring(0,p).trim().toLowerCase()
row("p_comment",null,1.0,0.0,null,null,null)
RequestBody.create(mediaType,(byte[])bodyContents)
/**   * Signal the maps/reduces to start.  */ static void signalTasks(MiniDFSCluster dfs,FileSystem fileSys,String mapSignalFile,String reduceSignalFile,int replication) throws IOException {   writeFile(dfs.getNameNode(),fileSys.getConf(),new Path(mapSignalFile),(short)replication);   writeFile(dfs.getNameNode(),fileSys.getConf(),new Path(reduceSignalFile),(short)replication); } 
analysis.getType(windowFunction)
(offset >= start && offset <= start + len) || (end >= start && end <= start + len)
compositeBuffer()
Boolean success
dfa == null
new Notification(notification)
new Color(0x696969ff)
context.restartRequired()
/**   * The exception thrown (if any) by the method called in  {@link #run()}  */ protected Throwable exceptionThrown=null; 
new ClusterConfiguration(initialConfig.getName(),logging.getMessagesLog(ClusterConfiguration.class),initialConfig.getMemberURIs())
id=15
SavedSearch.constructSavedSearches(get(getBaseURL() + "saved_searches.json",true))
IR.var(IR.name(shortName),googRequireNode)
options != null
BroadcasterFactory.getDefault().get(mapping)
new UnderFileStatus("dummy",isDirectory)
setParams().nx()
config.getMaxRedirects()
HBaseConfiguration conf
prefSize(new Fixed(width))
privObj.getObjectName().equals("masking_test_druid")
retry.attemptRetry()
dataFormatModel.setLabel(row.get("description"))
jniGetLocalAnchorA(addr,tmp)
this == NtiOnly
Number.class
? extends Exception
setLowHighExpected(lowResults,highResults,expectedResults,BCUBED_TP,12440,12450,12451.87)
node.has(Constants.ALIAS)
new IncrementalIndexSegment(rtIndex)
field.getRawType()
memoryReservation.getAndAdd(bytes)
Exception e
MAX_PRETTY_PRINTED_PROPERTIES=4
TimeUnit.SECONDS.toNanos(5)
timeout=60000
stopwatch.elapsedMillis()
subtypeProps.isEmpty()
AddressHelper.getPossibleSocketAddresses(address.getPort(),address.getHost(),3)
logger.error("table: {} column: {}, failed convert type {} to {}",columnName,value,sqlType)
new PeepholeSubstituteAlternateSyntax(true)
row1 * layerTileHeight
id=15837
mock.message(0).outBody(String.class)
uncollectedPointCreater.createUnCollectedPoint(timestamp)
resultEndpoint.assertIsNotSatisfied()
new byte[10]
List<Integer>
visitor.visitMethodInsn(opCode.getOpCode(),target.getClassName(),name,getMethodDescription())
SingleServerInventoryProvider.class
order.getInstructions()
mTfs.ls(Constants.PATH_SEPARATOR,true)
isCancelled0(result)
AvailablePortFinder.getNextAvailable()
Status.constructStatuses(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/statuses/friends/T4J_hudson.json"))
db.createIndex(new BasicDBObject(FIELD_UPDATED_AT,1).append(FIELD_UNCOMMITTED_ENTRIES,1).append(FIELD_WRITTEN_MESSAGES_1M,1))
conf.getSearchBaseURL()
client.getBulkReply()
LOG.error("XMLStreamReader {} not supporting Location")
queryStrings.append(name)
source != null
(UndeclaredThrowableException)wrapped
Multimap<Object,JSError>
allowedIdentifiersCheckDigits[i]
reservedWords.contains(codegenProperty.datatypeWithEnum)
monochrome=true
Assert.fail()
logger.info("Optimized Selector: " + selector.getClass().getName())
queueView.get().get(index.longValue())
uncompressedProto.length < 2560000
new DateTime(Long.parseLong(firstTimestamp) * 1000)
BED(99)
k < THREADS
AdviceWithTasks.beforeByToString(route,toString,answer,selectLast,selectFirst,selectFrom,selectTo,maxDeep)
new SctpMessage(streamIdentifier,protocolIdentifier,unordered,msg.retain())
TransactionException e
path.toString()
op.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(true)
variables.putAll(variables)
mMountTable.resolve(getPath(lastInode)).getPath()
tableMetadataBuilder(DEFAULT_TEST_LINEITEMS).column("orderkey",BIGINT).column("partkey",BIGINT).column("quantity",BIGINT)
DEFAULT_NUMBER_OF_READ_BUFFERS=128
ENGLISH_BIDIRECTIONAL_SENTENCE_ACCURACY=.564
ctx.alloc().heapBuffer()
queryNotifyLatch.await(25,TimeUnit.MILLISECONDS)
new GetExecutionVariableInstancesCmd(executionId,variableNames,false,locale,withLocalizationFallback)
Color.fromRGB(0xDECF2A)
log.info("Wanted to terminate %,d workers, but couldn't find any lazy ones!")
DEFAULT_MOVE_COST=100
mode == MODE_PULL_DOWN_TO_REFRESH
Integer.toString(1)
@Message(id=14151,value="Could not find view %s for EJB %s") RuntimeException viewNotFound(String viewClass,String ejbName); 
localAnchorA.set(joint.getLocalAnchorB().x,joint.getLocalAnchorB().y)
createPermissionsXmlAsset(new JndiPermission("*","lookup"))
Lists.newArrayList(stream1)
writeUnlock()
Math.min(RETRY_INTERVAL,timeout.timeLeft().toMillis())
StringUtils.isEmpty(parameter)
ch.unsafe().flushNow()
event.isResuming()
child.tagName.equals("base") || child.tagName.equals("script") || child.tagName.equals("link")|| child.tagName.equals("meta")|| child.tagName.equals("title")
2 < buf.length - count
id=13
mapContainer.getMapConfig().getMaxIdleSeconds() * 1000
cacheScaled5.setColor(red)
DEFAULT_MAX_UNION_SIZE=20
ChannelOption<Integer>
r.getRequest(false)
id=15835
privObj.getObjectName().equals("masking_test")
ChannelBuffers.copiedBuffer(sb.toString().getBytes(bodyCharset))
new SpdySessionStatus(11,"INTERNAL_ERROR")
new ConnectorRefsAttribute(CommonAttributes.STATIC_CONNECTORS,true,false)
assertEquals(2,map.size())
Integer olderThan
Thread.sleep(5000)
Thread.sleep(2200)
username.length()
DUE_DILIGENCE_MILLIS=50
EJBException nsee
new AutoValue_RegistrationResponse(sidecarRegistrationConfiguration,configurationOverride,actions,assignments)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class ConditionBasicDistributedTest extends ConditionBasicTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(2).newInstances();   } } 
assertTrue(predicate.apply(pickleEvent))
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
pieces.length <= wordColumn
Color.fromRGB(0x41CD34)
Assert.assertNull(ex.getCause())
rsMeta.getColumnName(i + 1)
mf.filter(r,message,transformed.message())
SimpleAttributeDefinitionBuilder.create(ModelDescriptionConstants.ANY_IPV4_ADDRESS,ModelType.BOOLEAN).setAllowExpression(false).setAllowNull(false)
executor.submit(new NamedRunnable("OkHttp %s stream %d",hostname,streamId){   @Override public void execute(){     try {       writeSynReset(streamId,errorCode);     }  catch (    IOException ignored) {     }   } } )
Arrays.asList("ErrorResponse","Response","Int","Int32","Int64","Int64","Float","Double","Bool","Void","String","Character","AnyObject","Any","Error","URL","class","Class","break","as","associativity","deinit","case","dynamicType","convenience","enum","continue","false","dynamic","extension","default","is","didSet","func","do","nil","final","import","else","self","get","init","fallthrough","Self","infix","internal","for","super","inout","let","if","true","lazy","operator","in","COLUMN","left","private","return","FILE","mutating","protocol","switch","FUNCTION","none","public","where","LINE","nonmutating","static","while","optional","struct","override","subscript","postfix","typealias","precedence","var","prefix","Protocol","required","right","set","Type","unowned","weak")
new PulsarComponent()
clusterService.getIndexerFailures(0,0)
id=15844
new IllegalArgumentException()
new GdxRuntimeException("Failed to read Vorbis.")
JavaConversions.asIterable(kafkaLog.logSegments(committedOffset,Long.MAX_VALUE))
new ClusterConfiguration("whatever",StringLogger.DEV_NULL,"cluster://1","cluster://2")
NbBundle.getMessage(ImporterGEXF.class,"importerGEXF_error_pid")
oldOverride.removeParameter("enabled")
zkWorker.getWorker()
EnumSet.of(DatabaseDriver.UNKNOWN,DatabaseDriver.ORACLE,DatabaseDriver.DB2,DatabaseDriver.DB2_AS400,DatabaseDriver.INFORMIX,DatabaseDriver.TERADATA)
Tuple2.of(timeoutPattern4,13L)
StringUtil.in(name,"base","basefont","bgsound","command","link","meta","noframes","style","title")
GL20.glVertexAttribPointer(indx,size,normalized,stride,((ByteBuffer)buffer).asFloatBuffer())
private final DynamicTrnasformerRegistry dynamicTransformerRegistry; 
s.elapsedTime(TimeUnit.NANOSECONDS)
!resource.getAtmosphereResourceEvent().isClosedByApplication() && !resource.isCancelled()
packFileName.substring(packFileName.length() - settings.atlasExtension.length())
LOG.error("Read offset {} before start of log at {}, starting to read from the beginning of the journal.",readOffset,logStartOffset)
GL20.glUniform2(location,v)
annotations == null
element.getChildByName("properties")
@ConditionalOnEnablednHealthIndicator("db")
Gdx.files.internal(fileName).nameWithoutExtension()
strategiesBuilder::messageWriter
n.intValue()
url2 != null
assertEquals(ex.getCause().getMessage(),"ClassInfo's name should be non-null")
dic.buildRouterChain(invokers)
LOGGER.debug("{} - Reset ({}) on connection {}",resetBits != 0 ? stringFromResetBits(resetBits) : "nothing",poolEntry.connection)
/**   * SSH port.  */ private String port="2000"; 
getCurrentRequestId()
DiagnosticGroups.registerGroup("functionParams",FunctionTypeBuilder.OPTIONAL_ARG_AT_END)
i < 1000
executor.submit(new NamedRunnable("OkHttp %s stream %d",hostName,streamId){   @Override public void execute(){     try {       handler.receive(newStream);     }  catch (    IOException e) {       throw new RuntimeException(e);     }   } } )
found.size() == 1
new Whitelist().addTags("a","b","blockquote","br","caption","cite","code","col","colgroup","dd","div","dl","dt","em","h1","h2","h3","h4","h5","h6","i","img","li","ol","p","pre","q","small","strike","strong","sub","sup","table","tbody","td","tfoot","th","thead","tr","u","ul")
1 << 20
getPath("InputPackageDeclarationDiffDirectoryAtParent.java")
factory.get(sBodyWildcard,NO_ANNOTATIONS,retrofit)
this.instanceManager != null
name="java:jboss/datasources/ExampleDS"
return faceBookProperties; 
request.getLocalAddr()
entry != null
{MAGIC_HIGH,MAGIC_LOW,0x20,20,0,0,0,0,0,0,0,0,0,0,0,0}
log.error(currentThread() + String.format("Trying to recover from dead Channel: %s ",channel))
name.startsWith("java.") || name.startsWith("javax.") || name.startsWith("junit.")|| name.startsWith("sun.")|| name.startsWith("com.sun.")
Utils.class
assertEquals(2,props.getConfigPathPatterns().length,2)
new PrestoException(INVALID_CAST_ARGUMENT,e)
new InetSocketAddress(configuration.getRestListenUri().getPort())
getMockEndpoint("mock:line").expectedMinimumMessageCount(1)
isSdkLocationValid(sdkLocation)
new ArrayList<>()
context.startRoute("consumer")
"http".equals(protocol)
public DerivedBuilder setMaximumConnectionsPerHost(int defaultMaxConnectionPerHost){   configBuilder.setMaximumConnectionsPerHost(defaultMaxConnectionPerHost);   return this; } 
assertEquals(15,tokens.size())
len % (1024 * 1024) / 10
builder120.build()
(JobFound)response
delay=2
assertSpnegoWorkflow(uri,mechTypes,kerberosToken,kerberosToken,true,true)
logger.debug("rapidRefreshFutureEnd stopping")
configureAtmosphereInterceptor(sc)
new CommandFormatException(result.toString())
Arrays.<Class<?>>asList(org.nd4j.linalg.api.ops.DynamicCustomOp.class,org.nd4j.linalg.api.ops.NoOp.class,org.nd4j.linalg.api.ops.custom.BarnesEdgeForces.class,org.nd4j.linalg.api.ops.custom.BarnesHutGains.class,org.nd4j.linalg.api.ops.custom.BarnesHutSymmetrize.class,org.nd4j.linalg.api.ops.custom.SpTreeCell.class,org.nd4j.linalg.api.ops.custom.Flatten.class,org.nd4j.linalg.api.ops.impl.broadcast.BiasAdd.class,org.nd4j.linalg.api.ops.impl.broadcast.BiasAddGrad.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastAMax.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastAMin.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastAddOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastCopyOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastDivOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastGradientArgs.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastMax.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastMin.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastMulOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastRDivOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastRSubOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastSubOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastTo.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastEqualTo.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastGreaterThan.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastGreaterThanOrEqual.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastLessThan.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastLessThanOrEqual.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastNotEqual.class,org.nd4j.linalg.api.ops.impl.controlflow.If.class,org.nd4j.linalg.api.ops.impl.controlflow.IfDerivative.class,org.nd4j.linalg.api.ops.impl.controlflow.Select.class,org.nd4j.linalg.api.ops.impl.controlflow.Where.class,org.nd4j.linalg.api.ops.impl.controlflow.WhereNumpy.class,org.nd4j.linalg.api.ops.impl.controlflow.While.class,org.nd4j.linalg.api.ops.impl.controlflow.WhileDerivative.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.Enter.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.Exit.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.LoopCond.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.Merge.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.NextIteration.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.StopGradient.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.Switch.class,org.nd4j.linalg.api.ops.impl.grid.FreeGridOp.class,org.nd4j.linalg.api.ops.impl.image.CropAndResize.class,org.nd4j.linalg.api.ops.impl.image.ExtractImagePatches.class,org.nd4j.linalg.api.ops.impl.image.NonMaxSuppression.class,org.nd4j.linalg.api.ops.impl.image.ResizeBilinear.class,org.nd4j.linalg.api.ops.impl.image.ResizeNearestNeighbor.class,org.nd4j.linalg.api.ops.impl.indexaccum.FirstIndex.class,org.nd4j.linalg.api.ops.impl.indexaccum.IAMax.class,org.nd4j.linalg.api.ops.impl.indexaccum.IAMin.class,org.nd4j.linalg.api.ops.impl.indexaccum.IMax.class,org.nd4j.linalg.api.ops.impl.indexaccum.IMin.class,org.nd4j.linalg.api.ops.impl.indexaccum.LastIndex.class,org.nd4j.linalg.api.ops.impl.indexaccum.custom.ArgMax.class,org.nd4j.linalg.api.ops.impl.indexaccum.custom.ArgMin.class,org.nd4j.linalg.api.ops.impl.layers.ExternalErrorsFunction.class,org.nd4j.linalg.api.ops.impl.layers.Linear.class,org.nd4j.linalg.api.ops.impl.layers.convolution.AvgPooling2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.AvgPooling3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.BatchNorm.class,org.nd4j.linalg.api.ops.impl.layers.convolution.BatchNormDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Col2Im.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv1D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv2DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv3DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv2DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv2DTF.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv3DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DepthToSpace.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DepthwiseConv2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Im2col.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Im2colBp.class,org.nd4j.linalg.api.ops.impl.layers.convolution.LocalResponseNormalization.class,org.nd4j.linalg.api.ops.impl.layers.convolution.LocalResponseNormalizationDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.MaxPooling2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.MaxPooling3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Pooling2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Pooling2DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Pooling3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Pooling3DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.SConv2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.SConv2DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.SpaceToDepth.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Upsampling2d.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Upsampling2dDerivative.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.GRUCell.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.LSTMBlockCell.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.LSTMCell.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.LSTMLayer.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.SRU.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.SRUCell.class,org.nd4j.linalg.api.ops.impl.loss.AbsoluteDifferenceLoss.class,org.nd4j.linalg.api.ops.impl.loss.CosineDistanceLoss.class,org.nd4j.linalg.api.ops.impl.loss.HingeLoss.class,org.nd4j.linalg.api.ops.impl.loss.HuberLoss.class,org.nd4j.linalg.api.ops.impl.loss.L2Loss.class,org.nd4j.linalg.api.ops.impl.loss.LogLoss.class,org.nd4j.linalg.api.ops.impl.loss.LogPoissonLoss.class,org.nd4j.linalg.api.ops.impl.loss.MeanPairwiseSquaredErrorLoss.class,org.nd4j.linalg.api.ops.impl.loss.MeanSquaredErrorLoss.class,org.nd4j.linalg.api.ops.impl.loss.SigmoidCrossEntropyLoss.class,org.nd4j.linalg.api.ops.impl.loss.SoftmaxCrossEntropyLoss.class,org.nd4j.linalg.api.ops.impl.loss.SoftmaxCrossEntropyWithLogitsLoss.class,org.nd4j.linalg.api.ops.impl.loss.SparseSoftmaxCrossEntropyLossWithLogits.class,org.nd4j.linalg.api.ops.impl.loss.WeightedCrossEntropyLoss.class,org.nd4j.linalg.api.ops.impl.loss.bp.AbsoluteDifferenceLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.CosineDistanceLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.HingeLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.HuberLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.LogLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.LogPoissonLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.MeanPairwiseSquaredErrorLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.MeanSquaredErrorLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.SigmoidCrossEntropyLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.SoftmaxCrossEntropyLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.SoftmaxCrossEntropyWithLogitsLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.SparseSoftmaxCrossEntropyLossWithLogitsBp.class,org.nd4j.linalg.api.ops.impl.meta.InvertedPredicateMetaOp.class,org.nd4j.linalg.api.ops.impl.meta.PostulateMetaOp.class,org.nd4j.linalg.api.ops.impl.meta.PredicateMetaOp.class,org.nd4j.linalg.api.ops.impl.meta.ReduceMetaOp.class,org.nd4j.linalg.api.ops.impl.nlp.CbowRound.class,org.nd4j.linalg.api.ops.impl.nlp.SkipGramRound.class,org.nd4j.linalg.api.ops.impl.reduce.HashCode.class,org.nd4j.linalg.api.ops.impl.reduce.Mmul.class,org.nd4j.linalg.api.ops.impl.reduce.MmulBp.class,org.nd4j.linalg.api.ops.impl.reduce.Moments.class,org.nd4j.linalg.api.ops.impl.reduce.NormalizeMoments.class,org.nd4j.linalg.api.ops.impl.reduce.SufficientStatistics.class,org.nd4j.linalg.api.ops.impl.reduce.TensorMmul.class,org.nd4j.linalg.api.ops.impl.reduce.ZeroFraction.class,org.nd4j.linalg.api.ops.impl.reduce.bool.All.class,org.nd4j.linalg.api.ops.impl.reduce.bool.Any.class,org.nd4j.linalg.api.ops.impl.reduce.bool.IsInf.class,org.nd4j.linalg.api.ops.impl.reduce.bool.IsNaN.class,org.nd4j.linalg.api.ops.impl.reduce.bp.CumProdBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.CumSumBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.DotBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.MaxBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.MeanBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.MinBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.Norm1Bp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.Norm2Bp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.NormMaxBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.ProdBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.SquaredNormBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.StandardDeviationBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.SumBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.VarianceBp.class,org.nd4j.linalg.api.ops.impl.reduce.custom.BatchMmul.class,org.nd4j.linalg.api.ops.impl.reduce.custom.LogSumExp.class,org.nd4j.linalg.api.ops.impl.reduce.floating.AMean.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Bias.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Entropy.class,org.nd4j.linalg.api.ops.impl.reduce.floating.LogEntropy.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Mean.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Norm1.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Norm2.class,org.nd4j.linalg.api.ops.impl.reduce.floating.NormMax.class,org.nd4j.linalg.api.ops.impl.reduce.floating.ShannonEntropy.class,org.nd4j.linalg.api.ops.impl.reduce.floating.SquaredNorm.class,org.nd4j.linalg.api.ops.impl.reduce.longer.CountNonZero.class,org.nd4j.linalg.api.ops.impl.reduce.longer.CountZero.class,org.nd4j.linalg.api.ops.impl.reduce.longer.MatchCondition.class,org.nd4j.linalg.api.ops.impl.reduce.same.AMax.class,org.nd4j.linalg.api.ops.impl.reduce.same.AMin.class,org.nd4j.linalg.api.ops.impl.reduce.same.ASum.class,org.nd4j.linalg.api.ops.impl.reduce.same.Max.class,org.nd4j.linalg.api.ops.impl.reduce.same.Min.class,org.nd4j.linalg.api.ops.impl.reduce.same.Prod.class,org.nd4j.linalg.api.ops.impl.reduce.same.Sum.class,org.nd4j.linalg.api.ops.impl.reduce3.CosineDistance.class,org.nd4j.linalg.api.ops.impl.reduce3.CosineSimilarity.class,org.nd4j.linalg.api.ops.impl.reduce3.Dot.class,org.nd4j.linalg.api.ops.impl.reduce3.EqualsWithEps.class,org.nd4j.linalg.api.ops.impl.reduce3.EuclideanDistance.class,org.nd4j.linalg.api.ops.impl.reduce3.HammingDistance.class,org.nd4j.linalg.api.ops.impl.reduce3.JaccardDistance.class,org.nd4j.linalg.api.ops.impl.reduce3.ManhattanDistance.class,org.nd4j.linalg.api.ops.impl.scalar.LeakyReLU.class,org.nd4j.linalg.api.ops.impl.scalar.LogX.class,org.nd4j.linalg.api.ops.impl.scalar.Pow.class,org.nd4j.linalg.api.ops.impl.scalar.PowDerivative.class,org.nd4j.linalg.api.ops.impl.scalar.RectifiedLinear.class,org.nd4j.linalg.api.ops.impl.scalar.Relu6.class,org.nd4j.linalg.api.ops.impl.scalar.ReplaceNans.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarAdd.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarDivision.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarFMod.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarMax.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarMin.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarMultiplication.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarRemainder.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarReverseDivision.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarReverseSubtraction.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarSet.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarSubtraction.class,org.nd4j.linalg.api.ops.impl.scalar.Step.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarAnd.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarEps.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarEquals.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarGreaterThan.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarGreaterThanOrEqual.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarLessThan.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarLessThanOrEqual.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarNot.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarNotEquals.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarOr.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarSetValue.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarXor.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterAdd.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterDiv.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterMax.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterMin.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterMul.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterNd.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterNdAdd.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterNdSub.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterNdUpdate.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterSub.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterUpdate.class,org.nd4j.linalg.api.ops.impl.shape.ApplyGradientDescent.class,org.nd4j.linalg.api.ops.impl.shape.Broadcast.class,org.nd4j.linalg.api.ops.impl.shape.BroadcastDynamicShape.class,org.nd4j.linalg.api.ops.impl.shape.Concat.class,org.nd4j.linalg.api.ops.impl.shape.ConfusionMatrix.class,org.nd4j.linalg.api.ops.impl.shape.Cross.class,org.nd4j.linalg.api.ops.impl.shape.Diag.class,org.nd4j.linalg.api.ops.impl.shape.DiagPart.class,org.nd4j.linalg.api.ops.impl.shape.ExpandDims.class,org.nd4j.linalg.api.ops.impl.shape.Eye.class,org.nd4j.linalg.api.ops.impl.shape.Gather.class,org.nd4j.linalg.api.ops.impl.shape.GatherNd.class,org.nd4j.linalg.api.ops.impl.shape.Linspace.class,org.nd4j.linalg.api.ops.impl.shape.MergeAvg.class,org.nd4j.linalg.api.ops.impl.shape.MergeMax.class,org.nd4j.linalg.api.ops.impl.shape.MergeSum.class,org.nd4j.linalg.api.ops.impl.shape.MeshGrid.class,org.nd4j.linalg.api.ops.impl.shape.OneHot.class,org.nd4j.linalg.api.ops.impl.shape.OnesLike.class,org.nd4j.linalg.api.ops.impl.shape.ParallelStack.class,org.nd4j.linalg.api.ops.impl.shape.Permute.class,org.nd4j.linalg.api.ops.impl.shape.Rank.class,org.nd4j.linalg.api.ops.impl.shape.ReductionShape.class,org.nd4j.linalg.api.ops.impl.shape.Repeat.class,org.nd4j.linalg.api.ops.impl.shape.Reshape.class,org.nd4j.linalg.api.ops.impl.shape.SequenceMask.class,org.nd4j.linalg.api.ops.impl.shape.Shape.class,org.nd4j.linalg.api.ops.impl.shape.ShapeN.class,org.nd4j.linalg.api.ops.impl.shape.Size.class,org.nd4j.linalg.api.ops.impl.shape.SizeAt.class,org.nd4j.linalg.api.ops.impl.shape.Slice.class,org.nd4j.linalg.api.ops.impl.shape.Split.class,org.nd4j.linalg.api.ops.impl.shape.SplitV.class,org.nd4j.linalg.api.ops.impl.shape.Squeeze.class,org.nd4j.linalg.api.ops.impl.shape.Stack.class,org.nd4j.linalg.api.ops.impl.shape.StridedSlice.class,org.nd4j.linalg.api.ops.impl.shape.Tile.class,org.nd4j.linalg.api.ops.impl.shape.Transpose.class,org.nd4j.linalg.api.ops.impl.shape.Unstack.class,org.nd4j.linalg.api.ops.impl.shape.ZerosLike.class,org.nd4j.linalg.api.ops.impl.shape.bp.ConcatBp.class,org.nd4j.linalg.api.ops.impl.shape.bp.SliceBp.class,org.nd4j.linalg.api.ops.impl.shape.bp.StridedSliceBp.class,org.nd4j.linalg.api.ops.impl.shape.bp.TileBp.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArray.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayConcat.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayGather.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayRead.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayScatter.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArraySize.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArraySplit.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayWrite.class,org.nd4j.linalg.api.ops.impl.summarystats.StandardDeviation.class,org.nd4j.linalg.api.ops.impl.summarystats.Variance.class,org.nd4j.linalg.api.ops.impl.transforms.Angle.class,org.nd4j.linalg.api.ops.impl.transforms.Assert.class,org.nd4j.linalg.api.ops.impl.transforms.BinCount.class,org.nd4j.linalg.api.ops.impl.transforms.CheckNumerics.class,org.nd4j.linalg.api.ops.impl.transforms.Cholesky.class,org.nd4j.linalg.api.ops.impl.transforms.Constant.class,org.nd4j.linalg.api.ops.impl.transforms.Histogram.class,org.nd4j.linalg.api.ops.impl.transforms.HistogramFixedWidth.class,org.nd4j.linalg.api.ops.impl.transforms.IdentityN.class,org.nd4j.linalg.api.ops.impl.transforms.MaxOut.class,org.nd4j.linalg.api.ops.impl.transforms.NthElement.class,org.nd4j.linalg.api.ops.impl.transforms.Pad.class,org.nd4j.linalg.api.ops.impl.transforms.ReluLayer.class,org.nd4j.linalg.api.ops.impl.transforms.any.Assign.class,org.nd4j.linalg.api.ops.impl.transforms.any.IsMax.class,org.nd4j.linalg.api.ops.impl.transforms.bool.BooleanNot.class,org.nd4j.linalg.api.ops.impl.transforms.bool.IsFinite.class,org.nd4j.linalg.api.ops.impl.transforms.bool.IsInf.class,org.nd4j.linalg.api.ops.impl.transforms.bool.IsNaN.class,org.nd4j.linalg.api.ops.impl.transforms.bool.MatchConditionTransform.class,org.nd4j.linalg.api.ops.impl.transforms.clip.ClipByNorm.class,org.nd4j.linalg.api.ops.impl.transforms.clip.ClipByNormBp.class,org.nd4j.linalg.api.ops.impl.transforms.clip.ClipByValue.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.CompareAndReplace.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.CompareAndSet.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.Eps.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldEqualTo.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldGreaterThan.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldGreaterThanOrEqual.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldLessThan.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldLessThanOrEqual.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldMax.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldMin.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldNotEqualTo.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ATan2.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Assign.class,org.nd4j.linalg.api.ops.impl.transforms.custom.BatchToSpace.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Choose.class,org.nd4j.linalg.api.ops.impl.transforms.custom.CumProd.class,org.nd4j.linalg.api.ops.impl.transforms.custom.CumSum.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Dilation2D.class,org.nd4j.linalg.api.ops.impl.transforms.custom.DotProductAttention.class,org.nd4j.linalg.api.ops.impl.transforms.custom.DotProductAttentionBp.class,org.nd4j.linalg.api.ops.impl.transforms.custom.DynamicPartition.class,org.nd4j.linalg.api.ops.impl.transforms.custom.DynamicStitch.class,org.nd4j.linalg.api.ops.impl.transforms.custom.EqualTo.class,org.nd4j.linalg.api.ops.impl.transforms.custom.FakeQuantWithMinMaxArgs.class,org.nd4j.linalg.api.ops.impl.transforms.custom.FakeQuantWithMinMaxVars.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Fill.class,org.nd4j.linalg.api.ops.impl.transforms.custom.GreaterThan.class,org.nd4j.linalg.api.ops.impl.transforms.custom.GreaterThanOrEqual.class,org.nd4j.linalg.api.ops.impl.transforms.custom.InTopK.class,org.nd4j.linalg.api.ops.impl.transforms.custom.InvertPermutation.class,org.nd4j.linalg.api.ops.impl.transforms.custom.IsNonDecreasing.class,org.nd4j.linalg.api.ops.impl.transforms.custom.IsNumericTensor.class,org.nd4j.linalg.api.ops.impl.transforms.custom.IsStrictlyIncreasing.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LayerNorm.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LayerNormBp.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LessThan.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LessThanOrEqual.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ListDiff.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogMatrixDeterminant.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogSoftMax.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogicalAnd.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogicalNot.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogicalOr.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogicalXor.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixDeterminant.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixDiag.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixDiagPart.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixInverse.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixSetDiag.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Max.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Min.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MirrorPad.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MultiHeadDotProductAttention.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MultiHeadDotProductAttentionBp.class,org.nd4j.linalg.api.ops.impl.transforms.custom.NotEqualTo.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ParallelConcat.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Pow.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Reverse.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ReverseSequence.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ReverseV2.class,org.nd4j.linalg.api.ops.impl.transforms.custom.SoftMax.class,org.nd4j.linalg.api.ops.impl.transforms.custom.SpaceToBatch.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Standardize.class,org.nd4j.linalg.api.ops.impl.transforms.custom.StandardizeBp.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Svd.class,org.nd4j.linalg.api.ops.impl.transforms.custom.TopK.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Trace.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Unique.class,org.nd4j.linalg.api.ops.impl.transforms.custom.UniqueWithCounts.class,org.nd4j.linalg.api.ops.impl.transforms.custom.XwPlusB.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Zeta.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentMax.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentMean.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentMin.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentProd.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentSum.class,org.nd4j.linalg.api.ops.impl.transforms.dtype.Cast.class,org.nd4j.linalg.api.ops.impl.transforms.floating.RSqrt.class,org.nd4j.linalg.api.ops.impl.transforms.floating.Sqrt.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.CubeDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.DynamicPartitionBp.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.ELUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.GradientBackwardsMarker.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.HardSigmoidDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.HardTanhDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.LeakyReLUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.LogSoftMaxDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.RationalTanhDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.RectifiedTanhDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.Relu6Derivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.SELUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.SigmoidDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.SoftSignDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.SoftmaxBp.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.TanhDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.BinaryMinimalRelativeError.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.BinaryRelativeError.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.RelativeError.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.Set.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.AddOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.Axpy.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.CopyOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.DivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.FModOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.FloorDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.FloorModOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.MergeAddOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.MulOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.ModOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldAddOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldAtan2Op.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldFModOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldFloorDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldMulOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldRDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldRSubOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldSubOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.PowPairwise.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.RDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.RSubOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.RealDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.RemainderOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.SquaredDifferenceOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.SubOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.TruncateDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.AddBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.DivBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.FloorDivBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.FloorModBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.MulBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.RDivBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.RSubBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.SquaredDifferenceBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.SubBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.bool.And.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.bool.Not.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.bool.Or.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.bool.Xor.class,org.nd4j.linalg.api.ops.impl.transforms.same.AMax.class,org.nd4j.linalg.api.ops.impl.transforms.same.AMin.class,org.nd4j.linalg.api.ops.impl.transforms.same.Abs.class,org.nd4j.linalg.api.ops.impl.transforms.same.Ceil.class,org.nd4j.linalg.api.ops.impl.transforms.same.Cube.class,org.nd4j.linalg.api.ops.impl.transforms.same.Floor.class,org.nd4j.linalg.api.ops.impl.transforms.same.Identity.class,org.nd4j.linalg.api.ops.impl.transforms.same.Max.class,org.nd4j.linalg.api.ops.impl.transforms.same.Min.class,org.nd4j.linalg.api.ops.impl.transforms.same.Negative.class,org.nd4j.linalg.api.ops.impl.transforms.same.OldIdentity.class,org.nd4j.linalg.api.ops.impl.transforms.same.OldReverse.class,org.nd4j.linalg.api.ops.impl.transforms.same.OneMinus.class,org.nd4j.linalg.api.ops.impl.transforms.same.Reciprocal.class,org.nd4j.linalg.api.ops.impl.transforms.same.Round.class,org.nd4j.linalg.api.ops.impl.transforms.same.Sign.class,org.nd4j.linalg.api.ops.impl.transforms.same.Square.class,org.nd4j.linalg.api.ops.impl.transforms.same.TimesOneMinus.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentMax.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentMean.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentMin.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentProd.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentSqrtN.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentSum.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentMaxBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentMeanBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentMinBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentProdBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentSumBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentMaxBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentMeanBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentMinBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentProdBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentSqrtNBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentSumBp.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ACos.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ACosh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ASin.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ASinh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ATan.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ATanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Cos.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Cosh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ELU.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Erf.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Erfc.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Exp.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Expm1.class,org.nd4j.linalg.api.ops.impl.transforms.strict.GELU.class,org.nd4j.linalg.api.ops.impl.transforms.strict.GELUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.HardSigmoid.class,org.nd4j.linalg.api.ops.impl.transforms.strict.HardTanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Log.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Log1p.class,org.nd4j.linalg.api.ops.impl.transforms.strict.LogSigmoid.class,org.nd4j.linalg.api.ops.impl.transforms.strict.PreciseGELU.class,org.nd4j.linalg.api.ops.impl.transforms.strict.PreciseGELUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.RationalTanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.RectifiedTanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Rint.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SELU.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SetRange.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Sigmoid.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SigmoidDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Sin.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Sinh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SoftPlus.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SoftSign.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Stabilize.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Swish.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SwishDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Tan.class,org.nd4j.linalg.api.ops.impl.transforms.strict.TanDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Tanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.TanhDerivative.class,org.nd4j.linalg.api.ops.persistence.RestoreV2.class,org.nd4j.linalg.api.ops.persistence.SaveV2.class,org.nd4j.linalg.api.ops.random.compat.RandomStandardNormal.class,org.nd4j.linalg.api.ops.random.custom.DistributionUniform.class,org.nd4j.linalg.api.ops.random.custom.RandomBernoulli.class,org.nd4j.linalg.api.ops.random.custom.RandomExponential.class,org.nd4j.linalg.api.ops.random.custom.RandomNormal.class,org.nd4j.linalg.api.ops.random.impl.AlphaDropOut.class,org.nd4j.linalg.api.ops.random.impl.BernoulliDistribution.class,org.nd4j.linalg.api.ops.random.impl.BinomialDistribution.class,org.nd4j.linalg.api.ops.random.impl.BinomialDistributionEx.class,org.nd4j.linalg.api.ops.random.impl.Choice.class,org.nd4j.linalg.api.ops.random.impl.DropOut.class,org.nd4j.linalg.api.ops.random.impl.DropOutInverted.class,org.nd4j.linalg.api.ops.random.impl.GaussianDistribution.class,org.nd4j.linalg.api.ops.random.impl.Linspace.class,org.nd4j.linalg.api.ops.random.impl.LogNormalDistribution.class,org.nd4j.linalg.api.ops.random.impl.ProbablisticMerge.class,org.nd4j.linalg.api.ops.random.impl.Range.class,org.nd4j.linalg.api.ops.random.impl.TruncatedNormalDistribution.class,org.nd4j.linalg.api.ops.random.impl.UniformDistribution.class)
return 0; 
super(pipeline,null,HEAD_NAME,false,true); 
file.getName().startsWith("branched-")
entry.getValue().acccessibleNodeLabels
id=15864
item.getClass()
Color.fromRGB(0x287697)
GL11.glTexParameter(target,pname,params)
context.registerSubsystem(SUBSYSTEM_NAME,1,0)
this.thrown.equals(IllegalStateException.class)
LOG.error(result.getDescription())
UriBuilder.fromResource(StreamAlertResource.class).build()
id=4
existingOne == null
Sets.<Integer>newHashSet()
decodeLast(ctx,e.getChannel(),cumulation,state)
List<INPUT>
ufsDeleter.delete(alluxioUriToDel,delInode)
id=31
executorCount--
id=15874
mBlockStream.remaining()
"maxHeaderSize must be a positive integer: " + maxChunkSize
Exception ex
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class ReplicatedMapHitsAndLastAccessTimeTest extends ReplicatedMapBaseTest {   @Test public void test_hitsAndLastAccessTimeSetToAnyValueAfterStartTime_object() throws Exception {     testHitsAndLastAccessTimeIsSetToAnyValueAfterStartTime(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAndLastAccessTimeSetToAnyValueAfterStartTime_Binary() throws Exception {     testHitsAndLastAccessTimeIsSetToAnyValueAfterStartTime(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAndLastAccessTimeIsSetToAnyValueAfterStartTime(  Config config) throws Exception {     final long startTime=Clock.currentTimeMillis();     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     warmUpPartitions(instance1,instance2);     final String mapName=randomMapName();     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap(mapName);     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap(mapName);     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        Map.Entry<String,String> entry : map1.entrySet()) {           assertRecord(getReplicatedRecord(map1,entry.getKey()),startTime);         }       }     } );     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        Map.Entry<String,String> entry : map2.entrySet()) {           assertRecord(getReplicatedRecord(map2,entry.getKey()),startTime);         }       }     } );   }   private void assertRecord(  ReplicatedRecord<String,String> record,  long startTime){     assertNotNull(record);     long hits=record.getHits();     long lastAccessTime=record.getLastAccessTime();     long now=Clock.currentTimeMillis();     assertTrue(String.format("Hits should be greater than 0: %d > %d",hits,0),hits > 0);     assertTrue(String.format("Hits should be less than 1000: %d < %d",hits,1000),hits < 1000);     assertTrue(String.format("LastAccessTime should be greater than startTime: %d > %d",lastAccessTime,startTime),lastAccessTime > startTime);     assertTrue(String.format("LastAccessTime should be less or equal than current time: %d <= %d",lastAccessTime,now),lastAccessTime <= now);   }   @Test public void test_hitsAreZeroInitially_withSingleNode_object() throws Exception {     testHitsAreZeroInitiallyWithSingleNode(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAreZeroInitially_withSingleNode_Binary() throws Exception {     testHitsAreZeroInitiallyWithSingleNode(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAreZeroInitiallyWithSingleNode(  Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map=instance1.getReplicatedMap(randomMapName());     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map.put(key,"bar");     }     for (    String key : keys) {       final ReplicatedRecord<String,String> replicatedRecord=getReplicatedRecord(map,key);       assertNotNull(replicatedRecord);       assertEquals(0,replicatedRecord.getHits());     }   }   @Test public void test_hitsAndLastAccessTimeAreSet_withSingleNode_object() throws Exception {     testHitsAndLastAccessTimeAreSetWithSingleNode(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAndLastAccessTimeAreSet_withSingleNode_Binary() throws Exception {     testHitsAndLastAccessTimeAreSetWithSingleNode(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAndLastAccessTimeAreSetWithSingleNode(  Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map=instance1.getReplicatedMap(randomMapName());     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map.put(key,"bar");     }     for (    String key : keys) {       map.containsKey(key);     }     for (    String key : keys) {       final ReplicatedRecord<String,String> replicatedRecord=getReplicatedRecord(map,key);       assertNotNull(replicatedRecord);       assertEquals(1,replicatedRecord.getHits());       assertTrue("Last access time should be set for " + key,replicatedRecord.getLastAccessTime() > 0);     }   }   @Test public void test_hitsAndLastAccessTimeAreSet_with2Nodes_object() throws Exception {     testHitsAndLastAccessTimeAreSetFor1Of2Nodes(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAndLastAccessTimeAreSet_with2Nodes_Binary() throws Exception {     testHitsAndLastAccessTimeAreSetFor1Of2Nodes(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAndLastAccessTimeAreSetFor1Of2Nodes(  Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     warmUpPartitions(instance1,instance2);     final String mapName=randomMapName();     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap(mapName);     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap(mapName);     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");       map1.containsKey(key);     }     for (    String key : keys) {       final ReplicatedRecord<String,String> replicatedRecord=getReplicatedRecord(map1,key);       assertNotNull(replicatedRecord);       assertEquals(1,replicatedRecord.getHits());       assertTrue("Last access time should be set for " + key,replicatedRecord.getLastAccessTime() > 0);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           final ReplicatedRecord<String,String> replicatedRecord=getReplicatedRecord(map2,key);           assertNotNull(replicatedRecord);           assertEquals(0,replicatedRecord.getHits());           assertTrue("Last access time should be set for " + key,replicatedRecord.getLastAccessTime() > 0);         }       }     } );   }   @Test public void test_hitsAreIncrementedOnPuts_withSingleNode_object() throws Exception {     testHitsAreIncrementedOnPutsWithSingleNode(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAreIncrementedOnPuts_withSingleNode_Binary() throws Exception {     testHitsAreIncrementedOnPutsWithSingleNode(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAreIncrementedOnPutsWithSingleNode(  final Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map=instance1.getReplicatedMap(randomMapName());     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map.put(key,"bar");     }     for (    String key : keys) {       map.put(key,"bar");     }     for (    String key : keys) {       final ReplicatedRecord<String,String> record=getReplicatedRecord(map,key);       assertNotNull(record);       assertEquals(1,record.getHits());     }   }   @Test public void test_hitsAreIncrementedOnPuts_with2Nodes_object() throws Exception {     testHitsAreIncrementedOnPutsFor1Of2Nodes(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAreIncrementedOnPuts_with2Nodes_Binary() throws Exception {     testHitsAreIncrementedOnPutsFor1Of2Nodes(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAreIncrementedOnPutsFor1Of2Nodes(  final Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     warmUpPartitions(instance1,instance2);     final String mapName=randomMapName();     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap(mapName);     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap(mapName);     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           final ReplicatedRecord<String,String> record1=getReplicatedRecord(map1,key);           assertNotNull(record1);           assertEquals(1,record1.getHits());           final ReplicatedRecord<String,String> record2=getReplicatedRecord(map2,key);           assertNotNull(record2);           assertEquals(0,record2.getHits());         }       }     } );   } } 
config.trustStoreLocation != null
this == OtiOnly
protected FontMetrics fontMetrics; 
view.getCurrentMode()
ObjectMapper.class
LOG.info("Getting synchronous method stub from channel")
stat.st_ctim.tv_nsec.get()
Collector.<T,ImmutableSet.Builder<T>,ImmutableSet<T>>of(ImmutableSet.Builder::new,ImmutableSet.Builder::add,(ImmutableSet.Builder<T> left,ImmutableSet.Builder<T> right) -> {   left.addAll(right.build());   return left; } ,ImmutableSet.Builder::build)
executor.scheduleWithFixedDelay(this,period,period,unit)
isDirect=true
sessionConf.get("tez.queue.name") != null
this.connectTo(vertex,null,null,indexOfOutputGate,indexOfInputGate,DistributionPattern.BIPARTITE,false)
Assert.assertEquals(workerAddress,new InetSocketAddress(defaultHostname,10001))
attributes == null
/**   * This is the primary connection pool class that provides the basic pooling behavior for HikariCP.  * @author Brett Wooldridge  */ public abstract class BaseHikariPool implements HikariPoolMBean, IBagStateListener {   protected final Logger LOGGER=LoggerFactory.getLogger(getClass());   private static final long ALIVE_BYPASS_WINDOW=Long.getLong("com.zaxxer.hikari.aliveBypassWindow",1000L);   protected static final int POOL_RUNNING=0;   protected static final int POOL_SUSPENDED=1;   protected static final int POOL_SHUTDOWN=2;   public final String catalog;   public final boolean isReadOnly;   public final boolean isAutoCommit;   public int transactionIsolation;   protected final PoolUtilities poolUtils;   protected final HikariConfig configuration;   protected final AtomicInteger totalConnections;   protected final ConcurrentBag<PoolBagEntry> connectionBag;   protected final ThreadPoolExecutor addConnectionExecutor;   protected final ThreadPoolExecutor closeConnectionExecutor;   protected final ScheduledThreadPoolExecutor houseKeepingExecutorService;   protected final boolean isUseJdbc4Validation;   protected final boolean isIsolateInternalQueries;   protected volatile int poolState;   protected volatile long connectionTimeout;   protected volatile long validationTimeout;   private final LeakTask leakTask;   private final DataSource dataSource;   private final GlobalPoolLock suspendResumeLock;   private final IConnectionCustomizer connectionCustomizer;   private final AtomicReference<Throwable> lastConnectionFailure;   private final String username;   private final String password;   private volatile MetricsTracker metricsTracker;   private volatile boolean isRecordMetrics;   /**   * Construct a HikariPool with the specified configuration.  * @param configuration a HikariConfig instance  */   public BaseHikariPool(  HikariConfig configuration){     this(configuration,configuration.getUsername(),configuration.getPassword());   }   /**   * Construct a HikariPool with the specified configuration.  We cache lots of configuration items in class-local final members for speed.  * @param configuration a HikariConfig instance  * @param username authentication username  * @param password authentication password  */   public BaseHikariPool(  HikariConfig configuration,  String username,  String password){     this.username=username;     this.password=password;     this.configuration=configuration;     this.poolUtils=new PoolUtilities(configuration);     this.connectionBag=createConcurrentBag(this);     this.totalConnections=new AtomicInteger();     this.connectionTimeout=configuration.getConnectionTimeout();     this.validationTimeout=configuration.getValidationTimeout();     this.lastConnectionFailure=new AtomicReference<Throwable>();     this.isReadOnly=configuration.isReadOnly();     this.isAutoCommit=configuration.isAutoCommit();     this.suspendResumeLock=configuration.isAllowPoolSuspension() ? new GlobalPoolLock(true) : GlobalPoolLock.FAUX_LOCK;     this.catalog=configuration.getCatalog();     this.connectionCustomizer=initializeCustomizer();     this.transactionIsolation=getTransactionIsolation(configuration.getTransactionIsolation());     this.isIsolateInternalQueries=configuration.isIsolateInternalQueries();     this.isUseJdbc4Validation=configuration.getConnectionTestQuery() == null;     setMetricRegistry(configuration.getMetricRegistry());     setHealthCheckRegistry(configuration.getHealthCheckRegistry());     this.dataSource=poolUtils.initializeDataSource(configuration.getDataSourceClassName(),configuration.getDataSource(),configuration.getDataSourceProperties(),configuration.getDriverClassName(),configuration.getJdbcUrl(),username,password);     this.addConnectionExecutor=createThreadPoolExecutor(configuration.getMaximumPoolSize(),"HikariCP connection filler (pool " + configuration.getPoolName() + ")",configuration.getThreadFactory(),new ThreadPoolExecutor.DiscardPolicy());     this.closeConnectionExecutor=createThreadPoolExecutor(4,"HikariCP connection closer (pool " + configuration.getPoolName() + ")",configuration.getThreadFactory(),new ThreadPoolExecutor.CallerRunsPolicy());     long delayPeriod=Long.getLong("com.zaxxer.hikari.housekeeping.periodMs",TimeUnit.SECONDS.toMillis(30L));     ThreadFactory threadFactory=configuration.getThreadFactory() != null ? configuration.getThreadFactory() : new DefaultThreadFactory("Hikari Housekeeping Timer (pool " + configuration.getPoolName() + ")",true);     this.houseKeepingExecutorService=new ScheduledThreadPoolExecutor(1,threadFactory,new ThreadPoolExecutor.DiscardPolicy());     this.houseKeepingExecutorService.scheduleAtFixedRate(getHouseKeeper(),delayPeriod,delayPeriod,TimeUnit.MILLISECONDS);     this.houseKeepingExecutorService.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);     this.leakTask=(configuration.getLeakDetectionThreshold() == 0) ? LeakTask.NO_LEAK : new LeakTask(configuration.getLeakDetectionThreshold(),houseKeepingExecutorService);     setRemoveOnCancelPolicy(houseKeepingExecutorService);     poolUtils.setLoginTimeout(dataSource,connectionTimeout);     registerMBeans(configuration,this);     initializeConnections();   }   /**   * Get a connection from the pool, or timeout after connectionTimeout milliseconds.  * @return a java.sql.Connection instance  * @throws SQLException thrown if a timeout occurs trying to obtain a connection  */   public final Connection getConnection() throws SQLException {     return getConnection(connectionTimeout);   }   /**   * Get a connection from the pool, or timeout after the specified number of milliseconds.  * @param hardTimeout the maximum time to wait for a connection from the pool  * @return a java.sql.Connection instance  * @throws SQLException thrown if a timeout occurs trying to obtain a connection  */   public final Connection getConnection(  final long hardTimeout) throws SQLException {     suspendResumeLock.acquire();     long timeout=hardTimeout;     final long start=System.currentTimeMillis();     final MetricsContext metricsContext=(isRecordMetrics ? metricsTracker.recordConnectionRequest(start) : MetricsTracker.NO_CONTEXT);     try {       do {         final PoolBagEntry bagEntry=connectionBag.borrow(timeout,TimeUnit.MILLISECONDS);         if (bagEntry == null) {           break;         }         final long now=System.currentTimeMillis();         if (bagEntry.evicted || (now - bagEntry.lastAccess > ALIVE_BYPASS_WINDOW && !isConnectionAlive(bagEntry.connection))) {           closeConnection(bagEntry,"(connection evicted or dead)");           timeout=hardTimeout - elapsedTimeMs(start);         }  else {           metricsContext.setConnectionLastOpen(bagEntry,now);           metricsContext.stop();           return ProxyFactory.getProxyConnection((HikariPool)this,bagEntry,leakTask.start(bagEntry));         }       }  while (timeout > 0L);     }  catch (    InterruptedException e) {       throw new SQLException("Interrupted during connection acquisition",e);     }  finally {       suspendResumeLock.release();     }     logPoolState("Timeout failure ");     throw new SQLTimeoutException(String.format("Timeout after %dms of waiting for a connection.",elapsedTimeMs(start)),lastConnectionFailure.getAndSet(null));   }   /**   * Release a connection back to the pool, or permanently close it if it is broken.  * @param bagEntry the PoolBagEntry to release back to the pool  */   public final void releaseConnection(  final PoolBagEntry bagEntry){     metricsTracker.recordConnectionUsage(bagEntry);     if (bagEntry.evicted) {       LOGGER.debug("Connection returned to pool {} is broken or evicted.  Closing connection.",configuration.getPoolName());       closeConnection(bagEntry,"(connection broken or evicted)");     }  else {       connectionBag.requite(bagEntry);     }   }   /**   * Shutdown the pool, closing all idle connections and aborting or closing active connections.  * @throws InterruptedException thrown if the thread is interrupted during shutdown  */   public final void shutdown() throws InterruptedException {     if (poolState != POOL_SHUTDOWN) {       poolState=POOL_SHUTDOWN;       LOGGER.info("HikariCP pool {} is shutting down.",configuration.getPoolName());       logPoolState("Before shutdown ");       connectionBag.close();       softEvictConnections();       houseKeepingExecutorService.shutdown();       addConnectionExecutor.shutdownNow();       houseKeepingExecutorService.awaitTermination(5L,TimeUnit.SECONDS);       addConnectionExecutor.awaitTermination(5L,TimeUnit.SECONDS);       final ExecutorService assassinExecutor=createThreadPoolExecutor(configuration.getMaximumPoolSize(),"HikariCP connection assassin",configuration.getThreadFactory(),new ThreadPoolExecutor.CallerRunsPolicy());       final long start=System.currentTimeMillis();       do {         softEvictConnections();         abortActiveConnections(assassinExecutor);       }  while (getTotalConnections() > 0 && elapsedTimeMs(start) < TimeUnit.SECONDS.toMillis(5));       assassinExecutor.shutdown();       assassinExecutor.awaitTermination(5L,TimeUnit.SECONDS);       closeConnectionExecutor.shutdown();       closeConnectionExecutor.awaitTermination(5L,TimeUnit.SECONDS);       logPoolState("After shutdown ");       unregisterMBeans(configuration,this);       metricsTracker.close();     }   }   /**   * Evict a connection from the pool.  * @param proxyConnection the connection to evict  */   public final void evictConnection(  IHikariConnectionProxy proxyConnection){     closeConnection(proxyConnection.getPoolBagEntry(),"(connection evicted by user)");   }   /**   * Get the wrapped DataSource.  * @return the wrapped DataSource  */   public final DataSource getDataSource(){     return dataSource;   }   /**   * Get the pool configuration object.  * @return the {@link HikariConfig} for this pool  */   public final HikariConfig getConfiguration(){     return configuration;   }   @Override public String toString(){     return configuration.getPoolName();   }   /**   * {@inheritDoc}   */   @Override public final int getActiveConnections(){     return connectionBag.getCount(STATE_IN_USE);   }   /**   * {@inheritDoc}   */   @Override public final int getIdleConnections(){     return connectionBag.getCount(STATE_NOT_IN_USE);   }   /**   * {@inheritDoc}   */   @Override public final int getTotalConnections(){     return connectionBag.size() - connectionBag.getCount(STATE_REMOVED);   }   /**   * {@inheritDoc}   */   @Override public final int getThreadsAwaitingConnection(){     return connectionBag.getPendingQueue();   }   /**   * {@inheritDoc}   */   @Override public final void suspendPool(){     if (suspendResumeLock == GlobalPoolLock.FAUX_LOCK) {       throw new IllegalStateException("Pool " + configuration.getPoolName() + " is not suspendable");     }  else     if (poolState != POOL_SUSPENDED) {       suspendResumeLock.suspend();       poolState=POOL_SUSPENDED;     }   }   /**   * {@inheritDoc}   */   @Override public final void resumePool(){     if (poolState == POOL_SUSPENDED) {       poolState=POOL_RUNNING;       addBagItem();       suspendResumeLock.resume();     }   }   public void setMetricRegistry(  Object metricRegistry){     this.isRecordMetrics=metricRegistry != null;     if (isRecordMetrics) {       this.metricsTracker=new CodaHaleMetricsTracker(this,(MetricRegistry)metricRegistry);     }  else {       this.metricsTracker=new MetricsTracker(this);     }   }   public void setHealthCheckRegistry(  Object healthCheckRegistry){     if (healthCheckRegistry != null) {       CodahaleHealthChecker.registerHealthChecks(this,(HealthCheckRegistry)healthCheckRegistry);     }   }   /**   * {@inheritDoc}   */   @Override public Future<Boolean> addBagItem(){     FutureTask<Boolean> future=new FutureTask<Boolean>(new Runnable(){       public void run(){         long sleepBackoff=200L;         final int minimumIdle=configuration.getMinimumIdle();         final int maxPoolSize=configuration.getMaximumPoolSize();         while (poolState == POOL_RUNNING && totalConnections.get() < maxPoolSize && getIdleConnections() <= minimumIdle && !addConnection()) {           quietlySleep(sleepBackoff);           sleepBackoff=Math.min(connectionTimeout / 2,(long)((double)sleepBackoff * 1.5));         }       }     } ,true);     addConnectionExecutor.execute(future);     return future;   }   /**   * Create and add a single connection to the pool.  */   protected final boolean addConnection(){     if (totalConnections.incrementAndGet() <= configuration.getMaximumPoolSize()) {       Connection connection=null;       try {         connection=(username == null && password == null) ? dataSource.getConnection() : dataSource.getConnection(username,password);         if (isUseJdbc4Validation && !poolUtils.isJdbc4ValidationSupported(connection)) {           throw new SQLException("JDBC4 Connection.isValid() method not supported, connection test query must be configured");         }         final int originalTimeout=poolUtils.getAndSetNetworkTimeout(connection,connectionTimeout);         transactionIsolation=(transactionIsolation < 0 ? connection.getTransactionIsolation() : transactionIsolation);         poolUtils.setupConnection(connection,isAutoCommit,isReadOnly,transactionIsolation,catalog);         connectionCustomizer.customize(connection);         poolUtils.executeSql(connection,configuration.getConnectionInitSql(),isAutoCommit);         poolUtils.setNetworkTimeout(connection,originalTimeout);         connectionBag.add(new PoolBagEntry(connection,this));         lastConnectionFailure.set(null);         return true;       }  catch (      Exception e) {         lastConnectionFailure.set(e);         if (poolState == POOL_RUNNING) {           LOGGER.debug("Connection attempt to database {} failed: {}",configuration.getPoolName(),e.getMessage(),e);         }         poolUtils.quietlyCloseConnection(connection,"(exception during connection creation)");       }     }     totalConnections.decrementAndGet();     return false;   }   /**   * Fill pool up from current idle connections (as they are perceived at the point of execution) to minimumIdle connections.  */   protected void fillPool(){     final int connectionsToAdd=configuration.getMinimumIdle() - getIdleConnections();     for (int i=0; i < connectionsToAdd; i++) {       addBagItem();     }     if (connectionsToAdd > 0 && LOGGER.isDebugEnabled()) {       addConnectionExecutor.execute(new Runnable(){         public void run(){           logPoolState("After fill ");         }       } );     }   }   /**   * Permanently close the real (underlying) connection (eat any exception).  * @param connectionProxy the connection to actually close  */   protected abstract void closeConnection(  final PoolBagEntry bagEntry,  final String closureReason);   /**   * Check whether the connection is alive or not.  * @param connection the connection to test  * @return true if the connection is alive, false if it is not alive or we timed out  */   protected abstract boolean isConnectionAlive(  final Connection connection);   /**   * Attempt to abort() active connections on Java7+, or close() them on Java6.  * @param assassinExecutor   * @throws InterruptedException   */   protected abstract void abortActiveConnections(  final ExecutorService assassinExecutor) throws InterruptedException ;   /**   * Create the JVM version-specific ConcurrentBag instance used by the pool.  * @param listener the IBagStateListener instance  * @return a ConcurrentBag instance  */   protected abstract ConcurrentBag<PoolBagEntry> createConcurrentBag(  IBagStateListener listener);   /**   * Create the JVM version-specific Housekeeping runnable instance used by the pool.  * @return the HouseKeeper instance  */   protected abstract Runnable getHouseKeeper();   /**   * Fill the pool up to the minimum size.  */   private void initializeConnections(){     if (configuration.isInitializationFailFast()) {       try {         try {           if (!addConnection()) {             shutdown();             throw new PoolInitializationException(lastConnectionFailure.getAndSet(null));           }           ConnectionProxy connection=(ConnectionProxy)getConnection();           connection.getPoolBagEntry().evicted=(configuration.getMinimumIdle() == 0);           connection.close();         }  catch (        SQLException e) {           shutdown();           throw new PoolInitializationException(e);         }       }  catch (      InterruptedException ie) {         throw new PoolInitializationException(ie);       }     }     fillPool();   }   /**   * Construct the user's connection customizer, if specified.  * @return an IConnectionCustomizer instance  */   @SuppressWarnings("deprecation") private IConnectionCustomizer initializeCustomizer(){     if (configuration.getConnectionCustomizerClassName() != null) {       return createInstance(configuration.getConnectionCustomizerClassName(),IConnectionCustomizer.class);     }     return configuration.getConnectionCustomizer();   }   public final void logPoolState(  String... prefix){     if (LOGGER.isDebugEnabled()) {       LOGGER.debug("{}pool stats {} (total={}, inUse={}, avail={}, waiting={})",(prefix.length > 0 ? prefix[0] : ""),configuration.getPoolName(),getTotalConnections(),getActiveConnections(),getIdleConnections(),getThreadsAwaitingConnection());     }   } } 
"Deleting existing file: " + tempTarget
edgeData.getAttributes() == null
JSError.make(ModuleLoader.MODULE_CONFLICT,getName())
assertClusterSize(2,data2,data3)
new MapStoreWithStoreCount(expectedStoreCount,300,100)
count <= 0
StringByteIteartor.putAllAsByteIterators(result,jedis.hgetAll(key))
serverSocket.setReuseAddress(false)
executor.submit(new NamedRunnable("OkHttp Window Update %s stream %d",hostName,streamId){   @Override public void execute(){     try {       frameWriter.windowUpdate(streamId,unacknowledgedBytesRead);     }  catch (    IOException ignored) {     }   } } )
!returnValue
renderer.filledRect(x + rect.x + settings.paddingX,y + rect.y + settings.paddingY,rect.width - settings.paddingX,rect.height - settings.paddingY)
activeCount == maxActive
logger.error("InfluxDB is not yet connected")
ProcedureTestingUtility.waitNoProcedureRunning(master.getMasterProcedureExecutor())
MANAGEMENT_API_MICRO_VERSION=0
new ValidationException("Unable to deserialize string '" + base64String + "' of base class '"+ baseClass.getName()+ "'.")
promise.tryFailure(new ClosedChannelException())
null != rootCause
start.set(Calendar.DAY_OF_MONTH,startMonth)
DirectMessage.constructDirectMessages(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/direct_messages.json"))
System.arraycopy(value,0,value,length,value.length)
new AndroidFiles(this.getService().getAssets())
Assert.assertFalse(mFileSystem.getStatus(uri).getInMemoryPercentage() == 100)
mock.expectedBodiesReceived("Hello World 3")
ExceptionUtils.getFullStackTrace(th)
clientInvocation.invokeUrgent().andThen(new ExecutionCallback<ClientMessage>(){   @Override public void onResponse(  ClientMessage response){     if (connection.isAlive()) {       connection.onHeartbeatReceived();     }   }   @Override public void onFailure(  Throwable t){     if (connection.isAlive()) {       logger.warning("Error receiving heartbeat for connection: " + connection,t);     }   } } )
targetActor.addListener(listener)
heatpumpValues[65]
!tableLayoutHandle.getPartitions().isPresent()
id=15851
private final Executor eventExecutor; 
Arrays.asList("spring-boot-starter-tomcat-","tomcat-embed-core-","tomcat-embed-el-","tomcat-embed-logging-juli-","tomcat-embed-websocket-")
String result=""; 
c < ic
NbBundle.getMessage(DesktopImportControllerUI.class,"DesktopImportControllerUI.spigot.ui.dialog.title")
annotatorImplementation.custom(inputProps,customName)
Preconditions.checkNotNull(manager)
GL20.glGetUniform(program,location,params)
EXTFramebufferObject.glGetRenderbufferParameterEXT(target,pname,params)
simple.getFromSentDate()
new CustomChangeException("Failed to insert one or more concept map types")
ConnectorSplitManager.class
unlockForRegularUsage()
Thread.sleep(3000)
before != after
totalConnections.incrementAndGet() > configuration.getMaximumPoolSize()
List<String>
new RuntimeException("Could not create TypeInformation for type " + type.getName() + "; please specify the TypeInformation manually via "+ "ExecutionEnvironment#fromElements(Collection, TypeInformation)")
stat.st_mode.get()
config.getMaxQueryMemoryPerNode().toBytes() < maxMemory.toBytes()
@Overridee
MongoConnection.getInstance().connect(null,null,"localhost","graylog2test",Integer.valueOf(27017),"false")
unsafeBuffers.contains(buffer,true)
ObjectStreamClass.lookupAny(clazz)
handle.parent().exists()
assertEquals(10,events.size())
new URI(parentUri.getScheme(),parentUri.getAuthority(),parentUri.getPath() + SEPARATOR,null)
assertEquals(c1.counts + c2.counts,SIZE * COUNTDOWN)
progress.start(0.45f)
activeFrom.getTime()
((ExchangeIdempotentRepository<String>)idempotentRepository).contains(exchange,messageId)
theClass.getConstructor(new Class[0])
new Path(testBucket.getParent(),".test-2.inprogress").toString()
data.remaining()
HornetQAutoConfiguration.class
assertEquals(response.getStatusCode(),302)
assertEquals(1,this.context.getBean(FilterChainProxy.class).getFilterChains().size())
conf.set("tez.queue.name",null)
new StringBuilder(561)
LOG.error("Failed to shut down ActorSystem")
jmsTemplate.setPubSubDomain(false)
JSError.make(currentStatement,Es6ToEs3Converter.CANNOT_CONVERT,"Undecomposable expression")
knownType != null
NodeUtil.getFunctionNameNode(enclosingFunction)
cache5.setColor(red)
testOffset=4875454l
2f / 3f
SimpleAttributeDefinitionBuilder.create(ModelDescriptionConstants.ANY_IPV6_ADDRESS,ModelType.BOOLEAN).setAllowExpression(false).setAllowNull(false)
cr.session_timeout_ms != 0
name="java:comp/ds"
twitter1.getRetweeterIds(18594701629l,-1)
LOG.info("Creating short circuit output stream for block {} @ {}",blockId,address)
@Override public Cell deepClone(){   throw new UnsupportedOperationException(); } 
new RuntimeException("Unexpected rule: " + ruleStr)
ssl.has(CommonAttributes.CERTIFICATE_KEY_FILE)
m_data.getFixString((int)m_length)
assertEquals(1,historyService.createHistoricActivityInstanceQuery().processInstanceId(processInstance.getId()).list().size())
edge.setType(EdgeDirection.UNDIRECTED)
/**   * The package controller for the current file. Used for performance optimisation.  */ private PkgControl currentLeaf; 
id=15870
setUnknownLabels(binarized,mainLabel)
new Duration(TimeUnit.MILLISECONDS,CRETAED_EXPIRY_TIME_IN_MSEC)
basicInvocation.potentialResponse == null
initialCapacity < capacity
name="org.jboss.as.test.integration.ee.datasourcedefinition.DataSourceBean/dataSource3"
conceptToValidate.getConceptId()
findClass
log.errorf("started ResourceAdapterService %s",context.getController().getName())
final StringBuffer result=new StringBuffer(20); 
List<ConformanceConfig>
pushExecutor.submit(new NamedRunnable("OkHttp %s Push Headers[%s]",hostName,streamId){   @Override public void execute(){     boolean cancel=pushObserver.onHeaders(streamId,requestHeaders,inFinished);     try {       if (cancel)       frameWriter.rstStream(streamId,ErrorCode.CANCEL);       if (cancel || inFinished) { synchronized (SpdyConnection.this) {           currentPushRequests.remove(streamId);         }       }     }  catch (    IOException ignored) {     }   } } )
javaBeanSerializer.getFieldValues(json)
new DataSegment("test",new Interval("2012-02-01/2012-02-02"),new DateTime().toString(),Maps.<String,Object>newHashMap(),Lists.<String>newArrayList(),Lists.<String>newArrayList(),new NoneShardSpec(),1)
/**   * Returns messages older than the message ID specified as a numeric string. This is useful for paginating messages. For example, if you're currently viewing 20 messages and the oldest is number 2912, you could append "?olderThan=2912 to your request to get the 20 messages prior to those you're seeing.  */ private Integer olderThan=-1; 
CellUtil.estimatedHeapSizeOf(c)
logger.info("{} exists but cannot be executed even when execute permissions set; " + "check volume for \"noexec\" flag; use -Dio.netty.native.workdir=[path] " + "to set native working directory separately.",tmpFile.getPath())
uncompressedProto.length < 2500000
event.getColumns()
new GenericAggregationFunction(NAME,inputTypes,intermediateType,BIGINT,false,false,factory)
10 * Constants.SECOND_MS
assertEquals(302,t.request().get().getStatus())
config.setBeanCache(model.get(EJB3SubsystemModel.CLIENT_MAPPINGS_CACHE).asString())
oldestUnflushedStoreSequenceIds.put(encodedRegionName,oldestUnflushedStoreSequenceIdsOfRegion)
offset * 12
GL20.glGetVertexAttrib(index,pname,params)
NSNumber.numberWithLong(val)
@IntMethodAnnotation(value=-45)
new CSVFilter(lines)
new ResourceProfile(Double.MAX_VALUE,Integer.MAX_VALUE,Integer.MAX_VALUE,Integer.MAX_VALUE,Integer.MAX_VALUE,managedMemoryPerSlot,Collections.emptyMap())
IntrospectionSupport.setProperties(jpa,options)
mock.expectedMessageCount(0)
new HashMap<>(queryMemoryReservations)
ImmutableSortedSet.of("a","abbr","acronym","address","area","b","bdo","big","blockquote","br","caption","cite","code","colgroup","dd","del","div","dfn","dl","dt","em","fieldset","font","h1","h2","h3","h4","h5","h6","hr","i","img","ins","kbd","li","ol","p","pre","q","samp","small","span","strong","style","sub","sup","table","tbody","td","tfoot","th","thead","tr","tt","ul")
from("direct:b").delay(500)
500 * 1000000L
END + " End Message Interceptor"
Assert.assertFalse(rule.appliesTo(builder.interval(new Interval(now.minusDays(1),now.plusDays(1))).build(),now))
g.tool.errMgr.grammarError(ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED,g.fileName,tree.token)
getWrappedEngine().release()
doubleValue == 0
primitiveType != null
exclude
new RMNodeImpl(nodeId,rmContext,null,0,0,null,null,null)
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
UriBuilder.fromResource(AlarmCallbackResource.class).path("{alarmCallbackId}").build(id)
/**   * {@code "x-frame-options"}  */ public static final CharSequence X_FRAME_OPTIONS=new AsciiString("x-frame-options"); 
assertEquals(2,data.size())
Logger.getLogger(loggerName).getLevel()
block.useSourceInfoFromForTree(exprRoot)
public class XpathRegressionNestedForDepthTest extends AbstractXpathTestSupport {   @Test public void testCorrect() throws Exception {     final String checkName=NestedForDepthCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionNestedForDepth.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(NestedForDepthCheck.class);     final String[] expectedViolation={"7:17: " + getCheckMessage(NestedForDepthCheck.class,NestedForDepthCheck.MSG_KEY,2,1)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionNestedForDepth']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_FOR/SLIST/LITERAL_FOR/SLIST/LITERAL_FOR");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
twitter4j.List.constructListOfLists(get(getApiBaseURL() + V1 + user+ "/lists/subscriptions.json?cursor="+ cursor,true))
8 * Bytes.SIZEOF_LONG
new NativeCodeGenerator().generate()
String.format("Starting audit...%n" + expectedPath + ":3:14: "+ "warning: Name 'InputMain' must match pattern '^[a-z0-9]*$'.%n"+ expectedPath+ ":5:7: "+ "warning: Name 'InputMainInner' must match pattern '^[a-z0-9]*$'.%n"+ "Audit done.%n")
req.getServletPath()
newCount < reservoirSize
instance.managementService.unregister()
new InstrumentedTimingCollector(Metrics.defaultRegistry(),Database.class)
id=15831
Assert.assertEquals(2,visitor.getConditions().size())
/**   * @return the root {@link PkgControl} object loaded.  */ private PkgControl getRoot(){   return stack.peek(); } 
public class XpathRegressionExplicitInitializationTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=ExplicitInitializationCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ExplicitInitializationCheck.class);     final String[] expectedViolation={"4:17: " + getCheckMessage(ExplicitInitializationCheck.class,ExplicitInitializationCheck.MSG_KEY,"a",0)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitOne']" + "/OBJBLOCK/VARIABLE_DEF[@text='a']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=ExplicitInitializationCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ExplicitInitializationCheck.class);     final String[] expectedViolation={"6:20: " + getCheckMessage(ExplicitInitializationCheck.class,ExplicitInitializationCheck.MSG_KEY,"bar","null")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='bar']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
stackTrace.length < depth
/**   */ class SctpServerPipelineSink extends AbstractScptChannelSink {   static final InternalLogger logger=InternalLoggerFactory.getInstance(SctpServerPipelineSink.class);   private final SctpWorker[] workers;   private final AtomicInteger workerIndex=new AtomicInteger();   SctpServerPipelineSink(  Executor workerExecutor,  int workerCount){     workers=new SctpWorker[workerCount];     for (int i=0; i < workers.length; i++) {       workers[i]=new SctpWorker(workerExecutor);     }   }   @Override public void eventSunk(  ChannelPipeline pipeline,  ChannelEvent e) throws Exception {     Channel channel=e.getChannel();     if (channel instanceof SctpServerChannelImpl) {       handleServerSocket(e);     }  else     if (channel instanceof SctpChannelImpl) {       handleAcceptedSocket(e);     }   }   private void handleServerSocket(  ChannelEvent e){     if (!(e instanceof ChannelStateEvent)) {       return;     }     ChannelStateEvent event=(ChannelStateEvent)e;     SctpServerChannelImpl channel=(SctpServerChannelImpl)event.getChannel();     ChannelFuture future=event.getFuture();     ChannelState state=event.getState();     Object value=event.getValue(); switch (state) { case OPEN:       if (Boolean.FALSE.equals(value)) {         close(channel,future);       }     break; case BOUND:   if (value != null) {     bind(channel,future,(SocketAddress)value);   }  else {     close(channel,future);   } case INTEREST_OPS: if (event instanceof SctpBindAddressEvent) {   SctpBindAddressEvent bindAddressEvent=(SctpBindAddressEvent)event;   bindAddress(channel,bindAddressEvent.getFuture(),bindAddressEvent.getValue()); } if (event instanceof SctpUnbindAddressEvent) { SctpUnbindAddressEvent unbindAddressEvent=(SctpUnbindAddressEvent)event; unbindAddress(channel,unbindAddressEvent.getFuture(),unbindAddressEvent.getValue()); } break; } } private void handleAcceptedSocket(ChannelEvent e){ if (e instanceof ChannelStateEvent) { ChannelStateEvent event=(ChannelStateEvent)e; SctpChannelImpl channel=(SctpChannelImpl)event.getChannel(); ChannelFuture future=event.getFuture(); ChannelState state=event.getState(); Object value=event.getValue(); switch (state) { case OPEN: if (Boolean.FALSE.equals(value)) { channel.worker.close(channel,future); } break; case BOUND: case CONNECTED: if (value == null) { channel.worker.close(channel,future); } break; case INTEREST_OPS: channel.worker.setInterestOps(channel,future,(Integer)value); break; } }  else if (e instanceof MessageEvent) { MessageEvent event=(MessageEvent)e; SctpChannelImpl channel=(SctpChannelImpl)event.getChannel(); boolean offered=channel.writeBuffer.offer(event); assert offered; channel.worker.writeFromUserCode(channel); } } private void bind(SctpServerChannelImpl channel,ChannelFuture future,SocketAddress localAddress){ boolean bound=false; boolean bossStarted=false; try { channel.serverChannel.bind(localAddress,channel.getConfig().getBacklog()); bound=true; channel.setBound(); future.setSuccess(); fireChannelBound(channel,channel.getLocalAddress()); Executor bossExecutor=((SctpServerSocketChannelFactory)channel.getFactory()).bossExecutor; DeadLockProofWorker.start(bossExecutor,new Boss(channel)); bossStarted=true; }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); }  finally { if (!bossStarted && bound) { close(channel,future); } } } private void bindAddress(SctpServerChannelImpl channel,ChannelFuture future,InetAddress localAddress){ try { channel.serverChannel.bindAddress(localAddress); future.setSuccess(); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void unbindAddress(SctpServerChannelImpl channel,ChannelFuture future,InetAddress localAddress){ try { channel.serverChannel.unbindAddress(localAddress); future.setSuccess(); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void close(SctpServerChannelImpl channel,ChannelFuture future){ boolean bound=channel.isBound(); try { if (channel.serverChannel.isOpen()) { channel.serverChannel.close(); Selector selector=channel.selector; if (selector != null) { selector.wakeup(); } } channel.shutdownLock.lock(); try { if (channel.setClosed()) { future.setSuccess(); if (bound) { fireChannelUnbound(channel); } fireChannelClosed(channel); }  else { future.setSuccess(); } }   finally { channel.shutdownLock.unlock(); } }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } SctpWorker nextWorker(){ return workers[Math.abs(workerIndex.getAndIncrement() % workers.length)]; } private final class Boss implements Runnable { private final Selector selector; private final SctpServerChannelImpl channel; Boss(SctpServerChannelImpl channel) throws IOException { this.channel=channel; selector=Selector.open(); boolean registered=false; try { channel.serverChannel.register(selector,SelectionKey.OP_ACCEPT); registered=true; }   finally { if (!registered) { closeSelector(); } } channel.selector=selector; } @Override public void run(){ final Thread currentThread=Thread.currentThread(); channel.shutdownLock.lock(); try { for (; ; ) { try { if (selector.select(500) > 0) { selector.selectedKeys().clear(); } SctpChannel acceptedSocket=channel.serverChannel.accept(); if (acceptedSocket != null) { registerAcceptedChannel(acceptedSocket,currentThread); } }  catch (SocketTimeoutException e) { } catch (CancelledKeyException e) { } catch (ClosedSelectorException e) { } catch (ClosedChannelException e) { break; } catch (Throwable e) { if (logger.isWarnEnabled()) { logger.warn("Failed to accept a connection.",e); } try { Thread.sleep(1000); }  catch (InterruptedException e1) { } } } }   finally { channel.shutdownLock.unlock(); closeSelector(); } } private void registerAcceptedChannel(SctpChannel acceptedSocket,Thread currentThread){ try { ChannelPipeline pipeline=channel.getConfig().getPipelineFactory().getPipeline(); SctpWorker worker=nextWorker(); worker.register(new SctpAcceptedChannel(channel.getFactory(),pipeline,channel,SctpServerPipelineSink.this,acceptedSocket,worker,currentThread),null); }  catch (Exception e) { if (logger.isWarnEnabled()) { logger.warn("Failed to initialize an accepted socket.",e); } try { acceptedSocket.close(); }  catch (IOException e2) { if (logger.isWarnEnabled()) { logger.warn("Failed to close a partially accepted socket.",e2); } } } } private void closeSelector(){ channel.selector=null; try { selector.close(); }  catch (Exception e) { if (logger.isWarnEnabled()) { logger.warn("Failed to close a selector.",e); } } } } } 
registrar.checkExisting(metric)
TIMEOUT=15000
logger.error("Invalid state {}",r)
seenVertices.contains(startAncestor)
id=9
id=15838
i > BY_DYE_DATA.length
cSet.setConcept(this)
autoCommit != conn.getAutoCommit()
new SSL((short)0,(short)MIN_SSL_OPTIONS,(short)sslPort)
public DerivedBuilder setRealmUsePreemptiveAuth(boolean usePreemptiveAuth){   realm().setUsePreemptiveAuth(usePreemptiveAuth);   return this; } 
assertEquals(iter.next().getMessage(),"Unable to open ''.")
hotRestartState != null
new CreateTable(temporaryTableName,ImmutableList.of(new LikeClause(originalTableName,Optional.of(INCLUDING))),false,tablePropertiesOverride,Optional.empty())
AsyncHttpClient.class
@UriPath
return areaHeight; 
plugin != null
Pattern.compile(CURRENT_DIR)
assertEquals(0,deserialized.getOwnedEntryMemoryCost())
clazz.getInterfaces().length <= 0
gen.get().document()
LOGGER.log(Level.SEVERE,LocalizationMessages.ERROR_COMMITTING_OUTPUT_STREAM())
ch == '?'
this.conf.addResource(coreSiteXMLInputStream)
Integer[]
route.setDelay(5000)
numMessages=1000
configList.size() == 0
ctx.write("Welcome to " + InetAddress.getLocalHost().getHostName() + " secure chat service!\n")
lockForRegularUsage()
Boolean.parseBoolean(ac)
return localVertices; 
assertEquals(503,cause.getStatusCode())
new StringBuilder()
editor.commit()
indexFile.exists()
@UriParam(label="producer",defaultValue="1") private Integer requestRequiredAcks=1; 
if (mCheckUnusedThrows) {   final ClassResolver cr=new ClassResolver(getClassLoader(),mPackageFullIdent.getText(),mImports);   try {     final Class clazz=cr.resolve(tag.getArg1());     reqd=!RuntimeException.class.isAssignableFrom(clazz) && !Error.class.isAssignableFrom(clazz);   }  catch (  ClassNotFoundException e) {     log(tag.getLineNo(),"javadoc.classInfo","@throws",tag.getArg1());   } } 
wrapper.shutdownNow()
proxyServer != null
Status.constructStatuses(get(getBaseURL() + "favorites.json",new PostParameter[0],true))
condition.isEmpty()
factory.get(sResponseWildcard,NO_ANNOTATIONS,retrofit)
HL7Constants.HL7_LOCAL_CONCEPT.equals(codingSystem)
@IntMethodAnnotation(-44)
result.expectedMessageCount(1)
runAllTasks()
this.r != null
AbstactStoreHandler<DelayedEntry>
left.getFieldName().equals(right.getFieldName())
GL20.glUniform2(location,v)
page.getSizeInBytes()
timeout=600000
logger.debug("myq ReturnCode: {}",returnCode)
@RunWith(HazelcastParallelClassRunner.class) @Category(value={QuickTest.class,ParallelTest.class}) public class ReplicatedMapAntiEntropyTest extends ReplicatedMapBaseTest {   @After public void cleanup(){     System.clearProperty("hazelcast.serialization.custom.override");   }   @Test public void testMapConvergesToSameValueWhenMissingReplicationUpdate() throws Exception {     Config config=new Config();     SerializationConfig serializationConfig=new SerializationConfig();     SerializerConfig serializerConfig=new SerializerConfig();     serializerConfig.setTypeClassName(PutOperation.class.getName());     serializerConfig.setImplementation(new PutOperationWithNoReplicationSerializer());     serializationConfig.addSerializerConfig(serializerConfig);     config.setSerializationConfig(serializationConfig);     System.setProperty("hazelcast.serialization.custom.override","true");     String mapName=randomMapName();     TestHazelcastInstanceFactory factory=createHazelcastInstanceFactory();     HazelcastInstance instance1=factory.newHazelcastInstance(config);     HazelcastInstance instance2=factory.newHazelcastInstance(config);     HazelcastInstance instance3=factory.newHazelcastInstance(config);     final ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap(mapName);     final ReplicatedMap<Object,Object> map2=instance2.getReplicatedMap(mapName);     final ReplicatedMap<Object,Object> map3=instance3.getReplicatedMap(mapName);     final String key=generateKeyOwnedBy(instance2);     final String value=randomString();     map1.put(key,value);     assertEquals(value,map1.get(key));     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(value,map2.get(key));         assertEquals(value,map3.get(key));       }     } );   } public class PutOperationWithNoReplicationSerializer implements StreamSerializer<PutOperation> {     @Override public void write(    ObjectDataOutput out,    PutOperation object) throws IOException {       object.writeData(out);     }     @Override public PutOperation read(    ObjectDataInput in) throws IOException {       final PutOperationWithNoReplication operation=new PutOperationWithNoReplication();       operation.readData(in);       return operation;     }     @Override public int getTypeId(){       return 8778;     }     @Override public void destroy(){     }   } class PutOperationWithNoReplication extends PutOperation {     public PutOperationWithNoReplication(){     }     @Override protected Collection<Address> getMemberAddresses(){       return Collections.emptyList();     }   } } 
new FilterConfiguration(filterParams,filterClass)
new ClientBuilderImpl().serviceUrl(getPulsarBrokerUrl()).ioThreads(2)
sctpChannelClass.getMethod("open",null)
public class Arial extends FontMetrics { {     maxCharHeight=781;     widths[32]=277;     widths[33]=277;     widths[34]=354;     widths[35]=556;     widths[36]=556;     widths[37]=889;     widths[38]=666;     widths[39]=190;     widths[40]=333;     widths[41]=333;     widths[42]=389;     widths[43]=583;     widths[44]=277;     widths[45]=333;     widths[46]=277;     widths[47]=277;     widths[48]=556;     widths[49]=556;     widths[50]=556;     widths[51]=556;     widths[52]=556;     widths[53]=556;     widths[54]=556;     widths[55]=556;     widths[56]=556;     widths[57]=556;     widths[58]=277;     widths[59]=277;     widths[60]=583;     widths[61]=583;     widths[62]=583;     widths[63]=556;     widths[64]=1015;     widths[65]=666;     widths[66]=666;     widths[67]=722;     widths[68]=722;     widths[69]=666;     widths[70]=610;     widths[71]=777;     widths[72]=722;     widths[73]=277;     widths[74]=500;     widths[75]=666;     widths[76]=556;     widths[77]=833;     widths[78]=722;     widths[79]=777;     widths[80]=666;     widths[81]=777;     widths[82]=722;     widths[83]=666;     widths[84]=610;     widths[85]=722;     widths[86]=666;     widths[87]=943;     widths[88]=666;     widths[89]=666;     widths[90]=610;     widths[91]=277;     widths[92]=277;     widths[93]=277;     widths[94]=469;     widths[95]=556;     widths[96]=333;     widths[97]=556;     widths[98]=556;     widths[99]=500;     widths[100]=556;     widths[101]=556;     widths[102]=277;     widths[103]=556;     widths[104]=556;     widths[105]=222;     widths[106]=222;     widths[107]=500;     widths[108]=222;     widths[109]=833;     widths[110]=556;     widths[111]=556;     widths[112]=556;     widths[113]=556;     widths[114]=333;     widths[115]=500;     widths[116]=277;     widths[117]=556;     widths[118]=500;     widths[119]=722;     widths[120]=500;     widths[121]=500;     widths[122]=500;     widths[123]=333;     widths[124]=259;     widths[125]=333;     widths[126]=583;   } } 
registration.registerOperationHandler(CommonAttributes.DISABLE_CONTEXT,ModClusterDisableContext.INSTANCE,disableContext,false)
minIdle < 0
Collection<String>
ImmutableSortedSet.of("p","br","li","dt","dd","td","hr","img","tr","th","td")
ImmutableSortedSet.of("a","abbr","acronym","address","area","b","bdo","big","blockquote","br","caption","cite","code","colgroup","dd","del","div","dfn","dl","dt","em","fieldset","h1","h2","h3","h4","h5","h6","hr","i","img","ins","kbd","li","ol","p","pre","q","samp","small","span","strong","style","sub","sup","table","tbody","td","tfoot","th","thead","tr","tt","ul")
Arrays.asList("onContextStart","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onComponentAdd","onEndpointAdd","onComponentRemove","onContextStop")
query.getDimensionSpec().preservesOrdering()
logger.debug("Illegal argument in chart: {}",e)
Object key
ConfigAssertions.recordDefaults(FeaturesConfig.class).setExperimentalSyntaxEnabled(false).setDistributedIndexJoinsEnabled(false).setDistributedJoinsEnabled(true).setRedistributeWrites(true).setOptimizeMetadataQueries(false).setOptimizeHashGeneration(true).setOptimizeSingleDistinct(true).setPushTableWriteThroughUnion(false)
lexer.token() == (Token.SELECT)
factory.get(sBodyClass,NO_ANNOTATIONS,retrofit)
items[22]
this.mrwork.getHadoopSupportsSplittable()
Assert.assertEquals(1,fastJsonConfig.getFeatures().length)
postAgg.getName().equals(metricName)
id=46
waitYieldLatch.await(25,TimeUnit.MILLISECONDS)
elementName=options.get(ARRAY_NAME)
customerResourceLocator(url)
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class)
qp.getExclusiveMinimum()
BlockWorkerUtils.getWorkerAddress(mTachyonConf).getAddress().getCanonicalHostName()
containedToken.get(TokenizerBenchmarkTestCase.MWTTokenCharacterOffsetEndAnnotation.class)
getDatabaseCatalog() != null
injectionConfiguration.getSource().getResourceValue(serviceBuilder,context,managedReferenceFactoryValue)
createOrcWriterOptions(sourceOi,conf,cacheWriter,allocSize)
Arrays.asList("spring-boot-starter-jetty-","jetty-continuation","jetty-util-","javax.servlet-","jetty-io-","jetty-http-","jetty-server-","jetty-security-","jetty-servlet-","jetty-servlets","jetty-webapp-","websocket-api","javax.annotation-api","jetty-plus","javax-websocket-server-impl-","asm-","javax.websocket-api-","asm-tree-","asm-commons-","websocket-common-","jetty-annotations-","javax-websocket-client-impl-","websocket-client-","websocket-server-","jetty-xml-","websocket-servlet-")
new StringBuilder(239)
gradHidden3[nodeIndex]
Integer.valueOf(quantifier)
new EntryEvent(packet.getName(),(int)packet.getLongValue(),toObject(packet.getKey()),toObject(packet.getValue()))
new NagiosNscaStub(25667,"password")
((Number)s.first()).intValue()
timeout=10_000L
n.getCharno()
ProcessorDefinition<ProcessorDefinition>
exchange.addRequestHeader(HttpHeaders.AUTHORIZATION,"OAuth " + currentToken)
logger.debug("Trying to map {} to {}",t,path)
NoClassDefFoundError ex
gen.generateParser()
startOffset > pages.size()
buildPages.getTypes()
logPageUrl != null || logPageUrl.length() > 0
a.getTypeByte()
LinkedHashSet<String>
AcquireJobsRunnable.class
id=15871
LOG.info("Processing changes for pool " + poolName + ": "+ pools.get(poolName))
TimeUnit.SECONDS.toMillis(3)
getSrcPath("checks/javadoc/Input_02.java")
twitter1.getRetweets(18594701629l)
header.writeBytes(mask)
Float.valueOf(value.toString())
new File(value).getPath()
methodName.equals("scan")
client.srandmember(key)
GL.glDeleteTexturesEXT(n,textures,Memory.getPosition(textures))
items[20]
(Node)container
timeOut=30_000
AlluxioWorker.class
row(null,null,null,null,null,null,null,null,null,null,null,null,null,null)
new PrestoException(INVALID_CAST_ARGUMENT,e)
calendar.get(HOUR)
CachePutAllCodec.encodeRequest(nameWithPrefix,entries,expiryPolicyData,partitionId)
assertFalse(model.getUniqueItems())
propResource.get(BOOT_TIME).asBoolean()
value | 0xff
buffer.capacity()
InetAddress.getLocalHost()
Namespace.CURRENT.toString()
GL20.glUniformMatrix2(location,transpose,value)
log.info("Performing lookup: %s --> %s",nodeIds,retVal)
applicationContext != null
jtaEnvironmentBean.getValue().getPerformImmediateCleanupOfCommitMarkableResourceBranchesMap().remove(immediateCleanup)
name=Resources.REQUEST_QUEUE
session.getMachineIdentifier().equals(config.getMachineIdentifier())
new JedisClusterCommand<Set<String>>(connectionHandler,timeout,maxRedirections){   @Override public Set<String> execute(  Jedis connection){     return connection.spop(key,count);   } } 
mAbsListView.getPositionForView(childView) == position
log.error("Checking bounds [{}, {}) (expect {} keys)",new Object[]{startCol,endCol,expected.size()})
DiagnosticType.error("JSC_TOO_MANY_TEMPLATE_PARAMS","{0}")
record.getLength() > store.getRecordSize() - store.getRecordHeaderSize()
BIG_ENOUGH_INT + 0.5
64 * 1024 * 0124
scrollbarsOnTop && scrollX
gran.next(timeStart)
String.format("Starting audit...%n" + expectedPath + ":3:14: "+ "Name 'InputMain' must match pattern '^[a-z0-9]*$'.%n"+ expectedPath+ ":5:7: "+ "Name 'InputMainInner' must match pattern '^[a-z0-9]*$'.%n"+ "Audit done.%n"+ "Checkstyle ends with 2 errors.%n")
messageHandler.serverAcceptor()
@Override public Cell deepClone(){   byte[] copy=Bytes.copy(this.bytes,this.offset,this.length);   KeyValue kv=new KeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } 
GL.glPolygonOffsetEXT(factor,units)
http2c.setInitialStreamSendWindow(initialStreamSendWindow)
toObject(value)
LOG.debug("Retrieving location for state={} of job={} from the key-value state location oracle.",jobId,queryableStateName)
id=15845
public String getPort(){   return this.port; } 
POLL_PERIOD=100L
PORT=6335
(getSource().y() + getTarget().y()) / 2f
assertEquals(10,events.size())
numConnections=5
Arrays.asList("bash","-c",command)
getPreferences().store(fos,"")
PathUtils.concatPath(src,child)
getExpressionTypesFromInput(TEST_SESSION,metadata,SQL_PARSER,INPUT_TYPES,ImmutableList.of(translatedProjection),ImmutableList.of())
logger.debug("rapidRefreshFuture scheduleing for {} millis",millis)
type.createBlockBuilder(new BlockBuilderStatus(),100)
LOG.error("Failed to look for classes in " + jarFileName + ": "+ ioEx)
http2.setInitialStreamSendWindow(initialStreamSendWindow)
IntrospectionSupport.setProperty(jpa,"timestamp",msg.getTimestamp())
createMessageConsumer(session,destinationName,null,false,null,true)
jniGetLocalAnchorA(addr,tmp)
isTestOnBorrow()
WORKER_SESSION_TIMEOUT_MS(Name.WORKER_SESSION_TIMEOUT_MS,10000)
-90
LOG.warn("discarding {} messages because the Netty client to {} is being closed",numMessages,dstAddressPrefixedName)
Arrays.asList(TYPE,SUBSCRIBE_TYPE,MESSAGE,TIMESTAMP,SIGNATURE,SIGNATURE_VERSION,MESSAGE_ID,SUBJECT,TOPIC,TOKEN)
dimensionsSpec.getDimensions()
4 * Bytes.SIZEOF_BOOLEAN
new ThreadPoolExecutor(5,Integer.MAX_VALUE,6L,TimeUnit.SECONDS,new SynchronousQueue(),new ExecutorThreadFactory(node.threadGroup,node.getThreadPoolNamePrefix("cached"),classLoader),new RejectionHandler()){   protected void beforeExecute(  Thread t,  Runnable r){     threadPoolBeforeExecute(t,r);   } } 
final PkgControl root=ImportControlLoader.load(new File(getPath("import-control_WithNewElement.xml")).toURI()); 
new ChronicleEngineEnpoint(uri,this,configuration)
NoObjectType noResolvedType=new NoResolvedType(this); 
new ClobTypeHandler()
supportSession=true
ImmutableList.of(result)
Bullet.init()
scaleX == 0
fields[i] >= 0
Character.toLowerCase(ch)
@RunWith(HazelcastParallelClassRunner.class) @Category(value={QuickTest.class,ParallelTest.class}) public class ReplicatedMapReadYourWritesTest extends ReplicatedMapBaseTest {   @Test public void testReadYourWritesBySize() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     HazelcastInstance instance2=nodeFactory.newHazelcastInstance();     final ReplicatedMap<Integer,Integer> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<Integer,Integer> map2=instance2.getReplicatedMap("default");     HashMap<Integer,Integer> map=new HashMap<Integer,Integer>();     final int count=100;     for (int i=0; i < count; i++) {       map.put(i,i);     }     map1.putAll(map);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(count,map1.size());         assertEquals(count,map2.size());       }     } );   }   @Test public void testReadYourWritesByGet() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     HazelcastInstance instance2=nodeFactory.newHazelcastInstance();     ReplicatedMap<String,Integer> map1=instance1.getReplicatedMap("default");     ReplicatedMap<String,Integer> map2=instance2.getReplicatedMap("default");     for (int i=0; i < 1000; i++) {       assertReadYourWriteByGet(instance2,map1,i);       assertReadYourWriteByGet(instance1,map2,i);     }   }   @Test public void testReadYourWritesByContainsKey() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     HazelcastInstance instance2=nodeFactory.newHazelcastInstance();     ReplicatedMap<String,Integer> map1=instance1.getReplicatedMap("default");     ReplicatedMap<String,Integer> map2=instance2.getReplicatedMap("default");     for (int i=0; i < 1000; i++) {       assertReadYourWriteByContainsKey(instance2,map1,i);       assertReadYourWriteByContainsKey(instance1,map2,i);     }   }   @Test public void testReadYourWritesByContainsValue() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     HazelcastInstance instance2=nodeFactory.newHazelcastInstance();     ReplicatedMap<String,Integer> map1=instance1.getReplicatedMap("default");     ReplicatedMap<String,Integer> map2=instance2.getReplicatedMap("default");     for (int i=0; i < 1000; i++) {       assertReadYourWriteByContainsValue(instance2,map1,i);       assertReadYourWriteByContainsValue(instance1,map2,i);     }   }   private void assertReadYourWriteByGet(  HazelcastInstance instance,  ReplicatedMap<String,Integer> map,  int value){     String key=generateKeyAndPutValue(instance,map,value);     assertEquals(value,(int)map.get(key));   }   private void assertReadYourWriteByContainsKey(  HazelcastInstance instance,  ReplicatedMap<String,Integer> map,  int value){     String key=generateKeyAndPutValue(instance,map,value);     assertTrue(map.containsKey(key));   }   private void assertReadYourWriteByContainsValue(  HazelcastInstance instance,  ReplicatedMap<String,Integer> map,  int value){     generateKeyAndPutValue(instance,map,value);     assertTrue(map.containsValue(value));   }   private String generateKeyAndPutValue(  HazelcastInstance instance,  ReplicatedMap<String,Integer> map,  int value){     String key=generateKeyOwnedBy(instance);     map.put(key,value);     return key;   } } 
lockForRescale()
Primitive.longObjectMap(32)
TEST_UTIL.waitTableEnabled(tableName)
initial=10
synchronized (this) {   if (transformed == null) {     transformed=initializer.initializeBroadcastVariable(data);     data=null;   }   return transformed; } 
(System.currentTimeMillis() - this.lastAccessedTime.getTime()) > maxInactiveInterval
t.report(n,REFERENCE_TO_SHORT_IMPORT_BY_LONG_NAME)
callTimeout=5000
Iterable<ObjectType>
getSessionTimeout().toMinutes()
Arrays.asList(STANFORD_TOKENIZE,STANFORD_SSPLIT,STANFORD_POS,STANFORD_LEMMA,STANFORD_NER)
ImmutableMap.<String,Type>of(StandardTypes.BOOLEAN,BOOLEAN,StandardTypes.BIGINT,BIGINT,StandardTypes.DOUBLE,DOUBLE,StandardTypes.VARCHAR,VARCHAR,VARCHAR.getTypeSignature().toString(),VARCHAR)
target == null
status.isDir()
conn.getResponseCode() == 201
width - originY
logger.debug("AtmosphereResource {} is resuming",uuid())
@UriPath(label="producer",defaultValue="true")
Calendar.getInstance()
new StringBuilder(709)
from(Constants.PARALLEL_LOANBROKER_URI).process(new CreditScoreProcessor(Constants.CREDITAGENCY_ADDRESS)).multicast(new BankResponseAggregationStrategy()).setParallelProcessing(true)
assertEquals(countDownLatch.getCount(),3L)
"value".equals(key)
log.warn("You did not add unauthenticated() nor session() but also don't have a current user. You probably meant unauthenticated(). This is a bug!")
libDirectory="."
contentType != null
event.isResuming()
urlToNotify.openConnection()
id=15857
callTimeoutMillis=3000
new Jackson2HalModule.HalHandlerInstantiator(HalObjectMapperConfiguration.this.relProvider,HalObjectMapperConfiguration.this.curieProvider)
ImmutableList.of()
@Override public ResponseImpl description(String description){   this.setDescription(description);   return this; } 
FiltersTopComponent.findInstance().getUiModel().getSelectedQuery()
Utils.getInt(storm_conf.get(Config.TOPOLOGY_WORKERS))
glyphPositions[i] - x <= x - glyphPositions[i - 1]
setAll(lowResults,highResults,expectedResults,MUC_TP,5965)
new DropTableEvent(tbl,deleteData,success,this)
setLowHighExpected(lowResults,highResults,expectedResults,CONLL_SCORE,53.75,54.00,54.01)
ids.getIDs().length > 90
value.isEmpty()
Byte.valueOf(value.toString())
quoteMatcher.group(0)
(xmin > x && xmin < x + width) || (xmax > x && xmax < x + width)
TestUtils.randomByte() + 127
new byte[17]
incomingMessage.getMessagePayloadByte(1)
Arrays.asList("abstract","continue","for","new","switch","assert","default","if","package","synchronized","boolean","do","goto","private","this","break","double","implements","protected","throw","byte","else","import","public","throws","case","enum","instanceof","return","transient","catch","extends","int","short","try","char","final","interface","static","void","class","finally","long","strictfp","volatile","const","float","native","super","while")
TupleDomain.none()
new IllegalStateException()
Thread.sleep(20000)
Object deserialize(byte[] b); 
new ModelNode().set(240000)
element.getNodeName()
clazz.isPrimitive() || clazz.isArray()
case BOLD: 
args.length != 2
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
logger.info("The GENA Subscription for serviceID {} is established for device {}",sub.getService().getServiceId(),sub.getService().getDevice())
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.SentencesAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.BeforeAnnotation.class,CoreAnnotations.AfterAnnotation.class,CoreAnnotations.TokenBeginAnnotation.class,CoreAnnotations.TokenEndAnnotation.class,CoreAnnotations.IndexAnnotation.class,CoreAnnotations.OriginalTextAnnotation.class,CoreAnnotations.SentenceIndexAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class)
address.getHostText()
deployment.addServletContainerInitalizer(new ServletContainerInitializerInfo(Initializer.class,new ImmediateInstanceFactory<ServletContainerInitializer>(initializer),NO_CLASSES))
ErrorHandlerFactory builder=routeContext.getRoute().getErrorHandlerBuilder(); 
handleSecurityPermissionActions(principalNode,permConfig)
n < count(coll)
new RuntimeException("Missing type parameter.")
AtmosphereResourceImpl.class.cast(r)
t.report(n,UNUSED_PRIVATE_PROPERTY)
superClass == Object.class
MESSAGES.pathEntryNotFound(path)
new EnumValidator<TransactionMode>(TransactionMode.class,true,false)
Thread.sleep(2000)
assertThat(response).isEqualToIgnoringCase("Woop woop. yay\n")
assertClusterSize(2,h2)
new BufferedImage(region.height,region.width,page.getType())
renderUpdate(out,results)
AlluxioLogServer.class
setComplete(length)
LOGGER.error("no property for " + type + ", "+ format)
assertTrue(model.getUniqueItems())
assertEquals("There should be no files",files.length,0)
this.thrown.equals("File must exist")
GL20.glUniform4(location,toIntBuffer(v,offset,count << 2))
Collection<? extends IJsonNode>
MathUtils.PI * (this.width * this.height) / 2
new DataSize(42,Unit.MEGABYTE)
exportReturnCodes(exporter)
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
ImmutableMap.of(columnFamily,mutations)
patient.getIdentifiers().size() == 1
/**   * The resource.   */ private T mResource; 
TimeUnit.SECONDS.toMillis(25)
new StringBuilder(254)
chain.filter(exchange).compose((call) -> filter(exchange,call))
Utilities.getInputPaths(jobConf,mapWork,emptyScratchDir,ctx)
recordDefaults(HiveS3Config.class).setS3AwsAccessKey(null).setS3AwsSecretKey(null).setS3Endpoint(null).setS3SignerType(null).setS3PathStyleAccess(false).setS3UseInstanceCredentials(true).setS3SslEnabled(true).setS3SseEnabled(false).setS3SseType(PrestoS3SseType.S3).setS3SseKmsKeyId(null).setS3KmsKeyId(null).setS3EncryptionMaterialsProvider(null).setS3MaxClientRetries(5).setS3MaxErrorRetries(10).setS3MaxBackoffTime(new Duration(10,TimeUnit.MINUTES)).setS3MaxRetryTime(new Duration(10,TimeUnit.MINUTES)).setS3ConnectTimeout(new Duration(5,TimeUnit.SECONDS)).setS3SocketTimeout(new Duration(5,TimeUnit.SECONDS)).setS3MultipartMinFileSize(new DataSize(16,Unit.MEGABYTE)).setS3MultipartMinPartSize(new DataSize(5,Unit.MEGABYTE)).setS3MaxConnections(500).setS3StagingDirectory(new File(StandardSystemProperty.JAVA_IO_TMPDIR.value())).setPinS3ClientToCurrentRegion(false).setS3UserAgentPrefix("").setS3AclType(PrestoS3AclType.PRIVATE).setSkipGlacierObjects(true)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class RingbufferBasicLocalTest extends RingbufferBasicTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(1).newInstances(config);   } } 
registry.put("connectionFactoryMock",connectionFactoryMock)
logger.error("",ex)
view != null
logger.error("Configuration for influxdb not yet loaded or broken.")
taskService.createTaskQuery().orderByTaskId()
BeforeAfterTester t=new BeforeAfterTester(new DisconnectionBehavior(h2,h1),new QueueCallBuilder(h2)); 
testError("class Foo extends BaseFoo { method() { Foo.base(this, 'method'); } }",GOOG_BASE_CLASS_ERROR)
WebAppUtils.getResolvedRMWebAppURLWithoutScheme(new Configuration())
mock.expectedMessageCount(1)
OptionalIdentifiedType<RoutesDefinition>
new BroadcastAction(originalMessage)
DEFAULT_DATA_SIZE_PER_COLUMN=10
DEFAULT_NUMBER_OF_WRITE_BUFFERS=128
Optional.of(Duration.seconds(1))
ProxyHelper.createProxy(endpoint,ISay.class)
servletPath.equals("/")
endFunction("write_column_statistics: ",ret != false)
xtw.writeCharacters(customProperty.getSimpleValue())
SimpleAttributeDefinitionBuilder.create("min-level",ModelType.STRING)
new InputStreamReader(bais,StandardCharsets.UTF_8)
GL20.glUniform3(location,v)
Arrays.equals(oldVal,val)
"Can't have more than 32767 vertices per batch: " + maxTriangles
method.invoke(method,ByteBuffer.allocate(1))
onCompletions != null
ResponseBody.create(MediaType.get("text/plain"),new byte[0])
totalBytesOnTiers.get(tierAlias) > 0
testError("class Foo extends BaseFoo { constructor() { Foo.base(this); } }",GOOG_BASE_CLASS_ERROR)
writeLock()
Ints.min(completedSplits.get(),splits)
dstPath.getPath()
privObj.getObjectName().equals("masking_test_subq")
assertOpenEventually(latch,3)
i < 10000
new RuntimeException("should execute connector.connect() first")
lock.lock()
STANADALONE
new ZipAggregationStrategy(true)
/**   * TreeTableCellEditor implementation. Component returned is the JTree.  */ private class TreeTableCellEditor extends AbstractCellEditor implements TableCellEditor {   @Override public Component getTableCellEditorComponent(  JTable table,  Object value,  boolean isSelected,  int row,  int column){     return tree;   }   /**   * Overridden to return false, and if the event is a mouse event it is forwarded to the tree. <p>The behavior for this is debatable, and should really be offered as a property. By returning false, all keyboard actions are implemented in terms of the table. By returning true, the tree would get a chance to do something with the keyboard events. For the most part this is ok. But for certain keys, such as left/right, the tree will expand/collapse where as the table focus should really move to a different column. Page up/down should also be implemented in terms of the table. By returning false this also has the added benefit that clicking outside of the bounds of the tree node, but still in the tree column will select the row, whereas if this returned true that wouldn't be the case. <p>By returning false we are also enforcing the policy that the tree will never be editable (at least by a key sequence).  * @see TableCellEditor  */   @Override public boolean isCellEditable(  EventObject e){     if (e instanceof MouseEvent) {       for (int counter=getColumnCount() - 1; counter >= 0; counter--) {         if (getColumnClass(counter) == TreeTableModel.class) {           final MouseEvent me=(MouseEvent)e;           final MouseEvent newME=new MouseEvent(tree,me.getID(),me.getWhen(),me.getModifiers(),me.getX() - getCellRect(0,counter,true).x,me.getY(),me.getClickCount(),me.isPopupTrigger());           tree.dispatchEvent(newME);           break;         }       }     }     return false;   } } 
retries=2
LOG.error("Fail to set owner for {} with user: {}, group: {}",path,user,group,e)
analysis.getTypeWithCoercions(windowFunction)
executionJobVertex.getParallelism()
new JmxEndpointProperties(this.environment)
out.writeObject(function)
tempBlock.getCommitPath()
cachedMessages=b.getBroadcasterConfig().applyFilters(r,t)
Status.constructStatuses(get(getBaseURL() + "statuses/retweeted_to_me.json",null,paging.asPostParameterList(),true))
transitiveClosure.setNumberOfPartitions(6)
logger.error("NODE {}: DeleteReturnRoute command failed.")
Preconditions.checkNotNull(worker)
i > BY_WOOL_DATA.length
queryPurger.scheduleAtFixedRate(new PurgeQueriesRunnable(queries.keySet(),queryManager),200,200,TimeUnit.MILLISECONDS)
System.currentTimeMillis()
new Texture(file,TextureFilter.isMipMap(min) || TextureFilter.isMipMap(max) ? true : false)
LOG.error("Failed to freeSpace: No StorageDirView has enough capacity of {} bytes",availableBytes)
reducerCount=5
new IllegalStateException()
labelProbsForToken.get(label) < entityLabelProbVals.get(label)
(getSource().z() + getTarget().z()) / 2f
props.getProperty("exporter")
getSwaggerType(swaggerModel.getAdditionalProperties())
ctx.nextOutboundMessageBuffer()
packed[j]
sentences.get(0).entityMentions() != null
Arrays.asList("Int","Float","Double","Bool","Void","String","Character")
bufferSize != minAllocSize
deploymentInfo.setDefaultEncoding(mergedMetaData.getDefaultEncoding())
id=78
frustum.update(combined)
OpenmrsProfileWithoutTest1Module.class
new HiveTableTypeMapping()
scanFeatures(getCamelKarafFeatureUrl(),"camel-core","camel-spring","camel-test")
new RetryDriver(maxRetryAttempts,minSleepTime,maxSleepTime,scaleFactor,maxRetryTime,exceptions)
heartBeatTimerTask != null
test("var foo = function () {if (true) var module = {};" + "module.exports = {};};" + "module.exports = foo;","goog.provide('module$test');" + "var foo$$module$test=function(){if(true)var module={};" + "module.exports={}};"+ "var module$test=foo$$module$test")
items[24]
Thread.sleep(200)
mavenBundle("info.cukes","cucumber-jvm-deps","1.0.4-SNAPSHOT")
public class ArialBlack extends FontMetrics { {     maxCharHeight=770;     widths[32]=333;     widths[33]=333;     widths[34]=500;     widths[35]=660;     widths[36]=666;     widths[37]=1000;     widths[38]=889;     widths[39]=277;     widths[40]=389;     widths[41]=389;     widths[42]=556;     widths[43]=660;     widths[44]=333;     widths[45]=333;     widths[46]=333;     widths[47]=277;     widths[48]=666;     widths[49]=666;     widths[50]=666;     widths[51]=666;     widths[52]=666;     widths[53]=666;     widths[54]=666;     widths[55]=666;     widths[56]=666;     widths[57]=666;     widths[58]=333;     widths[59]=333;     widths[60]=660;     widths[61]=660;     widths[62]=660;     widths[63]=610;     widths[64]=740;     widths[65]=777;     widths[66]=777;     widths[67]=777;     widths[68]=777;     widths[69]=722;     widths[70]=666;     widths[71]=833;     widths[72]=833;     widths[73]=389;     widths[74]=666;     widths[75]=833;     widths[76]=666;     widths[77]=943;     widths[78]=833;     widths[79]=833;     widths[80]=722;     widths[81]=833;     widths[82]=777;     widths[83]=722;     widths[84]=722;     widths[85]=833;     widths[86]=777;     widths[87]=1000;     widths[88]=777;     widths[89]=777;     widths[90]=722;     widths[91]=389;     widths[92]=277;     widths[93]=389;     widths[94]=660;     widths[95]=500;     widths[96]=333;     widths[97]=666;     widths[98]=666;     widths[99]=666;     widths[100]=666;     widths[101]=666;     widths[102]=389;     widths[103]=666;     widths[104]=666;     widths[105]=333;     widths[106]=333;     widths[107]=666;     widths[108]=333;     widths[109]=1000;     widths[110]=666;     widths[111]=666;     widths[112]=666;     widths[113]=666;     widths[114]=443;     widths[115]=610;     widths[116]=443;     widths[117]=666;     widths[118]=610;     widths[119]=943;     widths[120]=666;     widths[121]=610;     widths[122]=556;     widths[123]=389;     widths[124]=277;     widths[125]=389;     widths[126]=660;   } } 
case 11: 
new StringBuilder(247)
Nd4j.getAffinityManager().getDeviceForThread(Thread.currentThread())
privObj.getObjectName().equals("masking_test_view")
items[30]
MetricMonitorValues.getMetric(metrics,TRANSACTION_UNSAMPLED_NEW,UNSUPPORTED_GAUGE)
Math.abs(diff - maxAge) <= 1
name="java:/topic/myAwesomeTopic"
new HttpDigestAuthFilter(DIGEST_TEST_LOGIN,DIGEST_TEST_PASS,1)
new GenerationException(e)
DEFAULT_SHUFFLE_PORT=8080
Cli.buildCli("presto",Runnable.class)
latch.await(1,TimeUnit.MINUTES)
topicRegistrations == null && topicRegistrations.isEmpty()
GL20.glUniform2(location,toIntBuffer(v,offset,count << 1))
contentLength > 0
@Override GelfOutput create(Stream stream,Configuration configuration); 
Mockito.doNothing().when(mFileSystemMasterClient).rename(src,dst)
AstUtils.hasLeastOneAnnotation(classNode,"Controller","EnableWebMvc")
id=12
testClass.getMethod(SUITE_METHODNAME,new Class[0])
Arrays.asList(STANFORD_TOKENIZE,STANFORD_SSPLIT)
assertSizeEventually(COUNT,map)
!regex.equals(lastRegex)
log.debug("Failed to transfer file from TaskExecutor {}.",taskManagerId,throwable)
TimeUnit.SECONDS.toNanos(timeoutSeconds)
page=TESTING_AUTHENTICATION_SETUP
reg.getCounters(transformFilter(filter))
final AuditEvemtFormatter formatter=new AuditEventDefaultFormatter(); 
Optional<T>
node1.checkTreeTypeAwareEqualsSilent(node2)
Status.constructStatuses(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/statuses/public_timeline.json"))
resultEndpoint.expectedBodiesReceived("one","three")
logger.debug("Mapped {} to {}",t,e.getValue())
DUPLICATE_OPS_TOLERANCE=5
nodeData.getAttributes() == null
mock.expectedMessageCount(2)
Optional<ZkWorker>
Assert.assertFalse(rule.appliesTo(builder.interval(new Interval("0500-01-01/2100-12-31")).build(),now))
is.read(data)
logger.debug("Removing: {}",r)
executeCommand("EXPLAIN OPTIONAL MATCH (n) RETURN n;","DbHits","No data returned")
executionListenerContextCloseListener.addClosedExecutionListener(executionListener,execution,executionVariablesToUse,customPropertiesMapToUse)
Assert.assertTrue(provider.checkValid("SELECT * FROM T WHERE FID = 40 OR EXTRACTVALUE(4484,CONCAT(0x5c,0x7163646371,(SELECT (CASE WHEN (4484=4484) THEN 1 ELSE 0 END)),0x7165767271))"))
public Integer getRequestRequiredAcks(){   return requestRequiredAcks; } 
new Duration(2,SECONDS)
assertThat(configs.get(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG)).isEqualTo(123L)
Arrays.asList(STANFORD_TOKENIZE,STANFORD_SSPLIT)
result.expectedBodiesReceived("A+C+E+G+I","B+D+F+H+J")
Float.valueOf(encoding.substring(equalsPos + 1))
getConcept() != null || getConcept().getDescription() != null
intbuf.get()
this.categoryWithApiModel=categoryWithApiModel
configElements[1]
FilterRegistrationBean.class
logger.info("Skipped renaming " + instancesSkipped + " invalidated "+ "properties, "+ propsSkipped+ " instances of properties "+ "that were skipped for specific types and "+ singleTypeProps+ " properties that were referenced from only one type.")
new IOException()
public Long getAutoCommitInterval(){   return this.autoCommitInterval; } 
assertEquals(2,historyService.createHistoricActivityInstanceQuery().finished().list().size())
writtenOutputPhysicalDataSize+=stageStats.getPhysicalWrittenDataSize().toBytes()
invoke(agentInfoList,payload,DEFUALT_FUTURE_TIMEOUT)
builder.add(new ImplementSampleAsFilter(),new SimplifyExpressions(metadata),new UnaliasSymbolReferences(),new PruneRedundantProjections(),new SetFlatteningOptimizer(),new LimitPushDown(),new PredicatePushDown(metadata,splitManager),new PredicatePushDown(metadata,splitManager),new MergeProjections(),new SimplifyExpressions(metadata),new UnaliasSymbolReferences(),new PruneRedundantProjections(),new PruneUnreferencedOutputs())
DefaultFileSystemMaster.class
strategiesBuilder::messageReader
queryParams != null
articleMgmtService.addArticle(requestJSONObject)
id=32
GL.glBindTextureEXT(target,texture)
super(RowResolver.getCombinedRR(leftRR,rightRR),true,false,false,false,false,false,false,false,false,false); 
i < getATN().maxTokenType
new CamelExchangeException("JettyClient failed with state " + exchangeState,exchange)
tickTupleInterval == 0
4 * Constants.KB
r.getResponse().sendError(503)
isDoubleA && isIntA
public QueryRunner printPlan(){   printPlan=true;   return this; } 
Utilities.LOG14535.info("creating new paths " + System.identityHashCode(fsp2) + " for "+ dirName+ ", childSpec "+ unionPath+ ": tmpPath "+ fsp2.getTmpPath()+ ", task path "+ fsp2.getTaskOutputTempPath(),new Exception())
getJSDocTypeWithBraces(cp)
new IntRangeValidator(1,true,true)
StringUtils.isEmpty(formKey)
imageUrl.length() >= MAX_FILE_NAME_LENGTH
AnimationAdapter<T>
type.getSimpleName()
UfsUtils.loadUfs(mFileSystem,new AlluxioURI(AlluxioURI.SEPARATOR),new AlluxioURI(mUfsRoot + AlluxioURI.SEPARATOR),new PrefixList("alluxio;exclusions",";"),mLocalAlluxioClusterResource.get().getMasterConf())
p.getFileSystem(conf).delete(p)
maxPendingPersists > 0
location.belongTo(BlockStoreLocation.anyDirInTier(tierAlias))
log.debug(message,exception)
i < 50
assertThat(getField(graphite,"port")).isEqualTo(8080)
AbstractRanking.refreshMinMax(this,graph)
LOG.warn("Block of ID " + getCurrentBlockId() + " could not be cached into Tachyon",ioe)
executeConnectAsync=false
LOG.warn(e)
broadcasterFactoryClassName != null
/**   * Telnet port.  */ private String port="5000"; 
public class DefaultDynamicTransformerRegistry implements DynamicTrnasformerRegistry {   private final Logger logger=LoggerFactory.getLogger(this.getClass());   private final ConcurrentMap<TransformerKey,ClassFileTransformer> transformerMap=new ConcurrentHashMap<TransformerKey,ClassFileTransformer>();   @Override public void onRetransformRequest(  Class<?> target,  final ClassFileTransformer transformer){     add(target.getClassLoader(),target.getName(),transformer);     if (logger.isInfoEnabled()) {       logger.info("added retransformer classLoader: {}, class: {}, registry size: {}",target.getClassLoader(),target.getName(),transformerMap.size());     }   }   @Override public void onTransformRequest(  ClassLoader classLoader,  String targetClassName,  ClassFileTransformer transformer){     add(classLoader,targetClassName,transformer);     if (logger.isInfoEnabled()) {       logger.info("added dynamic transformer classLoader: {}, className: {}, registry size: {}",classLoader,targetClassName,transformerMap.size());     }   }   private void add(  ClassLoader classLoader,  String targetClassName,  ClassFileTransformer transformer){     ClassFileTransformer prev=transformerMap.putIfAbsent(new TransformerKey(classLoader,targetClassName.replace('.','/')),transformer);     if (prev != null) {       throw new ProfilerException("Transformer already exists. classLoader: " + classLoader + ", target: "+ targetClassName+ ", transformer: "+ prev);     }   }   @Override public ClassFileTransformer getTransformer(  ClassLoader classLoader,  String targetClassName){     if (transformerMap.isEmpty()) {       return null;     }     ClassFileTransformer transformer=transformerMap.remove(new TransformerKey(classLoader,targetClassName));     if (logger.isDebugEnabled()) {       logger.info("removed dynamic transformer classLoader: {}, className: {}, registry size: {}",classLoader,targetClassName,transformerMap.size());     }     return transformer;   } private static final class TransformerKey {     private final ClassLoader classLoader;     private final String targetClassName;     public TransformerKey(    ClassLoader classLoader,    String targetClassName){       this.classLoader=classLoader;       this.targetClassName=targetClassName;     }     @Override public int hashCode(){       return classLoader.hashCode() * 31 + targetClassName.hashCode();     }     @Override public boolean equals(    Object obj){       TransformerKey other=(TransformerKey)obj;       return this.classLoader.equals(other.classLoader) && this.targetClassName.equals(other.targetClassName);     }   } } 
LOG.warn("Failed to get mount information: {}",e.getMessage())
Thread.sleep(1350)
Assert.assertEquals("Wrong messages count: " + messages.size(),messages.size(),1)
MESSAGES.deploymentUnitNotFound(absolutePath,puName,current)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class ListBasicDistributedTest extends ListBasicTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(2).newInstances(config);   } } 
args.length == 0
logger.info("Computing Control Flow Graph")
ctClass.toClass()
BiMap<Integer,String>
new PriorityTieredBrokerSelectorStrategy(0,1)
enchantments.putAll(stack.enchantments)
logger.debug("Retreiveing door data")
c.admin().indices().existsAliases(new IndicesGetAliasesRequest(alias))
(int)timeoutMs * 1000
path(11)
ALIAS.addResourceAttributeDescription(resources,keyPrefix,container)
processDefinition.getTenantId() == null
conf.setInt("hbase.hregion.memstore.block.multiplier",10)
Set<String>
SSLHandshakeException.class
url.getServiceInterface()
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class AtomicLongBasicDistributedTest extends AtomicLongBasicTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(2).newInstances();   } } 
getMemberships().stream().filter(m -> m.isActive() && m.getPatientId().equals(patient.getPatientId())).collect(Collectors.toList())
status.isDirectory()
routeList == null
StringUtils.hasLength(secretQuestion) || StringUtils.hasLength(secretAnswer)
public DerivedBuilder setRealmEnconding(String enc){   realm().setEnconding(enc);   return this; } 
ast.getNextSibling() != null
!NettyUtils.isDomainSocketSupported(dataSource)
new ObjectRecordWithStats(key,v)
maxRowsPerFrame=100_000
Float.parseFloat(position.getChildByName("Y").getText())
T
id=18
compile.minus(provided)
@GET @Path("/{petId}") @ApiOperation(value="Find pet by ID",notes="Returns a pet when ID < 10.  ID > 10 or nonintegers will simulate API error conditions",response=Pet.class) @ApiResponses(value={@ApiResponse(code=400,message="Invalid ID supplied"),@ApiResponse(code=404,message="Pet not found")}) public Response getPetById(@ApiParam(value="ID of pet that needs to be fetched",allowableValues="range[1,5]",required=true) @PathParam("petId") String petId) throws NotFoundException {   Pet pet=petData.getPetbyId(ru.getLong(0,100000,0,petId));   if (null != pet) {     return Response.ok().entity(pet).build();   }  else {     throw new NotFoundException(404,"Pet not found");   } } 
n.intValue()
GL11.glGetFloat(pname,params)
c.getPath() == null
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class QueueBasicLocalTest extends QueueBasicTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(1).newInstances(config);   } } 
mpline.substring(0,p).trim().toLowerCase()
LOG.error(e.getMessage())
model.getNodeTextColumns() == null
configuration.addClientInterceptor(method,factory,InterceptorOrder.View.COMPONENT_DISPATCHER)
new ArrayList<FileInputSplit>(numSubtasks)
Object... pathParams
checkArgument(keyGroupRange.contains(keyGroup))
views.html.search.noresults.render(currentUser(),q,searchResult)
op.get("address").set("host",host)
PojoUtils.realize(list.toArray(),invokeMethod.getParameterTypes())
assertEquals(2,conceptStopWords.size())
controller.execute(ExecutionContextBuilder.Factory.create(update).build(),resultHandler)
assertEquals(6358482,received.get(0)[1])
assertResultExchange(result.getExchanges().get(0),false)
expression.indexOf("${") >= 0
Mockito.doThrow(EXCEPTION).when(mFileSystemMasterClient).rename(src,dst)
p == null
return softDepend; 
!locations.isDefined()
registration.registerOperationHandler(CommonAttributes.ENABLE,ModClusterEnable.INSTANCE,enable,false)
VertexAttribute.Color()
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
isTop() || isUnknown()
defaultRowFlushBoundary == null ? 500000 : defaultRowFlushBoundary
(outputFolder + File.separator + apiFolder).replaceAll("/",File.separator)
LOG.warn(e.getMessage())
multiValueRow.get(1)
map.set(keyValue.getKeyData(),value,0,TimeUnit.SECONDS)
globalExecutionStats.getSplits()
AbstractBootstrap<ServerBootstrap,ServerChannel>
Ordered.HIGHEST_PRECEDENCE + 11
String pattern=this.prefix; 
new SwiftRange(mPos,endPos)
sendCommand(CLIENT_LIST)
assertEquals(8,lm.getFields().size())
getMockEndpoint("mock:" + i).expectedMessageCount(1000)
getBinaryTupledSet()
partitionKey.getType().toString()
new LocalAlluxioClusterResource(1000,Constants.GB,Constants.SECURITY_AUTHENTICATION_TYPE,AuthType.SIMPLE.getAuthName())
buffer.rewind().forward((int)n).getFixString((int)str_len)
(outputFolder + File.separator + modelFolder).replaceAll("/",File.separator)
SimpleAttributeDefinitionBuilder.create(ModelDescriptionConstants.ANY_ADDRESS,ModelType.BOOLEAN).setAllowExpression(false).setAllowNull(false)
JedisClusterHashTagUtil.isClusterCompliantMatchPattern(matchPattern)
int retries() default 0; 
registry.put("eventBus",new EventBus())
Exception e
ServiceHelper.startService(jmx)
assertEquals(3,historyServer.getServices().size())
JsonNode::isLong
new GetExecutionVariableInstancesCmd(executionId,variableNames,false)
internalExecutor.submit(command)
logger.error("Error connecting to Plex",e)
id=19904
connection.local().createStream(toStreamId(i))
id=49
index > templateTypes.size()
Size.kilobytes(32)
new DynamicAwareEntry("http://localhost:80/test",null,null)
from("jms:queue:order").to("bean:validateOrder").to("mock:validate").threads(20).unmarshal(mySecureDataFormat).delay(1000)
@ConditionalOnEnablednHealthIndicator("redis")
Expression.eq("searchable",format)
from("direct:tap").delay(100)
public class XpathRegressionJavadocVariableTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=JavadocVariableCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionJavadocVariableOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(JavadocVariableCheck.class);     final String[] expectedViolation={"5:5: " + getCheckMessage(JavadocVariableCheck.class,JavadocVariableCheck.MSG_JAVADOC_MISSING)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='age']","/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='age']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='age']/MODIFIERS/LITERAL_PRIVATE");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=JavadocVariableCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionJavadocVariableTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(JavadocVariableCheck.class);     final String[] expectedViolation={"6:9: " + getCheckMessage(JavadocVariableCheck.class,JavadocVariableCheck.MSG_JAVADOC_MISSING)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableTwo']/OBJBLOCK" + "/CLASS_DEF[@text='InnerInner2']/OBJBLOCK/VARIABLE_DEF[@text='fData']","/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableTwo']/OBJBLOCK" + "/CLASS_DEF[@text='InnerInner2']/OBJBLOCK/VARIABLE_DEF[@text='fData']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableTwo']/OBJBLOCK" + "/CLASS_DEF[@text='InnerInner2']/OBJBLOCK/VARIABLE_DEF[@text='fData']/MODIFIERS" + "/LITERAL_PUBLIC");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
keys.isEmpty()
DatabaseDescriptor.getListenAddress().getHostName()
IRON_SWORD(267,1,59)
new CSVFilter("")
put(v)
UnderFileSystemUtils.deleteIfExists(mUfs,mTempCheckpointPath)
"unable to parse " + abstractOption
expected.getType().equals(actual.getType().toString())
/**   * Change the permission of a file or directory specified by args recursively.  */ public final class ChmodRecursiveCommand extends AbstractACLCommand {   public ChmodRecursiveCommand(  TachyonConf conf,  TachyonFileSystem tfs){     super(conf,tfs);   }   @Override public String getCommandName(){     return "chmodr";   }   @Override protected int getNumOfArgs(){     return 2;   }   @Override public void run(  String... args) throws IOException {     String modeStr=args[0];     TachyonURI path=new TachyonURI(args[1]);     chmod(path,modeStr,true);   }   @Override public String getUsage(){     return "chmodr <mode> <path>";   } } 
testSame("yz();","function yz() {}",VarCheck.NAME_REFERENCE_IN_EXTERNS_ERROR,true)
assertEquals(1,historyService.createHistoricActivityInstanceQuery().finished().list().size())
new GameOver(Gdx.app)
value={StringFilterAggregator.class}
Endpoint server
ImmutableSortedSet.of("a","abbr","acronym","address","area","b","bdo","big","blockquote","br","caption","cite","code","colgroup","del","div","dfn","dl","em","fieldset","h1","h2","h3","h4","h5","h6","hr","i","img","ins","kbd","li","ol","p","pre","q","samp","small","span","strong","style","sub","sup","table","tbody","td","tfoot","th","thead","tr","tt","ul")
new BulletTestCollection()
size=500
oldModel.getVendorExtensions().get("x-className") == null
bucketerContext.update(context.timestamp(),currentProcessingTime,context.currentWatermark())
CellUtil.estimatedHeapSizeOf(cell)
verifyViewMethodsNotDeclaredFinal(sessionBeanClass,remoteBusinessInterfaces)
registry.put("sessionStateListener",new SessionStateListener(){   @Override public void onStateChange(  SessionState arg0,  SessionState arg1,  Session arg2){   } } )
GL20.glVertexAttribPointer(indx,size,normalized,stride,(FloatBuffer)buffer)
Math.min(clientCount,1)
/**   * {@inheritDoc}  */ @Override public AtmosphereResource removeAtmosphereResource(AtmosphereResource r){   if (destroyed.get()) {     logger.debug(DESTROYED,getID(),"removeAtmosphereResource(AtmosphereResource r)");     return r;   }   if (!resources.contains(r)) {     return null;   }   boolean removed=resources.remove(r);   if (removed) {     if (resources.isEmpty()) {       notifyEmptyListener();       if (scope != SCOPE.REQUEST && lifeCyclePolicy.getLifeCyclePolicy() == EMPTY) {         releaseExternalResources();       }  else       if (scope == SCOPE.REQUEST || lifeCyclePolicy.getLifeCyclePolicy() == EMPTY_DESTROY) {         BroadcasterFactory.getDefault().remove(this,name);         destroy();       }     }   }   return r; } 
testSame(js,js)
el.className()
DeleteOptions.defaults().setRecursive(true).setAlluxioOnly(false).setUnchecked(false)
public static AnimationAction $(float scaleX,float scaleY,float duration){   ScaleTo action=pool.obtain();   action.scaleX=scaleX;   action.scaleY=scaleY;   action.duration=duration;   action.invDuration=1 / duration;   return action; } 
servers.isEmpty()
DataFormat.PAYLOAD == message.get(DataFormat.class)
from("direct:b").delay(3000)
putInternal(mapService.getMapServiceContext().toData(entry.getKey(),partitionStrategy),mapService.getMapServiceContext().toData(entry.getValue()),-1,TimeUnit.MILLISECONDS)
Database.builder()
KafkaInput.class
realIndex < columns.size()
bytesRead != 0
0xff << shift
Object edge
minPriority == null ? 0 : minPriority
n.getNodeData().getId().toLowerCase().contains(str)
new GrammaticalRelation(Language.UniversalChinese,"amod:ordmod","ordinal numeric modifier",ADJECTIVAL_MODIFIER,"NP|QP",tregexCompiler,"NP < (QP=target < OD !< CLP)","NP|QP < ( DNP=target < (QP < OD !< CD) !< JJ|ADJP $++ NP|QP )")
standardSearchRequest(query,IndexHelper.determineAffectedIndices(indexRangeService,deflector,range))
getTimeout()
assertFalse(predicate.apply(pickleEvent))
TfsShell.convertMsToDate(files[0].getCreationTimeMs())
public IMetric registerMetric(String name,IReducer reducer,int timeBucketSizeInSecs){   return registerMetric(name,new ReducedMetric(reducer),timeBucketSizeInSecs); } 
RouteContext key
@ConditionalOnEnablednHealthIndicator("mail")
buf.clear()
ImplemetationMethodDescriptor methodDescriptor
expectedCountsForADoc(weights,ind)
from("direct:a").delay(500)
Threads.sleep(2000)
constructors[TXN_REMOVE_ALL]
!type.isInterface()
callTimeout=1000
ChannelStateHandler handler=(ChannelStateHandler)handler(); 
new ChannelHandlerAdapter(){   @Override public void channelWritabilityChanged(  ChannelHandlerContext ctx) throws Exception {     buf.append(ctx.channel().isWritable());     buf.append(' ');   } } 
sname.getParent().getSimpleName().substring(9)
reportMissingOverride.isOn() && !declaredOverride && superClassHasDeclaredProperty&& declaredLocally
+portNum
id=15861
((ExecutorService)executor).isShutdown()
out.writeDouble((Float)obj)
InterruptedException e
WebServicesTestUtils.checkStringMatch("hadoopBuildVersion",VersionInfo.getBuildVersion(),hadoopBuildVersion)
System.getProperty("RecoveryEnvironmentBean.expiryScannerClassNames") != null
instance.connect(null,null,"localhost","graylog2test",Integer.valueOf(27017),"false")
getConcept() != null || getConcept().getName() != null
id=15848
8 * Constants.MB
Map<K,? extends V>
singletonComponent == null
ApplicationPidFileWriter.class
!ElementsParser.isAlphaNumeric(ch2)
waitForJobExecutorToProcessAllJobsAndExecutableTimerJobs(10000,200)
logger.info("Expanding Jquery Aliases")
_availMemory + amount
app.getGraphics().newFont(app.getFiles().getInternalFileHandle("data/arial.ttf"),12,FontStyle.Plain,true)
public class XpathRegressionRightCurlyTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=RightCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRightCurlyOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RightCurlyCheck.class);     final String[] expectedViolation={"8:9: " + getCheckMessage(RightCurlyCheck.class,RightCurlyCheck.MSG_KEY_LINE_SAME,"}",9)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRightCurlyOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_IF/SLIST/RCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=RightCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRightCurlyTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RightCurlyCheck.class);     moduleConfig.addAttribute("option",RightCurlyOption.ALONE.toString());     final String[] expectedViolation={"9:15: " + getCheckMessage(RightCurlyCheck.class,RightCurlyCheck.MSG_KEY_LINE_NEW,"}",15)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRightCurlyTwo']/OBJBLOCK" + "/METHOD_DEF[@text='fooMethod']/SLIST/LITERAL_TRY/SLIST/RCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testThree() throws Exception {     final String checkName=RightCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRightCurlyThree.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RightCurlyCheck.class);     moduleConfig.addAttribute("option",RightCurlyOption.ALONE.toString());     final String[] expectedViolation={"5:72: " + getCheckMessage(RightCurlyCheck.class,RightCurlyCheck.MSG_KEY_LINE_ALONE,"}",72)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRightCurlyThree']/OBJBLOCK" + "/METHOD_DEF[@text='sample']/SLIST/LITERAL_IF/SLIST/RCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testFour() throws Exception {     final String checkName=RightCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRightCurlyFour.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RightCurlyCheck.class);     moduleConfig.addAttribute("option",RightCurlyOption.SAME.toString());     final String[] expectedViolation={"7:27: " + getCheckMessage(RightCurlyCheck.class,RightCurlyCheck.MSG_KEY_LINE_BREAK_BEFORE,"}",27)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRightCurlyFour']/OBJBLOCK" + "/METHOD_DEF[@text='sample']/SLIST/LITERAL_IF/SLIST/RCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
mock2.expectedMinimumMessageCount(3)
Preconditions.checkNotNull(fileSystemMaster)
manager != null
message.getFormattedFields()
this.uncollectedPointCreater
new RuntimeException("Mocked failed close!")
id=13
items[32]
root.toURL()
ArrayList<String>
converterLookup.addCustomConverter(item,IntegerDecimalConverter.class)
RestartStrategies.fixedDelayRestart(3,0)
listeners != null
FileSystem.getLocal(conf).delete(localScratchDir)
assertOpenEventually("responseLatch",responseLatch,5)
PointLookupOptimizer.class
IOException e
assertEquals(12,tokens.size())
(!relaxLocality && (racks == null || racks.length == 0) && (nodes == null || nodes.length == 0))
modelNode.has(LOCAL)
new IllegalArgumentException()
sb.append(NC)
id=15863
tableName.toString()
new Interval(startTime,endTime)
"Unsupported filesystem scheme found in the backup target url. Error Message: " + newMsg
e.getMessage()
getMockEndpoint("mock:test.after.1").expectedMinimumMessageCount(10)
LOG.debug("Received ping --> {}",payload)
testConsumerConfig()
addListenerMethod1.addScopedInterceptor(NettyConstants.INTERCEPTOR_CHANNEL_PROMISE_ADD_LISTENER,NettyConstants.SCOPE,ExecutionPolicy.BOUNDARY)
super.getFamilyMap()
adapter.getArgumentResolvers()
waitUntil(() -> noHandlersErrors.get() == (NODE_COUNT - 1) * ADDRESSES_COUNT,30_000)
/**   * Remove a  {@link AtmosphereResource} from the list of item to be notified whenthe  {@link Broadcaster#broadcast} is invoked.  * @param resource an {@link AtmosphereResource}  * @return {@link AtmosphereResource} if removed, or null if it was not.  */ AtmosphereResource removeAtmosphereResource(AtmosphereResource resource); 
id=15832
(FontMetrics)c.newInstance()
DefaultAtmosphereRequest request
from("direct:c").delay(500)
camelContext.getExecutorServiceManager().shutdownNow(timeoutCheckerExecutorService)
assertEquals(5,AccessControlClient.getUserPermissions(systemUserConnection,TEST_TABLE.toString()).size())
public DerivedBuilder setRequestCompressionLevel(int requestCompressionLevel){   configBuilder.setRequestCompressionLevel(requestCompressionLevel);   return this; } 
i=3
Maps.newHashMap()
details.put(fileName,Long.toString(timestamp))
new HiveS3Config().setS3AwsAccessKey("abc123").setS3AwsSecretKey("secret").setS3Endpoint("endpoint.example.com").setS3SignerType(PrestoS3SignerType.S3SignerType).setS3PathStyleAccess(true).setS3UseInstanceCredentials(false).setS3SslEnabled(false).setS3SseEnabled(true).setS3SseType(PrestoS3SseType.KMS).setS3SseKmsKeyId("KMS_KEY_ID").setS3EncryptionMaterialsProvider("EMP_CLASS").setS3KmsKeyId("KEY_ID").setS3MaxClientRetries(9).setS3MaxErrorRetries(8).setS3MaxBackoffTime(new Duration(4,TimeUnit.MINUTES)).setS3MaxRetryTime(new Duration(20,TimeUnit.MINUTES)).setS3ConnectTimeout(new Duration(8,TimeUnit.SECONDS)).setS3SocketTimeout(new Duration(4,TimeUnit.MINUTES)).setS3MultipartMinFileSize(new DataSize(32,Unit.MEGABYTE)).setS3MultipartMinPartSize(new DataSize(15,Unit.MEGABYTE)).setS3MaxConnections(77).setS3StagingDirectory(new File("/s3-staging")).setPinS3ClientToCurrentRegion(true).setS3UserAgentPrefix("user-agent-prefix").setS3AclType(PrestoS3AclType.PUBLIC_READ).setSkipGlacierObjects(false)
ASYNC_CONSUMER_THREAD.getStackTrace()
LOCAL_OPTION.getOpt()
ttl > 0
(AST)child
modifiers.branchContains(TokenTypes.LITERAL_PRIVATE) || modifiers.branchContains(TokenTypes.ABSTRACT) || modifiers.branchContains(TokenTypes.FINAL)
new HttpClientCodec(4096,8192,8192,true)
fragUtils.getClass()
idAnnotation != null
InetAddress.getLoopbackAddress()
new HashCollisionNode(edit,count,hash,array)
Assert.assertEquals(9500,Utils.calculateHeapSize(10000))
j.getConfiguration().get("mapred.task.id","").equals("") && !("true".equals(j.getConfiguration().get("pig.illustrating")))
GL20.glGetUniform(program,location,params)
in.readInt()
resourceRegistration.registerAdditionalRuntimePackages(RuntimePackageDependency.optional("org.hibernate.search.orm"),RuntimePackageDependency.required("org.hibernate"))
(byte)0xff
new JobConf(config_)
List<String>
LOG.error("Failed to get next entry from " + jarFileName + ": "+ ioEx)
serialVersionUID=1L
ShrinkWrap.create(WebArchive.class).addClass(MyBatchlet.class).addAsWebInfResource(EmptyAsset.INSTANCE,ArchivePaths.create("beans.xml")).addAsManifestResource("META-INF/batch-jobs/myJob.xml","batch-jobs/myJob.xml")
setBytes(0,data,index,length)
inputFuture.cancel(mayInterruptIfRunning)
public class XpathRegressionDefaultComesLastTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=DefaultComesLastCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionDefaultComesLastOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(DefaultComesLastCheck.class);     final String[] expectedViolation={"8:13: " + getCheckMessage(DefaultComesLastCheck.class,DefaultComesLastCheck.MSG_KEY)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionDefaultComesLastOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP","/CLASS_DEF[@text='SuppressionXpathRegressionDefaultComesLastOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP" + "/LITERAL_DEFAULT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=DefaultComesLastCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionDefaultComesLastTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(DefaultComesLastCheck.class);     moduleConfig.addAttribute("skipIfLastAndSharedWithCase","true");     final String[] expectedViolation={"15:13: " + getCheckMessage(DefaultComesLastCheck.class,DefaultComesLastCheck.MSG_KEY_SKIP_IF_LAST_AND_SHARED_WITH_CASE)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionDefaultComesLastTwo']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP/LITERAL_DEFAULT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
ImmutableList.of(new Identifier("a"))
Status.constructStatuses(get(getBaseURL() + "statuses/user_timeline.json",null,paging.asPostParameterList(),true))
Configuration.getLong(PropertyKey.USER_FILE_WAITCOMPLETED_POLL_MS)
processEngineConfiguration.setEnableSafeBpmnXml(false)
GL20.glUniform1(location,toFloatBuffer(v,offset,count))
Site.me().setRetryTimes(3).setSleepTime(100)
getExecutorService()
beans.add(0,bean)
public Object getBean() throws Exception {   Object value=lookupBean();   if (value == null) {     throw new NoBeanAvailableException(name);   }   if (value != bean) {     bean=value;     processor=null;     if (!ObjectHelper.equal(ObjectHelper.type(bean),ObjectHelper.type(value))) {       beanInfo=null;     }   }   return value; } 
twitter1.checkUserListSubscription(id1.screenName,id2.id,userList.getId())
word=START_WORD
"Searching class for device type " + deviceAddress
DEFAULT_AKKA_LOG_LIFECYCLE_EVENTS=false
methodsToImplement(methods)
UnsupportedOperationException ex
DEFAULT_OCTREE_WIDTH=10000
getMockEndpoint("mock:start").expectedMinimumMessageCount(4)
assertEquals(9,this.context.getBean(FilterChainProxy.class).getFilterChains().size())
new NotifyBuilder(context).whenDone(4)
serverService.getIncomingInterceptors()
SSOBaseCase.executeFormAuthSingleSignOnTest(baseURLNoAuth,baseURLNoAuth,log)
Preconditions.checkNotNull(blockIds)
RCFileMergeMapper.jobClose(outputPath,noName,job,console)
id=15857
e instanceof MaybePrimitiveExpr && e.hasJavaClass()
Assert.assertEquals(result,expected)
ResponseImpl schema(Property property); 
logger.debug("{} {}",errorCode,message)
timeoutMs=500
public void testWithDFS() throws IOException {   MiniDFSCluster dfs=null;   MiniMRCluster mr=null;   FileSystem fileSys=null;   try {     final int taskTrackers=4;     Configuration conf=new Configuration();     dfs=new MiniDFSCluster(conf,4,true,null);     fileSys=dfs.getFileSystem();     JobConf jtConf=new JobConf();     jtConf.setInt(TTConfig.TT_MAP_SLOTS,1);     jtConf.setInt(TTConfig.TT_REDUCE_SLOTS,1);     jtConf.setLong(JTConfig.JT_TRACKER_EXPIRY_INTERVAL,10 * 1000);     mr=new MiniMRCluster(taskTrackers,fileSys.getUri().toString(),1,null,null,jtConf);     testFailCommitter(CommitterWithFailSetup.class,mr.createJobConf());     testFailCommitter(CommitterWithFailCommit.class,mr.createJobConf());     testSetupAndCleanupKill(mr,dfs,true);     fileSys.delete(setupSignalFile,true);     fileSys.delete(cleanupSignalFile,true);     testSetupAndCleanupKill(mr,dfs,false);   }   finally {     if (dfs != null) {       dfs.shutdown();     }     if (mr != null) {       mr.shutdown();     }   } } 
IllegalArgumentException e
implemetationMethodDescriptors.build()
cursor.retry()
new MalformedException("Unused message placeholder: " + phName,objLitNode)
Optional.of(resourceManagementScheduler)
Integer newerThan
assertEquals(0,localReplicatedMapStats.getOwnedEntryMemoryCost())
type=500
decoder.readOutbound()
table != null
operation.get(OPERATION_HEADERS,ALLOW_RESOURCE_SERVICE_RESTART).set(true)
options.setLanguageIn(LanguageMode.ECMASCRIPT5)
new Long(3)
new Color(pixels[i])
options.needsTranspilationFrom(ES7)
sentencesFile == null
row.size() == 0
mLockMode == InodeTree.LockMode.READ
(ResourceAdapterDeploymentService)controller.getService()
DiagnosticType.disabled("JSC_GOOG_MODULE_IN_NON_MODULE","goog.module() call must be the first statement in a module.")
/**   * Matches no characters.   */ public static final FastMatcher NONE=new FastMatcher(){   @Override public boolean matches(  char c){     return false;   }   @Override public String replaceFrom(  CharSequence sequence,  CharSequence replacement){     checkNotNull(replacement);     return sequence.toString();   }   private void checkNotNull(  CharSequence replacement){   }   @Override public String collapseFrom(  CharSequence sequence,  char replacement){     return sequence.toString();   }   @Override public String trimTrailingFrom(  CharSequence sequence){     return sequence.toString();   } } ; 
stat.st_size.get()
mMountTable.resolve(getPath(dir)).getPath()
Map<String,String>
ChannelBufferHolders.catchAllBuffer()
TfsShell.convertMsToDate(files[2].getCreationTimeMs())
inUseByte != Record.IN_USE.byteValue()
Preconditions.checkNotNull(timer)
SSLContext.setCertificateChainFile(ctx,trustCertChainFile.getPath(),true)
batteryVp >= full
user.hasPrivilege(OpenmrsConstants.PRIV_EDIT_USERS)
new SemanticException(generateErrorMessage(tabref,"Schema of both sides of union should match: Column " + field + " is of type "+ lInfo.getType().getTypeName()+ " on first table and type "+ rInfo.getType().getTypeName()+ " on second table"))
resource().transport() != AtmosphereResource.TRANSPORT.WEBSOCKET
types.get(channel)
overrideDeploymentConfig
newEmbeddedDatabaseBuilder(path)
buffer.readableBytes() < 4
newNode.makeNonIndexable()
new StringBuilder(741)
reg.put(LDAP_CONN_NAME,getWiredConnection(ldapServer))
createRecord(value,expiryTime)
S3DataSegmentKiller.class
!force || EventCacheBroadcasterCache.class.isAssignableFrom(broadcasterCache.getClass())
reportMissingOverride.isOn() && !declaredOverride && interfaceHasProperty
complete.expectedBodiesReceived("finish","stop","faulted","except")
sourceNodeTextData.getText().isEmpty()
1024 * 1024 * 14
(getSource().x() + getTarget().x()) / 2f
offset > 0
annotations.get(node)
GL15.glGetBufferParameter(target,pname,params)
logger.debug("Item not found error while generating chart.")
id=15872
Preconditions.checkNotNull(blockWorker)
parser.parse(INFO_OPTIONS,args,false)
request.getContentType().equals("application/x-www-form-urlencoded")
PositiveIntegerValidator.class
OpenmrsProfileWithoutTest1Module bean=applicationContext.getBean(OpenmrsProfileWithoutTest1Module.class); 
new NullPointerException("the annotation is null")
ResponseImpl example(String type,Object example); 
setSunPosition(calendar,latitude,longitude,sun)
System.currentTimeMillis()
String retval=""; 
alluxioUri.getPath()
index <= mInUseLocks.length()
GL20.glUniform3(location,toFloatBuffer(v,offset,count * 3))
client.getState().setCredentials(new AuthScope(null,-1,AuthScope.ANY_REALM),defaultcreds)
new TableException(String.format("Unable to generate a string representation of the serializer snapshot of '%s' " + "describing the class '%s' for the ANY type.",serializer.getClass().getName(),clazz.toString()))
Gdx.input.getX()
!SystemPropertyUtil.getBoolean("io.netty.noJdkZlibDecoder",true)
timelineObjectHolder.getObject().getChunk(0).getObject().getDimensions()
Subqueries.gt(0L,subquery)
i < 10
routes.SessionsController.index()
retVal.put(p.getKey(),p.getValue())
rejectRemoteInitiatedRenegotiation && SSL.getHandshakeCount(ssl) > 1
new WebApplicationException(serverError(e))
mTestStream.getBytesFlushed()
visibleOnly=false
assertEquals(JavadocTagInfo.VERSION.getType(),JavadocTagInfo.Type.BLOCK)
32 * 1024 * 1024
params.getInt("numPages")
info.getRegionName()
!namespaces.isDefined()
Assert.assertEquals(1062,details.get(0).getAbsolutePosition())
exchange.getOut()
new StoreFile(this.fs,linkFilePath,conf,cacheConf,BloomType.NONE,NoOpDataBlockEncoder.INSTANCE)
BeanFactoryUtils.beanNamesForTypeIncludingAncestors(beanFactory,JwtAccessTokenConverter.class)
logger.error("Endpoint {} not found on node {}. Cannot set command classes.",endpoint,this.getNode().getNodeId())
assertEquals(row.getField(0),3L)
logError(lcurly,"lcurly",lcurlyPos)
Assert.assertFalse("reload-required".equals(result.get(RESPONSE_HEADERS).get(PROCESS_STATE).asString()))
type == TokenTypes.CLASS_DEF
!segments.add(segment)
websocketComponent.setMaxThreads(11)
conceptAnswer.getConcept()
ChronicleEngineEnpoint.class
new StringBuilder()
true_parts.addAll(Hive.get().getPartitions(tab))
id=13307
minSize(new Fixed(width))
id=15865
new RuntimeIOException(e)
final string clientSecret="your client secret"; 
logger.warn("gave up waiting for query reply from device {}",m_address)
registration.registerOperationHandler(CommonAttributes.STOP,ModClusterStop.INSTANCE,stop,false)
!mPreferredHost.equals("localhost")
ownedEntryCount >= nearCacheSize
ImportAutoConfigurationWithItemsOne.class
r1
database.FindProduct(node.getManufacturer(),node.getDeviceType(),node.getDeviceId())
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
new SimpleAttributeDefinitionBuilder(CommonAttributes.NAME,ModelType.STRING,false).setXmlName(Attribute.NAME.getLocalName()).setAllowExpression(true)
GL20.glUniform4(location,toFloatBuffer(v,offset,count << 2))
name="java:/ConnectionFactory"
lDirAllocator.getLocalPathForWrite(ContainerLocalizer.USERCACHE + Path.SEPARATOR + user+ Path.SEPARATOR+ ContainerLocalizer.APPCACHE+ Path.SEPARATOR+ appIdStr+ Path.SEPARATOR+ containerIdStr,LocalDirAllocator.SIZE_UNKNOWN,this.conf)
Latkes.getStaticPath()
Color.fromRGB(0x51301A)
logger.info("Installing Filter {}",servletClassName)
stats.getLastAccessTime() > lastAccessTime
latch.await(10,SECONDS)
MAX_ARITY=22
toByteBuffer()
flushAfterDuration(entry.getKey(),entry.getValue())
(Long)123l
ShrinkWrap.create(WebArchive.class).addClass(BatchTestHelper.class).addClass(MyInputRecord.class).addClass(MyItemProcessor.class).addClass(MyItemReader.class).addClass(MyItemWriter.class).addClass(MyOutputRecord.class).addAsWebInfResource(EmptyAsset.INSTANCE,ArchivePaths.create("beans.xml")).addAsManifestResource("META-INF/batch-jobs/myJob.xml","batch-jobs/myJob.xml")
logger.debug("Invalid Account Credentials")
/**   * Loads the value of a given key. If distributed map doesn't contain the value for the given key then Hazelcast will call implementation's load (key) method to obtain the value. Implementation can use any means of loading the given key; such as an O/R mapping tool, simple SQL or reading a file etc.  * @param key  * @return value of the key  */ Object load(Object key); 
assertEquals(5,AccessControlLists.getTablePermissions(conf,TEST_TABLE).size())
region.getRegionWidth()
JSError.make(REPORT_PATH_IO_ERROR,reportPath)
id=34
new HTable(TABLE)
new Interval(timeList.get(0).getValue().getMinTime().getMillis(),timeList.get(0).getValue().getMaxTime().getMillis())
DependencyFilterUtils.classpathFilter(JavaScopes.COMPILE)
DEFAULT_HEAP_LIMIT_CAP=500
LOG.error("Unable to unmarshall exception content",e)
slice.getAddress()
invocation.logger.warning("'is-executing': " + executing + " -> "+ invocation)
/**   * {@inheritDoc}  */ @Override public AtmosphereResource addAtmosphereResource(AtmosphereResource r){   try {     if (destroyed.get()) {       logger.debug(DESTROYED,getID(),"addAtmosphereResource(AtmosphereResource<?, ?> r");       return r;     }     start();     if (scope == SCOPE.REQUEST && requestScoped.getAndSet(true)) {       throw new IllegalStateException("Broadcaster " + this + " cannot be used as its scope is set to REQUEST");     }     if (maxSuspendResource.get() > 0 && resources.size() >= maxSuspendResource.get()) {       if (policy == POLICY.FIFO) {         AtmosphereResource resource=resources.poll();         try {           logger.warn("Too many resource. Forcing resume of {} ",resource);           resource.resume();         }  catch (        Throwable t) {           logger.warn("failed to resume resource {} ",resource,t);         }       }  else       if (policy == POLICY.REJECT) {         throw new RejectedExecutionException(String.format("Maximum suspended AtmosphereResources %s",maxSuspendResource));       }     }     if (resources.contains(r)) {       return r;     } synchronized (concurrentSuspendBroadcast) {       if (resources.isEmpty()) {         BroadcasterFactory.getDefault().add(this,name);       }       checkCachedAndPush(r,r.getAtmosphereResourceEvent());       if (isAtmosphereResourceValid(r)) {         resources.add(r);       }     }   }   finally {     if (resources.size() > 0) { synchronized (awaitBarrier) {         awaitBarrier.notifyAll();       }     }   }   return r; } 
assertEquals(model.getProperties().get(NAME).getType(),"string")
new Tag(text,line)
MenuInflater.this.getClass()
id=23
new StormClientHandler(client)
Exception exception
LOG.error("Unable to read HTTP response content",e)
logger.debug(getName() + " has been started")
Mockito.any()
keyClass(NullWritable.class)
idGenerator.generateId()
value.longValue()
!lowByte.equals("")
nlDataOutNodes != null & nlDataOutNodes.getLength() > 0
n.intValue()
logger.info("Session created")
new StringBuilder(246)
callerPrincipalCallback == null
UndertowServletWebServer.class
plugin.isEnabled()
clusterService != null
Iterables.get(batchServerInventoryView.getInventory(),0).getSegments().size() != testSegments.size()
file.getFileName()
Preconditions.checkNotNull(containerIdGenerator)
world.add("capsule",5f,2.125f,5f)
defaultCometSupport(useServlet30Async)
logger.debug("myq securityToken: {}",securityToken)
ss.getAuthorizerV2().checkPrivileges(type,Arrays.asList(commandObj),null)
Long autoCommitInterval
NSString value=(NSString)nsDictionary.get(convertKey(key)); 
XMLInputFactory.newFactory()
new IdentityHashMap<>(values.length)
System.currentTimeMillis() - start + 200
LOG.info(getName() + " caught: ",e)
mLocalWorkerAddress.getRpcPort()
webSocketProcessor.close(webSocket,0)
session != null
batteryVp >= high
e.getCause()
modulePath.split(File.pathSeparator)[1]
chooser.showSaveDialog(null)
simple.getFromSentDate()
new ChannelInboundHandlerAdapter(){   @Override public void userEventTriggered(  ChannelHandlerContext ctx,  Object evt) throws Exception {     if (evt instanceof WebSocketServerProtocolHandler.HandshakeComplete) {       assertNull(ctx.pipeline().context(WebSocketServerProtocolHandshakeHandler.class));     }   } } 
String id=reader.getAttributeValue(null,"id"); 
assertThat(page2.pagination().getGlobalTotal()).isEqualTo(7)
(ZWaveConfigurationCommandClass)node.getCommandClass(CommandClass.WAKE_UP)
@Override public Cell deepClone(){   byte[] copy=Bytes.copy(this.bytes,this.offset,this.length);   KeyValue kv=new NoTagsKeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } 
longValue == 0
new DynamicAwareEntry("http://localhost/test",null,null)
maxSize(new Fixed(width))
"https".equals(protocol)
GL.glTexSubImage2DEXT(target,level,xoffset,yoffset,width,height,format,type,pixels,Memory.getPosition(pixels))
column.createColumnObserver()
group != null
wrappedBuffer(byteBuffer)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class TransactionalSetBasicLocalTest extends TransactionalSetBasicTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(1).newInstances(config);   } } 
comparePartitionOwnership(true,localMember,partition)
GL20.glGetActiveUniform(program,index,256,typeTmp)
LOG.info("Building gRPC server on <any address>" + ":" + configuration.getPort())
hasMatch=true
mFixedExecutionService.shutdown()
id=41
i <= repeatCount
public DerivedBuilder setCompressionEnabled(boolean compressionEnabled){   configBuilder.setCompressionEnabled(compressionEnabled);   return this; } 
new Server(port)
TypeUtils.getKoltinConstructor(constructors)
private final DefaultChannelPipeline pipeline; 
ReactiveHelper.scheduleLast(() -> processor.process(exchange,done -> {   if (exchange.getException() != null) {     getExceptionHandler().handleException("Error processing aggregated exchange",exchange,exchange.getException());   }  else {     log.trace("Processing aggregated exchange: {} complete.",exchange);   } } ),"sending aggregated exchange")
cached.get(walCacheLock)
entry.getKey().isEmpty()
Status.constructStatuses(get(getBaseURL() + "statuses/retweets_of_me.json",null,paging.asPostParameterList(),true))
connection.remote().nextStreamId()
sequenceFileVersion == SEQUENCE_FILE_VERSION
/**   * Changes the group of a file or directory specified by args.  */ public final class ChgrpCommand extends AbstractACLCommand {   public ChgrpCommand(  TachyonConf conf,  TachyonFileSystem tfs){     super(conf,tfs);   }   @Override public String getCommandName(){     return "chgrp";   }   @Override protected int getNumOfArgs(){     return 2;   }   @Override public void run(  String... args) throws IOException {     String group=args[0];     TachyonURI path=new TachyonURI(args[1]);     chgrp(path,group,false);   }   @Override public String getUsage(){     return "chgrp <group> <path>";   } } 
public class XpathRegressionIllegalThrowsTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=IllegalThrowsCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionIllegalThrowsOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(IllegalThrowsCheck.class);     final String[] expectedViolation={"4:35: " + getCheckMessage(IllegalThrowsCheck.class,IllegalThrowsCheck.MSG_KEY,"RuntimeException")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionIllegalThrowsOne']/OBJBLOCK" + "/METHOD_DEF[@text='sayHello']/LITERAL_THROWS[@text='RuntimeException']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=IllegalThrowsCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionIllegalThrowsTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(IllegalThrowsCheck.class);     final String[] expectedViolation={"8:45: " + getCheckMessage(IllegalThrowsCheck.class,IllegalThrowsCheck.MSG_KEY,"java.lang.Error")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionIllegalThrowsTwo']/OBJBLOCK" + "/METHOD_DEF[@text='methodTwo']/LITERAL_THROWS/DOT[@text='Error']");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
@Override public Cell deepClone(){   byte[] copy=new byte[this.length];   ByteBufferUtils.copyFromBufferToArray(copy,this.buf,this.offset,0,this.length);   KeyValue kv=new KeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } 
nameDefinitionMultimap.keys()
EVICT_ALL + 1
writeMethod1.addScopedInterceptor(NettyConstants.INTERCEPTOR_CHANNEL_PIPELINE_WRITE,NettyConstants.SCOPE_WRITE,ExecutionPolicy.BOUNDARY)
ImmutableSet<ImplemetationMethodDescriptor>
ObjectHelper.isEmpty(configuration.getClusterService())
serversByLoad.lastKey()
id=24
StringBuilder sb=new StringBuilder(64); 
methodName.startsWith("save")
new byte[13]
assertEquals(mock.getExchanges().get(0).getIn().getHeader(ChronicleEngineConstants.MAP_EVENT_TYPE),ChronicleEngineMapEventType.INSERT)
Y
timer.isActive()
registry.put("dummy",new ReactiveStreamsTestService("from-registry"))
LOG.isInfoEnabled()
ResponseImpl header(String name,Property property); 
testWarning(LINE_JOINER.join("goog.module('m');","","var d = goog.require('a.b.d');","var c = goog.require('a.c');","","alert(1);"),REQUIRES_NOT_SORTED,"goog.require() statements are not sorted. The correct order is:\n\n" + "var c = goog.require('a.c');\nvar d = goog.require('a.b.d');\n\n")
configureWebDotXmlAtmosphereHandler(sc)
public class XpathRegressionImportControlTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=ImportControlCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionImportControlOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ImportControlCheck.class);     moduleConfig.addAttribute("file",getPath(checkName,"SuppressionXpathRegressionImportControlOne.xml"));     final String[] expectedViolation={"3:1: " + getCheckMessage(ImportControlCheck.class,ImportControlCheck.MSG_DISALLOWED,"java.util.Scanner")};     final List<String> expectedXpathQueries=Collections.singletonList("/IMPORT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=ImportControlCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionImportControlTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ImportControlCheck.class);     moduleConfig.addAttribute("file",getPath(checkName,"SuppressionXpathRegressionImportControlTwo.xml"));     final String[] expectedViolation={"1:1: " + getCheckMessage(ImportControlCheck.class,ImportControlCheck.MSG_UNKNOWN_PKG)};     final List<String> expectedXpathQueries=Collections.singletonList("/PACKAGE_DEF");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testThree() throws Exception {     final String checkName=ImportControlCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionImportControlThree.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ImportControlCheck.class);     final String[] expectedViolation={"1:1: " + getCheckMessage(ImportControlCheck.class,ImportControlCheck.MSG_MISSING_FILE)};     final List<String> expectedXpathQueries=Collections.singletonList("/PACKAGE_DEF");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testFour() throws Exception {     final String checkName=ImportControlCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionImportControlFour.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ImportControlCheck.class);     moduleConfig.addAttribute("file",getPath(checkName,"SuppressionXpathRegressionImportControlFour.xml"));     final String[] expectedViolation={"4:1: " + getCheckMessage(ImportControlCheck.class,ImportControlCheck.MSG_DISALLOWED,"java.util.Scanner")};     final List<String> expectedXpathQueries=Collections.singletonList("/IMPORT[./DOT[@text='Scanner']]");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
NettyAsyncHttpProvider.class
@InputIntMethodAnnotation(42)
CliBroker.class
selectedFile != null
Configuration.getInt(PropertyKey.MASTER_TTL_CHECKER_INTERVAL_MS)
context.add("exceptionalMethod",123f)
LOG.info("Cannot access storage directory " + rootPath,ex)
public class XpathRegressionHiddenFieldTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=HiddenFieldCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(HiddenFieldCheck.class);     final String[] expectedViolation={"10:34: " + getCheckMessage(HiddenFieldCheck.class,HiddenFieldCheck.MSG_KEY,"value")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitOne']/OBJBLOCK" + "/INSTANCE_INIT/SLIST/EXPR/METHOD_CALL/ELIST/LAMBDA/PARAMETERS" + "/PARAMETER_DEF[@text='value']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=HiddenFieldCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(HiddenFieldCheck.class);     final String[] expectedViolation={"8:45: " + getCheckMessage(HiddenFieldCheck.class,HiddenFieldCheck.MSG_KEY,"other")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitTwo']/OBJBLOCK" + "/METHOD_DEF[@text='method']/PARAMETERS/PARAMETER_DEF[@text='other']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
file.length() >= Integer.MAX_VALUE
invoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
logger.error("Cannot retrieve item {} for widget {}",itemName,w.eClass().getInstanceTypeName())
mock.expectedMinimumMessageCount(3)
getParser().parse(args)
ModuleReflectionUtils::isCheckstyleCheck
Map<String,String>
case QUIT: 
new IndexOutOfBoundsException()
LOG.error("Failed to find " + baseDirectory.getAbsolutePath())
HashMap<String,Operator<? extends Serializable>>
LOG.debug("EOL(end-of-line) defined for the CSV: {}",crlf)
new DBException(String.format("Error while creating Aerospike " + "client for %s:%d.",host,port))
this.configuration.getMappedStatement(id)
lookupService.lookupPrincipalByGroupName(user)
loader.loadClass(name)
size=5000
"Notes".equals(subSectionName) || "Rule Description".equals(subSectionName)
handles[i]
-26
o instanceof Xid
/**   * @author Eric Vergnaud  */ public class Python2Target extends AbstractPython3Target {   protected static final String[] python2Keywords={"abs","all","any","apply","as","bin","bool","buffer","bytearray","callable","chr","classmethod","coerce","compile","complex","delattr","dict","dir","divmod","enumerate","eval","execfile","file","filter","float","format","frozenset","getattr","globals","hasattr","hash","help","hex","id","input","int","intern","isinstance","issubclass","iter","len","list","locals","map","max","min","next","memoryview","object","oct","open","ord","pow","print","property","range","raw_input","reduce","reload","repr","reversed","round","set","setattr","slice","sorted","staticmethod","str","sum","super","tuple","type","unichr","unicode","vars","with","xrange","zip","__import__","True","False","None"};   /**   * Avoid grammar symbols in this set to prevent conflicts in gen'd code.   */   protected final Set<String> badWords=new HashSet<String>();   public Python2Target(  CodeGenerator gen){     super(gen,"Python2");   }   @Override public String getVersion(){     return "4.4.0";   }   public Set<String> getBadWords(){     if (badWords.isEmpty()) {       addBadWords();     }     return badWords;   }   protected void addBadWords(){     badWords.addAll(Arrays.asList(python2Keywords));     badWords.add("rule");     badWords.add("parserRule");   } } 
type != EventType.QUERY
bc.getExecutorService()
public DerivedBuilder setScheduledExecutorService(ScheduledExecutorService reaper){   configBuilder.setScheduledExecutorService(reaper);   return this; } 
@Override public ResponseImpl schema(Property property){   throw new RuntimeException("Not implemented"); } 
NetworkAddressUtils.assertValidPort(Preconditions.checkNotNull(address),mTachyonConf)
failure != null
analysis.getType(aggregate)
Boolean.getBoolean("java.awt.headless")
argumentCount.isValidCount(actualCount)
hashSymbols.keySet()
sort.sort(inputRects.items,new Comparator<Rect>(){   public int compare(  Rect o1,  Rect o2){     int n1=o1.width > o1.height ? o1.width : o1.height;     int n2=o2.width > o2.height ? o2.width : o2.height;     return n2 - n1;   } } ,0,inputRects.size)
maxActiveSessions == null
new Whitelist().addTags("a","b","blockquote","br","cite","code","dd","dl","dt","em","i","li","ol","p","pre","q","small","strike","strong","sub","sup","u","ul")
invocation.pendingResponse == null
public Integer getNewerThan(){   return newerThan; } 
report(n,MISPLACED_ANNOTATION)
estimatedLength < 8
that.getPath() == null
MockReset.before()
Thread.sleep(200)
future1.get(1,TimeUnit.SECONDS)
processor.getOrCreateManifest(archive)
this.connectTo(vertex,channelType,compressionLevel,indexOfOutputGate,indexOfInputGate,distributionPattern,false)
from("jms:queue2:parallelLoanRequestQueue").process(new CreditAgency()).multicast(new BankResponseAggregationStrategy().setAggregatingOutMessage(true)).setParallelProcessing(true)
ImmutableSet.<String>builder().add(BUFFERS_READ,FIELDNAMES_READ,INDEXERCLUSTER_READ,INPUTS_READ,JOURNAL_READ,JVMSTATS_READ,MESSAGECOUNT_READ,MESSAGES_READ,METRICS_READ,SYSTEM_READ,THROUGHPUT_READ,SAVEDSEARCHES_CREATE,SAVEDSEARCHES_EDIT,SAVEDSEARCHES_READ)
Assert.assertEquals(2,propertyCategories.size())
context.createTaskContext().addPipelineContext(0,true,true)
JsonProcessingExceptionMapper.class
OptionalIdentifiedType<FromDefinition>
@InputIntMethodAnnotation(value=-45)
name.substring(0,name.length() - 1)
SLEEP_TIME=500
incomingDir.exists()
zwaveCommandClass.handleApplicationCommandRequest(serialMessage,offset + 2,1)
ImmutableSet.Builder<ImplemetationMethodDescriptor>
GL20.glUniform4(location,v)
asList(8L)
First=word.substring(0,3)
assertSame(conf,(Configuration)serializeDeserialize(conf))
@Override public Cell deepClone(){   return new KeyValue(this); } 
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class ReliableTopicBasicDistributedTest extends ReliableTopicBasicTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(2).newInstances(config);   } } 
GL.glGenTexturesEXT(n,textures,Memory.getPosition(textures))
node.actor.getY() <= high
logger.info("Normalizing")
(a & 0xe0) == 0xb0
channel.getPipeline().sendUpstream(new DefaultExceptionEvent(channel,cause))
private final StringBuffer tmpSb=new StringBuffer(); 
System.out.println()
!scriptsToUpdate.add(n)
bulkInsertableMap.get(entityClass)
TransactionMetadata::setInActive
event.remove(factory.getName())
container.getTimeFormat().equals(TimeFormat.DATE)
environmentVariableMode=1
DataStream<OUT>
ArrayUtils.subarray(args,4,args.length)
op.getJavaName()
JSError.make(AbstractCompiler.READ_ERROR,sourceFile.getName())
stat.st_mtim.tv_nsec.get()
new EnumValidator(ParticipantStatus.class,false,false)
ssl.has(CommonAttributes.CA_REVOCATION_URL)
LOG.error("I/O error when running rpc",e)
headerFilterStrategy.applyFilterToCamelHeaders(entry.getKey(),entry.getValue(),camelExchange)
/**   * Creates an exception indicating the transactional entity manager cannot be closed when it is managed by the container.  * @return an {@link IllegalStateException} for the error.  */ @Message(id=11424,value="Container managed entity manager can only be closed by the container " + "(auto-cleared at tx/invocation end and closed when owning component is closed.)") IllegalArgumentException cannotCloseTransactionContainerEntityManger(); 
public DerivedBuilder setExecutorService(ExecutorService applicationThreadPool){   configBuilder.setExecutorService(applicationThreadPool);   return this; } 
/**   * Loads the import control file from a file.  * @param uri the uri of the file to load.  * @return the root {@link PkgControl} object.  * @throws CheckstyleException if an error occurs.  */ public static PkgControl load(final URI uri) throws CheckstyleException {   final InputStream inputStream;   try {     inputStream=uri.toURL().openStream();   }  catch (  final MalformedURLException ex) {     throw new CheckstyleException("syntax error in url " + uri,ex);   } catch (  final IOException ex) {     throw new CheckstyleException("unable to find " + uri,ex);   }   final InputSource source=new InputSource(inputStream);   return load(source,uri); } 
id=21
Ordered.LOWEST_PRECEDENCE - 20
config.getStorageImpl()
content.readable()
id=15865
ctx.sendDownstream(e)
id=15
getter.getRawReturnType()
MessageOutput.Factory<GelfOutput>
InetAddress.getLocalHost()
addResult.getNumRowsInSegment() > tuningConfig.getMaxRowsPerSegment()
Arrays.asList("Java","CSharp","Python2","Python3","Node")
Mockito.anyString()
RexUtil.simplify(rexBuilder,node)
checkArgument(prestoTypeParameters.size() == fieldTypes.size())
ugi.reloginFromKeytab()
serverEnvironment.getLaunchType() == ServerEnvironment.LaunchType.DOMAIN
Exception e
ssl.has(CommonAttributes.PROTOCOL)
yAmount > 0
stationItemName != null
/**   * Tests for  {@link Es6SortedDependencies}  */ public class Es6SortedDependenciesTest extends SortedDependenciesTest {   @Override public SortedDependencies<SimpleDependencyInfo> createSortedDependencies(  List<SimpleDependencyInfo> shuffled) throws CircularDependencyException {     return new Es6SortedDependencies<>(shuffled);   }   @Override public boolean handlesCycles(){     return true;   } } 
id=15806
level <= RF_STATUS_MEDIUM_SIGNAL
IntrospectionSupport.getProperties(configuration,params,null)
size=1000
RuntimeException.class
new SimpleProxyPool(httpProxyList)
new JSONParseSpec(new TimestampSpec("timestamp","iso"),new DimensionsSpec(Arrays.asList(DIMENSIONS),Arrays.<String>asList(),null),JSONParseSpec.JSON)
Preconditions.checkState(n.isModuleBody() || scope.getParent() == null)
location.belongTo(BlockStoreLocation.anyTier())
SaveTask.class
planNode.getPlanNodeCpuTime()
data + END
!undirected && vizConfig.isShowArrows() && !edge.isSelfLoop()
new HashSet<RecordReplicationInfo>()
isTrivial()
Exception cause
13 * Bytes.SIZEOF_LONG
Reflection.methodHandle(type,"sizeOf",null)
pushExecutor.submit(new NamedRunnable("OkHttp %s Push Request[%s]",hostName,streamId){   @Override public void execute(){     boolean cancel=pushObserver.onRequest(streamId,requestHeaders);     try {       if (cancel) {         frameWriter.rstStream(streamId,ErrorCode.CANCEL); synchronized (SpdyConnection.this) {           currentPushRequests.remove(streamId);         }       }     }  catch (    IOException ignored) {     }   } } )
id=15847
getSslStoreProvider().getKeyStore()
mock.expectedMessageCount(10)
value.getType().getCanonicalName()
assertEquals(148,map.getLocalMapStats().getHeapCost())
new DatabaseFormatterOracle()
CsvReporter.forRegistry(registry).convertDurationsTo(getDurationUnit()).convertDurationsTo(getRateUnit())
RevisionVersion=2
new ModelNode().set(60000)
assertEquals(fStopwatch.runtime(MILLISECONDS),800d,250d)
Collection<DelayedEntry>
IntrospectionSupport.setProperties(config,componentProperties,null)
makeResponse(new AuthorizationException("UI request '" + op + "' for '"+ user+ "' user is not authorized"),containerRequestContext,401)
new SimpleCanalConnector(address,username,password,destination,null)
/**   * Call WebModuleUtil.startModule on each started module  * @param servletContext  * @throws ModuleMustStartException if the context cannot restart due to a{@link MandatoryModuleException} or {@link OpenmrsCoreModuleException}  */ public static void performWebStartOfModules(ServletContext servletContext) throws ModuleMustStartException, Throwable {   Log log=LogFactory.getLog(Listener.class);   List<Module> startedModules=new ArrayList<Module>();   startedModules.addAll(ModuleFactory.getStartedModules());   boolean someModuleNeedsARefresh=false;   for (  Module mod : startedModules) {     try {       boolean thisModuleCausesRefresh=WebModuleUtil.startModule(mod,servletContext,true);       someModuleNeedsARefresh=someModuleNeedsARefresh || thisModuleCausesRefresh;     }  catch (    Exception e) {       mod.setStartupErrorMessage("Unable to start module",e);     }   }   if (someModuleNeedsARefresh) {     try {       WebModuleUtil.refreshWAC(servletContext,true,null);     }  catch (    ModuleMustStartException ex) {       throw ex;     } catch (    Exception e) {       Throwable rootCause=getActualRootCause(e,true);       if (rootCause != null) {         log.fatal("Unable to refresh the spring application context.  Root Cause was:",rootCause);       }  else {         log.fatal("Unable to refresh the spring application context. Unloading all modules,  Error was:",e);       }       try {         WebModuleUtil.shutdownModules(servletContext);         for (        Module mod : ModuleFactory.getLoadedModules()) {           if (!mod.isCoreModule() && !mod.isMandatory()) {             try {               ModuleFactory.stopModule(mod,true,true);             }  catch (            Throwable t3) {               log.trace("Unable to shutdown module:" + mod,t3);             }           }         }         WebModuleUtil.refreshWAC(servletContext,true,null);       }  catch (      MandatoryModuleException ex) {         throw new MandatoryModuleException(ex.getModuleId(),"Got an error while starting a mandatory module: " + e.getMessage() + ". Check the server logs for more information");       } catch (      Throwable t2) {         log.warn("caught another error: ",t2);         throw t2;       }     }   }   for (  Module mod : ModuleFactory.getStartedModules()) {     WebModuleUtil.loadServlets(mod,servletContext);     WebModuleUtil.loadFilters(mod,servletContext);   } } 
public class XpathRegressionOuterTypeNumberTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=OuterTypeNumberCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionOuterTypeNumber.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(OuterTypeNumberCheck.class);     moduleConfig.addAttribute("max","0");     final String[] expectedViolation={"1:1: " + getCheckMessage(OuterTypeNumberCheck.class,OuterTypeNumberCheck.MSG_KEY,3,0)};     final List<String> expectedXpathQueries=Collections.singletonList("/PACKAGE_DEF");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
child.getProperties().isNodePartitionedOn(partitioningRequirement)
override.toString()
@ConditionalOnEnablednHealthIndicator("jms")
log.warn("Unable to provision more workers. Current workerCount[%d] maximum workerCount[%d].")
assertTrueEventually(new AssertTask(){   @Override public void run() throws Exception {     assertFalse(lock.isLocked());   } } ,5)
RequestBody.create(mediaType,(File)bodyContents)
eventJournalConfig.getMapName()
assertEquals(6358481,received.get(0)[1])
getMapNearCacheManager(dataMember)
new AutoValue_PackageFiles(chunks,jsFiles,cssFiles)
CHECK_TEXT.get("Properties")
public IMetric registerMetric(String name,IReducer reducer,int timeBucketSizeInSecs){   return _topoContext.registerMetric(name,new ReducedMetric(reducer),timeBucketSizeInSecs); } 
setAttributeInternal(tempInodePath,true,opTimeMs,options)
resource.removeExtractor(input.getId(),extractorId)
/**   * Make sure we don't attempt to recover inline; if the parser successfully recovers, it won't throw an exception.  */ @Override public Token recoverInline(BaseRecognizer recognizer) throws RecognitionException {   throw new RuntimeException(new InputMismatchException(recognizer)); } 
war.addAsWebInfResource(SimpleWebTestCase.class.getPackage(),"web.xml")
(JobResponse)response
id=15858
dumpErrorCountThreshold=3
partProps.size()
List<String>
getIntProperty("tachyon.master.web.threads",5)
ps.setString(i,parameter)
Arrays.asList("spring-boot-starter-tomcat-","tomcat-embed-core-","tomcat-embed-el-","tomcat-embed-logging-juli-")
Files.delete(dir.toPath())
ReferenceCountUtil.safeRelease(holder)
LOG.trace("The sequence id for {} is continuous, pass")
new ContinueProcessOperation(this,execution,true)
Arrays.asList("SuppressWithNearbyCommentFilter.fileContents","SuppressionCommentFilter.fileContents","MethodNameCheck.applyToPackage","MethodNameCheck.applyToPrivate","MethodNameCheck.applyToProtected","MethodNameCheck.applyToPublic")
isNodeHealing(node.getNodeId())
assertFalse("reuse-address",networkConfig.isReuseAddress())
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class SetBasicLocalTest extends SetBasicTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(1).newInstances(config);   } } 
id=15848
DefaultAtmosphereRequest.newInstance()
sourceMapping != null
id=15869
currentlyProcessing.addCallback(callback)
LOG.warn("Failed to send receipt of data to worker {} for request {}: {}.",mAddress,mReadRequest,e.getMessage())
ImmutableSet.of("testAutoIndexKeyDroppingWithPersistence","testReIndexingOfElements","testGettingVerticesAndEdgesWithKeyValue")
uri.toString().equalsIgnoreCase(future.getURI().toString())
System.identityHashCode(this)
controller.getState() != ServiceController.State.UP
@PathParam("interval")
i=1
AvailablePortFinder.getNextAvailable()
/**   * Represents the formatter for log message which is used in UTs. Message format is: filePath:lineNo:columnNo: message.  * @author Andrei Selkin  */ public class AuditEventUtFormatter implements AuditEvemtFormatter {   /**   * Length of all separators.   */   private static final int LENGTH_OF_ALL_SEPARATORS=4;   @Override public String format(  AuditEvent event){     final String fileName=event.getFileName();     final String message=event.getMessage();     final int bufLen=event.getFileName().length() + event.getMessage().length() + LENGTH_OF_ALL_SEPARATORS;     final StringBuilder sb=new StringBuilder(bufLen);     sb.append(fileName).append(':').append(event.getLine());     if (event.getColumn() > 0) {       sb.append(':').append(event.getColumn());     }     sb.append(": ").append(message);     return sb.toString();   } } 
region != null
assertEquals(0,beanInfo.getOperations().length)
GL20.glUniform1(location,toIntBuffer(v,offset,count))
new DatagramDnsQuery(addr,null,1)
millis % offset == 0
COUNT_DATABASE.put(key,val)
public class CourierNew extends FontMetrics { {     maxCharHeight=678;     for (int i=0; i < 128; i++)     widths[i]=600;   } } 
lastFailureException instanceof ConnectException
Integer.getInteger("org.neo4j.io.pagecache.impl.muninn.MuninnPagedFile.stripeFactor",8)
getConfiguration().getConnectionFactory()
toHeapData(key)
Thread.sleep(100)
values[i] == values
context.getLogger().logAttributeWarning(address,SLOT_ATTRIBUTE_NAME,MESSAGES.invalidJSFSlotValue(slot.asString()))
Optional.of(resourceManagement.getStats())
assertThat(page1reverse.pagination().getGlobalTotal()).isEqualTo(7)
steps < 0
transactionalMap.put(key,value)
taskOutput.getState().isDone()
n.getNodeData().getLabel().toLowerCase().contains(str)
assertTrue(latch.await(5,TimeUnit.MINUTES))
framework.getBroadcasterFactory().lookup(a.broadcaster(),true)
new StringLengthValidator(1,Integer.MAX_VALUE,true,true)
Status.constructStatuses(get(getBaseURL() + "statuses/mentions.json",null,true))
ObjectTypeAttributeDefinition.Builder.of(ModelKeys.REMOTE_SERVER,OUTBOUND_SOCKET_BINDING).setAllowNull(true)
protected abstract BlockBuilder getBlock(); 
this.createError == null
name="java:/TransactionManager"
mock.expectedMessageCount(4)
findModule(name)
LOG.error("Cannot create writer for app " + this.applicationId + ". Skip log upload this time. ")
index > n
LOG.error("Couldn't upload logs for " + containerId + ". Skipping this container.")
new StringBuilder()
broadcasterClassName.equalsIgnoreCase(DefaultBroadcaster.class.getName())
RequestTokenFactory.createOAuth2Request(null,"foo",null,false,Collections.singleton("ns_admin:read"),null,null,null)
dests.size() == 1
Status.constructStatuses(get(getBaseURL() + "favorites/" + id+ ".json",new PostParameter[0],true))
id=19
"ppc64".equals(arch) || "ppc64le".equals(arch)
Throwable t2
new CommandFormatException("The result couldn't be retrieved (perhaps the task was cancelled",e)
Color.fromRGB(0x1E1B1B)
assertEquals(actual().toString(),typeString)
authentication.hasDefined(USERS)
new BranchedDataException(e)
id=7
Foundation.NSLog("[error] " + tag + ": "+ message)
new DynamicAwareEntry("https://localhost:8443/test",null,null)
toBeRemovedKeys.clear()
logger.debug("defineClass pluginClass:{} cl:{}",className,classLoader)
endFunction("delete_column_statistics_by_table: ",ret != false)
conn.getResponseCode() == HttpURLConnection.HTTP_OK
kryo.readObjectOrNull(input,JobID.class)
DeletionRetentionStrategy.class
options.getLambdaRole()
target.addTask(task)
@UnrelatedOne
(System.currentTimeMillis() - lastAccessedTime.getTime()) > timeout
file.getAbsoluteFile()
logger.severe("Failed to process response: " + responsePacket + " on response thread:"+ getName())
DiagnosticType.error("JSC_GOOG_MODULE_IN_NON_MODULE","goog.module() call must be the first statement in a module.")
Status.constructStatuses(get(getBaseURL() + "statuses/retweets_of_me.json",null,true))
new RMNodeStatusEvent(node.getNodeID(),status,new ArrayList<ContainerStatus>(),null,null,null)
node.getNodeName()
new FastPathBalancedQueueRpcExecutor("deafult.FPBQ",handlerCount,maxPriorityQueueLength,priority,conf,server)
LOG.error("OpenTracing: Failed to capture tracing data",t)
filteredSearchRequest(query,filter,IndexHelper.determineAffectedIndices(indexRangeService,deflector,range))
mTFS.exists(turi)
FISHING_ROD(346,1,32)
volumes.toString()
UnavailableException e
new S_Command("00FE30",20.0)
log.rollWriter()
"streams:" + filter
invoke(args.first(),args.rest())
MESSAGES.unknownMessageListenerType(resourceAdapterName,messageListenerInterface.getName())
LOG.error("Unable to delete {} because listInternal returns null",path)
id=15843
CanalParseException e
isTouched(0.75f,1)
this.registry.getValue().addXAResourceRecovery(recovery)
total=10000
System.err.format("Tier %d: Not enough space on %s. %n" + "Desired quota: %s%n" + "Used in tiered storage: %s%n"+ "Available: %s%n",level,storageEntry.getKey(),FormatUtils.getSizeFromBytes(quota),FormatUtils.getSizeFromBytes(used),FormatUtils.getSizeFromBytes(available))
bytesToString(data).split("&")
size=50000
new ModelNode().set(15000)
body.transferTo(position,Long.MAX_VALUE,target)
LOG.error("Failed to transit standby cluster to " + SyncReplicationState.DOWNGRADE_ACTIVE)
targetCondn == null
new DynamicAwareEntry("https://localhost:443/test",null,null)
parent.decrementPrioritizableForTree(amt)
getTaskWriterCount(session) > 1
GL20.glUniform3(location,toIntBuffer(v,offset,count * 3))
src[srcIdx]
logger.info(sb.toString())
JSError.make(boundFunNode,GOOG_BIND_EXPECTS_FUNCTION)
new IncrementalIndexSegment(TestIndex.getIncrementalTestIndex())
requestReceived.await()
"Excluding secondary region " + regionToFlush + " - trying to find a different region to refresh files."
new IndexSizeExceededException(getOutOfRowsReason())
payload.getBodySources().size() == 1
assertEquals(2,map.size())
mapper.writeValueAsString(segment)
30 * 1000
T
catalog.validateLanguagePredicate(null,"simple",detail.getSimple())
factory.getEmbdeddedServletContainer(initializers[0],initializers[1])
config.setSslKeyAlias(ssl.get(CommonAttributes.PROTOCOL).asString())
Status.constructStatuses(get(getBaseURL() + "statuses/retweeted_by_me.json",null,true))
getCamelContext().getTypeConverter().convertTo(int.class,dataTimeout)
SCHEMA(35,true)
Thread.sleep(2000)
mLocalAlluxioClusterResource.get().getWorkerAddress()
GL11.glGetTexParameter(target,pname,params)
!traceIds.isEmpty()
s.contains(a.getName())
new DashboardServiceImpl(mongoRule.getMongoConnection(),metricRegistry,searches,dashboardWidgetCreator)
expectedMapSize * HASHMAP_DEFAULT_LOAD_FACTOR
@InputIntMethodAnnotation(value=43)
new SslContextBuilder(true)
id=15809
id=42
Throwable t
LOG.error("Could not parse syslog message. Not further handling.",e)
log.error("Not updating metadata, existing state[%s] in metadata store doesn't match to the new start state[%s].",oldCommitMetadataBytesFromDb,startMetadata)
offset=e.startOffset
Arrays.asList("/css/**","/js/**","/images/**","/**/favicon.ico")
contact.GetWorldManifold()
new IOException(ExceptionMessage.BLOCK_NOT_LOCALLY_AVAILABLE.getMessage(mBlockId))
new IllegalArgumentException(e)
entry.getCompleteStore()
exchange.getContext().getTypeConverter().mandatoryConvertTo(InputStream.class,graph)
assertEquals(2,props.getDisabledPlugins().length,2)
c.write("[" + ctx.channel().remoteAddress() + "] "+ msg+ '\n')
id=15836
LOG.info("Building gRPC server on " + configuration.getHost() + ":"+ configuration.getPort())
rsWrap.getMobFileCacheAccessCount()
context.var("double")
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class CountDownLatchBasicDistributedTest extends CountDownLatchBasicTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(2).newInstances();   } } 
file.name().contains(".etc1")
new Font(nodeFontName,nodeFontSize,nodeFontStyle)
JoinFunction.class
progress.start(0.19f)
this.getNotEmptyWaitThreadPeak()
boolean mutiValueResponse() default false; 
new StreamTaskException(exceptionMessage)
gauge.getValue() instanceof Long
ShrinkWrap.create(JavaArchive.class).addClasses(EmployeeBean.class,Employee.class).addAsManifestResource(EmptyAsset.INSTANCE,"beans.xml")
final ClassNotFoundException ignored
prop.getParamName()
"GET".equals(httpMethod)
new BlobLibraryCacheManager(blobServer,FlinkUserCodeClassLoaders.ResolveOrder.CHILD_FIRST)
Wt.getSlice(slice).mult(Wt.getSlice(slice).transpose())
new IllegalStateException("PLAIN supports neither integrity nor privacy")
logger.info("Creating Object {}",count.getAndIncrement())
address.getHostName()
!mIsMessageReady
from("jms:queue:order").to("bean:validateOrder").to("mock:validate").threads(20).unmarshal(mySecureDataFormat).delay(500)
AsyncResult<Boolean>
Status.constructStatuses(get(getBaseURL() + "favorites.json","page",String.valueOf(page),true))
setAttributeInternal(inodePath,true,opTimeMs,options)
!template.contains(PATH_AUTO_NODE_INDEX) && !template.contains(PATH_AUTO_RELATIONSHIP_INDEX)
processInstanceArray.size() == 0
reg.put("localhost:" + port,ctx)
historicState(item,timestamp)
createMessageConsumer(session,destinationName,messageSelector,false,null,true)
assertTrueAllTheTime(() -> {   assertTrue(map.containsKey(0));   Collection<Employee> valuesNullCity=map.values(predicateCityNull);   assertEquals(2,valuesNullCity.size());   Collection<Employee> valuesNotNullCity=map.values(Predicates.equal("city","cityname"));   assertEquals(3,valuesNotNullCity.size()); } ,5)
HIVE_SERVER2_ASYNC_EXEC_SHUTDOWN_TIMEOUT("hive.server2.async.exec.shutdown.timeout",10L)
new IOException(ExceptionMessage.BLOCK_UNAVAILABLE.getMessage(blockId))
from("direct:start").aggregator().header("id").batchTimeout(2000L)
fMethodDescriptions.put(method,description)
TailArraySchema schema=new TailArraySchema(); 
return true; 
getPreferences().setProperty(key,value)
handleSecurityPermissionEndpoints(principalNode,permConfig)
factory.get(sResponseClass,NO_ANNOTATIONS,retrofit)
delegate.getChild(element)
Response<L>
endpoint.expectedMessageCount(1)
-1
i < 100
SingleServerInventoryProvider.class
getSession(false)
LOG.warn("Exception while fetching metrics.",e)
ConcurrentHashMap<Url,Channel>
this.loggingSystem.initialize(null,null)
LOG.warn("Failed to write to TachyonStore stream, block " + getCurrentBlockId() + " will not be in TachyonStorage.",ioe)
logger.info("Renamed " + instancesRenamed + " instances of "+ propsRenamed+ " properties.")
!b.getAtmosphereResources().contains(r)
Bytes.toBytesBinary(tableNameOrRegionName)
CAPACITY=500L
report(n,MISPLACED_ANNOTATION)
InputStream is=IOUtils.getInputStreamFromURLOrClasspathOrFileSystem(languagePropertiesFile)
factory.get(sResultClass,NO_ANNOTATIONS,retrofit)
rSocketMessageHandler.serverAcceptor()
agg.setBatchTimeout(1000L)
assertFalse(dr.isFailure())
OrderedMap.class
deploymentUnit.getParent() == null
response.getResponseBody().isEmpty()
LOG.error("Unable to parse HTTP response content",e)
this.repositories.add(repository)
delegate.tokenize(token,regex)
ObjectConverter.toBoolean(scriptValue)
DefaultBroadcaster.class.cast(resource.getBroadcaster()).broadcasterCache.addToCache(resource,msg)
url.toServiceString()
fileName.startsWith("/")
HashMap<String,ASTNode>
Thread.sleep(500)
input.mark(firstReadBufferSize)
key.equals(OAuthConstants.SCOPE)
waitUntil(() -> pongsReceived.get() == ADDRESSES_COUNT,30_000)
public class XpathRegressionLeftCurlyTest extends AbstractXpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=LeftCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionLeftCurlyOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(LeftCurlyCheck.class);     final String[] expectedViolation={"4:1: " + getCheckMessage(LeftCurlyCheck.class,LeftCurlyCheck.MSG_KEY_LINE_PREVIOUS,"{",1)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyOne']/OBJBLOCK","/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyOne']/OBJBLOCK/LCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=LeftCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionLeftCurlyTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(LeftCurlyCheck.class);     moduleConfig.addAttribute("option",LeftCurlyOption.NL.toString());     final String[] expectedViolation={"3:53: " + getCheckMessage(LeftCurlyCheck.class,LeftCurlyCheck.MSG_KEY_LINE_NEW,"{",53)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyTwo']/OBJBLOCK","/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyTwo']/OBJBLOCK/LCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testThree() throws Exception {     final String checkName=LeftCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionLeftCurlyThree.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(LeftCurlyCheck.class);     final String[] expectedViolation={"5:19: " + getCheckMessage(LeftCurlyCheck.class,LeftCurlyCheck.MSG_KEY_LINE_BREAK_AFTER,"{",19)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyThree']/OBJBLOCK" + "/METHOD_DEF[@text='sample']/SLIST/LITERAL_IF/SLIST");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
waitUntil(() -> externalNodesStarted.get() == NODE_COUNT,30_000)
/**   * Tests setup and cleanup attempts getting killed from command-line  and lost tracker  * @param mr  * @param dfs  * @param commandLineKill if true, test with command-line killelse, test with lost tracker  * @throws IOException  */ private void testSetupAndCleanupKill(MiniMRCluster mr,MiniDFSCluster dfs,boolean commandLineKill) throws IOException {   RunningJob job=launchJobWithWaitingSetupAndCleanup(mr);   JobTracker jt=mr.getJobTrackerRunner().getJobTracker();   JobInProgress jip=jt.getJob(job.getID());   TaskAttemptID setupID=getRunningTaskID(jip.getTasks(TaskType.JOB_SETUP));   if (commandLineKill) {     killTaskFromCommandLine(job,setupID,jt);   }  else {     killTaskWithLostTracker(mr,setupID);   }   UtilsForTests.writeFile(dfs.getNameNode(),dfs.getFileSystem().getConf(),setupSignalFile,(short)3);   while (job.reduceProgress() != 1.0f) {     try {       Thread.sleep(100);     }  catch (    InterruptedException ie) {     }   }   TaskAttemptID cleanupID=getRunningTaskID(jip.getTasks(TaskType.JOB_CLEANUP));   if (commandLineKill) {     killTaskFromCommandLine(job,cleanupID,jt);   }  else {     killTaskWithLostTracker(mr,cleanupID);   }   UtilsForTests.writeFile(dfs.getNameNode(),dfs.getFileSystem().getConf(),cleanupSignalFile,(short)3);   job.waitForCompletion();   assertEquals(JobStatus.SUCCEEDED,job.getJobState());   assertEquals(TaskStatus.State.KILLED,jt.getTaskStatus(setupID).getRunState());   assertEquals(TaskStatus.State.KILLED,jt.getTaskStatus(cleanupID).getRunState()); } 
t.add(R.id.frame,new SampleListFragment())
bindingGroup.has(PORT_OFFSET)
Assert.assertNotNull(text)
ServiceAnnouncingChatHandlerProvider.class
