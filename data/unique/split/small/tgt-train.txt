public Builder setUserAgent(String userAgent){   configBuilder.setUserAgent(userAgent);   return this; } 
GL11.glGetTexParameterfv(target,pname,params)
ticket.notifyAll()
expectedValue.equals(oldObject)
new Neo4jGraph(database.graph,false)
id=10855
engine.execute(query).dumpToString()
config.getIdleConnectionTimeoutInMs() > 0 && requestTimeout != -1 && requestTimeout < config.getIdleConnectionTimeoutInMs()
statistics.addGetTimeNanos(System.nanoTime() - start)
b.getBroadcasterConfig().applyFilters(r,t)
id=50
Assert.assertEquals("Recall outside target range",0.691,r,0.001)
simple.getToReceivedDate()
new DeserializationException("Error reading field " + fieldNumber + " as "+ target.getClass().getName(),e)
toJSON(entry.getValue(),config)
WebAppUtils.getResolvedRMWebAppURLWithScheme(conf)
setMode(RIGHT)
pool != null && pool.getDataSource().getClass().isAssignableFrom(iface)
theirs=theirIterator.next()
id=19
new MalformedException("Unrecognized message placeholder referenced: " + phName,node)
streamTokenizer.ttype == StreamTokenizer.TT_WORD || streamTokenizer.ttype == '"'
testSame("asdf;","var asdf;",VarCheck.NAME_REFERENCE_IN_EXTERNS_ERROR)
hashFunction.hashBytes(bigEndian)
sExecutorService.shutdownNow()
assertEquals(9,set.size())
!isAllFiles()
buffer.put(indices,offset,count)
VARBINARY.createBlockBuilder(new BlockBuilderStatus(),1)
loadTask instanceof LongTask
public Long getOlderThan(){   return olderThan; } 
/**   * Signal the maps/reduces to start.  */ static void signalTasks(MiniDFSCluster dfs,FileSystem fileSys,boolean isMap,String mapSignalFile,String reduceSignalFile) throws Exception {   writeFile(dfs.getNameNode(),fileSys.getConf(),isMap ? new Path(mapSignalFile) : new Path(reduceSignalFile),(short)1); } 
twitter1.checkUserListMembership(id1.screenName,userList.getId(),id2.id)
annotation == OriginalType.MAP || annotation == OriginalType.MAP_KEY_VALUE
EnterpriseMapPublisherCreateWithValueCodec.decodeResponse(response).response
group.shutdownGracefully(0,10,TimeUnit.SECONDS)
size=10.0f
postAgg.getName().equalsIgnoreCase(topNMetricName)
from("direct:start").multicast(new AggregationStrategy(){   public Exchange aggregate(  Exchange oldExchange,  Exchange newExchange){     if (oldExchange == null) {       return newExchange;     }     String body=oldExchange.getIn().getBody(String.class);     oldExchange.getIn().setBody(body + newExchange.getIn().getBody(String.class));     return oldExchange;   } } ).parallelProcessing().timeout(1000)
page.getRetainedSizeInBytes()
((VarcharType)type).getLengthSafe()
assertThat(context.getBeansOfType(WebServerFactoryCustomizer.class)).hasSize(2)
id=28
(short)0777
addGroupedInterceptor(filter,interceptorClassName,null,group,executionPolicy)
detailNode != null && detailNode.getNodeType().equals(JsonNodeType.OBJECT)
v.getCreationTime() + timeToLive < now
converter.tryConvertTo(leftValue.getClass(),rightValue)
ImmutableMultiset<String>
cacheConfig.isUseCache()
restEnableGzip=true
logger.debug("NODE {}: Retry timout: Advancing",node.getNodeId())
@Override public Response header(String name,Property property){   addHeader(name,property);   return this; } 
assertThat(xml).isEqualToIgnoringWhitespace(expectedContent)
{14,3.5f}
/**   * Gets the exception thrown (if any) by the method called in  {@link #run()}  * @return the thrown exception (if any).  */ public Exception getExceptionThrown(){   return exceptionThrown; } 
columnType.equalsIgnoreCase("date") || columnType.equalsIgnoreCase("timestamp")
!fields.contains(name)
callTimeoutMs=10000
CONCURRENT_THREAD_COUNT=30
new Exception("Apparent connection leak detected")
id=18
typeTmp.get(1)
getStreamNode(vertexID)
new DynamicAwareEntry("https4://localhost/test",null,null,null)
new Path(tblDesc.getLocation(),Warehouse.makePartPath(addPartitionDesc.getPartSpec()))
new NullOutputOperatorFactory(operatorId,sourceTypes)
DEFAULT_ROW_FLUSH_BOUNDARY=75000
new ArrayList<Object>(literalList.size())
touchEventPool.freeAll(touchEvents)
LOG.debug("Requesting paths for query services failed.",throwable)
NullPointerException.class
_barrier.waitFor(nextSequence,1000,TimeUnit.MILLISECONDS)
tfs.getFile(fileId)
new IllegalArgumentException("Command not found in bolt message: " + shellMsg)
Status.createStatuseList(get(getBaseURL() + "statuses/user_timeline/" + id+ ".json",null,paging.asPostParameterList(),http.isAuthenticationEnabled()))
JSError.make(callNode,NOT_UNIQUE_INSTANTIATION,funType.toString(),UniqueNameGenerator.getOriginalName(typeParam),types.toString(),funType.toString())
"Segment initialized with too large address: " + offHeapAddress + " ; Max allowed address is "+ (Long.MAX_VALUE - Integer.MAX_VALUE - 1)
new PoolBagEntry(null,0,TestElf.getPool(ds))
MBeanInfoAssembler.class
JavadocTagContinuationIndentationCheck.class
GL20.glUniform4iv(location,v)
logger.fine("Parsing Dep: " + filePath)
/**   * Gets the key of bind hostname.  * @return key of bind hostname  */ public PropertyKey getBindHostKey(){   return mBindHostKey; } 
new File(resourceArr[i])
interceptors.addLast(newAInterceptor(a))
Assert.assertEquals(21,as.getAllGlobalProperties().size())
!paused.get()
new GrammaticalRelation(Language.UniversalChinese,"nummod","numeric modifier",MODIFIER,"QP|NP|DP",tregexCompiler,"NP|QP < ( QP  =target << M $++ NN|NP|QP)")
TEST_UTIL.waitUntilAllRegionsAssigned(TEST_TABLE.getTableName())
probeParentLoaderLast=false
@GwtIncompatible("ObjectInputStream") public void restoreState(InputStream inputStream) throws IOException {   try (final ObjectInputStream objectInputStream=new ObjectInputStream(inputStream)){     CompilerState compilerState=runInCompilerThread(new Callable<CompilerState>(){       @Override public CompilerState call() throws Exception {         return (CompilerState)objectInputStream.readObject();       }     } );     externs=compilerState.externs;     inputs=compilerState.inputs;     inputsById.clear();     inputsById.putAll(compilerState.inputsById);     typeRegistry=compilerState.typeRegistry;     externAndJsRoot=compilerState.externAndJsRoot;     externsRoot=compilerState.externsRoot;     jsRoot=compilerState.jsRoot;     mostRecentTypechecker=compilerState.mostRecentTypeChecker;     synthesizedExternsInput=compilerState.synthesizedExternsInput;     synthesizedExternsInputAtEnd=compilerState.synthesizedExternsInputAtEnd;     injectedLibraries.clear();     injectedLibraries.putAll(compilerState.injectedLibraries);     lastInjectedLibrary=compilerState.lastInjectedLibrary;     globalRefMap=compilerState.globalRefMap;     symbolTable=compilerState.symbolTable;     hasRegExpGlobalReferences=compilerState.hasRegExpGlobalReferences;     typeValidator=compilerState.typeValidator;     setLifeCycleStage(compilerState.lifeCycleStage);     externProperties=compilerState.externProperties;   }    initWarningsGuard(options.getWarningsGuard());   maybeSetTracker(); } 
targetDirectory.file("unwritable")
location.add(deltaX / delta,deltaY / delta,deltaZ / delta)
version > 1
sorted_files.get(i).createReader(canUseDrop)
ch == '&' && JdbcConstants.POSTGRESQL.equals(dbType)
entry.getHeader().getEventLength() * 6
ModelVersion.create(2,0,0)
return 2; 
public String getRequestRequiredAcks(){   return configuration.getRequestRequiredAcks(); } 
z.next_in[z.next_in_index++] != 0
new ClusterConfiguration(name,Collections.singleton(boundAt))
ServiceLoader.load(WorkerFactory.class,WorkerFactory.class.getClassLoader())
(short)0777
new WordToSentenceProcessor<IN>(WordToSentenceProcessor.NewlineIsSentenceBreak.ALWAYS)
AdviceWithTasks.afterByToString(route,toString,answer,selectFirst,selectLast,selectFrom,selectTo,maxDeep)
mPersistedFiles.removeAll(persistedFiles)
Thread.sleep(300)
position <= mSrcDragPos
out.writeInt(this.connectionAddress.getPort())
Ordered.LOWEST_PRECEDENCE - 2
EnumValidator.create(Target.class,true,false)
LOG.error(result.getDescription(),e)
DEFAULT_RM_ACL_ENABLE=true
Status.createStatuseList(get(getBaseURL() + "statuses/user_timeline.json",true))
mMethod.invoke(mContext,params)
cache.removeRecord(key)
runPartialSorter(sorter,NUM_RECORDS,25)
this.traceHandlers.remove(traceHandler)
value.toBigInteger()
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class RingbufferBasicDistributedTest extends RingbufferAbstractTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(2).newInstances(config);   } } 
new GdxRuntimeException("Error during Vorbis decoding.",e)
ImmutableList.of(bang,qmark)
this.cli.jar("secure.groovy","data-jpa.groovy")
type == VertexDataType.VertexBufferObject || Mesh.forceVBO
alpha=0
format("RowBlock{SingleRowBlockWriter=%d, fieldBlockBuilderReturned=true}",numFields)
itemActionLayout > 0
/**   */ class SctpClientPipelineSink extends AbstractSctpChannelSink {   static final InternalLogger logger=InternalLoggerFactory.getInstance(SctpClientPipelineSink.class);   final Executor bossExecutor;   private final Boss boss=new Boss();   private final SctpWorker[] workers;   private final AtomicInteger workerIndex=new AtomicInteger();   SctpClientPipelineSink(  Executor bossExecutor,  Executor workerExecutor,  int workerCount){     this.bossExecutor=bossExecutor;     workers=new SctpWorker[workerCount];     for (int i=0; i < workers.length; i++) {       workers[i]=new SctpWorker(workerExecutor);     }   }   @Override public void eventSunk(  ChannelPipeline pipeline,  ChannelEvent e) throws Exception {     if (e instanceof ChannelStateEvent) {       ChannelStateEvent event=(ChannelStateEvent)e;       SctpClientChannel channel=(SctpClientChannel)event.getChannel();       ChannelFuture future=event.getFuture();       ChannelState state=event.getState();       Object value=event.getValue(); switch (state) { case OPEN:         if (Boolean.FALSE.equals(value)) {           channel.worker.close(channel,future);         }       break; case BOUND:     if (value != null) {       bind(channel,future,(SocketAddress)value);     }  else {       channel.worker.close(channel,future);     }   break; case CONNECTED: if (value != null) {   connect(channel,future,(SocketAddress)value); }  else {   channel.worker.close(channel,future); } break; case INTEREST_OPS: if (event instanceof SctpBindAddressEvent) { SctpBindAddressEvent bindAddressEvent=(SctpBindAddressEvent)event; bindAddress(channel,bindAddressEvent.getFuture(),bindAddressEvent.getValue()); }  else if (event instanceof SctpUnbindAddressEvent) { SctpUnbindAddressEvent unbindAddressEvent=(SctpUnbindAddressEvent)event; unbindAddress(channel,unbindAddressEvent.getFuture(),unbindAddressEvent.getValue()); }  else { channel.worker.setInterestOps(channel,future,((Integer)value).intValue()); } break; } }  else if (e instanceof MessageEvent) { MessageEvent event=(MessageEvent)e; SctpChannelImpl channel=(SctpChannelImpl)event.getChannel(); boolean offered=channel.writeBuffer.offer(event); assert offered; channel.worker.writeFromUserCode(channel); } } private void bind(SctpClientChannel channel,ChannelFuture future,SocketAddress localAddress){ try { channel.channel.bind(localAddress); channel.boundManually=true; channel.setBound(); future.setSuccess(); fireChannelBound(channel,channel.getLocalAddress()); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void bindAddress(SctpClientChannel channel,ChannelFuture future,InetAddress localAddress){ try { channel.channel.bindAddress(localAddress); future.setSuccess(); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void unbindAddress(SctpClientChannel channel,ChannelFuture future,InetAddress localAddress){ try { channel.channel.unbindAddress(localAddress); future.setSuccess(); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void connect(final SctpClientChannel channel,final ChannelFuture cf,SocketAddress remoteAddress){ try { if (channel.channel.connect(remoteAddress)) { channel.worker.register(channel,cf); }  else { channel.getCloseFuture().addListener(new ChannelFutureListener(){ @Override public void operationComplete(ChannelFuture f) throws Exception { if (!cf.isDone()) { cf.setFailure(new ClosedChannelException()); } } } ); cf.addListener(ChannelFutureListener.CLOSE_ON_FAILURE); channel.connectFuture=cf; boss.register(channel); } }  catch (Throwable t) { cf.setFailure(t); fireExceptionCaught(channel,t); channel.worker.close(channel,succeededFuture(channel)); } } SctpWorker nextWorker(){ return workers[Math.abs(workerIndex.getAndIncrement() % workers.length)]; } private final class Boss implements Runnable { volatile Selector selector; private boolean started; private final AtomicBoolean wakenUp=new AtomicBoolean(); private final Object startStopLock=new Object(); private final Queue<Runnable> registerTaskQueue=QueueFactory.createQueue(Runnable.class); Boss(){ super(); } void register(SctpClientChannel channel){ Runnable registerTask=new RegisterTask(this,channel); Selector selector; synchronized (startStopLock) { if (!started) { try { this.selector=selector=Selector.open(); }  catch (Throwable t) { throw new ChannelException("Failed to create a selector.",t); } boolean success=false; try { DeadLockProofWorker.start(bossExecutor,this); success=true; }   finally { if (!success) { try { selector.close(); }  catch (Throwable t) { logger.warn("Failed to close a selector.",t); } this.selector=selector=null; } } }  else { selector=this.selector; } assert selector != null && selector.isOpen(); started=true; boolean offered=registerTaskQueue.offer(registerTask); assert offered; } if (wakenUp.compareAndSet(false,true)) { selector.wakeup(); } } @Override public void run(){ boolean shutdown=false; Selector selector=this.selector; long lastConnectTimeoutCheckTimeNanos=System.nanoTime(); for (; ; ) { wakenUp.set(false); try { int selectedKeyCount=selector.select(500); if (wakenUp.get()) { selector.wakeup(); } processRegisterTaskQueue(); if (selectedKeyCount > 0) { processSelectedKeys(selector.selectedKeys()); } long currentTimeNanos=System.nanoTime(); if (currentTimeNanos - lastConnectTimeoutCheckTimeNanos >= 500 * 1000000L) { lastConnectTimeoutCheckTimeNanos=currentTimeNanos; processConnectTimeout(selector.keys(),currentTimeNanos); } if (selector.keys().isEmpty()) { if (shutdown || bossExecutor instanceof ExecutorService && ((ExecutorService)bossExecutor).isShutdown()) { synchronized (startStopLock) { if (registerTaskQueue.isEmpty() && selector.keys().isEmpty()) {   started=false;   try {     selector.close();   }  catch (  IOException e) {     if (logger.isWarnEnabled()) {       logger.warn("Failed to close a selector.",e);     }   }  finally {     this.selector=null;   }   break; }  else {   shutdown=false; } } }  else { shutdown=true; } }  else { shutdown=false; } }  catch (Throwable t) { if (logger.isWarnEnabled()) { logger.warn("Unexpected exception in the selector loop.",t); } try { Thread.sleep(1000); }  catch (InterruptedException e) { } } } } private void processRegisterTaskQueue(){ for (; ; ) { final Runnable task=registerTaskQueue.poll(); if (task == null) { break; } task.run(); } } private void processSelectedKeys(Set<SelectionKey> selectedKeys){ for (Iterator<SelectionKey> i=selectedKeys.iterator(); i.hasNext(); ) { SelectionKey k=i.next(); i.remove(); if (!k.isValid()) { close(k); continue; } if (k.isConnectable()) { connect(k); } } } private void processConnectTimeout(Set<SelectionKey> keys,long currentTimeNanos){ ConnectException cause=null; for (SelectionKey k : keys) { if (!k.isValid()) { continue; } SctpClientChannel ch=(SctpClientChannel)k.attachment(); if (ch.connectDeadlineNanos > 0 && currentTimeNanos >= ch.connectDeadlineNanos) { if (cause == null) { cause=new ConnectException("connection timed out"); } ch.connectFuture.setFailure(cause); fireExceptionCaught(ch,cause); ch.worker.close(ch,succeededFuture(ch)); } } } private void connect(SelectionKey k){ SctpClientChannel ch=(SctpClientChannel)k.attachment(); try { if (ch.channel.finishConnect()) { k.cancel(); ch.worker.register(ch,ch.connectFuture); } }  catch (Throwable t) { ch.connectFuture.setFailure(t); fireExceptionCaught(ch,t); k.cancel(); ch.worker.close(ch,succeededFuture(ch)); } } private void close(SelectionKey k){ SctpClientChannel ch=(SctpClientChannel)k.attachment(); ch.worker.close(ch,succeededFuture(ch)); } } private static final class RegisterTask implements Runnable { private final Boss boss; private final SctpClientChannel channel; RegisterTask(Boss boss,SctpClientChannel channel){ this.boss=boss; this.channel=channel; } @Override public void run(){ try { channel.channel.register(boss.selector,SelectionKey.OP_CONNECT,channel); }  catch (ClosedChannelException e) { channel.worker.close(channel,succeededFuture(channel)); } int connectTimeout=channel.getConfig().getConnectTimeoutMillis(); if (connectTimeout > 0) { channel.connectDeadlineNanos=System.nanoTime() + connectTimeout * 1000000L; } } } } 
Color.fromRGB(0xDECF2A)
final ImportControl root=ImportControlLoader.load(new File(getPath("import-control_complete.xml")).toURI()); 
DirectMessage.createDirectMessageList(get(getBaseURL() + "direct_messages.json",null,paging.asPostParameterList(),true))
new S3DataSegmentMover(mockS3Client,new S3DataSegmentPusherConfig())
!webSocketProcessorName.equalsIgnoreCase(WebSocketProcessor.class.getName())
fail("IllegalArgumentException is expected")
level < RF_STATUS_FULL_SIGNAL
new GatherGetterAndSetterProperties(compiler)
context.revertReloadRequired()
form instanceof IObj && !(form instanceof Var) && ((IObj)form).meta() != null
GL20.glUniform1fv(location,v)
LinkedList<Object>
headers.get(ROLLBACK_ON_RUNTIME_FAILURE)
paramAttribute.split("\\.")
new GdxRuntimeException("Failure reading Vorbis.",e)
Validate.configurationDirectoryExists(controllerJavaHome,"controllerJavaHome must exist at " + controllerJavaHome)
RawTCPInput.class
Bukkit.getOperators()
timeout=30000
resetTimeInSeconds * 1000L
configure(COMPONENT,"cxf-jaxb")
registry.bind("groovyShellFactory",groovyShellFactory)
messageHandler.responder()
new ArrayList<Data>(entries.size())
mock.expectedBodiesReceivedInAnyOrder("Hello World")
mTfs.delete(mTfs.open(new TachyonURI(dirPath)),true)
bagEntry != null && bagEntry.state().compareAndSet(STATE_NOT_IN_USE,STATE_IN_USE)
id=10859
lastUpdateTime2 >= lastUpdateTime
target != null && !target.isEmpty()
config.getIdleConnectionInPoolTimeoutInMs()
logger.trace("Return Object {} now at size {}",b,count.getAndDecrement())
matched && matcher.groupCount() > 0
CreateFileOptions.defaults().setBlockSizeBytes(Constants.KB).setRecursive(true).setTtl(0)
NUMBER_OF_IDS_PER_THREAD=40000
in.readData()
conf.getInt(Constants.TFS_PERMISSIONS_UMASK_KEY)
absEdge.getTarget(view.getViewId())
new DescribeInstances(awsConfig).execute()
new ModelNode().set(5000L)
fields.put(PERMISSIONS,perms)
Assert.assertEquals(getNotAllowedExceptionMessage("helloForNone"),e.getCause().getMessage())
activeFrom.getTime()
new byte[10]
MAX_CACHED_HBASE_INSTANCES=2001
MD5Loader.loadModel(Gdx.files.internal("data/zfat.md5mesh").read(),false)
layout.createSequentialGroup().addPreferredGap(javax.swing.LayoutStyle.ComponentPlacement.RELATED).addComponent(availableStrategiesComboBox,0,218,Short.MAX_VALUE)
buffer.nextOneRow(changeColumns,true)
Assert.assertEquals(3,json.size())
setDiskExpiryThreadIntervalSeconds(Long.valueOf((String)cacheSettings.get("diskExpiryThreadIntervalSeconds")).longValue())
rImpl.getRequest()
read(buffer,0,(int)Math.min(buffer.length,len))
Preconditions.checkNotNull(hostname,"hostname")
mUfs.create(testFile,CreateOptions.defaults().setEnsureAtomic(true))
i=0
Executors.newSingleThreadExecutor(new ThreadFactory(){   private AtomicInteger count=new AtomicInteger();   @Override public Thread newThread(  final Runnable runnable){     return new Thread(runnable,"Atmosphere-BroadcasterConfig-" + count.getAndIncrement());   } } )
logger.fine("Recording function information")
includedGroup == null
getMockEndpoint("mock:event").expectedMessageCount(6)
waitUntil(() -> pongsReceived.get() == NODE_COUNT * NODE_COUNT * ADDRESSES_COUNT,60_000)
new SkinRenderer(context,"start.ftl")
id=10842
!shouldFollowLinksIn(webURL) || robotstxtServer.allows(webURL)
id=10860
DeploymentDescription.getReplaceDeploymentOperation(locale)
waitForJobExecutorToProcessAllJobsAndExecutableTimerJobs(20000,200)
converter.tryConvertTo(rightValue.getClass(),leftValue)
connection.pexpireAt(key,millisecondsTimestamp)
JavaConversions.asJavaIterable(logManager.allLogs())
new IllegalArgumentException("Command not found in spout message: " + shellMsg)
graphModel.getDirectedGraphVisible()
ufsPath.toString()
endFunction("get_column_statistics_by_table: ",statsObj != null,null)
newName.putProp(Node.ORIGINALNAME_PROP,qName)
i < 100
new LinkedHashMap<String,JdbcSqlStat>(maxSize,0.75f,false)
minZ != 0f || maxZ != 0f
Thread.sleep(1000)
verify(collector,never())
new OptiqSemanticException(generateErrorMessage(tabref,"Schema of both sides of union should match: field " + field + ":"+ " appears on the left side of the UNION at column position: "+ getPositionFromInternalName(lInfo.getInternalName())+ ", and on the right side of the UNION at column position: "+ getPositionFromInternalName(rInfo.getInternalName())+ ". Column positions should match for a UNION"))
TypeMirror maybeWildcardType
relationship(19,c,"KNOWS",d)
LOG.debug("Finding all components using class resolver: {} -> {}",new Object[]{resolver})
ctx.writeAndFlush("Your session is protected by " + ctx.pipeline().get(SslHandler.class).engine().getSession().getCipherSuite() + " cipher suite.\n")
activeFrom == null
x instanceof ISeq || x instanceof IPersistentList
SyslogTcpTransport.class
SimpleAttributeDefinitionBuilder.create("max-backup-index",ModelType.INT,true)
new EnumValidator<Mode>(Mode.class,false,true)
waitForJobExecutorToProcessAllJobs(5000,500)
Never
private final PropertyKey mHostNameKey; 
case READ_UNCOMMITTED: 
JSError.make(declNode,TypeCheck.CONFLICTING_SHAPE_TYPE,"dict",className)
routes.InputTypesResource()
c.getSimpleName()
return EOF_DATA; 
body[0][0][1]
preloadQueue.size == 0 || tasks.size() == 0
version == null || version.equals("")
KBP_MINIMUM_SCORE=.456
events == null && this.calDavLoader != null
WebUiResource.class
cache.put(new Element(key,element))
asyncResult.cause()
containedToken.beginPosition()
new RagManager()
Arrays.asList("spring-boot-starter-jetty-","jetty-continuation","jetty-util-","javax.servlet-","jetty-io-","jetty-http-","jetty-server-","jetty-security-","jetty-servlet-","jetty-servlets","jetty-webapp-","websocket-api","javax.annotation-api","jetty-plus","javax-websocket-server-impl-","asm-","javax.websocket-api-","asm-tree-","asm-commons-","websocket-common-","jetty-annotations-","javax-websocket-client-impl-","websocket-client-","websocket-server-","jetty-xml-","websocket-servlet-")
id=43
collection(StreamImpl.class).update(match,modify,false,true)
sizeModeClass.equals("ProportionalSizeMode")
this.assignmentManager.isRegionInTransition(regionInfo) != null
3 >= buf.length - count
distinctValues.put(slice,distinct)
BALD
original.getScreenName().endsWith("new") || original.getName().endsWith("new")
Math.max(1000L,connectionTimeout)
"source".equals(key) || "target".equals(key) || "value".equals(key)|| "weight".equals(key)|| "label".equals(key)
response.getStatus().getCode() / 100
IOUtils.toString(stencilsetStream,"utf-8")
DefaultObjectNameFactory.class
new IllegalStateException("File " + file.getPath() + " should not exist")
!getPath(tFile).startsWith(MASTER_CONF.TEMPORARY_FOLDER)
input.entrySet()
!exported
FileUtil.compactPath(path,'/')
Assert.assertEquals(new InetSocketAddress("RemoteMaster1",10000),masterAddress)
qp.isExclusiveMaximum()
checkArgument(!"/".equals(resourcePath),"%s is the classpath root",resourcePath)
new RequestManager(testTimer,3000)
assertThat(context).getBeans(HandlerMapping.class).hasSize(5)
rackIdToNodes.getOrDefault(rid,Collections.emptyList())
MoreObjects.toStringHelper(this).add("user",getUser()).add("timeZoneKey",timeZoneKey).add("locale",locale).add("startTime",startTime).add("properties",propertyValues)
new BadRequestException("Field " + field + " is not of a numeric type and the cardinality could not be calculated either.",e1)
yx*=ly
logger.debug("NODE {}: BATTERY LOW!",this.getNode().getNodeId())
LOG.warn("SpaceReserver failed to free tier {} to {} bytes used: {}",tierAlias,reservedSpace,e.getMessage())
ImmutableSortedSet.of("a","abbr","acronym","address","area","b","bdo","big","blockquote","br","caption","cite","code","colgroup","dd","del","div","dfn","dl","dt","em","fieldset","font","h1","h2","h3","h4","h5","h6","hr","i","img","ins","kbd","li","ol","p","pre","q","samp","small","span","strong","style","sub","sup","table","tbody","td","tfoot","th","thead","tr","tt","u","ul","var")
assertContains(actualTables,expectedTables)
Character.isWhitespace(origText.charAt(i))
DEFAULT_ALLOW_SPILLING=true
Exception e
type == REPARTITION
String.valueOf(0.09)
soLingerTime.toMilliseconds()
96.0f / 160
assertNotNull("Failed to trigger savepoint",savepointPath)
test("var foo = function (a) {}; foo.call(this, 1);","var foo = function () {var a$jscomp$1 = 1;}; foo.call(this);")
cleanString(nameAttribute.getValue())
id=10866
bindings.or(ImmutableMap.<ColumnHandle,Object>of())
(Source)value
delta < 11000
CamelCloudServiceCallRoutesAutoConfiguration.class
(byte)0xe2
runOTIafterNTI=true
promise.tryFailure(cause)
!DruidDataSourceUtils.isRemoveAbandoned(datasource)
manualClock.addTimeMs(1001)
(short)0777
log.debug("Performing lookup: %s --> %s",ips,retVal)
JSError.make(AbstractCompiler.READ_ERROR,getName(),e.getMessage())
message + end
sections.get(section)
assertPlanEquals(expectedPlan,actualPlan)
Thread.sleep(500)
m.isReadBackupData()
LOG.debug("Retrieving location for state={} of job={} from the cache.",queryableStateName,jobId)
maxSize < (used / 1024 / 1024)
layout.setReleaseLabel(label)
ctx.write(msg,promise)
sendCommand(CLIENT,Keyword.SETNAME.raw,name)
{@link ImportControl}
server.getState()
assertEquals("[]",q.toString())
lc + lp
Long.parseLong(args[2])
id=7
URIStatus::getLength
!isDistinct(child)
lights != null && lights.shadowMap != null
intBuffer.clear()
-2
/**   * @see ConceptService#getCountOfConceptReferenceTerms(String,ConceptSource,boolean)  */ public Long getCountOfConceptReferenceTerms(String query,ConceptSource conceptSource,boolean includeRetired) throws DAOException ; 
logger.warn("Failed to set channel option '{}' with value '{}' for channel '{}'",option,value,channel,t)
times + BASE_FILE_NUMBER
Arrays.asList("Java","CSharp","Cpp")
-1
new DynamicAwareEntry("http4://localhost/test",null,null,null)
DiagnosticType.warning("JSC_REDECLARED_VARIABLE","Redeclared variable: {0}")
!byteBuf.readable()
m_data.rewind().forward((int)key_offset).getFixString((int)key_length,charsetName)
final Integer firstLineKey=lines.firstKey(); 
getFirstByType(type)
this(host,port,threadName,queueSize,timeout,sendBufferSize,DEFAULT_BUFFER_SIZE); 
assertTrueEventually(new AssertTask(){   @Override public void run(){     getStats(client,clientEngine);   } } )
ZWaveSwitchAllCommandClass.class
mViewAbove.setCurrentItem(0,animate)
LOG.warn("Syslog message is missing date or date could not be parsed. (Possibly set {} to true) " + "Not further handling. Message was: {}",SyslogInputBase.CK_ALLOW_OVERRIDE_DATE,new String(msg.getRaw()))
Assert.assertEquals(values,expected)
count == 0 && position == buffer.length
entry.getName().equals(BOOT_INF_CLASSES)
Assert.assertEquals("Message key '" + retrievedMessage + "' is not valid","unable.open.cause",retrievedMessage)
r.getUri().getPath()
getHandledPredicate()
status != null
that.getDomain() == null && getDomain() != null
JSError.make(n,Es6ToEs3Converter.CANNOT_CONVERT_YET,"Case statements that contain yields")
new MockQueryExecution(2)
buffer.indexOf(partToMatch,indexOf + replacement.length())
value <= 0
this.setAutoCommitOnClose(true)
LOG.error("Error while deserializing payload",e)
1000 * 60
id=10833
GraphDatabaseSetting<Long>
new SimpleDateFormat(format,JSON.defaultLocale)
new LwjglPreferences(name,".prefs/")
getOrCreateConnectionFactory()
Context.getPersonService().getRelationshipsByPerson(Context.getPersonService().getPerson(personId))
SocketUtils.findAvailableTcpPort(41000)
logger.fine("Collapsed " + numRenamedPropertyNames + " properties into "+ numNewPropertyNames+ " and skipped renaming "+ numSkippedPropertyNames+ " properties.")
id=10997
SetUtil.class
IllegalArgumentException.class
new UnsafeBasedStringCharProvider(unsafe,stringValueFieldOffset,str)
response.get(ROLLED_BACK)
new IntRangeValidator(1,true,true)
failureDesc.contains("14807") || failureDesc.contains("14883") || failureDesc.contains("13456")|| failureDesc.contains("11340")
GL20.glUniformMatrix3fv(location,transpose,value)
@RunWith(HazelcastSerialClassRunner.class) @Category(QuickTest.class) public class UserCodeDeploymentPermissionTest extends PermissionTestSupport {   @Override protected Permission createPermission(  String name,  String... actions){     return new CardinalityEstimatorPermission(name,actions);   }   @Test public void checkDeployPermission_whenAll(){     new CheckPermission().of("deploy").against("deploy").expect(true).run();   }   @Test public void checkDeployPermission(){     new CheckPermission().of("deploy").against("all").expect(true).run();   }   @Test public void checkAllPermission_whenDeploy(){     new CheckPermission().of("all").against("deploy").expect(false).run();   } } 
ChannelBuffers.wrappedBuffer(bytes,0,length)
id=16500
is(5)
promise.tryFailure(new ClosedChannelException())
log.warn("Annotation scanning mode loaded {} type converters. Its recommended to migrate to @Converter(loader = true) for fast type converter mode.",additional)
Thread.sleep(100)
assertEquals(3,historyService.createHistoricActivityInstanceQuery().processDefinitionId(processInstance.getProcessDefinitionId()).list().size())
factory.get(fResponseWildcard,NO_ANNOTATIONS,retrofit)
sendTo("direct:foo")
id=27
Color.fromRGB(0x1E1B1B)
Preconditions.checkNotNull(path,"path")
(BeanDefinitionRegistry)beanFactory
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class CountDownLatchBasicLocalTest extends CountDownLatchAbstractTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(1).newInstances();   } } 
new ClusterConfiguration("clusterName",initialHosts)
event.isTouchFocusCancel() || !calculatePositionAndValue(x,y)
new ConversionException("Expected a proto but was: " + body.mimeType())
Exception e
attributeMap.get(attributeName)
MAX_USER_NAME_LENGTH=64
new IllegalStateException("Result is already complete: succeeded")
drawable != null
columnType.equalsIgnoreCase("string") || columnType.toLowerCase().startsWith("char") || columnType.toLowerCase().startsWith("varchar")
ENDER_PORTAL_FRAME(120)
xmlDocAnnotation.get(CoreAnnotations.TokensAnnotation.class).get(543)
assertFalse(jmsTemplate.isPubSubDomain())
obj1.isLoose && obj2.isLoose
legacyValue.isDefined()
TestSuiteEnvironment.getServerAddressNode1()
LOG.debug("Creating netty input stream for block {} @ {} from client {}",blockId,address,NetworkAddressUtils.getClientHostName())
@Override protected Block getBlock(){   return blockBuilder; } 
@Path(PATH_RELATIONSHIP_INDEX_ID)
mail.getClass().getSimpleName()
LOG.debug("Date could not be parsed. Was set to NOW because {} is true.",SyslogInputBase.CK_ALLOW_OVERRIDE_DATE)
javaClass.addNestedType().setPackagePrivate()
outputFile.lastModified() <= grammarFile.lastModified()
Assert.assertEquals(select.size(),0)
(long)y & 0xFFFFFFFFL
channelIdle(ctx,IdleState.WRITER_IDLE,lastWriteTime)
new TestResultPrinter(new PrintStream(output)){   public void printErrors(  TestResult result){     getWriter().println("Errors here");   } } 
new PoolBagEntry(null,0,pool)
commandLineArguments.isLocal() || commandLineArguments.isDebug()
collisionPoints.get(0)
id=10807
ProtobufUtil.createSnapshotDesc(snapshot)
(t instanceof MetaException) && t.getMessage().matches("(?s).*(JDO[a-zA-Z]*|TProtocol|TTransport)Exception.*") && !t.getMessage().contains("java.sql.SQLIntegrityConstraintViolationException")
Iterable<T>
log.tracef("%s finished request %d",ManagementChannel.this,header.getBatchId())
localFilteredData.addAccessRestrictedResource(absoluteChildAddr)
RedisTemplate<Object,Object>
graphModel.getGraph().getNodeCount()
resultEndpoint.expectedMinimumMessageCount(2)
final DeletionRetentionStrategyConfig deletionRetentionStrategyConfig=clusterConfigService.get(DeletionRetentionStrategyConfig.class); 
getResponse("GET","/books/" + bookId,null)
items[32]
id=10834
format(conf,false)
new Duration(60,TimeUnit.SECONDS)
compressedProto.length < 380000
shift > 0 && newroot.length == 1
@RunWith(HazelcastSerialClassRunner.class) @Category(QuickTest.class) public class ReplicatedMapTest extends ReplicatedMapAbstractTest {   @Test public void testEmptyMapIsEmpty() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance=nodeFactory.newHazelcastInstance();     ReplicatedMap<Integer,Integer> map=instance.getReplicatedMap(randomName());     assertTrue("map should be empty",map.isEmpty());   }   @Test public void testNonEmptyMapIsNotEmpty() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance=nodeFactory.newHazelcastInstance();     ReplicatedMap<Integer,Integer> map=instance.getReplicatedMap(randomName());     map.put(1,1);     assertFalse("map should not be empty",map.isEmpty());   }   @Test(expected=IllegalArgumentException.class) public void testNegativeTtlThrowsException() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance=nodeFactory.newHazelcastInstance();     ReplicatedMap<Integer,Integer> map=instance.getReplicatedMap(randomName());     map.put(1,1,-1,TimeUnit.DAYS);   }   @Test public void testAddObject() throws Exception {     testAdd(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testAddBinary() throws Exception {     testAdd(buildConfig(InMemoryFormat.BINARY));   }   private void testAdd(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );   }   @Test public void testPutAllObject() throws Exception {     testPutAll(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testPutAllBinary() throws Exception {     testPutAll(buildConfig(InMemoryFormat.BINARY));   }   private void testPutAll(  Config config) throws TimeoutException {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     final Map<String,String> mapTest=new HashMap<String,String>();     for (    String key : keys) {       mapTest.put(key,"bar");     }     map1.putAll(mapTest);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );   }   @Test public void testClearObject() throws Exception {     testClear(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testClearBinary() throws Exception {     testClear(buildConfig(InMemoryFormat.BINARY));   }   private void testClear(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );     map1.clear();     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(0,map1.size());         assertEquals(0,map2.size());       }     } );   }   @Test public void testAddTtlObject() throws Exception {     testAddTtl(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testAddTtlBinary() throws Exception {     testAddTtl(buildConfig(InMemoryFormat.BINARY));   }   private void testAddTtl(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar",10,TimeUnit.MINUTES);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           ReplicatedRecord<String,String> record=getReplicatedRecord(map1,key);           assertNotNull(record);           assertNotEquals(0,record.getTtlMillis());         }       }     } );     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map2.get(key));           ReplicatedRecord<String,String> record=getReplicatedRecord(map2,key);           assertNotNull(record);           assertNotEquals(0,record.getTtlMillis());         }       }     } );   }   @Test public void testUpdateObject() throws Exception {     testUpdate(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testUpdateBinary() throws Exception {     testUpdate(buildConfig(InMemoryFormat.BINARY));   }   private void testUpdate(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );     for (    String key : keys) {       map2.put(key,"bar2");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar2",map1.get(key));           assertEquals("bar2",map2.get(key));         }       }     } );   }   @Test public void testUpdateTtlObject() throws Exception {     testUpdateTtl(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testUpdateTtlBinary() throws Exception {     testUpdateTtl(buildConfig(InMemoryFormat.BINARY));   }   private void testUpdateTtl(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );     for (    String key : keys) {       map2.put(key,"bar2",10,TimeUnit.MINUTES);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar2",map1.get(key));           ReplicatedRecord<String,String> record=getReplicatedRecord(map1,key);           assertNotNull(record);           assertTrue(record.getTtlMillis() > 0);         }       }     } );     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar2",map2.get(key));           ReplicatedRecord<String,String> record=getReplicatedRecord(map2,key);           assertNotNull(record);           assertTrue(record.getTtlMillis() > 0);         }       }     } );   }   @Test public void testRemoveObject() throws Exception {     testRemove(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testRemoveBinary() throws Exception {     testRemove(buildConfig(InMemoryFormat.BINARY));   }   @Test public void testContainsKey_returnsFalse_onRemovedKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     map.remove(1);     assertFalse(map.containsKey(1));   }   @Test public void testContainsKey_returnsFalse_onNonexistentKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     assertFalse(map.containsKey(1));   }   @Test public void testContainsKey_returnsTrue_onExistingKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     assertTrue(map.containsKey(1));   }   @Test public void testKeySet_notIncludes_removedKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     final ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     map.put(2,Integer.MIN_VALUE);     map.remove(1);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         Set<Integer> keys=new HashSet<Integer>(map.keySet());         assertFalse(keys.contains(1));       }     } ,20);   }   @Test public void testEntrySet_notIncludes_removedKeys() throws Exception {     HazelcastInstance node=createHazelcastInstance();     final ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     map.put(2,Integer.MIN_VALUE);     map.remove(1);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         Set<Entry<Integer,Integer>> entries=map.entrySet();         for (        Entry<Integer,Integer> entry : entries) {           if (entry.getKey().equals(1)) {             fail(String.format("We do not expect an entry which's key equals to %d in entry set",1));           }         }       }     } ,20);   }   private void testRemove(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertEquals("bar",map1.get(key));           assertEquals("bar",map2.get(key));         }       }     } );     for (    String key : keys) {       map2.remove(key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertFalse(map1.containsKey(key));           assertFalse(map2.containsKey(key));         }       }     } );   }   @Test public void testSizeObject() throws Exception {     testSize(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testSizeBinary() throws Exception {     testSize(buildConfig(InMemoryFormat.BINARY));   }   private void testSize(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     final SimpleEntry<String,String>[] testValues=buildTestValues(keys);     int half=testValues.length / 2;     for (int i=0; i < testValues.length; i++) {       final ReplicatedMap<String,String> map=i < half ? map1 : map2;       final SimpleEntry<String,String> entry=testValues[i];       map.put(entry.getKey(),entry.getValue());     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(keys.size(),map1.size());         assertEquals(keys.size(),map2.size());       }     } );   }   @Test public void testContainsKeyObject() throws Exception {     testContainsKey(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testContainsKeyBinary() throws Exception {     testContainsKey(buildConfig(InMemoryFormat.BINARY));   }   private void testContainsKey(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertTrue(map1.containsKey(key));           assertTrue(map2.containsKey(key));         }       }     } );   }   @Test public void testContainsValue_returnsFalse_onNonexistentValue() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     assertFalse(map.containsValue(1));   }   @Test public void testContainsValueObject() throws Exception {     testContainsValue(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testContainsValueBinary() throws Exception {     testContainsValue(buildConfig(InMemoryFormat.BINARY));   }   private void testContainsValue(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     int half=keys.size() / 2, i=0;     for (    String key : keys) {       final ReplicatedMap<String,String> map=i++ < half ? map1 : map2;       map.put(key,key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           assertTrue(map1.containsValue(key));           assertTrue(map2.containsValue(key));         }       }     } );   }   @Test public void testValuesWithComparator() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance=nodeFactory.newHazelcastInstance();     ReplicatedMap<Integer,Integer> map=instance.getReplicatedMap(randomName());     for (int i=0; i < 100; i++) {       map.put(i,i);     }     Collection<Integer> values=map.values(new DescendingComparator());     int v=100;     for (    Integer value : values) {       assertEquals(--v,(int)value);     }   }   @Test public void testValuesObject() throws Exception {     testValues(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testValuesBinary() throws Exception {     testValues(buildConfig(InMemoryFormat.BINARY));   }   private void testValues(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     int half=keys.size() / 2, i=0;     for (    String key : keys) {       final ReplicatedMap<String,String> map=i++ < half ? map1 : map2;       map.put(key,key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(keys,new HashSet<String>(map1.values()));         assertEquals(keys,new HashSet<String>(map2.values()));       }     } );   }   @Test public void testKeySetObject() throws Exception {     testKeySet(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testKeySetBinary() throws Exception {     testKeySet(buildConfig(InMemoryFormat.BINARY));   }   private void testKeySet(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     int half=keys.size() / 2, i=0;     for (    String key : keys) {       final ReplicatedMap<String,String> map=i++ < half ? map1 : map2;       map.put(key,key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(keys,new HashSet<String>(map1.keySet()));         assertEquals(keys,new HashSet<String>(map2.keySet()));       }     } );   }   @Test public void testEntrySetObject() throws Exception {     testEntrySet(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testEntrySetBinary() throws Exception {     testEntrySet(buildConfig(InMemoryFormat.BINARY));   }   private void testEntrySet(  Config config) throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     int half=keys.size() / 2, i=0;     for (    String key : keys) {       final ReplicatedMap<String,String> map=i++ < half ? map1 : map2;       map.put(key,key);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         List<Entry<String,String>> entrySet1=new ArrayList<Entry<String,String>>(map1.entrySet());         List<Entry<String,String>> entrySet2=new ArrayList<Entry<String,String>>(map2.entrySet());         assertEquals(keys.size(),entrySet1.size());         assertEquals(keys.size(),entrySet2.size());         for (        Entry<String,String> e : entrySet1) {           assertTrue(keys.contains(e.getKey()));         }         for (        Entry<String,String> e : entrySet2) {           assertTrue(keys.contains(e.getKey()));         }       }     } );   }   @Test public void testAddListenerObject() throws Exception {     testAddEntryListener(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testAddListenerBinary() throws Exception {     testAddEntryListener(buildConfig(InMemoryFormat.BINARY));   }   private void testAddEntryListener(  Config config) throws TimeoutException {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     SimpleEntryListener listener=new SimpleEntryListener(1,0);     map2.addEntryListener(listener,keys.iterator().next());     for (    String key : keys) {       map1.put(key,"bar");     }     assertOpenEventually(listener.addLatch);   }   @Test public void testEvictionObject() throws Exception {     testEviction(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void testEvictionBinary() throws Exception {     testEviction(buildConfig(InMemoryFormat.BINARY));   }   private void testEviction(  Config config) throws TimeoutException {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap("default");     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     SimpleEntryListener listener=new SimpleEntryListener(0,100);     map2.addEntryListener(listener);     SimpleEntryListener listenerKey=new SimpleEntryListener(0,1);     map1.addEntryListener(listenerKey,keys.iterator().next());     for (    String key : keys) {       map1.put(key,"bar",3,TimeUnit.SECONDS);     }     assertOpenEventually(listener.evictLatch);     assertOpenEventually(listenerKey.evictLatch);   } private class SimpleEntryListener extends EntryAdapter<String,String> {     CountDownLatch addLatch;     CountDownLatch evictLatch;     SimpleEntryListener(    int addCount,    int evictCount){       addLatch=new CountDownLatch(addCount);       evictLatch=new CountDownLatch(evictCount);     }     @Override public void entryAdded(    EntryEvent event){       addLatch.countDown();     }     @Override public void entryEvicted(    EntryEvent event){       evictLatch.countDown();     }   }   @Test(expected=IllegalArgumentException.class) public void putNullKey() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap("default");     map1.put(null,1);   }   @Test(expected=IllegalArgumentException.class) public void removeNullKey() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap("default");     map1.remove(null);   }   @Test public void removeEmptyListener() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap("default");     assertFalse(map1.removeEntryListener("2"));   }   @Test(expected=IllegalArgumentException.class) public void removeNullListener() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap("default");     map1.removeEntryListener(null);   }   @Test public void testSizeAfterRemove() throws Exception {     HazelcastInstance node=createHazelcastInstance();     ReplicatedMap<Integer,Integer> map=node.getReplicatedMap("default");     map.put(1,Integer.MAX_VALUE);     map.remove(1);     assertTrue(map.size() == 0);   }   @Test public void testDestroy() throws Exception {     HazelcastInstance instance=createHazelcastInstance();     ReplicatedMap<Object,Object> replicatedMap=instance.getReplicatedMap(randomName());     replicatedMap.put(1,1);     replicatedMap.destroy();     Collection<DistributedObject> objects=instance.getDistributedObjects();     assertEquals(0,objects.size());   } class DescendingComparator implements Comparator<Integer> {     @Override public int compare(    Integer o1,    Integer o2){       return o1 == o2 ? 0 : o1 > o2 ? -1 : 1;     }   } } 
Double.isNaN(rate) || Double.isInfinite(rate)
AnnotatedElementUtils.hasAnnotation(type,Validated.class)
value()
initial(randToUse)
Object[]
request.getDueDate()
new RuntimeException("Error when launching multilang subprocess",e)
xAmount != 0
Pattern.compile("(--?[a-zA-Z_]+)=(.*)",Pattern.DOTALL)
notifier.getConfiguration().setPort(25669)
Ints.min(startedSplits.get(),splits)
toJSON(item,config)
test(externs,js,(String)null,null,ConstCheck.CONST_REASSIGNED_VALUE_ERROR)
prevNerEndIndex != (start - 1) && nextNerStartIndex != end
new RetryDriver(maxAttempts,minSleepTime,maxSleepTime,scaleFactor,maxRetryTime,exceptionWhiteList)
ret != null
!clusterVersion.onOrAfter(MINIMUM_ES_VERSION) || !clusterVersion.onOrBefore(MAXIMUM_ES_VERSION)
report(SHIFT_AMOUNT_OUT_OF_BOUNDS,n)
bar.setResultWaitTime(3500)
ImmutableList<ManyValues>
HeartbeatReelectionListener.class
log.warn(e,"Graceful shutdown of task[%s] aborted with exception.",task.getId())
(Integer)strategy.getOrNull("test",third)
dbCollection.save(clusterEvent,WriteConcern.FSYNCED)
MAX_LENGTH=200
FSImageFormatPBINode.class
socket != null
LOG.warn("Failed to write into TachyonStorage, the block " + getCurrentBlockId() + " will not be in TachyonStorage")
instance2.getLifecycleService().shutdown()
if (mAllowUndeclaredRTE) {   processImport(aAST); } 
In.forValue(apiKeyAuthConfig.in().toValue())
z / vz
LOG.debug("Creating short circuit input stream for block {} @ {}",blockId,address)
SecurityActions.getModuleClassLoader(module)
id=17
generator.generate(signedByKeyPair.getPrivate())
mPersistFileService.shutdown()
new PeepholeSubstituteAlternateSyntax(true)
RT.count(s)
new ModelNode().set(1L)
jarName.endsWith(".jar") || jarName.endsWith(".war")
id=14
!webSocket.isOpen()
CompletableFuture<Void>
potentialResponse != null
token.substring(0,p).trim().toLowerCase(Locale.US)
ArrayNodeBaseTest<LazyHeadArrayNode>
proxy == null || proxy != view.getAnimation()
log.info(error,cause)
spanEvent.getNextSpanId() != -1
DIODE(356)
1 <= user.getListedCount()
s != null && Boolean.parseBoolean(s)
getNonCompilablePath("InputPackageDeclarationDiffDirectoryAtSubpackage.java")
DirectMessage.createDirectMessageList(get(getBaseURL() + "direct_messages/sent.json",new PostParameter[0],paging.asPostParameterList(),true))
PROTOCOL_VERSION=2
exportAttributes && attributeModel != null
request.getDueBefore()
i <= maxIndex
ImmutableList<PersistentLocalScope>
ArrayBlockingQueue<BodyChunk>
public static XQueryBuilder xquery(File file,String characterSet) throws IOException {   return xquery(IOConverter.toInputStream(file),characterSet); } 
addKeys(externalClasses,DATE_TIME,"org.joda.time.DateTime","org.joda.time.ReadableDateTime","javax.xml.datatype.XMLGregorianCalendar","java.time.LocalDateTime")
assertEquals("val-1",mock.getExchanges().get(0).getIn().getBody(String.class))
docData.length() > 0 && docData.charAt(0) == 65279
attribute.getDefinition().getMarshaller()
cSet.getConceptSet()
map.set(key,"value",5,TimeUnit.SECONDS)
graphStack.push(lockingTx)
Assert.assertEquals(21,Context.getAdministrationService().getAllGlobalProperties().size())
getCode().split("\n",-1)
typeSerializer.getDeserializedType()
new LocalTachyonClusterResource(Constants.GB,BLOCK_SIZE,Constants.KEY_VALUE_ENABLED,"true",Constants.KEY_VALUE_PARTITION_SIZE_BYTES_MAX,Integer.toString(KEY_VALUE_PARTITION_SIZE))
Assert.assertEquals(new InetSocketAddress(defaultHostname,20000),masterAddress)
new JedisClusterCommand<Long>(connectionHandler,maxRedirections){   @Override public Long execute(  Jedis connection){     return connection.persist(key);   } } 
assertEquals(3,historyService.createHistoricActivityInstanceQuery().processInstanceId(processInstance.getId()).count())
new ConnectorTableLayout(handle,Optional.empty(),TupleDomain.none(),Optional.empty(),Optional.empty(),ImmutableList.of())
new ImportControl(stack.peek(),name,regex)
new NodeHistogram(application,range,responseTimes)
CopyOnWriteArrayList<EntryListener<?,?>>
bar.expectedMinimumMessageCount(2)
nodeId.equals(message.getToNode()) || nodeId.equals(message.getRouteId())
mock(ExampleService.class)
r.locals.ast=locals
GatherGetterAndSetterProperties.update(compiler,externsRoot,mainRoot)
LOG.debug("Creating netty output stream for block {} @ {} from client {}",blockId,address,NetworkAddressUtils.getClientHostName())
arguments == null || class_gd == null
new RefProperty(modelName)
!wrapRequest
new RuntimeException("Could not create TypeInformation for type " + data[0].getClass().getName() + "; please specify the TypeInformation manually via "+ "ExecutionEnvironment#fromElements(Collection, TypeInformation)",e)
Utils.javaDeserialize(_boltSer,IBatchBolt.class)
DEFAULT_SHUFFLE_PORT=13562
registry.bind("myManager",cacheManager)
ImmutableList<SuggestedFix>
entry.getUri()
HiveConf.setLongVar(jobConf,HiveConf.ConfVars.MAPREDMINSPLITSIZE,preferredSplitSize)
new ClosedByInterruptException()
endpoint.getBus().getInInterceptors().size() >= 1
this.applicationContext.register(RootConfig.class,PropertyPlaceholderAutoConfiguration.class,ManagementServerPropertiesAutoConfiguration.class,ServerPropertiesAutoConfiguration.class,EmbeddedServletContainerAutoConfiguration.class,DispatcherServletAutoConfiguration.class,WebMvcAutoConfiguration.class,EndpointWebMvcAutoConfiguration.class,ErrorMvcAutoConfiguration.class)
new CacheCreateConfigOperation(cacheConfig,createAlsoOnOthers,false)
GL11.glGetIntegerv(pname,params)
printLine("Unable to connect due to unrecognised server certificate")
Error|ClassNotFoundException
test("var foo = function (a) {}; foo.call(null, 1);","var foo = function () {var a$jscomp$1 = 1;}; foo.call(null);")
max=2000
SimpleAttributeDefinitionBuilder.create("new-level",ModelType.STRING,true)
cs.getNString(columnIndex)
id=16501
List<Data>
new HazelcastProperty("hazelcast.invalidation.reconciliation.interval.seconds",60,SECONDS)
DATABASE_TYPE_MSSQL.equals(databaseType)
new InMemoryMessageRepository()
config.getBroadcasterFactory().lookup(a.broadcaster(),path,true)
timeout=30000
beansXml.getOrCreateAlternatives()
Entry<String,Channel>
Assert.assertTrue(System.currentTimeMillis() - now < 5000)
String.format("NODE %d: Already in or beyond node stage, ignoring. current = %s, requested = %s",this.node.getNodeId(),this.node.getNodeStage().getLabel(),targetStage.getLabel())
Response description(String description); 
major == 1 && minor < 5
isHandshaking(clientResult) || isHandshaking(serverResult)
NETHER_WARTS(115)
QUEUE_TRANSACTION_LOG_RECORD=44
new HazelcastProperty("hazelcast.invalidation.min.reconciliation.interval.seconds",30,SECONDS)
ExceptionUtils.firstOrSuppressed(e,collectedExceptions)
cppFile.writeString(buffer.toString(),false,"UTF-8")
StringUtils.subString(url,"weburi-",".json",true)
Assert.assertEquals(new InetSocketAddress(defaultHostname,defaultPort),workerAddress)
getDatabaseSchema() != null && getDatabaseSchema().length() > 0
DiagnosticType.error("JSC_BAD_PRIVATE_GLOBAL_ACCESS","Access to private variable {0} not allowed outside file {1}.")
f.cancel(false)
initialCapacity > 1 << 30
patientExitObs != null && patientExitObs.size() > 0
new PrestoException(HIVE_FILESYSTEM_ERROR,"Failed to list directory: " + path,e)
basicGraph.getShortestPath(root,t,false)
message.contains("14807") || message.contains("14883") || message.contains("11340")
public CombinedMetric registerMetric(String name,ICombiner combiner,int timeBucketSizeInSecs){   return _topoContext.registerMetric(name,new CombinedMetric(combiner),timeBucketSizeInSecs); } 
ps.saveRelationship(rel)
InternalAttribute attribute=(InternalAttribute)o; 
builder(SingleSignOnDefinition.INSTANCE).addAttributes(SingleSignOnDefinition.DOMAIN,SingleSignOnDefinition.PATH,SingleSignOnDefinition.HTTP_ONLY,SingleSignOnDefinition.SECURE,SingleSignOnDefinition.COOKIE_NAME)
Object.class
assertOpenEventually(countDownLatch,300)
id=10846
toShort(bytes,0,SIZEOF_SHORT)
HIVE_PARTITION_OFFLINE(6,USER_ERROR)
(this.getExecContext().getLocalWork() != null && this.getExecContext().getLocalWork().getInputFileChangeSensitive()) && mapJoinTables != null
remoteAddressAliases != null && returnValue
public Builder setRealmScheme(Realm.AuthScheme scheme){   realm().setScheme(scheme);   return this; } 
combine(getDefaultCamelKarafOptions(),provision(TinyBundles.bundle().add("META-INF/persistence.xml",BlobStoreBlueprintRouteTest.class.getResource("/META-INF/persistence.xml")).add("OSGI-INF/blueprint/test.xml",BlobStoreBlueprintRouteTest.class.getResource("blueprintCamelContext.xml")).set(Constants.BUNDLE_SYMBOLICNAME,"CamelBlueprintJcloudsTestBundle").set(Constants.DYNAMICIMPORT_PACKAGE,"*").set("Meta-Persistence","META-INF/persistence.xml").build()),bundle(TinyBundles.bundle().add("OSGI-INF/blueprint/test.xml",BlobStoreBlueprintRouteTest.class.getResource("blueprintBlobStoreService.xml")).set(Constants.BUNDLE_SYMBOLICNAME,"org.apache.camel.jclouds.blobstore.service").set(Constants.BUNDLE_VERSION,"1.0.0").set(Constants.DYNAMICIMPORT_PACKAGE,"*").build()).start(),loadCamelFeatures("camel-blueprint","camel-jclouds"),workingDirectory("target/paxrunner/"))
AtmosphereResourceLifecycleInterceptor.class
items[22]
elementName=options.get(ELEMENT_NAME)
endTracksTo("main")
document.tokens().get(9)
mTfs.delete(mTfs.open(path),true)
type.getDataFormat(routeContext)
this.vertices.containsKey(node) || this.chainedTasks.containsKey(node) || this.iterations.containsKey(node)
trimmedLine.contains(delimiter)
computeAntiJoin(inputStatistics,inputStatistics,unknown,u)
reg.bind("localhost:" + port,env)
LOG.warn("calculatedMaxSteps:{} for loadbalancer's stochastic walk is larger than " + "maxSteps:{}. Hence load balancing may not work well. Setting parameter " + "\"hbase.master.balancer.stochastic.runMaxSteps\" to true can overcome this issue."+ "(This config change does not require service restart)",calculatedMaxSteps,maxSteps)
UnderFileSystem.get(tmpFolder,ufsConf)
bits2[1] == true
1 / 5f
@Override public ExtendedCell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   if (clonedBaseCell instanceof ByteBufferCell) {     return new ValueAndTagRewriteByteBufferCell((ByteBufferCell)clonedBaseCell,this.value,this.tags);   }   return new ValueAndTagRewriteCell(clonedBaseCell,this.value,this.tags); } 
curTime == 0 || totalTime / curTime == curOps
"Invalid modules directory: " + bundlesDir
result.addUnsafeEnchantment(enchantment,(Integer)entry.getValue())
Long.parseLong(args[1])
addProperty(secondNode,"band","The Clash")
Program.class
isDirect=true
Parameter.forConstructor(errorHandler,constructor)
return this; 
new AnnotationNode(desc,true)
getSSLContext().getSocketFactory().createSocket(arg0,arg1,arg2,true)
len >= bits.length
size() > this.capacity
serverEnvironment != null
line.toString(charset)
bundleContext.getBundle().getResource(uri)
Exception e
-1L
WebSocketEventListener.class.cast(l).onClose(event)
endpoint.setDataSource(target)
"Using bind address: " + bindAddress
getGlobalProperty(OpenmrsConstants.GLOBAL_PROPERTY_LOCALE_ALLOWED_LIST,"")
LOG.error("clear parameter error",ex)
args.length == 2
wrappersToPrimitives.put(wrapperType,primitiveType)
new StringInputRowParser(dataSpec == null ? null : dataSpec.toParseSpec(timestampSpec,dimensionExclusions),null,null,null,null)
ArrayList<>
KeyColumnValueStoreTest.class
assertEquals(ChronicleEngineMapEventType.REMOVE,mock.getExchanges().get(1).getIn().getHeader(ChronicleEngineConstants.MAP_EVENT_TYPE))
buffer.append(KEY_NODE_ID + "=").append(nodeId)
10 * 1
/**   * Retrieves X.  * @return a value  */ public T1 getX(){   return null; } 
status.getLastModificationTimeMs()
config.getInputShipStrategy(1)
SchematronProcessorFactory.newSchematronEngine(endpoint.getRules())
BufferUtils.disposeUnsafeByteBuffer(bytebuffer)
Foundation.log("[info] " + tag + ": "+ message)
NettyCometSupport.class
mTfs.mkdirs(path,true)
return true; 
constructor.getParameterTypes()
Assert.assertEquals(getNotAllowedExceptionMessage("helloForRole"),e.getCause().getMessage())
this.connectTo(vertex,channelType,compressionLevel,-1,-1,DistributionPattern.BIPARTITE,true)
deployments.get(deploymentName)
/**   * <code>CONCAT_AGG</code> aggregate function.  */ public static final SqlListAggFunction LISTAGG=new SqlListAggFunction(); 
binder.bindConstant().annotatedWith(Names.named("tlsServicePort")).to(8291)
@Override public Integer getValue(){   return getThreadCount(state); } 
ImmutableList<TypedVar>
new StringInputRowParser(new JSONParseSpec(new TimestampSpec("timestamp","auto"),new DimensionsSpec(Arrays.asList("dim1","dim2"),null,null)),null,null,null,null)
future.get(120,TimeUnit.SECONDS)
assertThat(child.getBeansOfType(ExampleBean.class)).hasSize(2)
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
additionalProperties.put(DATE_FORMAT,defaultDateFormat)
headerHandled=true
Color.fromRGB(0x287697)
model.getEnum().size() == 3
getPath("checks/javadoc/Input_03.java")
mSizeOnTier.containsKey(tierAlias) ? mSizeOnTier.get(tierAlias) : 0L
mFileLength - mPos >= mBlockSize
new AMQPProducer(metricRegistry,configuration,serverStatus)
reg.getHistograms(transformFilter(filter))
tx != null
new GZIPOutputStream(outputStream)
war.setWebXML(ClusteredWebTestCase.class.getPackage(),"web.xml")
"A task is in the ABORTED state but stage is " + currentState
raw.getOutParameters()
{189084,192250.913,195456.774,198696.946,201977.762,205294.444,208651.754,212042.099,215472.269,218941.91,222443.912,225996.845,229568.199,233193.568,236844.457,240543.233,244279.475,248044.27,251854.588,255693.2,259583.619,263494.621,267445.385,271454.061,275468.769,279549.456,283646.446,287788.198,291966.099,296181.164,300431.469,304718.618,309024.004,313393.508,317760.803,322209.731,326675.061,331160.627,335654.47,340241.442,344841.833,349467.132,354130.629,358819.432,363574.626,368296.587,373118.482,377914.93,382782.301,387680.669,392601.981,397544.323,402529.115,407546.018,412593.658,417638.657,422762.865,427886.169,433017.167,438213.273,443441.254,448692.421,453937.533,459239.049,464529.569,469910.083,475274.03,480684.473,486070.26,491515.237,496995.651,502476.617,507973.609,513497.19,519083.233,524726.509,530305.505,535945.728,541584.404,547274.055,552967.236,558667.862,564360.216,570128.148,575965.08,581701.952,587532.523,593361.144,599246.128,605033.418,610958.779,616837.117,622772.818,628672.04,634675.369,640574.831,646585.739,652574.547,658611.217,664642.684,670713.914,676737.681,682797.313,688837.897,694917.874,701009.882,707173.648,713257.254,719415.392,725636.761,731710.697,737906.209,744103.074,750313.39,756504.185,762712.579,768876.985,775167.859,781359,787615.959,793863.597,800245.477,806464.582,812785.294,819005.925,825403.057,831676.197,837936.284,844266.968,850642.711,856959.756,863322.774,869699.931,876102.478,882355.787,888694.463,895159.952,901536.143,907872.631,914293.672,920615.14,927130.974,933409.404,939922.178,946331.47,952745.93,959209.264,965590.224,972077.284,978501.961,984953.19,991413.271,997817.479,1004222.658,1010725.676,1017177.138,1023612.529,1030098.236,1036493.719,1043112.207,1049537.036,1056008.096,1062476.184,1068942.337,1075524.95,1081932.864,1088426.025,1094776.005,1101327.448,1107901.673,1114423.639,1120884.602,1127324.923,1133794.24,1140328.886,1146849.376,1153346.682,1159836.502,1166478.703,1172953.304,1179391.502,1185950.982,1192544.052,1198913.41,1205430.994,1212015.525,1218674.042,1225121.683,1231551.101,1238126.379,1244673.795,1251260.649,1257697.86,1264320.983,1270736.319,1277274.694,1283804.95,1290211.514,1296858.568,1303455.691}
connection.search(searchBase,filter,SearchScope.SUBTREE,groupIdAttribute,displayNameAttribute,"dn","uid","userPrincipalName","mail","rfc822Mailbox","memberOf","isMemberOf")
ImmutableMultimap<Feature<?>,Feature<?>>
tableMetadataBuilder(TPCH_SCHEMA_NAME,TPCH_ORDERS_NAME).column("orderkey",LONG).column("custkey",LONG).column("orderstatus",STRING).column("totalprice",DOUBLE).column("orderdate",STRING).column("orderpriority",STRING).column("clerk",STRING).column("shippriority",LONG)
id=38
config.get(CONFIG_KEY_LOCK_READ_TIMEOUT)
target.setField(1,val2)
res.sendError(501,"Websocket protocol not supported")
checkForMisplacedBindingAnnotations(method,errors) || !isValidMethod(injectableMethod,errors)
body.endsWith("6") || body.endsWith("10")
entries.remove(timeKey)
exchange.setRequestHeader(HttpHeaders.AUTHORIZATION,"OAuth " + accessToken)
@UriPath
new DirectDruidClient(warehouse,smileMapper,httpClient,server.getHost())
JSError.make("my/js.js",-1,-1,ModuleLoader.MODULE_CONFLICT,"my/js.js")
new FeaturesConfig().setExperimentalSyntaxEnabled(true).setDistributedIndexJoinsEnabled(true).setDistributedJoinsEnabled(false).setRedistributeWrites(false).setOptimizeMetadataQueries(true).setOptimizeHashGeneration(false).setOptimizeSingleDistinct(false).setPushTableWriteThroughUnion(false)
preMap.size()
results.expectedMessageCount(3)
resultEndpoint.expectedBodiesReceivedInAnyOrder("one","two","three")
julianDateFloor(range,(int)date + EPOCH_JULIAN,false)
pixmap.fillCircle(x,y,radius,color)
buffer.getUint8()
outputBatchSize=25
bigEndian.order()
Preconditions.checkNotNull(location,"location")
new GeoLocation(array.getDouble(1),array.getDouble(0))
ClosedChannelException e
Integer.toString(types.size())
id=16509
Files.deleteIfExists(file.toPath())
id=20
in.readUShortx()
when(rs.wasNull()).thenReturn(true)
serviceName == null || seenServiceNames.contains(serviceName)
next.getField(1)
!(topicParts.length > 2) || !topicParts[0].equals(TOPIC_PREFIX)
createNextExchange(processor,nextExchange)
logger.error("{} is already cancelled",impl.uuid())
hz.getCluster().getLocalMember().isLiteMember()
-0.5f
id=19904
pId + BASE_FILE_NUMBER
GenericUDFEnforceConstraint.class
Services.deploymentUnitName(deploymentUnit.getParent().getName(),nextPhase)
@Override public ExtendedCell deepClone(){   byte[] copy=new byte[this.length];   ByteBufferUtils.copyFromBufferToArray(copy,this.buf,this.offset,0,this.length);   KeyValue kv=new NoTagsKeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } 
new ClosureCodeRemoval(compiler)
id=10801
new ReadOnlyMapELResolver(beans)
!this.instanceName.equals(singleInstanceProfilingEvent.getInstanceName())
addOrGetIndex(definition.getKey(),definition.getValue(),partitionStoreAdapter)
time.put(current)
List<TaggedWord>
logger.trace("NODE {}: App version requested but Version class not supported",this.getNodeId())
new Argument().setIndex(1)
!serialNumber.equals(null)
new PercentType(percent)
private T actor; 
JSError.make(ref.source.getName(),ref.node,NAME_DEFINED_LATE_WARNING,name.fullName(),parent.fullName(),parent.declaration.source.getName(),String.valueOf(parent.declaration.node.getLineno()))
config.getClass().getName()
case REPLACE_IF_SAME: 
checkNotNull(getPropDefFromClass(superType,pname),"getPropDefFromClass(%s, %s) returned null",superType,pname)
new Packet()
ChannelBuffers.buffer(2)
Engineer manager=new GnomeEngineeringManager(); 
synchronized (mBlocks) {   return ImmutableSet.copyOf(mLostBlocks); } 
new FunctionCall("substring",new PathExpression(new ObjectAccess("addresses"),new ArrayAccess(0),new ObjectAccess("zipCode")),new ConstantExpression(0),new ConstantExpression(2))
node.executorManager.executeLocally(new Runnable(){   public void run(){     MembershipEvent membershipEvent=new MembershipEvent(ClusterImpl.this,dummy,MembershipEvent.MEMBER_ADDED);     for (    MembershipListener listener : listenerSet) {       listener.memberAdded(membershipEvent);     }   } } )
synchronized (CONFIG) {   ++threadCount;   if (session == null) {     try {       options=BigtableOptionsFactory.fromConfiguration(CONFIG);       session=new BigtableSession(options);       client=session.getDataClient();     }  catch (    IOException e) {       throw new DBException("Error loading options from config: ",e);     }   }  else {     client=session.getDataClient();   }   if (clientSideBuffering) {     heapSizeManager=new HeapSizeManager(Long.parseLong(getProperties().getProperty(ASYNC_MUTATOR_MAX_MEMORY,Long.toString(AsyncExecutor.ASYNC_MUTATOR_MAX_MEMORY_DEFAULT))),Integer.parseInt(getProperties().getProperty(ASYNC_MAX_INFLIGHT_RPCS,Integer.toString(AsyncExecutor.MAX_INFLIGHT_RPCS_DEFAULT))));     asyncExecutor=new AsyncExecutor(client,heapSizeManager);   } } 
promise.trySuccess(null)
(BlockParentHandler)getParent()
ShortBuffer target
public Builder setRealmPassword(String password){   realm().setPassword(password);   return this; } 
destination.getValue()
assertThat(request.getBody().readUtf8()).isIn("<my-object><message>hello world</message><count>10</count></my-object>","<my-object><count>10</count><message>hello world</message></my-object>")
!method.getName().equals(methodToSearch) || !method.getReturnType().isAssignableFrom(methodToFind.getReturnType()) || method.getParameterTypes().length != pTypes.length
KafkaEightFirehoseFactory.class
Assert.assertEquals(1456,details.get(6).getAbsolutePosition())
new VersionMismatchLogRequest()
new IOException(e)
compressedProto.length < 340000
return 16; 
CloudScanConfiguration.class
DEFAULT_MAX_QUERIES=4
assertThat(this.context.getBean(FilterChainProxy.class).getFilterChains()).hasSize(6)
Void ignored
calendar.set(Calendar.YEAR,2030)
Preconditions.checkNotNull(uri,"uri")
new StringBuilder(259)
new BasicSessionCredentials(accessKey,secretKey,sessionToken)
factory.terminateAll()
Status.createStatuseList(get(getBaseURL() + "statuses/home_timeline.json",true))
id=53
20000 * 4 * 4
Thread.sleep(2500)
targetDescription.getDeclaredValueClassName()
!(o instanceof Record)
partitionContainer.getExistingRecordStore(name)
FILES_BYTES * 1000.0
request.getRelaxLocality() == true
new BuildSecondHashMatchIterator(this.inputs[0],this.inputs[1],keyPositions2,keyPositions1,keyClasses,memoryManager,ioManager,this,availableMemory)
Generics.newTreeMap()
assertOpenEventually(countDownLatch)
public Builder setSSLEngineFactory(SSLEngineFactory sslEngineFactory){   configBuilder.setSSLEngineFactory(sslEngineFactory);   return this; } 
log.debug("Worker nodes %s do not have capacity to run any more tasks!",zkWorkers.values())
TypeScriptJqueryClientCodegen.class
connection.psubscribe(jedisPubSub,patterns)
Preconditions.checkState(hasInstanceType(),"Expected a constructor; got %s",this)
public Builder setProxyPort(int port){   this.proxyPort=port;   return this; } 
Mockito.doThrow(EXCEPTION).when(mFileSystemMasterClient).mount(alluxioPath,ufsPath,mountOptions)
id=15
logger.fine(name)
new DynamicAwareEntry("http://localhost:8080/test",null,null,null)
new StringBuilder(638)
response == null || response.value == null
String requestRequiredAcks
LinkedHashSet<String>
new byte[11]
Context.getEncounterService().saveEncounter(encounter)
configMonitor.init(this,envProperties)
assertEquals(3,historyService.createHistoricActivityInstanceQuery().executionId(processInstance.getId()).list().size())
K
new RuntimeException("Could not create TypeInformation for type " + type.getName() + "; please specify the TypeInformation manually via "+ "StreamExecutionEnvironment#fromElements(Collection, TypeInformation)",e)
cam.near=1f
cache.putRecord(key,record)
new AuthenticationException("Error validating LDAP user",e)
mock.expectedMinimumMessageCount(3)
from("seda:foo").startupOrder(1).delay(500)
DiagnosticType.error("AMBIGUOUS_FUNCTION_DECL","Ambiguous use of a named function: {0}.")
factory.getOrCreateProxyByName(packet.name)
EnterpriseMapPublisherCreateCodec.decodeResponse(response).response
javaWriter.emitSingleLineComment("foo")
sizeNeeded > items.length
this.nameDefinitionMultimap.remove(name,def)
private final ReplayingDecoderByteBuf replayable=new ReplayingDecoderByteBuf(); 
new HazelcastInstance[nodeCount]
new DefaultAgentOption(agentArgs,instrumentation,profilerConfig,pluginJars,bootStrapJarCorePath,serviceTypeRegistryService,annotationKeyRegistryService)
LOG.warn("Unable to close socket selector")
(color & 0x00FFFFFF) | (alpha << 24)
assertClusterSizeEventually(2,nodes[0])
assertEquals(id1,new Twitter(id3,pass3).verifyCredentials().getName())
group.id()
IllegalStateException.class
incomingMessage.setTransactionCanceled(true)
amq.getConfiguration().getOrCreateConnectionFactory()
julLogger.severe("Hello world")
logger.error(message,ex)
Map<String,Object>
Integer.MIN_VALUE + 9
0.0 == CheckUtils.parseFloat(text,type)
Status.createStatuseList(get(getBaseURL() + "statuses/home_timeline.json",null,paging.asPostParameterList(),true))
connection.zrevrangeByLex(key,max,min)
"Refreshing storefiles of region " + bestRegionReplica + " due to global heap pressure. memstore size="+ StringUtils.humanReadableInt(server.getRegionServerAccounting().getGlobalMemstoreSize())
assertThat(connector.getSoLingerTime()).isEqualTo(30000)
new TezTaskRunner2(conf,taskUgi,fragmentInfo.getLocalDirs(),taskSpec,request.getAppAttemptNumber(),serviceConsumerMetadata,envMap,startedInputsMap,taskReporter,executor,objectRegistry,pid,executionContext,memoryAvailable,false)
doAnswer(new Answer<Object>(){   @Override public Object answer(  InvocationOnMock invocation) throws Throwable {     sem.release();     return null;   } } ).when(loggerMock).warn(anyString())
incomingMessage.getMessagePayloadByte(1)
mBlockRemovalService.shutdown()
T1
!"true".equalsIgnoreCase(value)
testTLS(Cert.CLIENT_PEM_ROOT_CA,Trust.SERVER_JKS,Cert.SERVER_JKS,Trust.CLIENT_PEM_ROOT_CA).requiresClientAuth().serverUsesCrl()
classResolver.resolveMandatoryClass(type)
attribute.startsWith(keyPrefix) && attribute.length() > keyPrefix.length()
json.length() - 1
public class XpathRegressionMultipleVariableDeclarationsTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=MultipleVariableDeclarationsCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionMultipleVariableDeclarationOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(MultipleVariableDeclarationsCheck.class);     final String[] expectedViolation={"4:5: " + getCheckMessage(MultipleVariableDeclarationsCheck.class,MultipleVariableDeclarationsCheck.MSG_MULTIPLE_COMMA)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='i']","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='i']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='i']/TYPE","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='i']/TYPE/LITERAL_INT","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='j']","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='j']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='j']/TYPE","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='j']/TYPE/LITERAL_INT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=MultipleVariableDeclarationsCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionMultipleVariableDeclarationTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(MultipleVariableDeclarationsCheck.class);     final String[] expectedViolation={"4:5: " + getCheckMessage(MultipleVariableDeclarationsCheck.class,MultipleVariableDeclarationsCheck.MSG_MULTIPLE)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='i1']","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='i1']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='i1']/TYPE","/CLASS_DEF[@text='SuppressionXpathRegressionMultipleVariableDeclarationTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='i1']/TYPE/LITERAL_INT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
"access-control/default is missing operations: " + defaults
setColors(color)
type == TokenTypes.CLASS_DEF || type == TokenTypes.ENUM_DEF || type == TokenTypes.ANNOTATION_DEF
declaredIntentionToWrite.getMode() == DIRECT_TO_TARGET_NEW_DIRECTORY
this.loggerContext
id=10839
mTfs.mkdirs(new TachyonURI(dirPath),true)
new Version(0,1,0)
lines("Function.prototype.inherits = function(parentCtor) {","  function tempCtor() {};","  tempCtor.prototype = parentCtor.prototype;","  this.superClass_ = parentCtor.prototype;","  this.prototype = new tempCtor();","  this.prototype.constructor = this;","};","/** @constructor */ function A() {}","/** @constructor */ function B() {}","B.inherits(A);","use(B.superClass_);")
applicationStatistics.incrListUserTimes()
Cache.getTableName(type)
logger.debug("{} {}",errorCode,message)
tJvmGcDetailed.getJvmGcNewTime()
new NagiosNscaStub(25668,"secret")
registered.remove(objectName)
Object[]
result != null && endpointId <= result.getInstances()
LOG.error(exception,"Unexpected failure when handling parsing error. This is likely a bug in the implementation")
plugin.isEnabled()
type=100
id=19908
assertEquals(4,possibleOutcomes.size())
sendTo("bar")
this.getDefaultReadOnly()
new FileInputStream(aProps)
/**   * Exception thrown if the session-type of a session bean is not specified  */ @Message(id=14551,value="<session-type> not specified for ejb %s. This must be present in ejb-jar.xml") DeploymentUnitProcessingException sessionTypeNotSpecified(String bean); 
LOGGER.error("{} - Failed to execute isValid() for connection, configure connection test query. ({})",poolName,e.getMessage())
dis.readFully(serializedData,0,length)
new IOException(msg,e)
LOG.trace("No binding to service interface as @Body,@Header,@ExchangeProperty not detected. Using BeanInvocation as message body when calling proxy method: {}",method)
zk.exists(znode,false) == null
id=2
GL.glCopyTexSubImage2D(target,level,xoffset,yoffset,x,y,width,height)
public Builder setProxyPrincipal(String principal){   this.proxyPrincipal=principal;   return this; } 
level < RF_STATUS_HIGH_SIGNAL
public Builder setMaximumNumberOfRedirects(int maxDefaultRedirects){   configBuilder.setMaximumNumberOfRedirects(maxDefaultRedirects);   return this; } 
wizardModel.databaseConnection.contains("localhost") || wizardModel.databaseConnection.contains("127.0.0.1")
MD5Loader.loadModel(Gdx.files.internal("data/zfat.md5mesh").read(),true)
new RuntimeException("error initializing deserializer: " + deserializer.getClass().getName(),e)
new InputStreamReader(fileObject.getInputStream(),"UTF-8")
id=31
mStack.size() > 1
REPLACE_IF_SAME(7)
StringBuilder result
Function.class
new Tag(line,column,text,on,this)
channelIdle(ctx,IdleState.ALL_IDLE,lastIoTime)
clockSource.elapsedMillis(startTime)
prev.getNextProp()
closedChannelException == null
field.set(instance,value)
worldVertices.length != localVertices.length
id=49
!compactionStarted.getAndSet(true)
Integer.parseInt(options.getMaxKeys())
Assert.assertEquals(0,stringNumber)
row("p_comment",null,5.0,0.0,null,null,null)
util.getDataTestDirOnTestFS(table)
clientConfig.property(ClientProperties.READ_TIMEOUT,2000)
processInstance.getProcessDefinitionId()
logger.debug("NODE {}: Retry timout: Can't advance",node.getNodeId())
assertThat(page1.pagination().getGlobalTotal()).isEqualTo(5)
return 405; 
TABLE_FINISH
route.setDelay(5000)
/**   * Make sure we don't attempt to recover inline; if the parser successfully recovers, it won't throw an exception.  */ @Override public Token recoverInline(BaseRecognizer recognizer) throws RecognitionException {   throw new RuntimeException(new InputMismatchException(recognizer)); } 
Gauge<Integer>
headRef()
sourceNodeTextData != null
new SensitivityClassification(SUBSYSTEM_NAME,"web-connector",false,false,false)
AtmosphereResponse.newInstance()
maxSize < (used / total)
id=20
region.checkAndMutate(row1,fam1,qf1,CompareOp.EQUAL,new BinaryComparator(val1),delete,true)
/**   * Returns messages newer than the message ID specified as a numeric string. This should be used when polling for new messages. If you're looking at messages, and the most recent message returned is 3516, you can make a request with the parameter "?newerThan=3516 to ensure that you do not get duplicate copies of messages already on your page.  */ private Long newerThan=-1L; 
saveTaskDefinition(taskDefinition)
new BulletTestCollection()
invocation.logger.finest("Asking if operation execution has been started: " + invocation)
sshd.stop(true)
lock.lock(10000,TimeUnit.MILLISECONDS)
inputProcessor.touchDragged(event.x,event.y,event.pointer)
createService(apiKey,apiSecret,callback,defaultScope,responseType,null,userAgent,httpClientConfig,httpClient)
logger.fine("Aliasing common strings")
i < nodeCount
index > maxHeadersLength - headersLength
SpringBootVersion.class
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class QueueBasicDistributedTest extends QueueAbstractTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(2).newInstances(config);   } } 
msgType < values.length
LOG.warn("Ignoring duplicate class " + className)
statistics.addRemoveTimeNanos(System.nanoTime() - start)
mBuffer.remaining() >= toRead
GatherGetterAndSetterProperties.gather(compiler,mainRoot)
handler.isDifferent(existing)
new HttpDigestAuthFilter(DIGEST_TEST_LOGIN,DIGEST_TEST_INVALIDPASS)
privObj.getObjectName().equals("masking_acid_no_masking") || privObj.getObjectName().startsWith("masking_acid_no_masking_n")
items[28]
setNetworkTimeout(connection,originalTimeout)
new ModelNode().set(10L)
Map<String,Long>
new ModelNode(40)
public static XQueryBuilder xquery(File file) throws IOException {   return xquery(IOConverter.toInputStream(file),ObjectHelper.getDefaultCharacterSet()); } 
!mapServiceContext.hasRegisteredListener(mapName)
string.length() > 0
ConcurrentHashMap<Object,AggregationStrategy>
ti >= 0
new IllegalStateException(String.format("File \"%1$s\" has no indentation comment or its format " + "malformed. Error on line: %2$d(%3$s)",aFileName,lineNumber,line))
UnderFileSystemUtils.deleteFileIfExists(mCheckpointPath)
id=10867
new IllegalStateException(msg.getMessage())
mTfs.delete(mTfs.open(new TachyonURI(filePath)),true)
/**   * Loads the import control file from a  {@link InputSource}.  * @param source the source to load from.  * @param uri uri of the source being loaded.  * @return the root {@link PkgControl} object.  * @throws CheckstyleException if an error occurs.  */ private static ImportControl load(final InputSource source,final URI uri) throws CheckstyleException {   try {     final ImportControlLoader loader=new ImportControlLoader();     loader.parseInputSource(source);     return loader.getRoot();   }  catch (  final ParserConfigurationException|SAXException ex) {     throw new CheckstyleException("unable to parse " + uri + " - "+ ex.getMessage(),ex);   } catch (  final IOException ex) {     throw new CheckstyleException("unable to read " + uri,ex);   } } 
factory.get(mResultWildcard,NO_ANNOTATIONS,retrofit)
this.logger.isDebugEnabled()
period >= MINIMAL_POLL_PERIOD
id=10849
getRegistry().bind("hb",hb)
new RunnableAdapter<T>(task)
input.getDouble(0) < 0.05
doInvoke(args)
16 * 60000
String.format("<?xml version=\"1.0\" encoding=\"UTF-8\"?>%n" + "<checkstyle version=\"" + version + "\">%n"+ "<file name=\""+ expectedPath+ "\">%n"+ "</file>%n"+ "</checkstyle>%n",version,expectedPath)
propMember.getType()
i == -1 || nsname.equals("/")
SSL.getErrorString(stackError)
User.createUsersList(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/statuses/followers/T4J_hudson.json"))
testWarning(LINE_JOINER.join("goog.require('a.c');","/** @suppress {extraRequire} */","goog.require('a.b')"),REQUIRES_NOT_SORTED)
oldestNode == null || oldestNode.getLastSent() == null
names[0]
DSVHTTPDataAdapter.Config.builder().type(NAME).url("https://example.org/table.csv").separator(",").lineSeparator("\n").quotechar("\"").ignorechar("#").keyColumn(0)
ar2.cause()
objectMapper.reader(DataSegment.class)
timeout=150000
maxInvocationCountObservedDuringWarmup * 2
runningTasks.remove(assignedTask)
expirationTime == Long.MAX_VALUE || expirationTime < 0
req.getServletPath()
r.destination != null && !r.destination.isEmpty()
/**   * Represents black  */ BLACK('0',0x00)
val.get(k)
setDiskPersistent(Boolean.valueOf((String)cacheSettings.get("diskPersistent")))
loadResourceAsURL(name,loader)
context.setDelayer(2000L)
LOG.warn("delete failed: {}",e.getMessage())
CommonUtils.randomAlphaNumString(random.nextInt(10))
logger.trace("NODE {}: App version requested but version is unknown",this.getNodeId())
getSsl(ClientAuth.NEED,"password","src/test/resources/test.jks","src/test/resources/test.jks")
Arrays.asList(RFXComValueSelector.RAW_DATA,RFXComValueSelector.SIGNAL_LEVEL,RFXComValueSelector.COMMAND,RFXComValueSelector.MOOD,RFXComValueSelector.DIMMING_LEVEL,RFXComValueSelector.CONTACT)
assertFalse(isBufferCopyNeededForWrite(byteBuf.asReadOnly()))
ConnectionFactory connectionFactory
this.context.getLogAggregationStatusForApps().add(finalReport)
handler instanceof ChannelOutboundHandler
Configuration.getMs(PropertyKey.USER_NETWORK_NETTY_TIMEOUT_MS)
public class XpathRegressionRequireThisTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=RequireThisCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRequireThisOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RequireThisCheck.class);     moduleConfig.addAttribute("validateOnlyOverlapping","false");     final String[] expectedViolation={"7:9: " + getCheckMessage(RequireThisCheck.class,RequireThisCheck.MSG_VARIABLE,"age","")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRequireThisOne']/OBJBLOCK" + "/METHOD_DEF[@text='changeAge']/SLIST/EXPR/ASSIGN[@text='age']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=RequireThisCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRequireThisTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RequireThisCheck.class);     moduleConfig.addAttribute("validateOnlyOverlapping","false");     final String[] expectedViolation={"9:9: " + getCheckMessage(RequireThisCheck.class,RequireThisCheck.MSG_METHOD,"method1","")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRequireThisTwo']/OBJBLOCK" + "/METHOD_DEF[@text='method2']/SLIST/EXPR/METHOD_CALL[@text='method1']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
INVISIBILITY(14,PotionEffectType.INVISIBILITY,1)
uri.getRawPath()
sanitizeName(name)
javaChannel().isOpen() && config().getSoLinger() > 0
this.connectTo(vertex,channelType,compressionLevel,-1,-1,distributionPattern,true)
ImmutableSet<Key<?>>
getNonCompilablePath("InputPackageDeclarationDiffDirectory.java")
fileInfo.getUfsPath()
CONFIG_GRANULARITY.equals(configKey) || CONFIG_REFRESH.equals(configKey) || "service.pid".equals(configKey)
userGroupMember.getUserGroupId()
!consumer.endpoint.isAutoAck()
Status.createStatuseList(get(getApiBaseURL() + V1 + user+ "/lists/"+ id+ "/statuses.json",new PostParameter[0],paging.asPostParameterList(Paging.SMCP,Paging.PER_PAGE),true))
(Double)y
assertEquals(2,scheduler.getQueueManager().getQueues().size())
isClosed.get()
E
offset > 0
SimpleAttributeDefinitionBuilder.create("file",ModelType.OBJECT,false)
invoke(agentInfo,payload,DEFAULT_FUTURE_TIMEOUT)
memoryMap.getInt("mappedWithJournal",-1)
partition.getParameters()
JavaConversions.mapAsJavaMap(logManager.logsByTopicPartition())
Thread.sleep(50)
getUrl().getMethodPositiveParameter(methodName,TIMEOUT_KEY,DEFAULT_TIMEOUT)
getData() ^ 0x7
sliceInput.getRetainedSize()
HttpRequest.post("http://localhost:8080/ejbws-example/SingletonEndpoint",message,10,SECONDS)
6 * (float)Math.cbrt(radius)
(new Path(testBucket.getParent(),".test.inprogress")).getPath()
timeLeft <= 0
@DELETE
REMOVE_TIME_TAKEN_NANOS_UPDATER.compareAndSet(this,nanos,nanos + duration)
SingleMapBlock.class
logger.trace("Requsting URL {}",url)
assertEquals(2,map2.keySet().size())
QuotaCache.this.tableQuotaCache.containsKey(table)
stop <= start
Status.createStatuseList(get(getBaseURL() + "statuses/retweets/" + statusId+ ".json",true))
10 * 1000
bulkInsertableMap.containsKey(persistentObjectClass)
64 * 1024
id=16510
FileInStream.create(status,options.toInStreamOptions(),mFileSystemContext)
other.getLimit()
assertThat(page3.pagination().getGlobalTotal()).isEqualTo(5)
eq(false)
VertexAttribute.ColorPacked()
mLineageStore.reportLostFile(fileId)
Mono.just(entry.getKey()).zipWith(entry.getValue().health().compose(this.timeoutCompose))
emptyCheck.log(0,"msgKey")
id=10851
public ByteBuf getBufferFor(int index) throws IndexOutOfBoundsException {   if (index < 0 || index > capacity()) {     throw new IndexOutOfBoundsException("Invalid index: " + index + " - Bytes needed: "+ (index)+ ", maximum is "+ capacity());   }   int componentId=componentId(index);   return components[componentId].duplicate(); } 
registry.bind("firehoseClient",amazonKinesisFirehoseClient)
repo.setRecoveryInterval(1000,TimeUnit.MILLISECONDS)
scanFeatures(getKarafFeatureUrl(),"jetty")
doTestPositive(301)
Thread.sleep(51)
deserialze(parser,type,fieldName,0)
c * c
@Override public Long call() throws Exception {   MessageCountResponse response=api.get(MessageCountResponse.class).path("/count/total").execute();   return response.events; } 
logger.error("Error getting value for expression " + expressionField.getExpression() + " "+ e.getMessage(),e)
resultEndpoint.assertIsSatisfied(10000)
getTablename().getName()
this.setRemoveOperationIdPrefix(Boolean.valueOf(additionalProperties.get(CodegenConstants.REMOVE_OPERATION_ID_PREFIX).toString()))
id=23
c.getName()
ImmutableList<SourceFile>
waitLatch.await(1000,TimeUnit.MILLISECONDS)
Arrays.asList("cmd","ls","pwd")
val=2
n.getNodeData().y()
@InputMagicNumberIntMethodAnnotation(-44)
items[30]
DirectMessage.createDirectMessageList(get(getBaseURL() + "direct_messages.json",true))
ChannelHandler handler=new ChannelHandler(){   @Override public void channelActive(  ChannelHandlerContext ctx) throws Exception {     ctx.fireChannelActive();     peerRef.exchange(ctx.channel(),1L,SECONDS);   }   @Override public void channelRead(  ChannelHandlerContext ctx,  Object msg){     latch.countDown();     ctx.read();   }   @Override public void exceptionCaught(  ChannelHandlerContext ctx,  Throwable cause){     causeRef.set(cause);   } } ; 
(strLine=br.readLine()) != null && !strLine.isEmpty()
excludesPattern == null || requestURI == null
id=16
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
clazz.getConstructor(ConstantsAndVariables.class,PatternScoring.class,String.class,TwoDimensionalCounter.class,TwoDimensionalCounter.class,TwoDimensionalCounter.class,TwoDimensionalCounter.class,TwoDimensionalCounter.class,String.class)
DEFAULT_ROW_FLUSH_BOUNDARY=75000
LOG.warn("Async Kafka commit failed.",cause)
log.error("PID contains identifier with no assigning authority")
rs.getNString(columnIndex)
FileAlreadyExistException.class
getJSDocType(operation)
mock.expectedBodiesReceivedInAnyOrder("Hello World 2")
mFileLength <= mBlockSize
target.directory("zk" + id + "data",true)
twitter4j.List.createListList(get(getApiBaseURL() + V1 + user+ "/lists/memberships.json?cursor="+ cursor,true))
pti.getArity()
sendCommand(CLIENT,Keyword.GETNAME.raw)
!success
connector.getFilterChain()
!StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"flush") && !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"grant") && !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"create user")&& !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"drop user")&& !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"create database")&& !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"drop database")
id=10868
nodeEngine.getClusterService()
otherWriter.write(line)
new MethodInjectionTarget(methodInfo.declaringClass().name().toString(),methodName,methodInfo.returnType().name().toString())
suiteMethod.invoke(null)
edge.setDirection(EdgeDirection.DIRECTED)
flags.length == 1
new HashSet<RecordReplicationInfo>()
app.getAudio().newAudioRecoder(44100,true)
RetryHandlingBlockMasterClient.class
builder.addDependency(DependencyType.OPTIONAL,RegistryInstallerService.SERVICE_NAME)
IOConverter.toString(out,null)
views.html.search.noresults.render(currentUser(),q,searchResult,null)
clients.inMemory().withClient("my-trusted-client").authorizedGrantTypes("password","authorization_code","refresh_token","implicit").authorities("ROLE_CLIENT","ROLE_TRUSTED_CLIENT").scopes("read","write","trust").accessTokenValiditySeconds(60).additionalInformation("foo:bar","spam:bucket","crap")
this(true,false); 
id=14
new KafkaComponent(context)
getBoolean(ASYNC_CLIENT + "acceptAnyCertificate",false)
jmsManager.removeQueueFromJNDI(queueName)
Size.kilobytes(6)
JSError.make(SourceMapInput.SOURCEMAP_PARSE_FAILED,sourceMapPath,e.getMessage())
jedis.sadd(getSetKey(task),request.getUrl()) == 0
Class.forName(className.replace('/','.'),true,Thread.currentThread().getContextClassLoader())
cursor.getCurrentValueEndPosition()
execution.getJobs().remove(jobEntity)
var.setValueType(guessType(value))
/**   * Executes the given task in a new thread that is authenticated as the daemon user. <br/> <br/> This can only be called from  {@link TimerSchedulerTask} during actual task execution  * @param task the task to run  * @should not be called from other methods other than TimerSchedulerTask  * @should not throw error if called from a TimerSchedulerTask class  */ public static void executeScheduledTask(final Task task) throws Exception {   Class<?> callerClass=new OpenmrsSecurityManager().getCallerClass(0);   if (!TimerSchedulerTask.class.isAssignableFrom(callerClass)) {     throw new APIException("This method can only be called from the TimerSchedulerTask class, not " + callerClass.getName());   }   DaemonThread executeTaskThread=new DaemonThread(){     @Override public void run(){       isDaemonThread.set(true);       try {         Context.openSession();         TimerSchedulerTask.execute(task);       }  catch (      Exception e) {         exceptionThrown=e;       }  finally {         Context.closeSession();       }     }   } ;   executeTaskThread.start();   try {     executeTaskThread.join();   }  catch (  InterruptedException e) {   }   if (executeTaskThread.exceptionThrown != null) {     throw executeTaskThread.exceptionThrown;   } } 
Column::getName
public Builder setAllowPoolingConnection(boolean allowPoolingConnection){   configBuilder.setAllowPoolingConnection(allowPoolingConnection);   return this; } 
assertEquals(70008,exchange.getIn().getBody().toString().length())
new DynamicAwareEntry("https://localhost/test",null,null,null)
uncompressedProto.length < 2560000
new RuntimeException("to length:" + to.length + " from length:"+ from.length)
getRegistry().bind("myTable",ht)
Tuple2.of(timeoutPattern2,12L)
logger.fine("Moving functions + variable into deeper modules")
Assert.assertEquals("Invalid selection end",279,selector.getSelectionEnd())
ImmutableSortedMap<Integer,Integer>
binder.bindConstant().annotatedWith(Names.named("servicePort")).to(8089)
replicatedMapService.getReplicatedRecordStore(mapName,true)
tokens.getText()
new JSONParseSpec(new TimestampSpec("timestamp","auto"),new DimensionsSpec(Arrays.asList("dim1","dim2"),null,null))
mesh.getNumVertices() / 4
log.error("Multiple nodes are set, but execute() was called. This is most likely a bug and you meant to call executeOnAll()!",new Throwable())
currentPath == null || currentPath.isEmpty()
current.getLabel().startsWith("nt") && !pre.getLabel().startsWith("nt") && !pre.getValue().equals(Predefine.TAG_BIGIN)
_maxTransactionActive=1
parameter.name()
uri.getPort() == -1 && request.getVirtualHost() != null
findState > 0
Color.rgba8888ToColor(color,colorInt)
mapEntry.getValue().equals(source)
entry.getValue().getManagementInterfaceMicroVersion()
-121
scheduler.scheduleRecurring(indexPopulation,countInvocationsJob,2,MILLISECONDS)
handshakeFuture == null
c <= values.length()
CharSequence text
assertMockEndpointsSatisfied()
id=10858
program.getUuid()
Context.getProviderService().getAllProviderAttributeTypes(true)
numKeys > 0
createPermissionsXmlAsset(new SocketPermission("*:10389","connect,resolve"),new RuntimePermission("accessClassInPackage.com.sun.jndi.ldap"),new RuntimePermission("accessClassInPackage.com.sun.jndi.url.ldap"))
twitter.getDailyTrends()
i >= 0
pixmap.getHeight() - yHotspot - 1
GL20.glUniformMatrix2fv(location,transpose,toFloatBuffer(value,offset,count << 2))
StringBuffer pattern=new StringBuffer(this.prefix); 
zoneId.equals("+00:00") || zoneId.equals("-00:00")
new LinkedHashMap<String,Object>(whileListMaxSize,0.75f,false)
connectionTimeout / 4
showTooltip == null || showTooltip.targetActor == null
closeCode <= 1001
objectColumnCache.values()
Integer.parseInt(tokens[3])
TEST_UTIL.getAdmin()
UrlUtils.getHeartbeat(getUrl())
new DefaultAsyncHttpClient(config)
-1
obj.getRequiredTokens()
new JGroupsFilter(bc)
!super.equals(obj)
state.isTerminalState()
FISHING_ROD(346,1,32)
idx[j] > 0
from("direct:start").recipientList(header("slip")).aggregationStrategy(new AggregationStrategy(){   public Exchange aggregate(  Exchange oldExchange,  Exchange newExchange){     if (oldExchange == null) {       return newExchange;     }     String body=oldExchange.getIn().getBody(String.class);     oldExchange.getIn().setBody(body + newExchange.getIn().getBody(String.class));     return oldExchange;   } } ).parallelProcessing().timeout(1000)
footerRow != null
JournalStateMachine.class
registration.registerOperationHandler(CommonAttributes.ENABLE_CONTEXT,ModClusterEnableContext.INSTANCE,enableContext,false,runtimeOnlyFlags)
result.expectedMessageCount(1)
mFs.mkdirs(new Path(path))
size=10
/**   * t1.g4 -> t2.g4 -> t3.g4 ->t1.g4   */ CIRCULAR_DEPENDENCY(200,"your grammars contain a circular dependency and cannot be sorted into a valid build order",ErrorSeverity.ERROR)
error.expectedMinimumMessageCount(2)
logger.debug("Calimero library version {}",Settings.getLibraryVersion())
id=10850
latch.await(600,TimeUnit.SECONDS)
GL20.glUniform1iv(location,v)
DefaultBroadcaster.class.cast(resource.getBroadcaster()).broadcasterCache.retrieveFromCache(resource.getBroadcaster().getID(),resource)
getRequestParameters()
public class XpathRegressionFallThroughTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=FallThroughCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(FallThroughCheck.class);     final String[] expectedViolation={"11:13: " + getCheckMessage(FallThroughCheck.class,FallThroughCheck.MSG_FALL_THROUGH)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP","/CLASS_DEF[@text='SuppressionXpathRegressionExplicitOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP/LITERAL_CASE");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=FallThroughCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(FallThroughCheck.class);     moduleConfig.addAttribute("checkLastCaseGroup","true");     final String[] expectedViolation={"10:17: " + getCheckMessage(FallThroughCheck.class,FallThroughCheck.MSG_FALL_THROUGH_LAST)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitTwo']/OBJBLOCK" + "/METHOD_DEF[@text='methodFallThruCustomWords']/SLIST/LITERAL_WHILE/SLIST" + "/LITERAL_SWITCH/CASE_GROUP","/CLASS_DEF[@text='SuppressionXpathRegressionExplicitTwo']/OBJBLOCK" + "/METHOD_DEF[@text='methodFallThruCustomWords']/SLIST/LITERAL_WHILE/SLIST" + "/LITERAL_SWITCH/CASE_GROUP/LITERAL_DEFAULT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
meta.setContentType(Mimetypes.MIMETYPE_OCTET_STREAM)
getClusterMap().set(buildAttributeName(name),value)
setop.getIDLName()
nextRequest(newRequest,future)
this(true,16,arrayType); 
status == 404
batteryVp > low
assertEquals(1,failures.size())
op.getResultAsObject(false)
request.getDueAfter()
assertEquals(1,counter)
req.getSession().getMaxInactiveInterval() * 1000L
ImmutableList<Number>
new IllegalArgumentException("the name is null")
assertPresent(GsonConverter.class)
processEngineConfiguration.getCommandExecutor()
app.configuration().getString("timezone","")
5 * 60 * 1000
principalCookieName != null && httpRequest.getCookies() != null
getTokenDisplayNames()
ConfigUtils.absoluteStormLocalDir(stormConf)
assertEquals(8,LambdaOperations.values().length)
new NetAddress(resolvedHost,-1,resolvedPort)
new IllegalStateException(String.format("File \"%1$s\" has no indentation comment or its format " + "malformed. Error on line: %2$d",aFileName,lineNumber))
fields.getOrDefault("last_seen",0)
AtmosphereResourceEventListenerAdapter.class
proxy.getHost()
items[15]
propertiesComponent == null || propertiesComponent.isDefaultCreated()
"Content-Type".equalsIgnoreCase(name)
DiagnosticType.warning("JSC_MISPLACED_TYPE_ANNOTATION","Type annotations are not allowed here. " + "Are you missing parentheses?")
maxRelError=1e-3
(ChronicleEngineEndpoint)getEndpoint()
ppiY / 2.54f
i % dictionarySize
"memberOf".equalsIgnoreCase(attribute.getId()) || "isMemberOf".equalsIgnoreCase(attribute.getId())
AttributeUtils.getDefault().getMax(column,valuesArray)
DEFAULT_CAPACITY=1000
compressedProto.length < 390200
log.warn("Unexpected exception on closing transaction.  Cause: " + e)
outputPath=args[1]
new PrestoException(INVALID_CAST_ARGUMENT,"Value cannot be cast to date: " + value.toStringUtf8(),e)
Exception iae
DiagnosticGroups.registerGroup("oldCheckTypes",TypeValidator.ALL_DIAGNOSTICS,TypeCheck.ALL_DIAGNOSTICS,DiagnosticGroups.GLOBAL_THIS)
cache.flushAndForce()
properties.length > 4
new DefaultRouteContext(first.getBuilder().getProcessBuilder().getContext(),route,null,list)
log.debug(throwable,"Query %s failed",queryId)
ServiceAnnouncingChatHandlerProvider.class
ImmutableList.of("es3.js","es5.js","w3c_event.js","w3c_event3.js","gecko_event.js","ie_event.js","webkit_event.js","w3c_dom1.js","w3c_dom2.js","w3c_dom3.js","gecko_dom.js","ie_dom.js","webkit_dom.js","w3c_css.js","gecko_css.js","ie_css.js","webkit_css.js","google.js","deprecated.js","fileapi.js","flash.js","gears_symbols.js","gears_types.js","gecko_xml.js","html5.js","ie_vml.js","iphone.js","webstorage.js","w3c_css3d.js","w3c_elementtraversal.js","w3c_geolocation.js","w3c_indexeddb.js","w3c_range.js","w3c_selectors.js","w3c_xml.js","window.js","webkit_notifications.js","webgl.js")
assertEquals(5,set.size())
USER_UFS_DELEGATION_ENABLED(Name.USER_UFS_DELEGATION_ENABLED,true)
this.posColumn=column
prePassivates != null
new ResultSetIterator(conn,rs,getEndpoint().isUseJDBC4ColumnNameAndLabelSemantics())
shouldBackup=true
new BinaryWebSocketFrame(finalFragment,rsv,payload)
(short)0600
ScanFilterAndProjectOperator.class
new GeneralDataCoding(false,true,MessageClass.CLASS1,Alphabet.ALPHA_DEFAULT)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class IdGeneratorBasicLocalTest extends IdGeneratorAbstractTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(1).newInstances();   } } 
TIMEOUT=40000L
ObjectStore.isCurrentStatsValidForTheQuery(conf,params,statsWriteId,writeIdString,false)
parameters.getPositions().get(1)
log.err("Could not annotate via server! Trying to annotate locally...",t)
saHooks != null && !saHooks.isEmpty()
id=21
routes.UsersController.editUserForm(username)
assertMockEndpointsSatisfied(30,TimeUnit.SECONDS)
partId == null
pool.drain()
id=45
from("timer://foo?fixedRate=true&delay=0&period=500").to("bean:myBean","mock:result")
id=36
GL11.glTexParameterfv(target,pname,params)
testModules("var foo = function () {var module = {};module.exports = {};};" + "module.exports = foo;","goog.provide('module$test');" + "var foo$$module$test=function(){var module={};module.exports={}};" + "var module$test=foo$$module$test")
assertEquals(counter.get(),0)
Arrays.asList(RFXComValueSelector.RAW_DATA,RFXComValueSelector.SIGNAL_LEVEL,RFXComValueSelector.COMMAND,RFXComValueSelector.CONTACT)
AuditEventFormatter messageFormatter
rSocketMessageHandler.responder()
/**   * Tests for  {@link ClosureSortedDependencies}  */ public class ClosureSortedDependenciesTest extends SortedDependenciesTestHelper {   @Override public SortedDependencies<SimpleDependencyInfo> createSortedDependencies(  List<SimpleDependencyInfo> shuffled) throws CircularDependencyException {     return new ClosureSortedDependencies<>(shuffled);   }   @Override public boolean handlesCycles(){     return false;   } } 
id=19907
expression.length() - 1
rs.getNString(columnName)
GL.glGenTextures(n,toBuffer(textures,offset),0)
super.hashCode()
allDefinitions != null && composed.getInterfaces() != null
t != null && t.st == ST.LABEL
ImmutableList.copyOf(modules)
ImmutableList.copyOf(listeners)
!this.fs.delete(filePath,false)
active=false
id=10841
cachedMemoryUsageBytes <= softMemoryLimitBytes
mock.expectedFileExists("target/failed/error/bye.txt")
lexer.token == Token.HINT && !lexer.isEnabled(SQLParserFeature.StrictForWall)
pushExecutor.execute(new NamedRunnable("OkHttp %s Push Reset[%s]",hostName,streamId){   @Override public void execute(){     pushObserver.onReset(streamId,errorCode); synchronized (SpdyConnection.this) {       currentPushRequests.remove(streamId);     }   } } )
TestMapUsingMapStoreBuilder.create().mapName(mapName).withMapStore(mapStore).withNodeCount(nodeCount).withBackupCount(1)
inner.innerSetException((Throwable)result,true)
locator.getRegionLocation(regionName,true)
aliases.size() > 1
context != null && redirectUri == null
new IllegalArgumentException("ClassInfo's name should be non-null")
0 - originX
mTfs.free(mTfs.open(path),true)
synchronized (this) {   this.conn=conn;   this.stream=stream;   stream.beginRequest(this);   if (pendingMaxSize != -1) {     this.stream.doSetWriteQueueMaxSize(pendingMaxSize);   }   if (pendingChunks != null) {     ByteBuf pending=pendingChunks;     pendingChunks=null;     if (completed) {       writeHeadWithContent(pending,true);       conn.reportBytesWritten(written);       if (respHandler != null) {         this.stream.endRequest();       }     }  else {       writeHeadWithContent(pending,false);       if (headersCompletionHandler != null) {         headersCompletionHandler.handle(stream.version());       }     }   }  else {     if (completed) {       writeHeadWithContent(Unpooled.EMPTY_BUFFER,true);       conn.reportBytesWritten(written);       if (respHandler != null) {         this.stream.endRequest();       }     }  else {       if (writeHead) {         writeHead();         if (headersCompletionHandler != null) {           headersCompletionHandler.handle(stream.version());         }       }     }   } } 
Thread.sleep(2500)
timeout=120000
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
REAL_DRIVER.quit()
QuotaCache.this.namespaceQuotaCache.containsKey(ns)
AstUtils.hasAtLeastOneAnnotation(classNode,"MessageEndpoint","EnableIntegrationPatterns")
new DatabaseFormatterDb2()
logger.warn("fail-mock: " + invocation.getMethodName() + " fail-mock enabled , url : "+ directory.getUrl(),e)
/**   * Represents the default formatter for log message. Default log message format is: [SEVERITY LEVEL] filePath:lineNo:columnNo: message. [CheckName]  * @author Andrei Selkin  */ public class AuditEventDefaultFormatter implements AuditEventFormatter {   /**   * Length of all separators.   */   private static final int LENGTH_OF_ALL_SEPARATORS=10;   /**   * Suffix of module names like XXXXCheck.   */   private static final String SUFFIX="Check";   @Override public String format(  AuditEvent event){     final String fileName=event.getFileName();     final String message=event.getMessage();     final SeverityLevel severityLevel=event.getSeverityLevel();     final String severityLevelName;     if (severityLevel == SeverityLevel.WARNING) {       severityLevelName="WARN";     }  else {       severityLevelName=severityLevel.getName().toUpperCase(Locale.US);     }     final int bufLen=calculateBufferLength(event,severityLevelName.length());     final StringBuilder sb=new StringBuilder(bufLen);     sb.append('[').append(severityLevelName).append("] ").append(fileName).append(':').append(event.getLine());     if (event.getColumn() > 0) {       sb.append(':').append(event.getColumn());     }     sb.append(": ").append(message);     final String checkShortName=getCheckShortName(event);     sb.append(" [").append(checkShortName).append(']');     return sb.toString();   }   /**   * Returns the length of the buffer for StringBuilder. bufferLength = fileNameLength + messageLength + lengthOfAllSeparators + + severityNameLength + checkNameLength.  * @param event audit event.  * @param severityLevelNameLength length of severity level name.  * @return the length of the buffer for StringBuilder.  */   private static int calculateBufferLength(  AuditEvent event,  int severityLevelNameLength){     return LENGTH_OF_ALL_SEPARATORS + event.getFileName().length() + event.getMessage().length()+ severityLevelNameLength+ getCheckShortName(event).length();   }   /**   * Returns check name without 'Check' suffix.  * @param event audit ivent.  * @return check name without 'Check' suffix.  */   private static String getCheckShortName(  AuditEvent event){     final String checkFullName=event.getSourceName();     final String checkShortName;     final int lastDotIndex=checkFullName.lastIndexOf('.');     if (lastDotIndex == -1) {       if (checkFullName.endsWith(SUFFIX)) {         checkShortName=checkFullName.substring(0,checkFullName.lastIndexOf(SUFFIX));       }  else {         checkShortName=checkFullName.substring(0,checkFullName.length());       }     }  else {       if (checkFullName.endsWith(SUFFIX)) {         checkShortName=checkFullName.substring(lastDotIndex + 1,checkFullName.lastIndexOf(SUFFIX));       }  else {         checkShortName=checkFullName.substring(lastDotIndex + 1,checkFullName.length());       }     }     return checkShortName;   } } 
hazelcastFactory.newHazelcastClient(newClientConfig())
infos == null || infos.length == 0
currentStage != NodeStage.DONE && sendMessage() == false
!c.isEncoded()
i=2
Preconditions.checkNotNull(mBlockIdsOnTiers,"mBlockIdsOnTiers")
IdentifiedDataSerializable event
equalTo(5)
assertTrueEventually(new AssertTask(){   @Override public void run() throws Exception {     Collection<EventRegistration> regs1=eventService1.getRegistrations(MapService.SERVICE_NAME,mapName);     Collection<EventRegistration> regs2=eventService2.getRegistrations(MapService.SERVICE_NAME,mapName);     assertEquals("there should be only one registration",1,regs1.size());     assertEquals("there should be only one registration",1,regs2.size());   } } )
NIO_GROUP.shutdownGracefully(0,10,TimeUnit.SECONDS)
@Override public ExtendedCell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   return new TagRewriteCell(clonedBaseCell,this.tags); } 
LOG.warn("Cannot create the SAXParser XMLReader, due to {}",ex.getMessage(),ex)
graphModel.getUndirectedGraphVisible()
@SuppressWarnings("unused") private final WeakSafeReadWriteLock strongReference; 
mapConfig.getBackupCount()
Color.fromRGB(0xB3312C)
parent.incrementPrioritizableForTree0(amt,oldParent)
runTasks & 0x3F
exchange.getPartitioningScheme().isReplicateNullsAndAny()
i >= stripeStats.size()
id=10853
Response headers(Map<String,Property> headers); 
id=3
synchronized (CONFIG) {   --threadCount;   if (threadCount <= 0) {     try {       session.close();     }  catch (    IOException e) {       throw new DBException(e);     }   } } 
getLsResultStr("/testRoot/testDir",files[1].getCreationTimeMs(),1,LsCommand.STATE_FOLDER,testUser,testUser,files[1].getPermission(),files[1].isFolder())
endsWith("/home/source")
LOG.debug("Consumer subtask {} is trying to discover new partitions ...",getRuntimeContext().getIndexOfThisSubtask())
metric instanceof MetricsRate || metric instanceof MetricsString || metric instanceof MetricsHistogram|| metric instanceof ExactCounterMetric
IR.thisNode()
fireMessageReceived(ctx,completeMessage,e.getRemoteAddress())
masterAddress.split(":").length == 2
new ServletException("non-HTTP request or response",e)
LOGGER.error("{} - Failed to execute connection test query. ({})",poolName,e.getMessage())
i < 10000
callTimeoutMillis=3000
pm.runMigrationTasks(tasks,partitionId,replicaIndex,from)
connectors.put(connectorId,connector)
id=4
ReactiveHelper.schedule(() -> {   if (uow != null) {     uow.afterProcess(processor,exchange,callback,false);   }   if (log.isTraceEnabled()) {     log.trace("Exchange processed and is continued routed asynchronously for exchangeId: {} -> {}",exchange.getExchangeId(),exchange);   } } ,"CamelInternalProcessor - UnitOfWork - afterProcess - " + processor + " - "+ exchange.getExchangeId())
patientState.getState().getUuid()
s.setMaxVersions(region.getStores().values().iterator().next().getScanInfo().getMaxVersions())
bufferedBytes < maxBufferedBytes
assertEquals(6,config.getMapConfigs().size())
providers.size() > 0
new MMUnlockHandler(this)
dbCol.findOne(filter)
this.healthMvcEndpointProperties.getMapping() != null && this.healthMvcEndpointProperties.getMapping().size() > 0
endFunction("get_column_statistics_by_partition: ",statsObj != null,null)
Pattern.compile(foundAuthor,Pattern.LITERAL)
items[24]
String.format(SCOPED_AUTHORIZE_URL,config.getApiKey(),formURLEncode(config.getCallback()),formURLEncode(config.getScope()))
LOG.warn("Could not append. Requesting close of wal",e)
isNotNull(overriderParameters.get(i)) && !(isNullable(overriddenParameters.get(i)) || isNotNull(overriddenParameters.get(i))) && !errorElements.contains(overriderParameters.get(i))&& warnedElements.add(overriderParameters.get(i))
final ColumnFamilyDescriptor hcd=htd.getColumnFamily(familyName); 
DaggerAutoFactoryProcessorComponent.builder()
map.lock(key,1,TimeUnit.SECONDS)
config.setAdvertiseSecurityKey(modelconf.get(CommonAttributes.ADVERTISE_SECURITY_KEY).asString())
resource.removeExtractor(input.getId(),extractorId)
Exception ex
new AsyncWriteToken(r,finalMsg,entry.future,entry.originalMessage,entry.cache)
entity instanceof ProcessDefinitionEntity
region.getReplicaId()
public Builder setDefaultThrowableHandler(ThrowableHandler throwableHandler){   this.defaultThrowableHandler=throwableHandler;   return this; } 
ROOT_LOGGER.errorContextModuleNotFound(consoleSlot == null ? "main" : consoleSlot)
flushStatements(true)
new InputStreamReader(in,"UTF-8")
!Values.WEBSOCKET.equalsIgnoreCase(upgrade)
id=10
new GenericAggregationFunction(name,inputTypes,intermediateType,outputType,true,aggregationAnnotation.approximate(),factory)
case PLAYER_JOIN: 
mock.setResultWaitTime(4000)
Site.me().setRetryTimes(3).setSleepTime(1000)
fireMessageReceived(ctx,message,e.getRemoteAddress())
type.equalsIgnoreCase("integer") || type.equalsIgnoreCase("int")
!config.isAutoRead()
streamCachingStrategy.setSpoolThreshold(1L)
factory.getEmbeddedServletContainer(exampleServletRegistration(),new FilterRegistrationBean(new ExampleFilter()))
new CsvFilter(columns)
new CardinalityAggregatorFactory(input,Arrays.asList(input),byRow)
new SetExchangePatternType(exchangePattern)
assertEquals(orig.getResponse(),expectedResponse)
log.makeAlert(e,"Failed to remove segment")
new Entry[2048]
Arrays.asList(RFXComValueSelector.RAW_DATA,RFXComValueSelector.SIGNAL_LEVEL,RFXComValueSelector.COMMAND,RFXComValueSelector.DIMMING_LEVEL,RFXComValueSelector.CONTACT)
assertEquals("integer",model.getProperties().get(COUNT).getType())
factory.getProxy(getClass().getClassLoader())
!mkdirs(mBaseDir)
hotDrinkDelay=300
!this.transactional && this.referenceId == referenceId
UserGroupInformation.getLoginUser().checkTGTAndReloginFromKeytab()
Assert.assertEquals(1,configs.size())
c.getDomain() == null && getDomain() != null
public abstract class AbstractHikariConfig implements HikariConfigMXBean {   private static final Logger LOGGER=LoggerFactory.getLogger(HikariConfig.class);   private static final long CONNECTION_TIMEOUT=TimeUnit.SECONDS.toMillis(30);   private static final long VALIDATION_TIMEOUT=TimeUnit.SECONDS.toMillis(5);   private static final long IDLE_TIMEOUT=TimeUnit.MINUTES.toMillis(10);   private static final long MAX_LIFETIME=TimeUnit.MINUTES.toMillis(30);   private static int poolNumber;   private static boolean unitTest;   private volatile long connectionTimeout;   private volatile long validationTimeout;   private volatile long idleTimeout;   private volatile long leakDetectionThreshold;   private volatile long maxLifetime;   private volatile int maxPoolSize;   private volatile int minIdle;   private String catalog;   private String connectionCustomizerClassName;   private String connectionInitSql;   private String connectionTestQuery;   private String dataSourceClassName;   private String dataSourceJndiName;   private String driverClassName;   private String jdbcUrl;   private String password;   private String poolName;   private String transactionIsolationName;   private String username;   private boolean isAutoCommit;   private boolean isReadOnly;   private boolean isInitializationFailFast;   private boolean isIsolateInternalQueries;   private boolean isRegisterMbeans;   private boolean isAllowPoolSuspension;   private DataSource dataSource;   private Properties dataSourceProperties;   private IConnectionCustomizer customizer;   private ThreadFactory threadFactory;   private Object metricRegistry;   private Object healthCheckRegistry;   private Properties healthCheckProperties;   /**   * Default constructor  */   public AbstractHikariConfig(){     dataSourceProperties=new Properties();     healthCheckProperties=new Properties();     connectionTimeout=CONNECTION_TIMEOUT;     validationTimeout=VALIDATION_TIMEOUT;     idleTimeout=IDLE_TIMEOUT;     isAutoCommit=true;     isInitializationFailFast=true;     minIdle=-1;     maxPoolSize=10;     maxLifetime=MAX_LIFETIME;     customizer=new IConnectionCustomizer(){       @Override public void customize(      Connection connection) throws SQLException {       }     } ;     String systemProp=System.getProperty("hikaricp.configurationFile");     if (systemProp != null) {       loadProperties(systemProp);     }   }   /**   * Construct a HikariConfig from the specified properties object.  * @param properties the name of the property file  */   public AbstractHikariConfig(  Properties properties){     this();     PropertyBeanSetter.setTargetFromProperties(this,properties);   }   /**   * Construct a HikariConfig from the specified property file name.  <code>propertyFileName</code> will first be treated as a path in the file-system, and if that fails the  ClassLoader.getResourceAsStream(propertyFileName) will be tried.  * @param propertyFileName the name of the property file  */   public AbstractHikariConfig(  String propertyFileName){     this();     loadProperties(propertyFileName);   }   /**   * Get the default catalog name to be set on connections.  * @return the default catalog name  */   public String getCatalog(){     return catalog;   }   /**   * Set the default catalog name to be set on connections.  * @param catalog the catalog name, or null  */   public void setCatalog(  String catalog){     this.catalog=catalog;   }   /**   * Get the name of the connection customizer class to instantiate and execute on all new connections.  * @return the name of the customizer class, or null  */   @Deprecated public String getConnectionCustomizerClassName(){     return connectionCustomizerClassName;   }   /**   * Set the name of the connection customizer class to instantiate and execute on all new connections.  * @param connectionCustomizerClassName the name of the customizer class  */   @Deprecated public void setConnectionCustomizerClassName(  String connectionCustomizerClassName){     this.connectionCustomizerClassName=connectionCustomizerClassName;     LOGGER.warn("The connectionCustomizerClassName property has been deprecated and may be removed in a future release");   }   /**   * Get the customizer instance specified by the user.  * @return an instance of IConnectionCustomizer  */   @Deprecated public IConnectionCustomizer getConnectionCustomizer(){     return customizer;   }   /**   * Set the connection customizer to be used by the pool.  * @param customizer an instance of IConnectionCustomizer  */   @Deprecated public void setConnectionCustomizer(  IConnectionCustomizer customizer){     this.customizer=customizer;     LOGGER.warn("The connectionCustomizer property has been deprecated and may be removed in a future release");   }   /**   * Get the SQL query to be executed to test the validity of connections.  * @return the SQL query string, or null   */   public String getConnectionTestQuery(){     return connectionTestQuery;   }   /**   * Set the SQL query to be executed to test the validity of connections. Using the JDBC4 <code>Connection.isValid()</code> method to test connection validity can be more efficient on some databases and is recommended.  See  {@link HikariConfig#setJdbc4ConnectionTest(boolean)}.  * @param connectionTestQuery a SQL query string  */   public void setConnectionTestQuery(  String connectionTestQuery){     this.connectionTestQuery=connectionTestQuery;   }   /**   * Get the SQL string that will be executed on all new connections when they are created, before they are added to the pool.  * @return the SQL to execute on new connections, or null  */   public String getConnectionInitSql(){     return connectionInitSql;   }   /**   * Set the SQL string that will be executed on all new connections when they are created, before they are added to the pool.  If this query fails, it will be treated as a failed connection attempt.  * @param connectionInitSql the SQL to execute on new connections  */   public void setConnectionInitSql(  String connectionInitSql){     this.connectionInitSql=connectionInitSql;   }   /**   * {@inheritDoc}   */   @Override public long getConnectionTimeout(){     return connectionTimeout;   }   /**   * {@inheritDoc}   */   @Override public void setConnectionTimeout(  long connectionTimeoutMs){     if (connectionTimeoutMs == 0) {       this.connectionTimeout=Integer.MAX_VALUE;     }  else     if (connectionTimeoutMs < 1000) {       throw new IllegalArgumentException("connectionTimeout cannot be less than 1000ms");     }  else {       this.connectionTimeout=connectionTimeoutMs;     }   }   /**   * {@inheritDoc}   */   @Override public long getValidationTimeout(){     return validationTimeout;   }   /**   * {@inheritDoc}   */   @Override public void setValidationTimeout(  long validationTimeoutMs){     if (validationTimeoutMs < 1000) {       throw new IllegalArgumentException("validationTimeout cannot be less than 1000ms");     }  else {       this.validationTimeout=validationTimeoutMs;     }   }   /**   * Get the  {@link DataSource} that has been explicitly specified to be wrapped by thepool.  * @return the {@link DataSource} instance, or null  */   public DataSource getDataSource(){     return dataSource;   }   /**   * Set a  {@link DataSource} for the pool to explicitly wrap.  This setter is notavailable through property file based initialization.  * @param dataSource a specific {@link DataSource} to be wrapped by the pool  */   public void setDataSource(  DataSource dataSource){     this.dataSource=dataSource;   }   public String getDataSourceClassName(){     return dataSourceClassName;   }   public void setDataSourceClassName(  String className){     this.dataSourceClassName=className;   }   public void addDataSourceProperty(  String propertyName,  Object value){     dataSourceProperties.put(propertyName,value);   }   public String getDataSourceJNDI(){     return this.dataSourceJndiName;   }   public void setDataSourceJNDI(  String jndiDataSource){     this.dataSourceJndiName=jndiDataSource;   }   public Properties getDataSourceProperties(){     return dataSourceProperties;   }   public void setDataSourceProperties(  Properties dsProperties){     dataSourceProperties.putAll(dsProperties);   }   public String getDriverClassName(){     return driverClassName;   }   public void setDriverClassName(  String driverClassName){     try {       Class<?> driverClass=this.getClass().getClassLoader().loadClass(driverClassName);       driverClass.newInstance();       this.driverClassName=driverClassName;     }  catch (    Exception e) {       throw new RuntimeException("driverClassName specified class '" + driverClassName + "' could not be loaded",e);     }   }   /**   * {@inheritDoc}   */   @Override public long getIdleTimeout(){     return idleTimeout;   }   /**   * {@inheritDoc}   */   @Override public void setIdleTimeout(  long idleTimeoutMs){     if (idleTimeoutMs < 0) {       throw new IllegalArgumentException("idleTimeout cannot be negative");     }     this.idleTimeout=idleTimeoutMs;   }   public String getJdbcUrl(){     return jdbcUrl;   }   public void setJdbcUrl(  String jdbcUrl){     this.jdbcUrl=jdbcUrl;   }   /**   * Get the default auto-commit behavior of connections in the pool.  * @return the default auto-commit behavior of connections  */   public boolean isAutoCommit(){     return isAutoCommit;   }   /**   * Set the default auto-commit behavior of connections in the pool.  * @param isAutoCommit the desired auto-commit default for connections  */   public void setAutoCommit(  boolean isAutoCommit){     this.isAutoCommit=isAutoCommit;   }   /**   * Get the pool suspension behavior (allowed or disallowed).  * @return the pool suspension behavior  */   public boolean isAllowPoolSuspension(){     return isAllowPoolSuspension;   }   /**   * Set whether or not pool suspension is allowed.  There is a performance impact when pool suspension is enabled.  Unless you need it (for a redundancy system for example) do not enable it.  * @param isAllowPoolSuspension the desired pool suspension allowance  */   public void setAllowPoolSuspension(  boolean isAllowPoolSuspension){     this.isAllowPoolSuspension=isAllowPoolSuspension;   }   /**   * Get whether or not the construction of the pool should throw an exception if the minimum number of connections cannot be created.  * @return whether or not initialization should fail on error immediately  */   public boolean isInitializationFailFast(){     return isInitializationFailFast;   }   /**   * Set whether or not the construction of the pool should throw an exception if the minimum number of connections cannot be created.  * @param failFast true if the pool should fail if the minimum connections cannot be created  */   public void setInitializationFailFast(  boolean failFast){     isInitializationFailFast=failFast;   }   public boolean isIsolateInternalQueries(){     return isIsolateInternalQueries;   }   public void setIsolateInternalQueries(  boolean isolate){     this.isIsolateInternalQueries=isolate;   }   @Deprecated public boolean isJdbc4ConnectionTest(){     return false;   }   @Deprecated public void setJdbc4ConnectionTest(  boolean useIsValid){     LOGGER.warn("The jdbcConnectionTest property is now deprecated, see the documentation for connectionTestQuery");   }   /**   * Get the Codahale MetricRegistry, could be null.  * @return the codahale MetricRegistry instance  */   public Object getMetricRegistry(){     return metricRegistry;   }   /**   * Set a Codahale MetricRegistry to use for HikariCP.  * @param metricRegistry the Codahale MetricRegistry to set  */   public void setMetricRegistry(  Object metricRegistry){     if (metricRegistry != null) {       if (metricRegistry instanceof String) {         try {           InitialContext initCtx=new InitialContext();           metricRegistry=(MetricRegistry)initCtx.lookup((String)metricRegistry);         }  catch (        NamingException e) {           throw new IllegalArgumentException(e);         }       }       if (!(metricRegistry instanceof MetricRegistry)) {         throw new IllegalArgumentException("Class must be an instance of com.codahale.metrics.MetricRegistry");       }     }     this.metricRegistry=metricRegistry;   }   /**   * Get the Codahale HealthCheckRegistry, could be null.  * @return the Codahale HealthCheckRegistry instance  */   public Object getHealthCheckRegistry(){     return healthCheckRegistry;   }   /**   * Set a Codahale HealthCheckRegistry to use for HikariCP.  * @param healthCheckRegistry the Codahale HealthCheckRegistry to set  */   public void setHealthCheckRegistry(  Object healthCheckRegistry){     if (healthCheckRegistry != null) {       if (healthCheckRegistry instanceof String) {         try {           InitialContext initCtx=new InitialContext();           healthCheckRegistry=(HealthCheckRegistry)initCtx.lookup((String)healthCheckRegistry);         }  catch (        NamingException e) {           throw new IllegalArgumentException(e);         }       }       if (!(healthCheckRegistry instanceof HealthCheckRegistry)) {         throw new IllegalArgumentException("Class must be an instance of com.codahale.metrics.health.HealthCheckRegistry");       }     }     this.healthCheckRegistry=healthCheckRegistry;   }   public Properties getHealthCheckProperties(){     return healthCheckProperties;   }   public void setHealthCheckProperties(  Properties healthCheckProperties){     this.healthCheckProperties.putAll(healthCheckProperties);   }   public void addHealthCheckProperty(  String key,  String value){     healthCheckProperties.setProperty(key,value);   }   public boolean isReadOnly(){     return isReadOnly;   }   public void setReadOnly(  boolean readOnly){     this.isReadOnly=readOnly;   }   public boolean isRegisterMbeans(){     return isRegisterMbeans;   }   public void setRegisterMbeans(  boolean register){     this.isRegisterMbeans=register;   }   /**   * {@inheritDoc}   */   @Override public long getLeakDetectionThreshold(){     return leakDetectionThreshold;   }   /**   * {@inheritDoc}   */   @Override public void setLeakDetectionThreshold(  long leakDetectionThresholdMs){     this.leakDetectionThreshold=leakDetectionThresholdMs;   }   /**   * {@inheritDoc}   */   @Override public long getMaxLifetime(){     return maxLifetime;   }   /**   * {@inheritDoc}   */   @Override public void setMaxLifetime(  long maxLifetimeMs){     this.maxLifetime=maxLifetimeMs;   }   /**   * {@inheritDoc}   */   @Override public int getMaximumPoolSize(){     return maxPoolSize;   }   /**   * {@inheritDoc}   */   @Override public void setMaximumPoolSize(  int maxPoolSize){     if (maxPoolSize < 1) {       throw new IllegalArgumentException("maxPoolSize cannot be less than 1");     }     this.maxPoolSize=maxPoolSize;   }   /**   * {@inheritDoc}   */   @Override public int getMinimumIdle(){     return minIdle;   }   /**   * {@inheritDoc}   */   @Override public void setMinimumIdle(  int minIdle){     if (minIdle < 0) {       throw new IllegalArgumentException("minimumIdle cannot be negative");     }     this.minIdle=minIdle;   }   /**   * Get the default password to use for DataSource.getConnection(username, password) calls.  * @return the password  */   public String getPassword(){     return password;   }   /**   * Set the default password to use for DataSource.getConnection(username, password) calls.  * @param password the password  */   public void setPassword(  String password){     this.password=password;   }   /**   * {@inheritDoc}   */   @Override public String getPoolName(){     return poolName;   }   /**   * Set the name of the connection pool.  This is primarily used for the MBean to uniquely identify the pool configuration.  * @param poolName the name of the connection pool to use  */   public void setPoolName(  String poolName){     this.poolName=poolName;   }   public String getTransactionIsolation(){     return transactionIsolationName;   }   /**   * Set the default transaction isolation level.  The specified value is the constant name from the <code>Connection</code> class, eg.  <code>TRANSACTION_REPEATABLE_READ</code>.  * @param isolationLevel the name of the isolation level  */   public void setTransactionIsolation(  String isolationLevel){     this.transactionIsolationName=isolationLevel;   }   /**   * Get the default username used for DataSource.getConnection(username, password) calls.  * @return the username  */   public String getUsername(){     return username;   }   /**   * Set the default username used for DataSource.getConnection(username, password) calls.  * @param username the username  */   public void setUsername(  String username){     this.username=username;   }   /**   * Get the thread factory used to create threads.  * @return the thread factory (may be null, in which case the default thread factory is used)  */   public ThreadFactory getThreadFactory(){     return threadFactory;   }   /**   * Set the thread factory to be used to create threads.  * @param threadFactory the thread factory (setting to null causes the default thread factory to be used)  */   public void setThreadFactory(  ThreadFactory threadFactory){     this.threadFactory=threadFactory;   }   public void validate(){     Logger logger=LoggerFactory.getLogger(getClass());     validateNumerics();     if (connectionCustomizerClassName != null) {       try {         getClass().getClassLoader().loadClass(connectionCustomizerClassName);       }  catch (      Exception e) {         logger.warn("connectionCustomizationClass specified class '" + connectionCustomizerClassName + "' could not be loaded",e);         connectionCustomizerClassName=null;       }     }     if (driverClassName != null && jdbcUrl == null) {       logger.error("when specifying driverClassName, jdbcUrl must also be specified");       throw new IllegalStateException("when specifying driverClassName, jdbcUrl must also be specified");     }  else     if (driverClassName != null && dataSourceClassName != null) {       logger.error("both driverClassName and dataSourceClassName are specified, one or the other should be used");       throw new IllegalStateException("both driverClassName and dataSourceClassName are specified, one or the other should be used");     }  else     if (jdbcUrl != null) {     }  else     if (dataSource == null && dataSourceClassName == null) {       logger.error("one of either dataSource, dataSourceClassName, or jdbcUrl and driverClassName must be specified");       throw new IllegalArgumentException("one of either dataSource or dataSourceClassName must be specified");     }  else     if (dataSource != null && dataSourceClassName != null) {       logger.warn("both dataSource and dataSourceClassName are specified, ignoring dataSourceClassName");     }     if (transactionIsolationName != null) {       UtilityElf.getTransactionIsolation(transactionIsolationName);     }     if (poolName == null) {       poolName="HikariPool-" + poolNumber++;     }     if (LOGGER.isDebugEnabled() || unitTest) {       logConfiguration();     }   }   private void validateNumerics(){     Logger logger=LoggerFactory.getLogger(getClass());     if (validationTimeout > connectionTimeout && connectionTimeout != 0) {       logger.warn("validationTimeout is greater than connectionTimeout, setting validationTimeout to connectionTimeout.");       validationTimeout=connectionTimeout;     }     if (minIdle < 0 || minIdle > maxPoolSize) {       minIdle=maxPoolSize;     }     if (maxLifetime < 0) {       logger.error("maxLifetime cannot be negative.");       throw new IllegalArgumentException("maxLifetime cannot be negative.");     }  else     if (maxLifetime > 0 && maxLifetime < TimeUnit.SECONDS.toMillis(30)) {       logger.warn("maxLifetime is less than 30000ms, using default {}ms.",MAX_LIFETIME);       maxLifetime=MAX_LIFETIME;     }     if (idleTimeout != 0 && idleTimeout < TimeUnit.SECONDS.toMillis(10)) {       logger.warn("idleTimeout is less than 10000ms, using default {}ms.",IDLE_TIMEOUT);       idleTimeout=IDLE_TIMEOUT;     }  else     if (idleTimeout > maxLifetime && maxLifetime > 0) {       logger.warn("idleTimeout is greater than maxLifetime, setting to maxLifetime.");       idleTimeout=maxLifetime;     }     if (leakDetectionThreshold != 0 && leakDetectionThreshold < TimeUnit.SECONDS.toMillis(2) && !unitTest) {       logger.warn("leakDetectionThreshold is less than 2000ms, setting to minimum 2000ms.");       leakDetectionThreshold=2000L;     }   }   private void logConfiguration(){     LOGGER.debug("HikariCP pool {} configuration:",poolName);     final Set<String> propertyNames=new TreeSet<String>(PropertyBeanSetter.getPropertyNames(HikariConfig.class));     for (    String prop : propertyNames) {       try {         Object value=PropertyBeanSetter.getProperty(prop,this);         if ("dataSourceProperties".equals(prop)) {           Properties dsProps=PropertyBeanSetter.copyProperties(dataSourceProperties);           dsProps.setProperty("password","<masked>");           value=dsProps;         }         value=(prop.contains("password") ? "<masked>" : value);         LOGGER.debug((prop + "................................................").substring(0,32) + (value != null ? value : ""));       }  catch (      Exception e) {         continue;       }     }   }   abstract protected void loadProperties(  String propertyFileName);   public void copyState(  AbstractHikariConfig other){     for (    Field field : AbstractHikariConfig.class.getDeclaredFields()) {       if (!Modifier.isFinal(field.getModifiers())) {         field.setAccessible(true);         try {           field.set(other,field.get(this));         }  catch (        Exception e) {           throw new RuntimeException("Exception copying HikariConfig state: " + e.getMessage(),e);         }       }     }   } } 
put(TYPES,new MapTypeCaster(),Map.class)
Assert.fail("createDirectory was expected to fail with FileAlreadyExistsException")
PathUtils.concatPath(homeDir,YML_FILE_DIR)
args.length < 2
telegram.getTimestamp() > currentTime
buffer.limit()
preserve.asString()
asList(8L)
completionLatch.await(2500,TimeUnit.MILLISECONDS)
compressedSliceInput.getRetainedSize()
private ErrorPageFilter filter=new ErrorPageFilter(); 
role.description().orNull()
/**   * Converts quoted property accesses to dot syntax (a['b'] -> a.b)   */ CONVERT_TO_DOTTED_PROPERTIES{   @Override void apply(  CompilerOptions options,  boolean value){     options.setConvertToDottedProperties(value);   }   @Override String getJavaInfo(){     return "options.setConvertToDottedProperties(true)";   } } 
mock.message(0).arrives().between(6,9)
@Override public ExtendedCell deepClone(){   Cell clonedBaseCell=((ExtendedCell)this.cell).deepClone();   if (clonedBaseCell instanceof ByteBufferCell) {     return new TagRewriteByteBufferCell((ByteBufferCell)clonedBaseCell,this.tags);   }   return new TagRewriteCell(clonedBaseCell,this.tags); } 
configuredScriptEngineNames == null || configuredScriptEngineNames.isEmpty()
new LocalizedXStreams(classLoader,runtimeOptions.getConverters())
LOG.trace("Finding components in url: {}",url)
assertFalse(CompressionTest.testCompression("SNAPPY"))
asyncContext.currentAsyncTraceObject()
target.setField(0,edge)
mMountTable.resolve(getPath(next)).toString()
executor.execute(new NamedRunnable("OkHttp %s ping %08x%08x",hostName,payload1,payload2){   @Override public void execute(){     try {       writePing(reply,payload1,payload2,ping);     }  catch (    IOException ignored) {     }   } } )
expectQueryToFail("UserWith:Colon",ldapUserPassword,MALFORMED_CREDENTIALS_ERROR)
new StringInputRowParser(new DelimitedParseSpec(new TimestampSpec("ts","iso"),new DimensionsSpec(Arrays.asList(DIMENSIONS),null,null),"\t",Arrays.asList(COLUMNS)),null,null,null,null)
factory.get(fBodyWildcard,NO_ANNOTATIONS,retrofit)
from("direct:start").multicast(new MyAggregationStrategy()).parallelProcessing().timeout(1000)
return ctx; 
logger.fine("Strip code")
id=8
content().duplicate()
grammar.getTokenDisplayNames()
id=16508
1024 * 128
functionJSDocInfo != null && functionJSDocInfo.getAssociatedNode() != null
Status.createStatuseList(get(getBaseURL() + "statuses/public_timeline.json",false))
handshakeStatus == HandshakeStatus.NOT_HANDSHAKING || handshakeStatus == HandshakeStatus.FINISHED
Objects.hash(expressions,withOrdinality)
pws.getPatientPrograms(patient,program,null,completionDate,enrollmentDate,null,false)
DEFAULT_BLOCK_SIZE=100
ImmutableList.copyOf(sourcesAsStrings)
THREADS_PER_CLIENT=4
EnglishUdLas=88.72648417258083
LlapServlet.class
DiagnosticType.warning("JSC_CONSTANT_REASSIGNED_VALUE_ERROR","constant {0} assigned a value more than once.\n" + "Original definition at {1}")
BeanMapper.mapList(books,BookDto.class)
public Builder setRealmName(String realmName){   realm().setRealmName(realmName);   return this; } 
lineageInfo.getChildren()
taken > 150
ensureInChild(parent,FooImpl.class,Foo.class)
LOG.debug("Ignoring duplicate journal entry with SN {} when next SN is {}",newSN,mNextSequenceNumberToRead)
redeliveryDelayResult > maximumRedeliveryDelay
@Override public Response schema(Property property){   this.setSchema(property);   return this; } 
new LazyHeadArrayNode(record,schema)
parent.getRegionNameAsString()
securityDomain != null && !securityDomain.isEmpty()
new StringBuilder(729)
super.mySetupMutualAuthServerIsValidClientException(cause)
SecurityAutoConfiguration.class
Assert.assertTrue("Was not expecting this output " + acc,System.currentTimeMillis() - now < 5000)
queue.size() > 100000
new JSONParseSpec(new TimestampSpec("timestamp","auto"),new DimensionsSpec(null,null,null))
connections.get(target)
config.getBroadcasterFactory().lookup(m.broadcaster(),path,true)
region.getRegionHeight()
createMessageConsumer(session,destinationName,messageSelector,true,null)
cachedMessages=b.getBroadcasterConfig().applyFilters(r,t)
getOriginUrl()
Call<RemoteCallResponseType>
"Interrupted when attempting to close writer for end point: " + eldest
4 >= buf.length - count
Foundation.log("[debug] " + tag + ": "+ message)
aggMap.size()
cal.set(1900,0,1,hour,minute,second)
this(type,1); 
new WebSocketServerHandshakerFactory(getWebSocketLocation(req),null,true)
((StringLiteral)literal).getValue()
map.put(PASSWORD_KEY,password)
private static class TestException extends RuntimeException {   private static final long serialVersionUID=1L;   @Override public void printStackTrace(  PrintWriter printWriter){     printWriter.print("stackTrace");   } } 
factory.get(fBodyGeneric,NO_ANNOTATIONS,retrofit)
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
WebSocketEventListener.class.cast(l).onHandshake(event)
rj.reduceProgress()
timeoutLatch.await(2500,TimeUnit.MILLISECONDS)
/**   * Gets the key of service port.  * @return key of service port  */ public PropertyKey getPortKey(){   return mPortKey; } 
/**   * Changes the group of a file or directory specified by args recursively.  */ public final class ChgrpRecursiveCommand extends AbstractAclCommand {   public ChgrpRecursiveCommand(  TachyonConf conf,  TachyonFileSystem tfs){     super(conf,tfs);   }   @Override public String getCommandName(){     return "chgrpr";   }   @Override protected int getNumOfArgs(){     return 2;   }   @Override public void run(  String... args) throws IOException {     String group=args[0];     TachyonURI path=new TachyonURI(args[1]);     chgrp(path,group,true);   }   @Override public String getUsage(){     return "chgrpr <group> <path>";   } } 
fLines.addElement(st.nextToken())
pubSubDomain=false
refreshableViewWrapper.addView(newEmptyView)
routerChain.notifyFullInvokers(invokers,getUrl())
Color.fromRGB(0x3B511A)
GL20.glUniformMatrix4fv(location,transpose,toFloatBuffer(value,offset,count << 4))
stage.compareTo(currentStage) < 0
localY2 * cos
node1.isEquivalentTo(node2)
props.getProperty(propName)
assertEquals(3,historyService.createHistoricActivityInstanceQuery().executionId(processInstance.getId()).list().size())
DiagnosticType.error("JSC_REDECLARED_VARIABLE","Redeclared variable: {0}")
NbPreferences.forModule(DataTableTopComponent.class).getBoolean(DATA_LABORATORY_ONLY_VISIBLE,true)
CamelContextHelper.parseInteger(getCamelContext(),maxQueueSize)
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
logException(exception)
options.checkProvides.isOn() || options.enables(DiagnosticGroups.MISSING_PROVIDE)
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.BeforeAnnotation.class,CoreAnnotations.AfterAnnotation.class,CoreAnnotations.TokenBeginAnnotation.class,CoreAnnotations.TokenEndAnnotation.class,CoreAnnotations.PositionAnnotation.class,CoreAnnotations.IndexAnnotation.class,CoreAnnotations.OriginalTextAnnotation.class,CoreAnnotations.ValueAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class,CoreAnnotations.TokenIndexAnnotation.class)
new SimpleDateFormat(format,Locale.US)
GL20.glGetVertexAttribfv(index,pname,params)
new CommandLineException("Communication error",e)
logger.fine("Named " + namedCount + " anon functions using "+ bytesUsed+ " bytes")
public final TFAgentStatMapper tFAgentStatMapper=new TFAgentStatMapper(); 
GL.glCopyTexImage2D(target,level,internalformat,x,y,width,height,border)
metastore.getHost()
authManager.refresh(conf,new HBasePolicyProvider())
id=51
IOConverter.toInputStream(s,null)
tupleInfo != null && tupleInfo.getMessageId() != null
bean.getCollectionTime()
!Objects.isNull(value)
JsonObject.createObjectMapper().getFactory()
mapper.getFactory()
dataSource.setInitExceptionThrow(false)
private final PropertyKey mPortKey; 
final ProtocolCommand cmd
new CacheCreateConfigOperation(config,false)
assertEquals(avDegree,1.0)
KeyManagerFactory.getDefaultAlgorithm()
engine.execute(cypher).dumpToString()
new DefaultPropertyNamePatternsMatcher(TARGET_NAME_DELIMITERS,this.targetName)
first
new ImportControl(pkg,regex)
Color.fromRGB(0x41CD34)
return closeNotifyTimeoutMillis; 
new UDFArgumentTypeException(1,"The first and seconds arguments of function NLV should have the same type, " + "but they are different: \"" + arguments[0].getTypeName() + "\" and \""+ arguments[1].getTypeName()+ "\"")
connectionManager.markOwnerConnectionAsClosed()
computeAntiJoin(inputStatistics,inputStatistics,x,unknown)
mock.expectedHeaderReceived(CaffeineConstants.ACTION_HAS_RESULT,true)
expectedMinimumCount == -1 && expectedCount <= 0
Integer.parseInt(patchVersionString)
registration.registerOperationHandler(CommonAttributes.ADD_PROXY,ModClusterAddProxy.INSTANCE,addProxy,false,runtimeOnlyFlags)
_committedTo != lastCompletedOffset
SOURCE_PATH.deref()
DataTypes.TIME(3)
!Objects.equals(builtInVersion,configuredVersion)
Assert.assertEquals(getNotAllowedExceptionMessage("helloForRoles"),e.getCause().getMessage())
factory.get(fResultClass,NO_ANNOTATIONS,retrofit)
serverSocket == null || !serverSocket.isBound()
p >= 0
connection.hlen(key)
Configuration.getMs(PropertyKey.USER_FILE_LOAD_TTL)
Bytes.toString(qualifierName,start,end)
LOG.trace("Trying to open resource [{}] as a class path resource using the classloader [{}].",resource,this.getClass().getClassLoader())
@RunWith(HazelcastParallelClassRunner.class) @Category(value={QuickTest.class,ParallelTest.class}) public class ReplicatedMapLoadingTest extends ReplicatedMapAbstractTest {   @Test public void testAsyncFillUp() throws Exception {     Config config=new Config();     String mapName=randomMapName();     ReplicatedMapConfig replicatedMapConfig=config.getReplicatedMapConfig(mapName);     replicatedMapConfig.setAsyncFillup(true);     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     fillMapsAndAssertMapSizeEventually(nodeFactory,config,mapName);   }   @Test public void testSyncFillUp() throws Exception {     Config config=new Config();     String mapName=randomMapName();     ReplicatedMapConfig replicatedMapConfig=config.getReplicatedMapConfig(mapName);     replicatedMapConfig.setAsyncFillup(false);     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     fillMapsAndAssertMapSizeEventually(nodeFactory,config,mapName);   }   private void fillMapsAndAssertMapSizeEventually(  TestHazelcastInstanceFactory nodeFactory,  Config config,  String mapName){     final int first=1000;     final int second=2000;     final int third=3000;     HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<Integer,Integer> map1=instance1.getReplicatedMap(mapName);     fillMap(map1,0,first);     HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<Integer,Integer> map2=instance2.getReplicatedMap(mapName);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertMapSize("map1",first,map1);         assertMapSize("map2",first,map2);       }     } );     fillMap(map2,first,second);     HazelcastInstance instance3=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<Integer,Integer> map3=instance3.getReplicatedMap(mapName);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertMapSize("map1",second,map1);         assertMapSize("map2",second,map2);         assertMapSize("map3",second,map3);       }     } );     fillMap(map3,second,third);     HazelcastInstance instance4=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<Integer,Integer> map4=instance4.getReplicatedMap(mapName);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertMapSize("map1",third,map1);         assertMapSize("map2",third,map2);         assertMapSize("map3",third,map3);         assertMapSize("map4",third,map4);       }     } );   }   private void fillMap(  ReplicatedMap<Integer,Integer> map,  int start,  int end){     for (int i=start; i < end; i++) {       map.put(i,i);     }   }   private void assertMapSize(  String mapName,  int expectedMapSize,  ReplicatedMap<Integer,Integer> map){     assertEquals(format("%s should contain %d elements",mapName,expectedMapSize),expectedMapSize,map.size());   } } 
shardManager.commitShards(transactionId,tableId,columns,shardNodes,Optional.empty(),0)
ssl.hasDefined(CommonAttributes.CIPHER_SUITE)
complete()
sizeModeClass.equals("ScaledSizeMode")
msg.getType() == Message.Type.error || msg.getBody() == null
start.expectedMessageCount(7)
LOG.info("Table {} is disabled, give up reopening its regions",tableName)
!key.equals(PropertyKey.ZOOKEEPER_ENABLED)
request.getContextPath()
latch.await(10000,TimeUnit.MILLISECONDS)
port >= 21000
ServletTestSuite testSuite=new ServletTestSuite(testClass); 
System.currentTimeMillis() + WAIT_MILLIS_BEFORE_JOIN
new ServiceActivatorContextImpl(batchBuilder,serviceContainer)
Captain captain=(Captain)beans.get(ROWING_BEAN); 
subProperties.putIfAbsent(subName,value)
Assert.assertEquals(new InetSocketAddress("RemoteMaster3",defaultPort),masterAddress)
id=24
(Integer)strategy.getOrNull(third)
from("direct:a").delay(2000)
id=19910
transform.setToRotation(new Vector3(1,0,1).nor(),rotAngle)
new PooledCFAttribute(LOAD_BALANCING_CLASS_NAME,LOAD_BALANCING_POLICY_CLASS_NAME_METHOD)
new SingleInetAddressDns()
Arrays.asList("dirty","log","serialVersionUID","DATE_TIME_PATTERN","TIME_PATTERN","DATE_PATTERN","FORM_NAMESPACE_PATH_SEPARATOR","FORM_NAMESPACE_PATH_MAX_LENGTH","obsId","groupMembers","uuid","changedBy","dateChanged","voided","voidedBy","voidReason","dateVoided","formNamespaceAndPath","$jacocoData")
bindingConfiguration.getSource().getResourceValue(resolutionContext,serviceBuilder,phaseContext,service.getManagedObjectInjector())
items[17]
types.length > Tuple.MAX_ARITY
assertEquals(10,rows.size())
LOG.debug("Exception: ",e)
from(Constants.PARALLEL_LOANBROKER_URI).process(new CreditScoreProcessor(Constants.CREDITAGENCY_ADDRESS)).multicast(new BankResponseAggregationStrategy()).setParallelProcessing(true)
hazelcastFactory.newHazelcastInstance(newConfig())
resultEndpoint.setMinimumResultWaitTime(900)
oldestInflightEntry == null
invocation.addAttachments(context)
part.getPartitionPath()
report(n,MISPLACED_ANNOTATION,"@abstract","static methods cannot be abstract")
setMinHeight(minHeight)
new PrestoException(INVALID_CAST_ARGUMENT,"Value cannot be cast to timestamp: " + value.toStringUtf8(),e)
acquiredChannelCount < maxConnections
new JCacheProducer(this,cacheConfiguration)
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
inflightRepository != null
tsr.getReturnCode() != AbstractTaskResult.ReturnCode.SUCCESS && tsr.getReturnCode() != AbstractTaskResult.ReturnCode.TASK_NOT_FOUND
factory.lookup(DefaultBroadcaster.class,id,true)
new DynamicAwareEntry(uri,originalUri,properties,lenient)
!importedClassIndex.isEmpty()
await().atMost(20,TimeUnit.SECONDS)
new MockEnvironment("MockTask",3 * 1024 * 1024,new MockInputSplitProvider(),1024,new Configuration(),new ExecutionConfig(),maxParallelism,parallelism,subtaskIndex)
LOG.fatal("Cannot run ThriftServer",e)
items[20]
ArrayList<>
32 << 10
new IllegalArgumentException("'level' cannot be null")
o instanceof InternalAttribute
shardDao.insertShard(shard,tableId,null,0,0,0,0)
host.getHost()
@Override public Response headers(Map<String,Property> headers){   this.headers=headers;   return this; } 
connectPromise.tryFailure(t)
new TransactionOptions().setDurability(0).setTimeout(30,TimeUnit.SECONDS)
new File(dex.getParentFile(),FilenameUtils.getBaseName(file) + "_dex2jar.jar")
isFieldKept(input,uniqueField)
Metric<Long>
idleConnectionTimeout + nettyResponseFuture.getLastTouch()
@Deprecated
request.getServletPath()
id=10830
Status.createStatuseList(get(getBaseURL() + "statuses/retweeted_to_me.json",null,true))
responseFilters.isEmpty()
server.getSegment(segment.getIdentifier()) != null || peon.getSegmentsToLoad().contains(segment)
setAttributeInternal(inodePath,true,entry.getOpTimeMs(),options)
"false".equals(showRelationships) || result.hasErrors()
SemanticGraphFactory.makeFromTree(tree,mode,useExtras ? GrammaticalStructure.Extras.MAXIMAL : GrammaticalStructure.Extras.NONE,true)
getRequestMethod != null
Set<Object>
defaultMaxRowsInMemory=75000
Math.max(aggregateData.getAvgColLen(),newData.getAvgColLen())
id=19909
removeBlock(sessionId,blockId,BlockStoreLocation.anyTier())
!blocked.isDone()
idleTimeout < 30000 && idleTimeout != 0
@Override protected boolean handleResponse(ChannelHandlerContext ctx,Object response) throws Exception {   if (response instanceof HttpResponse) {     if (status != null) {       throw new HttpProxyConnectException(exceptionMessage("too many responses"),null);     }     HttpResponse res=(HttpResponse)response;     status=res.status();     inboundHeaders=res.headers();   }   boolean finished=response instanceof LastHttpContent;   if (finished) {     if (status == null) {       throw new HttpProxyConnectException(exceptionMessage("missing response"),inboundHeaders);     }     if (status.code() != 200) {       throw new HttpProxyConnectException(exceptionMessage("status: " + status),inboundHeaders);     }   }   return finished; } 
FsDatasetImpl.LOG.warn("Completed checkDirs. Removed " + removedVols.size() + " volumes. Current volumes: "+ this)
i <= end
noPendingBlockIteration >= MAX_NO_PENDING_BLOCK_ITERATIONS
id=42
Thread.sleep(800)
endPosition.getPosition() <= logfileoffset
Validate.notEmpty(name,"Cookie name must not be empty")
this.transactionsRepository.getTransaction(this.xidTransactionID)
obj.setContentType(Mimetypes.MIMETYPE_BINARY_OCTET_STREAM)
new KernelStatement(mock(KernelTransactionImplementation.class),mock(IndexReaderFactory.class),scanStore,null,null,null)
Context.getVisitService().getAllVisitTypes()
Long.valueOf(p.getProperty(screenName + ".id"))
hgraph.getTotalOutDegree(n)
registration.registerOperationHandler(CommonAttributes.STOP_CONTEXT,ModClusterStopContext.INSTANCE,stopContext,false,runtimeOnlyFlags)
paused.set(true)
reg.getMeters(transformFilter(filter))
mime == null || mime.value().length == 0
logger.error("Invalid Atmosphere Version {}",javascriptVersion)
/**   * Add a  {@link AtmosphereResource} to the list of item to be notified whenthe  {@link Broadcaster#broadcast} is invoked.  * @param resource an {@link AtmosphereResource}  * @return {@link AtmosphereResource} if added, or null if it was already there.  */ Broadcaster addAtmosphereResource(AtmosphereResource resource); 
id=10999
Thread.sleep(2000)
23 * ClassSize.REFERENCE
PostgreSQLConnectorConfig.class
new Date(1)
remoteTableHandle.isPresent()
new GeneralDataCoding(false,true,MessageClass.CLASS1,Alphabet.ALPHA_8_BIT)
DirectMessage.createDirectMessageList(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/statuses/friends/T4J_hudson.json"))
byteBuffer.get((SIZEOFLONG - 1) - i) & 0xffL
log.debug("Checking bounds key:[{}, {}) & col:[{}, {}) (expect {} keys)",new Object[]{keyStart,keyEnd,startCol,endCol,expected.size()})
id=48
LOG.info("recovered from " + StringUtils.stringifyException(e))
Short.parseShort(value.toString())
boundary.endsWith("\"")
assertEquals(11,lm.getFields().size())
map.set(key,toStoreValue(value))
LOG.warn("PriviledgedActionException as:" + this + " cause:"+ cause)
w.println(paddingText)
dictionary.put(words[0],words[2])
Context.getVisitService().getAllVisitTypes(true)
gl.glDeleteRenderbuffer(depthStencilPackedBufferHandle)
/**   * The root package controller.   */ private ImportControl root; 
minPriority == null ? 0 : minPriority
assertEquals(0,url.getPort())
callback.done(false)
LOG.info("Set the current default database as [{}] in the current default catalog [{}].",currentDatabaseName,currentCatalogName)
public Builder setConnectionTimeoutInMs(int connectionTimeuot){   configBuilder.setConnectionTimeoutInMs(connectionTimeuot);   return this; } 
logger.debug("Queue length is {} - deferring HEAL.",zController.getSendQueueLength())
count < 1
id=35
LOG.error("failed to send {} messages to {}: {}",numMessages,dstAddressPrefixedName,future.getCause())
ShrinkWrap.create(JavaArchive.class).addAsManifestResource("beans.xml")
getLsNoAclResultStr("/testRoot/testDir",files[1].getCreationTimeMs(),1,LsCommand.STATE_FOLDER)
Arrays.equals(this.element,other.element) || this.score == other.getScore()
map.tryPut(key,newValue,60,TimeUnit.SECONDS)
client.get(path,MIMETYPE_PROTOBUF)
item == null || item.getStatus() < 2
new LocalTachyonClusterResource(Constants.GB,Constants.KB,BLOCK_SIZE,Constants.KEYVALUE_ENABLED,"true")
waitLatch.await()
boolean injvm() default true; 
yamlFactory.createParser(input)
taskDao.findByUserId(2L,new Sort(Direction.ASC,"id"))
processor.open(w2,request,AtmosphereResponse.newInstance(framework.getAtmosphereConfig(),request,w))
new StringBuilder(734)
AdviceWithTasks.removeByToString(route,toString,selectFirst,selectLast,selectFrom,selectTo,maxDeep)
tFAgentStatMapper.map(agentStatBo)
ModuleFactory.stopModule(mod,true,true)
OfflineMetaRepair.class
providerConfig.setTimeout(5000)
defaultCamelContext.removeRoute(id)
logger.debug("Receive queue TAKE: Length={}",recvQueue.size())
assertEquals("One propagated header is expected.",6,headers.toArray().length)
items[25]
getLog().warn("register druid-driver mbean error",ex)
k++
id=20
from("jms:queue:order").to("bean:validateOrder").to("mock:validate").threads(20).unmarshal(mySecureDataFormat).delay(500)
outputBatchSize=1000
LOG.info("Node " + path + " already exists and this is not a "+ "retry")
requestContext.getUri().getRawPath()
!uuid.equals(NULL)
id=10854
localCache.put(name,cacheEntry)
GL.glDrawArrays(mode,first,count)
super.endPass(n)
responseCode < OK || MULTIPLE_CHOICES <= responseCode
out.writeData(entry.getValue())
assertThat(throttledLines(Duration.milliseconds(100))).doesNotHaveDuplicates().haveAtLeast(9,containsApplicationLog).haveAtMost(13,containsApplicationLog)
assertEquals(input.getFieldCount(),4)
StringBuilder text
uiAclHandler.permit(reqContext,op,topoConf)
checkArgument(partitionColumns.size() == values.size(),"Partition value count does not match the partition column count")
Bytes.toBytes(tableOrRegionName)
logger.debug("The GENA Subscription for serviceID {} ended for device {}",subscription.getService().getServiceId(),subscription.getService().getDevice())
ast != null && ast.atnState != null
c.setLong("hbase.hregion.memstore.flush.size",25000)
isStarted() || isStarting()
1000.0 * FILE_BYTES
e.getMessage()
args[4]
caught.isArrayPattern()
Assert.assertEquals(4,visitor.getConditions().size())
ImmutableSet.of("reportUnknownTypes","analyzerChecks")
id=10862
GL20.glGetActiveAttrib(program,index,256,size,typeTmp)
testerAnnotation.annotationType()
final P testedPrototype
stats.getLastUpdateTime() >= lastUpdateTime
assertEquals(Service.State.FAILED,service.state())
System.currentTimeMillis() - start
new CacheCreateConfigRequest(cacheConfig,false,partitionId)
context.addStep(response,operation,new NewStepHandler(){   public void execute(  final NewOperationContext context,  final ModelNode operation){     if (context.completeStep() == NewOperationContext.ResultAction.KEEP && context.isModelAffected()) {     }   } } ,NewOperationContext.Stage.VERIFY)
id=13106
System.currentTimeMillis() + 10000
CommandUtils.convertMsToDate(files[1].getCreationTimeMs())
mCurrentBlockLeftByte >= tLen
LOG.warn("Cannot access storage directory " + rootPath)
startTest(getMethodName())
this.connectTo(vertex,null,null,-1,-1,DistributionPattern.BIPARTITE,true)
public void testJobQueues() throws Exception {   JobClient jc=new JobClient(mrCluster.createJobConf());   String expectedQueueInfo="Maximum Tasks Per Job :: 10";   JobQueueInfo[] queueInfos=jc.getQueues();   assertNotNull(queueInfos);   assertEquals(1,queueInfos.length);   assertEquals("default",queueInfos[0].getQueueName());   assertEquals(QueueState.RUNNING.getStateName(),queueInfos[0].getQueueState());   JobConf conf=mrCluster.createJobConf();   FileSystem fileSys=dfsCluster.getFileSystem();   conf=configureWaitingJob(conf);   conf.setJobName("test-job-queue-info-test");   fileSys.delete(SHARE_DIR,true);   RunningJob rJob=jc.submitJob(conf);   while (rJob.getJobState() != JobStatus.RUNNING) {     UtilsForTests.waitFor(10);   }   int numberOfJobs=0;   for (  JobQueueInfo queueInfo : queueInfos) {     JobStatus[] jobStatusList=jc.getJobsFromQueue(queueInfo.getQueueName());     assertNotNull(queueInfo.getQueueName());     assertNotNull(queueInfo.getSchedulingInfo());     assertEquals(expectedQueueInfo,queueInfo.getSchedulingInfo());     numberOfJobs+=jobStatusList.length;     for (    JobStatus status : jobStatusList) {       assertEquals(JOB_SCHEDULING_INFO,status.getSchedulingInfo());     }   }   assertEquals(1,numberOfJobs);   UtilsForTests.signalTasks(dfsCluster,fileSys,getSignalFile(),getSignalFile(),4); } 
comparePartitionOwnership(true,localMember,partition)
new FieldFrame(currentFrame,isStaticInnerType,type == TokenTypes.CLASS_DEF || type == TokenTypes.ENUM_DEF ? ast.findFirstToken(TokenTypes.IDENT).getText() : null)
public Builder setSSLContext(final SSLContext sslContext){   configBuilder.setSSLContext(sslContext);   return this; } 
LOG.error("DataNode is out of memory. Will retry in 30 seconds.",ie)
@Override public Response example(String type,Object example){   if (examples == null) {     examples=new HashMap<String,Object>();   }   examples.put(type,example);   return this; } 
assertEquals("Unable to read 1 bytes, got 0",ex.getCause().getMessage())
/**   * Column number filter.   */ private CsvFilter columnFilter; 
queue.poll(15,TimeUnit.SECONDS)
id=10800
mockRegionInfo.isMetaTable()
wsdlLocation != null && wsdlLocation.length() > 0
LOG.debug("Getting asynchronous method stub from channel")
new TaskStatusUpdateEvent(counters,progress,stats,true)
StringBuilder pattern=new StringBuilder(this.prefix); 
originalValue != null && !originalValue.equals("-1")
executor.execute(new NamedRunnable("OkHttp %s ACK Settings",hostName){   @Override public void execute(){     try {       frameWriter.ackSettings(peerSettings);     }  catch (    IOException ignored) {     }   } } )
MapPutParameters.encodeSizeCost(NAME,BYTES_DATA,BYTES_DATA)
logError(rcurly,"rcurly",expandedTabsColumnNo(rcurly),curlyLevel())
actor.addCaptureListener(listener)
bestState.score()
logger.finest("Future response is already set! Current response: " + response + ", Offered response: "+ offeredResponse+ ", Invocation: "+ invocation)
Color.fromRGB(0xC354CD)
Preconditions.checkNotNull(jobName,"Streaming Job name should not be null.")
bindingConfig != null && converterHandler != null
logger.fine("Creating extern file for exports")
!endpoint.getConfiguration().isAllowManualCommit() && offsetRepository != null
this.dataCoding
n <= k && i > 0
member.getType()
mHeartbeatExecutor != null
executionStats.getStartedSplits()
setPin(file,true)
assertEquals(10,set.size())
@Nullable
/**   * Checkstyle frame model.   */ private final transient MainFrameModel model=new MainFrameModel(); 
context.var("long",2)
new SpringApplicationBuilder(SampleSecureApplication.class).properties("security.user.password=password")
/**   * A  {@link ChannelHandler} that is notified when it is added to or removedfrom a  {@link ChannelPipeline}.  Please note that the methods of this handler is called only when the  {@link ChannelPipeline} it belongs to hasbeen  {@linkplain ChannelPipeline#attach(Channel,ChannelSink) attached}.  * @author The Netty Project (netty-dev@lists.jboss.org)  * @author Trustin Lee (tlee@redhat.com)  * @version $Rev$, $Date$  */ public interface LifeCycleAwareChannelHandler extends ChannelHandler {   void beforeAdd(  ChannelHandlerContext ctx) throws Exception ;   void afterAdd(  ChannelHandlerContext ctx) throws Exception ;   void beforeRemove(  ChannelHandlerContext ctx) throws Exception ;   void afterRemove(  ChannelHandlerContext ctx) throws Exception ; } 
ImmutableSet.copyOf(modules)
20000 * 4 * 3
request.charset == null
ssl.hasDefined(CommonAttributes.CA_CERTIFICATE_FILE)
Outcome.noMatch("missing database driver " + driverClassName)
new PairPongMsg(getMessageCount(),(byte)0,(byte)0,this.srcAddr,dstAddr)
registerConsumer(owner,newUUIDString(),newUUIDString(),attributes)
realPointerIndex >= AndroidInput.NUM_TOUCHES
HIVE_TABLE_OFFLINE(2,USER_ERROR)
HttpHeaderValues.IDENTITY.contentEquals(targetContentEncoding)
qp.isUniqueItems()
fullName.split("[/@]",3)
new IllegalStateException(ex)
this.thrown.expectMessage("File must not be null")
log.debug("Metric=[%s] has no StatsD type mapping",statsDMetric)
R resource
(uptime - days) * 24
assertThat(response).isEqualTo("Ok.\n")
pos < end
rs.getMetaData()
waitUntil(() -> clusterManager.getNodes().size() == 2,60_000)
dirtyOutputBuffer() || currentPacket != null
this.comparatorIgnoringType
map.tryPut(key,value,60,TimeUnit.SECONDS)
new CancelJobSupervisorOperation(name,jobId)
return maxPagePartitioningBufferSize; 
b.length() - 2
testWarning(js,VariableReferenceCheck.REDECLARED_VARIABLE)
return ES8_MODULES; 
UriBuilder.fromResource(StreamAlertConditionResource.class).path("{conditionId}").build(stream.getId(),alertCondition.getId())
Thread.sleep(100)
user.getSystemId() == null || user.getSystemId().equals("")
id=16502
mTfs.unpin(mTfs.open(path))
config(" ",1)
loadMetadataSuceeded=false
ConversionException e
mock.expectedBodiesReceivedInAnyOrder("B+END","A+END")
Glue optionalGlue
@ConditionalOnEnabledHealthIndicator("solr")
type.getConstructor(String.class)
NONCONFORMING_LR_RULE(169,"rule <arg> is left recursive but doesn't conform to a pattern ANTLR can handle",ErrorSeverity.ERROR)
client.getVertx().setTimer(1000,id -> checkExpired())
HELSINKI{   @Override public ServiceNowProducer get(  ServiceNowEndpoint endpoint) throws Exception {     return new HelsinkiServiceNowProducer(endpoint);   } } 
columnType.equalsIgnoreCase("long") || columnType.equalsIgnoreCase("tinyint") || columnType.equalsIgnoreCase("smallint")|| columnType.equalsIgnoreCase("int")|| columnType.equalsIgnoreCase("bigint")
GL20.glUniform2fv(location,toFloatBuffer(v,offset,count << 1))
lookupLink(parseName(name))
t.getDeclaredConstructors()
!AtmosphereRequest.class.isAssignableFrom(request.getClass())
public class TimesNewRoman extends BasicFontMetrics { {     maxCharHeight=717;     widths[32]=250;     widths[33]=333;     widths[34]=408;     widths[35]=500;     widths[36]=500;     widths[37]=833;     widths[38]=777;     widths[39]=180;     widths[40]=333;     widths[41]=333;     widths[42]=500;     widths[43]=563;     widths[44]=250;     widths[45]=333;     widths[46]=250;     widths[47]=277;     widths[48]=500;     widths[49]=500;     widths[50]=500;     widths[51]=500;     widths[52]=500;     widths[53]=500;     widths[54]=500;     widths[55]=500;     widths[56]=500;     widths[57]=500;     widths[58]=277;     widths[59]=277;     widths[60]=563;     widths[61]=563;     widths[62]=563;     widths[63]=443;     widths[64]=920;     widths[65]=722;     widths[66]=666;     widths[67]=666;     widths[68]=722;     widths[69]=610;     widths[70]=556;     widths[71]=722;     widths[72]=722;     widths[73]=333;     widths[74]=389;     widths[75]=722;     widths[76]=610;     widths[77]=889;     widths[78]=722;     widths[79]=722;     widths[80]=556;     widths[81]=722;     widths[82]=666;     widths[83]=556;     widths[84]=610;     widths[85]=722;     widths[86]=722;     widths[87]=943;     widths[88]=722;     widths[89]=722;     widths[90]=610;     widths[91]=333;     widths[92]=277;     widths[93]=333;     widths[94]=469;     widths[95]=500;     widths[96]=333;     widths[97]=443;     widths[98]=500;     widths[99]=443;     widths[100]=500;     widths[101]=443;     widths[102]=333;     widths[103]=500;     widths[104]=500;     widths[105]=277;     widths[106]=277;     widths[107]=500;     widths[108]=277;     widths[109]=777;     widths[110]=500;     widths[111]=500;     widths[112]=500;     widths[113]=500;     widths[114]=333;     widths[115]=389;     widths[116]=277;     widths[117]=500;     widths[118]=500;     widths[119]=722;     widths[120]=500;     widths[121]=500;     widths[122]=443;     widths[123]=479;     widths[124]=200;     widths[125]=479;     widths[126]=541;   } } 
id=33
provider.isInBound(itemName) && credentialsMatch(provider,itemName,oauthCredentials) && thermostats.containsKey(provider.getThermostatIdentifier(itemName))
new Thread(shutdownHandler)
Status.createStatuseList(get(getBaseURL() + "favorites/" + id+ ".json","page",String.valueOf(page),true))
{(byte)this.getNode().getNodeId(),2,(byte)getCommandClass().getKey(),(byte)SWITCH_MULTILEVEL_STOP_LEVEL_CHANGE}
context.getStreamCachingStrategy().getSpoolCipher()
prevNerEndIndex != (start - 1) || nextNerStartIndex != end
new byte[20]
g.tool.errMgr.grammarError(ErrorType.INVALID_RULE_PARAMETER_REF,g.fileName,y,y.getText(),rref.name,expr)
return 8; 
ChannelBuffers.buffer(order(),length)
HazelcastClient.newHazelcastClient(clientConfig)
Exception ignored
ImmutableList.of(new ExpressionPostAggregator("a3","log((\"a1\" + \"a2\"))"),new ArithmeticPostAggregator("a4","quotient",ImmutableList.of(new FieldAccessPostAggregator(null,"a1"),new ConstantPostAggregator(null,0.25))))
@Bean @ConditionalOnMissingBean(NamedParameterJdbcOperations.class) public NamedParameterJdbcTemplate namedParameterJdbcTemplate(){   return new NamedParameterJdbcTemplate(this.dataSource); } 
d.setMinorVersion(1)
response.getHeader(Exchange.CONTENT_TYPE) != null && !cxfExchange.containsKey(org.apache.cxf.message.Message.CONTENT_TYPE)
report(n,MISPLACED_ANNOTATION,"@abstract","only functions or methods can be abstract")
model.calculateBoundingBox(bbox)
Throwable unexpectedException
id=10840
s.toString().toLowerCase()
visitStatement(node,context)
AlluxioWorker.class
new CheckPermission().of("all").against("deploy").expect(true)
elements != null && elements.size() > i
new ScheduledJob(job,jobName,delay,period)
sleepAtLeastMillis(1000)
counter + 1
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.BeforeAnnotation.class,CoreAnnotations.AfterAnnotation.class,CoreAnnotations.TokenBeginAnnotation.class,CoreAnnotations.TokenEndAnnotation.class,CoreAnnotations.PositionAnnotation.class,CoreAnnotations.IndexAnnotation.class,CoreAnnotations.OriginalTextAnnotation.class,CoreAnnotations.ValueAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class)
Double.parseDouble(value.toString())
encounter.getObsAtTopLevel(true)
maxLifetime < 120000 && maxLifetime != 0
12 * ClassSize.REFERENCE
Color.fromRGB(0xABABAB)
namespace == null || namespace.equals("")
type.toLowerCase(ENGLISH)
new AnnotationRepositoryConfigurationSource(metadata,getAnnotation(),this.resourceLoader,this.environment){   @Override public java.lang.Iterable<String> getBasePackages(){     return AbstractRepositoryConfigurationSourceSupport.this.getBasePackages();   } } 
addKeys(externalClasses,DATE,"org.joda.time.LocalDate","java.time.LocalDate")
option.getJavaType()
64 * 1024
latch.await(10000,TimeUnit.MILLISECONDS)
map.put(i,emp,0L,SECONDS,14L,SECONDS)
new OptiqSemanticException("Invalid Column Reference: " + grpbyExpr.dump())
logger.trace("Session destroyed")
assertEquals(512f,i,20f)
id=16507
barrier.await(2,TimeUnit.SECONDS)
selectBoxList.setScrollingDisabled(true,y)
id=54
IDAUTHORITY_RETRY_COUNT_DEFAULT=20
nodeManager.getWorkerNodes()
MESSAGES.failToReplicateAttribute(name,value.getClass().getCanonicalName())
ConditionalOnEnabledHealthIndicator.class
endFunction("delete_column_statistics_by_partition: ",ret != false,null)
new InputStreamReader(is,"UTF-8")
Sets.newHashSet(BUFFERS_READ,FIELDNAMES_READ,INDEXERCLUSTER_READ,INPUTS_READ,JVMSTATS_READ,MESSAGECOUNT_READ,MESSAGES_READ,METRICS_READ,SYSTEM_READ,THROUGHPUT_READ,SAVEDSEARCHES_CREATE,SAVEDSEARCHES_EDIT,SAVEDSEARCHES_READ)
new JSONParseSpec(timestampSpec,new DimensionsSpec(dimensions,dimensionExclusions,spatialDimensions))
uri.toString()
super.setV(v)
NodeTraversal.traverseEs6(compiler,scriptRoot,this)
users.size() > 50
this.contextRunner.withUserConfiguration(JwtDecoderConfiguration.class)
this(maxFrameLength,lengthFieldOffset,lengthFieldLength,lengthAdjustment,initialBytesToStrip,false); 
4 * Bytes.SIZEOF_LONG
traces.remove()
String.class
JavaAssistUtils.toPinpointParameterType(parameterTypes)
new MD5Renderer(model,false,true)
AcidUtils.getTableSnapshot(hive.getConf(),tbl)
DEFAULT_MAX=4096
new IllegalStateException(String.format("File \"%1$s\" has incorrect indentation in comment." + "Line %2$d: comment:%3$d, actual:%4$d.",aFileName,lineNumber,indentInComment,actualIndent))
static public final PowOut fastSlow=pow2Out; 
result.expectedMinimumMessageCount(2)
EXPLICIT_NO_UNSAFE_CAUSE != null
/**   * Change the permission of a file or directory specified by args.  */ public final class ChmodCommand extends AbstractAclCommand {   public ChmodCommand(  TachyonConf conf,  TachyonFileSystem tfs){     super(conf,tfs);   }   @Override public String getCommandName(){     return "chmod";   }   @Override protected int getNumOfArgs(){     return 2;   }   @Override public void run(  String... args) throws IOException {     String modeStr=args[0];     TachyonURI path=new TachyonURI(args[1]);     chmod(path,modeStr,false);   }   @Override public String getUsage(){     return "chmod <mode> <path>";   } } 
task.abort()
((Number)s.first()).doubleValue()
log.error("Both session() and unauthenticated() are set for this request, this is a bug, using session id.",new Throwable())
webSocketConnection.getRemote().sendStringByFuture(s)
BodyAvailabilityTest.class
EmitterProcessor.create(1,false)
private static final HBaseConfiguration config=new HBaseConfiguration(); 
!tmp.exists() || !tmp.isDirectory()
startServer(testAddress)
mjCtx.getOldMapJoin() == null || setReducer
"wrong partition, expected: " + getPartitionId() + " but found:"+ partitionId
id=17
monochrome=true
getIndexes().hasIndex() && OBJECT.equals(mapConfig.getInMemoryFormat())
cluster.getTypeFactory().createSqlType(SqlTypeName.DECIMAL,unscaled.toString().length(),bd.scale())
LOG.warn("Failed to get TachyonStore stream, the block " + currentBlockId + " will not be in TachyonStorage")
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
future.get(30,TimeUnit.SECONDS)
SimpleAttributeDefinitionBuilder.create("max-inclusive",ModelType.BOOLEAN,true)
getRedeliveryDelay()
options.removeUnusedVars || options.removeUnusedLocalVars
watch.taken()
timePassed >= 10000
edgeClass.isEnabled() && vizConfig.isShowArrows() && dataBridge.isDirected()
new ValueComparator(sortOrderAscending,type)
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class)
bLocations[0].getHosts()
GatherGetterAndSetterProperties.update(compiler,externs,root)
messageJournalEnabled=true
Mockito.doNothing().when(mFileSystemMasterClient).mount(alluxioPath,ufsPath,mountOptions)
model != null && model.getSelectedLayout() != null
TimeUnit.SECONDS.toMillis(5)
getClientConfig().getAddresses()
lastUpdate.after(updated) || lastUpdate.equals(updated)
items[27]
assertEquals(4933401l,received.get(0)[1])
elapsed >= config.getConnectionTimeout()
primitiveType == GL10.GL_POINTS
resultEndpoint.setResultWaitTime(5000)
LocalEjbReceiver.clone(resultCloner,exception)
sY != 0
globalSecurityDomain != null && !globalSecurityDomain.isEmpty()
field.getType()
new UnlockHandler(this)
id=34
a.length > count()
assertEquals(row.getField(0),3L)
Runnable t=new RunAfterTester(new DisconnectionBehavior(h2,h1),new MultiCallBuilder(h2)); 
LOG.warn("Failed to get files from " + baseDirectory.getAbsolutePath())
body.toByteArray()
new UnilateralSortMerger<TestData.Key,TestData.Value>(memoryManager,ioManager,40 * 1024 * 1024,1024 * 1024 * 1,10,2,keySerialization,valSerialization,keyComparator,reader,parentTask,0.7f)
new IOException("Test IOException")
line.substring(0,p).trim().toLowerCase(Locale.US)
row("p_comment",null,7.0,0.0,null,null,null)
RequestBody.create((byte[])bodyContents,mediaType)
/**   * Signal the maps/reduces to start.  */ static void signalTasks(MiniDFSCluster dfs,FileSystem fileSys,String mapSignalFile,String reduceSignalFile,int replication) throws Exception {   writeFile(dfs.getNameNode(),fileSys.getConf(),new Path(mapSignalFile),(short)replication);   writeFile(dfs.getNameNode(),fileSys.getConf(),new Path(reduceSignalFile),(short)replication); } 
analysis.getTypeWithCoercions(windowFunction)
(offset >= start && offset <= start + len) || (end >= start && end <= start + len) || (offset <= start && end >= start + len)
compositeBuffer(Integer.MAX_VALUE)
Void value
dfa == null || dfa.states.isEmpty()
new Notification(notification,nodeService)
new Color(0xbfbfbfff)
context.revertRestartRequired()
/**   * The exception thrown (if any) by the method called in  {@link #run()}  */ protected Exception exceptionThrown=null; 
new ClusterConfiguration(initialConfig.getName(),initialConfig.getMemberURIs())
id=18
SavedSearch.createSavedSearchList(get(getBaseURL() + "saved_searches.json",true))
IR.constNode(IR.name(shortName),googRequireNode)
options != null && options.getChildCount() > 0
BroadcasterFactory.getDefault().lookup(mapping,true)
new UnderFileStatus("dummy",0L,isDirectory,0L,"owner","group",(short)077)
setParams().xx()
clusterProperties.getMaxRedirects()
Configuration conf
prefSize(new Fixed(width),new Fixed(height))
privObj.getObjectName().equals("masking_test_druid") || privObj.getObjectName().startsWith("masking_test_druid_n")
retry.attempt()
dataFormatModel.setDescription(row.get("description"))
jniGetLocalAxisA(addr,tmp)
this == NTI_ONLY
Map.class
? extends T
setLowHighExpected(lowResults,highResults,expectedResults,BCUBED_TP,12440,12451.87,12451.87)
node.hasDefined(Constants.ALIAS)
new IncrementalIndexSegment(rtIndex,null)
field.getType()
memoryReservation.addAndGet(bytes)
Throwable t
MAX_PRETTY_PRINTED_PROPERTIES=10
TimeUnit.SECONDS.toMillis(5)
timeout=300000
stopwatch.elapsed(MILLISECONDS)
subtypeProps == null || subtypeProps.isEmpty()
AddressHelper.getPossibleSocketAddresses(address.getPort(),address.getHost(),1)
logger.error("table: {} column: {}, failed convert type {} to {}",tableName,columnName,value,sqlType)
new PeepholeSubstituteAlternateSyntax(false)
row2 * layerTileHeight
id=10837
mock.message(0).body(String.class)
uncollectedPointCreator.createUnCollectedPoint(timestamp)
resultEndpoint.assertIsSatisfied()
new byte[12]
ImmutableList<Integer>
visitor.visitMethodInsn(opCode.getOpCode(),target.getClassName(),name,getMethodDescription(),target.isInterface())
FilteredBatchServerViewProvider.class
order.getDosingInstructions()
tfs.ls(Constants.PATH_SEPARATOR,true)
!isCancelled0(result)
AvailablePortFinder.getNextAvailable(3000)
Status.createStatuseList(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/statuses/friends/T4J_hudson.json"))
db.createIndex(new BasicDBObject(FIELD_UPDATED_AT,1).append(FIELD_UNCOMMITTED_ENTRIES,1).append(FIELD_WRITTEN_MESSAGES_1M,1),new BasicDBObject("name","compound_0"))
conf.getRestBaseURL()
client.getStatusCodeReply()
LOG.error("XMLStreamReader {} not supporting Location",reader)
queryStrings.append(key)
source != null && !source.isEmpty()
(UndeclaredThrowableException)unwrapped
Multimap<JSType,JSError>
allowedIdentifiersCheckDigitsInts[i]
reservedWords.contains(codegenProperty.datatypeWithEnum) || name.equals(codegenProperty.datatypeWithEnum)
monochrome=false
Assert.fail(String.format("Expected file %s being deleted but it was not.",filePath))
logger.finest("Optimized Selector: " + selector.getClass().getName())
queueView.get().getExcerpt(index.longValue())
uncompressedProto.length < 2570000
new DateTime(Long.parseLong(firstTimestamp) * 1000,DateTimeZone.UTC)
BED(355)
k < FILES
AdviceWithTasks.beforeByToString(route,toString,answer,selectFirst,selectLast,selectFrom,selectTo,maxDeep)
new SctpMessage(protocolIdentifier,streamIdentifier,unordered,msg.retain())
Exception e
path.getPath()
op.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(false)
variables.putAll(transientVariabes)
mMountTable.resolve(getPath(lastInode)).toString()
tableMetadataBuilder(DEFAULT_TEST_LINEITEMS).column("orderkey",BIGINT).column("partkey",BIGINT).column("quantity",DOUBLE)
DEFAULT_NUMBER_OF_READ_BUFFERS=256
ENGLISH_BIDIRECTIONAL_SENTENCE_ACCURACY=.563
ctx.alloc().buffer()
queryNotifyLatch.await(1000,TimeUnit.MILLISECONDS)
new GetExecutionVariableInstancesCmd(executionId,variableNames,true,locale,withLocalizationFallback)
Color.fromRGB(0x253192)
log.info("Wanted to terminate %,d workers, but couldn't find any lazy ones!",excessWorkers)
DEFAULT_MOVE_COST=7
currentMode == MODE_PULL_DOWN_TO_REFRESH
Integer.toString(9)
@Message(id=14151,value="Could not find view %s for EJB %s") IllegalStateException viewNotFound(String viewClass,String ejbName); 
localAnchorB.set(joint.getLocalAnchorB().x,joint.getLocalAnchorB().y)
createPermissionsXmlAsset(new JndiPermission("*","lookup"),new RuntimePermission("accessClassInPackage.com.sun.jndi.ldap"))
Lists.newArrayList(stream1,stream2)
readUnlock()
Math.min(retryIntervalMillis,timeout.timeLeft().toMillis())
StringUtils.isEmpty(password)
ch.unsafe().flush()
event.isCancelled()
child.tagName.equals("base") || child.tagName.equals("script") || child.tagName.equals("link")|| child.tagName.equals("meta")|| child.tagName.equals("title")|| child.tagName.equals("style")|| child.tagName.equals("object")
2 >= buf.length - count
id=15
mapContainer.getMapConfig().getMaxIdleSeconds() * 1000L
cacheScaled5.setColors(red)
DEFAULT_MAX_UNION_SIZE=30
ChannelOption<Boolean>
r.getRequest(true)
id=10835
privObj.getObjectName().equals("masking_test") || privObj.getObjectName().startsWith("masking_test_n")
ChannelBuffers.wrappedBuffer(sb.toString().getBytes(bodyCharset))
new SpdySessionStatus(2,"INTERNAL_ERROR")
new ConnectorRefsAttribute(CommonAttributes.STATIC_CONNECTORS,true,true)
assertEquals(3,map.size())
Long olderThan
Thread.sleep(10000)
Thread.sleep(3000)
systemId.length()
DUE_DILIGENCE_MILLIS=100
IllegalStateException nsee
new AutoValue_RegistrationResponse(configuration,configurationOverride,actions,assignments)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class ConditionBasicDistributedTest extends ConditionAbstractTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(2).newInstances();   } } 
assertFalse(predicate.apply(pickleEvent))
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
pieces.length <= tagColumn
Color.fromRGB(0x7B2FBE)
Assert.assertNotNull(ex.getCause())
rsMeta.getColumnLabel(i + 1)
mf.filter(r,originalMessage,transformed.message())
SimpleAttributeDefinitionBuilder.create(ModelDescriptionConstants.ANY_IPV4_ADDRESS,ModelType.BOOLEAN).setAllowExpression(false).setAllowNull(true)
executor.execute(new NamedRunnable("OkHttp %s stream %d",hostname,streamId){   @Override public void execute(){     try {       writeSynReset(streamId,errorCode);     }  catch (    IOException ignored) {     }   } } )
Arrays.asList("ErrorResponse","Response","Int","Int32","Int64","Int64","Float","Double","Bool","Void","String","Character","AnyObject","Any","Error","URL","class","Class","break","as","associativity","deinit","case","dynamicType","convenience","enum","continue","false","dynamic","extension","default","is","didSet","func","do","nil","final","import","else","self","get","init","fallthrough","Self","infix","internal","for","super","inout","let","if","true","lazy","operator","in","COLUMN","left","private","return","FILE","mutating","protocol","switch","FUNCTION","none","public","where","LINE","nonmutating","static","while","optional","struct","override","subscript","postfix","typealias","precedence","var","prefix","Protocol","required","right","set","Type","unowned","weak","Data")
new PulsarComponent(context)
clusterService.getIndexerFailures(1,0)
id=10844
new IndexOutOfBoundsException()
new GdxRuntimeException("Failed to read Vorbis.",e)
JavaConversions.asJavaIterable(kafkaLog.logSegments(committedOffset,Long.MAX_VALUE))
new ClusterConfiguration("whatever","cluster://1","cluster://2")
NbBundle.getMessage(ImporterGEXF.class,"importerGEXF_error_pid",id)
oldOverride.addParameter("enabled","enabled")
zkWorker2.getWorker()
EnumSet.of(DatabaseDriver.UNKNOWN,DatabaseDriver.ORACLE,DatabaseDriver.DB2,DatabaseDriver.DB2_AS400,DatabaseDriver.INFORMIX,DatabaseDriver.SAP,DatabaseDriver.TERADATA)
Tuple2.of(timeoutPattern4,12L)
StringUtil.in(name,"base","basefont","bgsound","command","link","meta","noframes","script","style","title")
GL20.glVertexAttribPointer(indx,size,type,normalized,stride,((ByteBuffer)buffer).asFloatBuffer())
private final DynamicTransformerRegistry dynamicTransformerRegistry; 
s.elapsed(TimeUnit.NANOSECONDS)
!resource.getAtmosphereResourceEvent().isClosedByClient() && !resource.getAtmosphereResourceEvent().isClosedByApplication() && !resource.isCancelled()
packFileName.substring(0,packFileName.length() - settings.atlasExtension.length())
LOG.info("Read offset {} before start of log at {}, starting to read from the beginning of the journal.",readOffset,logStartOffset)
GL20.glUniform2iv(location,v)
annotations == null || annotations.isEmpty()
tileElement.getChildByName("properties")
@ConditionalOnEnabledHealthIndicator("db")
Gdx.files.internal(fileName).pathWithoutExtension()
strategiesBuilder::customMessageWriter
n.doubleValue()
url3 != null
assertEquals("ClassInfo's name should be non-null",ex.getCause().getMessage())
dic.buildRouterChain()
LOGGER.debug("{} - Reset ({}) on connection {}",poolName,resetBits != 0 ? stringFromResetBits(resetBits) : "nothing",poolEntry.connection)
/**   * SSH port.  */ private Integer port=2000; 
getBatchId()
DiagnosticGroups.registerGroup("functionParams",FunctionTypeBuilder.INEXISTENT_PARAM,FunctionTypeBuilder.OPTIONAL_ARG_AT_END)
i < 200
executor.execute(new NamedRunnable("OkHttp %s stream %d",hostName,streamId){   @Override public void execute(){     try {       handler.receive(newStream);     }  catch (    IOException e) {       throw new RuntimeException(e);     }   } } )
found.size() >= 1
new Whitelist().addTags("a","b","blockquote","br","caption","cite","code","col","colgroup","dd","div","dl","dt","em","h1","h2","h3","h4","h5","h6","i","img","li","ol","p","pre","q","small","span","strike","strong","sub","sup","table","tbody","td","tfoot","th","thead","tr","u","ul")
1 << 15
getNonCompilablePath("InputPackageDeclarationDiffDirectoryAtParent.java")
factory.get(mBodyWildcard,NO_ANNOTATIONS,retrofit)
this.instanceManager != null && this.scheduler != null
lookup="java:jboss/datasources/ExampleDS"
return facebookProperties; 
request.getRemoteAddr()
entry != null && !DropboxUploadMode.force.equals(mode)
{MAGIC_HIGH,MAGIC_LOW,0x02,20,0,0,0,0,0,0,0,0,0,0,0,0}
log.debug(currentThread() + String.format("Trying to recover from dead Channel: %s ",channel))
name.startsWith("java.") || name.startsWith("javax.") || name.startsWith("junit.")|| name.startsWith("sun.")|| name.startsWith("com.sun.")|| name.contains("cglib")
BlobStoreUtils.class
assertEquals(2,props.getConfigPathPatterns().length)
new PrestoException(INVALID_CAST_ARGUMENT,"Value cannot be cast to time: " + value.toStringUtf8(),e)
new InetSocketAddress(configuration.getRestListenUri().getHost(),configuration.getRestListenUri().getPort())
getMockEndpoint("mock:line").expectedMinimumMessageCount(0)
!isSdkLocationValid(sdkLocation)
new ArrayList<>(1)
context.start()
"http".equals(protocol) || "ws".equals(protocol)
public Builder setMaximumConnectionsPerHost(int defaultMaxConnectionPerHost){   configBuilder.setMaximumConnectionsPerHost(defaultMaxConnectionPerHost);   return this; } 
assertEquals(13,tokens.size())
len % (1024 * 1024) / 10000
builder200.build()
(JobFound)result
delay=5000
assertSpnegoWorkflow(uri,mechTypes,kerberosToken,kerberosToken,false,true)
logger.trace("rapidRefreshFutureEnd stopping")
configureAtmosphereInterceptor(scFacade)
new CommandLineException(result.toString())
Arrays.<Class<?>>asList(org.nd4j.linalg.api.ops.DynamicCustomOp.class,org.nd4j.linalg.api.ops.NoOp.class,org.nd4j.linalg.api.ops.custom.BarnesEdgeForces.class,org.nd4j.linalg.api.ops.custom.BarnesHutGains.class,org.nd4j.linalg.api.ops.custom.BarnesHutSymmetrize.class,org.nd4j.linalg.api.ops.custom.SpTreeCell.class,org.nd4j.linalg.api.ops.custom.Flatten.class,org.nd4j.linalg.api.ops.impl.broadcast.BiasAdd.class,org.nd4j.linalg.api.ops.impl.broadcast.BiasAddGrad.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastAMax.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastAMin.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastAddOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastCopyOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastDivOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastGradientArgs.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastMax.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastMin.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastMulOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastRDivOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastRSubOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastSubOp.class,org.nd4j.linalg.api.ops.impl.broadcast.BroadcastTo.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastEqualTo.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastGreaterThan.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastGreaterThanOrEqual.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastLessThan.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastLessThanOrEqual.class,org.nd4j.linalg.api.ops.impl.broadcast.bool.BroadcastNotEqual.class,org.nd4j.linalg.api.ops.impl.controlflow.If.class,org.nd4j.linalg.api.ops.impl.controlflow.IfDerivative.class,org.nd4j.linalg.api.ops.impl.controlflow.Select.class,org.nd4j.linalg.api.ops.impl.controlflow.Where.class,org.nd4j.linalg.api.ops.impl.controlflow.WhereNumpy.class,org.nd4j.linalg.api.ops.impl.controlflow.While.class,org.nd4j.linalg.api.ops.impl.controlflow.WhileDerivative.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.Enter.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.Exit.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.LoopCond.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.Merge.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.NextIteration.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.StopGradient.class,org.nd4j.linalg.api.ops.impl.controlflow.compat.Switch.class,org.nd4j.linalg.api.ops.impl.grid.FreeGridOp.class,org.nd4j.linalg.api.ops.impl.image.CropAndResize.class,org.nd4j.linalg.api.ops.impl.image.ExtractImagePatches.class,org.nd4j.linalg.api.ops.impl.image.NonMaxSuppression.class,org.nd4j.linalg.api.ops.impl.image.ResizeBilinear.class,org.nd4j.linalg.api.ops.impl.image.ResizeNearestNeighbor.class,org.nd4j.linalg.api.ops.impl.indexaccum.FirstIndex.class,org.nd4j.linalg.api.ops.impl.indexaccum.IAMax.class,org.nd4j.linalg.api.ops.impl.indexaccum.IAMin.class,org.nd4j.linalg.api.ops.impl.indexaccum.IMax.class,org.nd4j.linalg.api.ops.impl.indexaccum.IMin.class,org.nd4j.linalg.api.ops.impl.indexaccum.LastIndex.class,org.nd4j.linalg.api.ops.impl.indexaccum.custom.ArgMax.class,org.nd4j.linalg.api.ops.impl.indexaccum.custom.ArgMin.class,org.nd4j.linalg.api.ops.impl.layers.ExternalErrorsFunction.class,org.nd4j.linalg.api.ops.impl.layers.Linear.class,org.nd4j.linalg.api.ops.impl.layers.convolution.AvgPooling2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.AvgPooling3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.BatchNorm.class,org.nd4j.linalg.api.ops.impl.layers.convolution.BatchNormDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Col2Im.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv1D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv2DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Conv3DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv2DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv2DTF.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DeConv3DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DepthToSpace.class,org.nd4j.linalg.api.ops.impl.layers.convolution.DepthwiseConv2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Im2col.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Im2colBp.class,org.nd4j.linalg.api.ops.impl.layers.convolution.LocalResponseNormalization.class,org.nd4j.linalg.api.ops.impl.layers.convolution.LocalResponseNormalizationDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.MaxPooling2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.MaxPooling3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Pooling2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Pooling2DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Pooling3D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Pooling3DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.SConv2D.class,org.nd4j.linalg.api.ops.impl.layers.convolution.SConv2DDerivative.class,org.nd4j.linalg.api.ops.impl.layers.convolution.SpaceToDepth.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Upsampling2d.class,org.nd4j.linalg.api.ops.impl.layers.convolution.Upsampling2dDerivative.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.GRUCell.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.LSTMBlockCell.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.LSTMCell.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.LSTMLayer.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.SRU.class,org.nd4j.linalg.api.ops.impl.layers.recurrent.SRUCell.class,org.nd4j.linalg.api.ops.impl.loss.AbsoluteDifferenceLoss.class,org.nd4j.linalg.api.ops.impl.loss.CosineDistanceLoss.class,org.nd4j.linalg.api.ops.impl.loss.HingeLoss.class,org.nd4j.linalg.api.ops.impl.loss.HuberLoss.class,org.nd4j.linalg.api.ops.impl.loss.L2Loss.class,org.nd4j.linalg.api.ops.impl.loss.LogLoss.class,org.nd4j.linalg.api.ops.impl.loss.LogPoissonLoss.class,org.nd4j.linalg.api.ops.impl.loss.MeanPairwiseSquaredErrorLoss.class,org.nd4j.linalg.api.ops.impl.loss.MeanSquaredErrorLoss.class,org.nd4j.linalg.api.ops.impl.loss.SigmoidCrossEntropyLoss.class,org.nd4j.linalg.api.ops.impl.loss.SoftmaxCrossEntropyLoss.class,org.nd4j.linalg.api.ops.impl.loss.SoftmaxCrossEntropyWithLogitsLoss.class,org.nd4j.linalg.api.ops.impl.loss.SparseSoftmaxCrossEntropyLossWithLogits.class,org.nd4j.linalg.api.ops.impl.loss.WeightedCrossEntropyLoss.class,org.nd4j.linalg.api.ops.impl.loss.bp.AbsoluteDifferenceLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.CosineDistanceLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.HingeLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.HuberLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.LogLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.LogPoissonLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.MeanPairwiseSquaredErrorLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.MeanSquaredErrorLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.SigmoidCrossEntropyLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.SoftmaxCrossEntropyLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.SoftmaxCrossEntropyWithLogitsLossBp.class,org.nd4j.linalg.api.ops.impl.loss.bp.SparseSoftmaxCrossEntropyLossWithLogitsBp.class,org.nd4j.linalg.api.ops.impl.meta.InvertedPredicateMetaOp.class,org.nd4j.linalg.api.ops.impl.meta.PostulateMetaOp.class,org.nd4j.linalg.api.ops.impl.meta.PredicateMetaOp.class,org.nd4j.linalg.api.ops.impl.meta.ReduceMetaOp.class,org.nd4j.linalg.api.ops.impl.nlp.CbowRound.class,org.nd4j.linalg.api.ops.impl.nlp.SkipGramRound.class,org.nd4j.linalg.api.ops.impl.reduce.HashCode.class,org.nd4j.linalg.api.ops.impl.reduce.Mmul.class,org.nd4j.linalg.api.ops.impl.reduce.MmulBp.class,org.nd4j.linalg.api.ops.impl.reduce.Moments.class,org.nd4j.linalg.api.ops.impl.reduce.NormalizeMoments.class,org.nd4j.linalg.api.ops.impl.reduce.SufficientStatistics.class,org.nd4j.linalg.api.ops.impl.reduce.TensorMmul.class,org.nd4j.linalg.api.ops.impl.reduce.ZeroFraction.class,org.nd4j.linalg.api.ops.impl.reduce.bool.All.class,org.nd4j.linalg.api.ops.impl.reduce.bool.Any.class,org.nd4j.linalg.api.ops.impl.reduce.bool.IsInf.class,org.nd4j.linalg.api.ops.impl.reduce.bool.IsNaN.class,org.nd4j.linalg.api.ops.impl.reduce.bp.CumProdBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.CumSumBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.DotBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.MaxBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.MeanBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.MinBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.Norm1Bp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.Norm2Bp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.NormMaxBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.ProdBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.SquaredNormBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.StandardDeviationBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.SumBp.class,org.nd4j.linalg.api.ops.impl.reduce.bp.VarianceBp.class,org.nd4j.linalg.api.ops.impl.reduce.custom.BatchMmul.class,org.nd4j.linalg.api.ops.impl.reduce.custom.LogSumExp.class,org.nd4j.linalg.api.ops.impl.reduce.floating.AMean.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Bias.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Entropy.class,org.nd4j.linalg.api.ops.impl.reduce.floating.LogEntropy.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Mean.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Norm1.class,org.nd4j.linalg.api.ops.impl.reduce.floating.Norm2.class,org.nd4j.linalg.api.ops.impl.reduce.floating.NormMax.class,org.nd4j.linalg.api.ops.impl.reduce.floating.ShannonEntropy.class,org.nd4j.linalg.api.ops.impl.reduce.floating.SquaredNorm.class,org.nd4j.linalg.api.ops.impl.reduce.longer.CountNonZero.class,org.nd4j.linalg.api.ops.impl.reduce.longer.CountZero.class,org.nd4j.linalg.api.ops.impl.reduce.longer.MatchCondition.class,org.nd4j.linalg.api.ops.impl.reduce.same.AMax.class,org.nd4j.linalg.api.ops.impl.reduce.same.AMin.class,org.nd4j.linalg.api.ops.impl.reduce.same.ASum.class,org.nd4j.linalg.api.ops.impl.reduce.same.Max.class,org.nd4j.linalg.api.ops.impl.reduce.same.Min.class,org.nd4j.linalg.api.ops.impl.reduce.same.Prod.class,org.nd4j.linalg.api.ops.impl.reduce.same.Sum.class,org.nd4j.linalg.api.ops.impl.reduce3.CosineDistance.class,org.nd4j.linalg.api.ops.impl.reduce3.CosineSimilarity.class,org.nd4j.linalg.api.ops.impl.reduce3.Dot.class,org.nd4j.linalg.api.ops.impl.reduce3.EqualsWithEps.class,org.nd4j.linalg.api.ops.impl.reduce3.EuclideanDistance.class,org.nd4j.linalg.api.ops.impl.reduce3.HammingDistance.class,org.nd4j.linalg.api.ops.impl.reduce3.JaccardDistance.class,org.nd4j.linalg.api.ops.impl.reduce3.ManhattanDistance.class,org.nd4j.linalg.api.ops.impl.scalar.LeakyReLU.class,org.nd4j.linalg.api.ops.impl.scalar.LogX.class,org.nd4j.linalg.api.ops.impl.scalar.Pow.class,org.nd4j.linalg.api.ops.impl.scalar.PowDerivative.class,org.nd4j.linalg.api.ops.impl.scalar.RectifiedLinear.class,org.nd4j.linalg.api.ops.impl.scalar.Relu6.class,org.nd4j.linalg.api.ops.impl.scalar.ReplaceNans.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarAdd.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarDivision.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarFMod.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarMax.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarMin.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarMultiplication.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarRemainder.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarReverseDivision.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarReverseSubtraction.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarSet.class,org.nd4j.linalg.api.ops.impl.scalar.ScalarSubtraction.class,org.nd4j.linalg.api.ops.impl.scalar.Step.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarAnd.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarEps.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarEquals.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarGreaterThan.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarGreaterThanOrEqual.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarLessThan.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarLessThanOrEqual.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarNot.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarNotEquals.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarOr.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarSetValue.class,org.nd4j.linalg.api.ops.impl.scalar.comparison.ScalarXor.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterAdd.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterDiv.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterMax.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterMin.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterMul.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterNd.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterNdAdd.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterNdSub.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterNdUpdate.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterSub.class,org.nd4j.linalg.api.ops.impl.scatter.ScatterUpdate.class,org.nd4j.linalg.api.ops.impl.shape.ApplyGradientDescent.class,org.nd4j.linalg.api.ops.impl.shape.Broadcast.class,org.nd4j.linalg.api.ops.impl.shape.BroadcastDynamicShape.class,org.nd4j.linalg.api.ops.impl.shape.Concat.class,org.nd4j.linalg.api.ops.impl.shape.ConfusionMatrix.class,org.nd4j.linalg.api.ops.impl.shape.Cross.class,org.nd4j.linalg.api.ops.impl.shape.Diag.class,org.nd4j.linalg.api.ops.impl.shape.DiagPart.class,org.nd4j.linalg.api.ops.impl.shape.ExpandDims.class,org.nd4j.linalg.api.ops.impl.shape.Eye.class,org.nd4j.linalg.api.ops.impl.shape.Gather.class,org.nd4j.linalg.api.ops.impl.shape.GatherNd.class,org.nd4j.linalg.api.ops.impl.shape.Linspace.class,org.nd4j.linalg.api.ops.impl.shape.MergeAvg.class,org.nd4j.linalg.api.ops.impl.shape.MergeMax.class,org.nd4j.linalg.api.ops.impl.shape.MergeSum.class,org.nd4j.linalg.api.ops.impl.shape.MeshGrid.class,org.nd4j.linalg.api.ops.impl.shape.OneHot.class,org.nd4j.linalg.api.ops.impl.shape.OnesLike.class,org.nd4j.linalg.api.ops.impl.shape.ParallelStack.class,org.nd4j.linalg.api.ops.impl.shape.Permute.class,org.nd4j.linalg.api.ops.impl.shape.Rank.class,org.nd4j.linalg.api.ops.impl.shape.ReductionShape.class,org.nd4j.linalg.api.ops.impl.shape.Repeat.class,org.nd4j.linalg.api.ops.impl.shape.Reshape.class,org.nd4j.linalg.api.ops.impl.shape.SequenceMask.class,org.nd4j.linalg.api.ops.impl.shape.Shape.class,org.nd4j.linalg.api.ops.impl.shape.ShapeN.class,org.nd4j.linalg.api.ops.impl.shape.Size.class,org.nd4j.linalg.api.ops.impl.shape.SizeAt.class,org.nd4j.linalg.api.ops.impl.shape.Slice.class,org.nd4j.linalg.api.ops.impl.shape.Split.class,org.nd4j.linalg.api.ops.impl.shape.SplitV.class,org.nd4j.linalg.api.ops.impl.shape.Squeeze.class,org.nd4j.linalg.api.ops.impl.shape.Stack.class,org.nd4j.linalg.api.ops.impl.shape.StridedSlice.class,org.nd4j.linalg.api.ops.impl.shape.Tile.class,org.nd4j.linalg.api.ops.impl.shape.Transpose.class,org.nd4j.linalg.api.ops.impl.shape.Unstack.class,org.nd4j.linalg.api.ops.impl.shape.ZerosLike.class,org.nd4j.linalg.api.ops.impl.shape.bp.ConcatBp.class,org.nd4j.linalg.api.ops.impl.shape.bp.SliceBp.class,org.nd4j.linalg.api.ops.impl.shape.bp.StridedSliceBp.class,org.nd4j.linalg.api.ops.impl.shape.bp.TileBp.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArray.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayConcat.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayGather.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayRead.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayScatter.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArraySize.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArraySplit.class,org.nd4j.linalg.api.ops.impl.shape.tensorops.TensorArrayWrite.class,org.nd4j.linalg.api.ops.impl.summarystats.StandardDeviation.class,org.nd4j.linalg.api.ops.impl.summarystats.Variance.class,org.nd4j.linalg.api.ops.impl.transforms.Angle.class,org.nd4j.linalg.api.ops.impl.transforms.Assert.class,org.nd4j.linalg.api.ops.impl.transforms.BinCount.class,org.nd4j.linalg.api.ops.impl.transforms.CheckNumerics.class,org.nd4j.linalg.api.ops.impl.transforms.Cholesky.class,org.nd4j.linalg.api.ops.impl.transforms.Constant.class,org.nd4j.linalg.api.ops.impl.transforms.Histogram.class,org.nd4j.linalg.api.ops.impl.transforms.HistogramFixedWidth.class,org.nd4j.linalg.api.ops.impl.transforms.IdentityN.class,org.nd4j.linalg.api.ops.impl.transforms.MaxOut.class,org.nd4j.linalg.api.ops.impl.transforms.NthElement.class,org.nd4j.linalg.api.ops.impl.transforms.Pad.class,org.nd4j.linalg.api.ops.impl.transforms.ReluLayer.class,org.nd4j.linalg.api.ops.impl.transforms.any.Assign.class,org.nd4j.linalg.api.ops.impl.transforms.any.IsMax.class,org.nd4j.linalg.api.ops.impl.transforms.bool.BooleanNot.class,org.nd4j.linalg.api.ops.impl.transforms.bool.IsFinite.class,org.nd4j.linalg.api.ops.impl.transforms.bool.IsInf.class,org.nd4j.linalg.api.ops.impl.transforms.bool.IsNaN.class,org.nd4j.linalg.api.ops.impl.transforms.bool.MatchConditionTransform.class,org.nd4j.linalg.api.ops.impl.transforms.clip.ClipByNorm.class,org.nd4j.linalg.api.ops.impl.transforms.clip.ClipByNormBp.class,org.nd4j.linalg.api.ops.impl.transforms.clip.ClipByValue.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.CompareAndReplace.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.CompareAndSet.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.Eps.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldEqualTo.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldGreaterThan.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldGreaterThanOrEqual.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldLessThan.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldLessThanOrEqual.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldMax.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldMin.class,org.nd4j.linalg.api.ops.impl.transforms.comparison.OldNotEqualTo.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ATan2.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Assign.class,org.nd4j.linalg.api.ops.impl.transforms.custom.BatchToSpace.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Choose.class,org.nd4j.linalg.api.ops.impl.transforms.custom.CumProd.class,org.nd4j.linalg.api.ops.impl.transforms.custom.CumSum.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Dilation2D.class,org.nd4j.linalg.api.ops.impl.transforms.custom.DotProductAttention.class,org.nd4j.linalg.api.ops.impl.transforms.custom.DotProductAttentionBp.class,org.nd4j.linalg.api.ops.impl.transforms.custom.DynamicPartition.class,org.nd4j.linalg.api.ops.impl.transforms.custom.DynamicStitch.class,org.nd4j.linalg.api.ops.impl.transforms.custom.EqualTo.class,org.nd4j.linalg.api.ops.impl.transforms.custom.FakeQuantWithMinMaxArgs.class,org.nd4j.linalg.api.ops.impl.transforms.custom.FakeQuantWithMinMaxVars.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Fill.class,org.nd4j.linalg.api.ops.impl.transforms.custom.GreaterThan.class,org.nd4j.linalg.api.ops.impl.transforms.custom.GreaterThanOrEqual.class,org.nd4j.linalg.api.ops.impl.transforms.custom.InTopK.class,org.nd4j.linalg.api.ops.impl.transforms.custom.InvertPermutation.class,org.nd4j.linalg.api.ops.impl.transforms.custom.IsNonDecreasing.class,org.nd4j.linalg.api.ops.impl.transforms.custom.IsNumericTensor.class,org.nd4j.linalg.api.ops.impl.transforms.custom.IsStrictlyIncreasing.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LayerNorm.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LayerNormBp.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LessThan.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LessThanOrEqual.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ListDiff.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogMatrixDeterminant.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogSoftMax.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogicalAnd.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogicalNot.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogicalOr.class,org.nd4j.linalg.api.ops.impl.transforms.custom.LogicalXor.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixDeterminant.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixDiag.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixDiagPart.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixInverse.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MatrixSetDiag.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Max.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Min.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MirrorPad.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MultiHeadDotProductAttention.class,org.nd4j.linalg.api.ops.impl.transforms.custom.MultiHeadDotProductAttentionBp.class,org.nd4j.linalg.api.ops.impl.transforms.custom.NotEqualTo.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ParallelConcat.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Pow.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Reverse.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ReverseSequence.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ReverseV2.class,org.nd4j.linalg.api.ops.impl.transforms.custom.SoftMax.class,org.nd4j.linalg.api.ops.impl.transforms.custom.SpaceToBatch.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Standardize.class,org.nd4j.linalg.api.ops.impl.transforms.custom.StandardizeBp.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Svd.class,org.nd4j.linalg.api.ops.impl.transforms.custom.TopK.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Trace.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Unique.class,org.nd4j.linalg.api.ops.impl.transforms.custom.UniqueWithCounts.class,org.nd4j.linalg.api.ops.impl.transforms.custom.XwPlusB.class,org.nd4j.linalg.api.ops.impl.transforms.custom.Zeta.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentMax.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentMean.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentMin.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentProd.class,org.nd4j.linalg.api.ops.impl.transforms.custom.segment.SegmentSum.class,org.nd4j.linalg.api.ops.impl.transforms.dtype.Cast.class,org.nd4j.linalg.api.ops.impl.transforms.floating.RSqrt.class,org.nd4j.linalg.api.ops.impl.transforms.floating.Sqrt.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.CubeDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.DynamicPartitionBp.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.ELUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.GradientBackwardsMarker.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.HardSigmoidDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.HardTanhDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.LeakyReLUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.LogSoftMaxDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.RationalTanhDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.RectifiedTanhDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.Relu6Derivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.SELUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.SigmoidDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.SoftSignDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.SoftmaxBp.class,org.nd4j.linalg.api.ops.impl.transforms.gradient.TanhDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.BinaryMinimalRelativeError.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.BinaryRelativeError.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.RelativeError.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.Set.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.AddOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.Axpy.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.CopyOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.DivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.FModOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.FloorDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.FloorModOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.MergeAddOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.MulOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.ModOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldAddOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldAtan2Op.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldFModOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldFloorDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldMulOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldRDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldRSubOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.OldSubOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.PowPairwise.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.RDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.RSubOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.RealDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.RemainderOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.SquaredDifferenceOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.SubOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.TruncateDivOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.AddBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.DivBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.FloorDivBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.FloorModBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.MulBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.RDivBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.RSubBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.SquaredDifferenceBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.arithmetic.bp.SubBpOp.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.bool.And.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.bool.Not.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.bool.Or.class,org.nd4j.linalg.api.ops.impl.transforms.pairwise.bool.Xor.class,org.nd4j.linalg.api.ops.impl.transforms.same.AMax.class,org.nd4j.linalg.api.ops.impl.transforms.same.AMin.class,org.nd4j.linalg.api.ops.impl.transforms.same.Abs.class,org.nd4j.linalg.api.ops.impl.transforms.same.Ceil.class,org.nd4j.linalg.api.ops.impl.transforms.same.Cube.class,org.nd4j.linalg.api.ops.impl.transforms.same.Floor.class,org.nd4j.linalg.api.ops.impl.transforms.same.Identity.class,org.nd4j.linalg.api.ops.impl.transforms.same.Max.class,org.nd4j.linalg.api.ops.impl.transforms.same.Min.class,org.nd4j.linalg.api.ops.impl.transforms.same.Negative.class,org.nd4j.linalg.api.ops.impl.transforms.same.OldIdentity.class,org.nd4j.linalg.api.ops.impl.transforms.same.OldReverse.class,org.nd4j.linalg.api.ops.impl.transforms.same.OneMinus.class,org.nd4j.linalg.api.ops.impl.transforms.same.Reciprocal.class,org.nd4j.linalg.api.ops.impl.transforms.same.Round.class,org.nd4j.linalg.api.ops.impl.transforms.same.Sign.class,org.nd4j.linalg.api.ops.impl.transforms.same.Square.class,org.nd4j.linalg.api.ops.impl.transforms.same.TimesOneMinus.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentMax.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentMean.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentMin.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentProd.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentSqrtN.class,org.nd4j.linalg.api.ops.impl.transforms.segment.UnsortedSegmentSum.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentMaxBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentMeanBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentMinBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentProdBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.SegmentSumBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentMaxBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentMeanBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentMinBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentProdBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentSqrtNBp.class,org.nd4j.linalg.api.ops.impl.transforms.segment.bp.UnsortedSegmentSumBp.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ACos.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ACosh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ASin.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ASinh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ATan.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ATanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Cos.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Cosh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.ELU.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Erf.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Erfc.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Exp.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Expm1.class,org.nd4j.linalg.api.ops.impl.transforms.strict.GELU.class,org.nd4j.linalg.api.ops.impl.transforms.strict.GELUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.HardSigmoid.class,org.nd4j.linalg.api.ops.impl.transforms.strict.HardTanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Log.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Log1p.class,org.nd4j.linalg.api.ops.impl.transforms.strict.LogSigmoid.class,org.nd4j.linalg.api.ops.impl.transforms.strict.PreciseGELU.class,org.nd4j.linalg.api.ops.impl.transforms.strict.PreciseGELUDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.RationalTanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.RectifiedTanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Rint.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SELU.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SetRange.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Sigmoid.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SigmoidDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Sin.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Sinh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SoftPlus.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SoftSign.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Stabilize.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Swish.class,org.nd4j.linalg.api.ops.impl.transforms.strict.SwishDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Tan.class,org.nd4j.linalg.api.ops.impl.transforms.strict.TanDerivative.class,org.nd4j.linalg.api.ops.impl.transforms.strict.Tanh.class,org.nd4j.linalg.api.ops.impl.transforms.strict.TanhDerivative.class,org.nd4j.linalg.api.ops.persistence.RestoreV2.class,org.nd4j.linalg.api.ops.persistence.SaveV2.class,org.nd4j.linalg.api.ops.random.compat.RandomStandardNormal.class,org.nd4j.linalg.api.ops.random.custom.DistributionUniform.class,org.nd4j.linalg.api.ops.random.custom.RandomBernoulli.class,org.nd4j.linalg.api.ops.random.custom.RandomExponential.class,org.nd4j.linalg.api.ops.random.custom.RandomNormal.class,org.nd4j.linalg.api.ops.random.impl.AlphaDropOut.class,org.nd4j.linalg.api.ops.random.impl.BernoulliDistribution.class,org.nd4j.linalg.api.ops.random.impl.BinomialDistribution.class,org.nd4j.linalg.api.ops.random.impl.BinomialDistributionEx.class,org.nd4j.linalg.api.ops.random.impl.Choice.class,org.nd4j.linalg.api.ops.random.impl.DropOut.class,org.nd4j.linalg.api.ops.random.impl.DropOutInverted.class,org.nd4j.linalg.api.ops.random.impl.GaussianDistribution.class,org.nd4j.linalg.api.ops.random.impl.Linspace.class,org.nd4j.linalg.api.ops.random.impl.LogNormalDistribution.class,org.nd4j.linalg.api.ops.random.impl.ProbablisticMerge.class,org.nd4j.linalg.api.ops.random.impl.Range.class,org.nd4j.linalg.api.ops.random.impl.TruncatedNormalDistribution.class,org.nd4j.linalg.api.ops.random.impl.UniformDistribution.class,org.nd4j.linalg.api.ops.impl.transforms.custom.ShiftBits.class,org.nd4j.linalg.api.ops.impl.transforms.custom.RShiftBits.class,org.nd4j.linalg.api.ops.impl.transforms.custom.CyclicShiftBits.class,org.nd4j.linalg.api.ops.impl.transforms.custom.CyclicRShiftBits.class)
return 1; 
super(pipeline,null,HEAD_NAME,true,true); 
!file.getName().startsWith("branched-")
entry.getValue().accessibleNodeLabels
id=16511
item.annotationType()
Color.fromRGB(0xD88198)
GL11.glTexParameteriv(target,pname,params)
context.registerSubsystem(SUBSYSTEM_NAME,1,1)
this.thrown.expect(IllegalStateException.class)
LOG.error(result.getDescription(),t)
UriBuilder.fromResource(StreamAlertResource.class).build(streamid)
id=5
existingOne != null
Sets.<Long>newHashSet()
decodeLast(ctx,e.getChannel(),replayable,state)
ImmutableList<INPUT>
!ufsDeleter.delete(alluxioUriToDel,delInode)
id=29
workerCount--
id=10874
inStream.remaining()
"maxHeaderSize must be a positive integer: " + maxHeaderSize
Throwable ex
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class ReplicatedMapHitsAndLastAccessTimeTest extends ReplicatedMapAbstractTest {   @Test public void test_hitsAndLastAccessTimeSetToAnyValueAfterStartTime_object() throws Exception {     testHitsAndLastAccessTimeIsSetToAnyValueAfterStartTime(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAndLastAccessTimeSetToAnyValueAfterStartTime_Binary() throws Exception {     testHitsAndLastAccessTimeIsSetToAnyValueAfterStartTime(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAndLastAccessTimeIsSetToAnyValueAfterStartTime(  Config config) throws Exception {     final long startTime=Clock.currentTimeMillis();     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     warmUpPartitions(instance1,instance2);     final String mapName=randomMapName();     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap(mapName);     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap(mapName);     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        Map.Entry<String,String> entry : map1.entrySet()) {           assertRecord(getReplicatedRecord(map1,entry.getKey()),startTime);         }       }     } );     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        Map.Entry<String,String> entry : map2.entrySet()) {           assertRecord(getReplicatedRecord(map2,entry.getKey()),startTime);         }       }     } );   }   private void assertRecord(  ReplicatedRecord<String,String> record,  long startTime){     assertNotNull(record);     long hits=record.getHits();     long lastAccessTime=record.getLastAccessTime();     long now=Clock.currentTimeMillis();     assertTrue(String.format("Hits should be greater than 0: %d > %d",hits,0),hits > 0);     assertTrue(String.format("Hits should be less than 1000: %d < %d",hits,1000),hits < 1000);     assertTrue(String.format("LastAccessTime should be greater than startTime: %d > %d",lastAccessTime,startTime),lastAccessTime > startTime);     assertTrue(String.format("LastAccessTime should be less or equal than current time: %d <= %d",lastAccessTime,now),lastAccessTime <= now);   }   @Test public void test_hitsAreZeroInitially_withSingleNode_object() throws Exception {     testHitsAreZeroInitiallyWithSingleNode(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAreZeroInitially_withSingleNode_Binary() throws Exception {     testHitsAreZeroInitiallyWithSingleNode(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAreZeroInitiallyWithSingleNode(  Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map=instance1.getReplicatedMap(randomMapName());     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map.put(key,"bar");     }     for (    String key : keys) {       final ReplicatedRecord<String,String> replicatedRecord=getReplicatedRecord(map,key);       assertNotNull(replicatedRecord);       assertEquals(0,replicatedRecord.getHits());     }   }   @Test public void test_hitsAndLastAccessTimeAreSet_withSingleNode_object() throws Exception {     testHitsAndLastAccessTimeAreSetWithSingleNode(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAndLastAccessTimeAreSet_withSingleNode_Binary() throws Exception {     testHitsAndLastAccessTimeAreSetWithSingleNode(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAndLastAccessTimeAreSetWithSingleNode(  Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map=instance1.getReplicatedMap(randomMapName());     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map.put(key,"bar");     }     for (    String key : keys) {       map.containsKey(key);     }     for (    String key : keys) {       final ReplicatedRecord<String,String> replicatedRecord=getReplicatedRecord(map,key);       assertNotNull(replicatedRecord);       assertEquals(1,replicatedRecord.getHits());       assertTrue("Last access time should be set for " + key,replicatedRecord.getLastAccessTime() > 0);     }   }   @Test public void test_hitsAndLastAccessTimeAreSet_with2Nodes_object() throws Exception {     testHitsAndLastAccessTimeAreSetFor1Of2Nodes(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAndLastAccessTimeAreSet_with2Nodes_Binary() throws Exception {     testHitsAndLastAccessTimeAreSetFor1Of2Nodes(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAndLastAccessTimeAreSetFor1Of2Nodes(  Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     warmUpPartitions(instance1,instance2);     final String mapName=randomMapName();     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap(mapName);     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap(mapName);     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");       map1.containsKey(key);     }     for (    String key : keys) {       final ReplicatedRecord<String,String> replicatedRecord=getReplicatedRecord(map1,key);       assertNotNull(replicatedRecord);       assertEquals(1,replicatedRecord.getHits());       assertTrue("Last access time should be set for " + key,replicatedRecord.getLastAccessTime() > 0);     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           final ReplicatedRecord<String,String> replicatedRecord=getReplicatedRecord(map2,key);           assertNotNull(replicatedRecord);           assertEquals(0,replicatedRecord.getHits());           assertTrue("Last access time should be set for " + key,replicatedRecord.getLastAccessTime() > 0);         }       }     } );   }   @Test public void test_hitsAreIncrementedOnPuts_withSingleNode_object() throws Exception {     testHitsAreIncrementedOnPutsWithSingleNode(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAreIncrementedOnPuts_withSingleNode_Binary() throws Exception {     testHitsAreIncrementedOnPutsWithSingleNode(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAreIncrementedOnPutsWithSingleNode(  final Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(1);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final ReplicatedMap<String,String> map=instance1.getReplicatedMap(randomMapName());     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map.put(key,"bar");     }     for (    String key : keys) {       map.put(key,"bar");     }     for (    String key : keys) {       final ReplicatedRecord<String,String> record=getReplicatedRecord(map,key);       assertNotNull(record);       assertEquals(1,record.getHits());     }   }   @Test public void test_hitsAreIncrementedOnPuts_with2Nodes_object() throws Exception {     testHitsAreIncrementedOnPutsFor1Of2Nodes(buildConfig(InMemoryFormat.OBJECT));   }   @Test public void test_hitsAreIncrementedOnPuts_with2Nodes_Binary() throws Exception {     testHitsAreIncrementedOnPutsFor1Of2Nodes(buildConfig(InMemoryFormat.BINARY));   }   private void testHitsAreIncrementedOnPutsFor1Of2Nodes(  final Config config) throws Exception {     final TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory(2);     final HazelcastInstance instance1=nodeFactory.newHazelcastInstance(config);     final HazelcastInstance instance2=nodeFactory.newHazelcastInstance(config);     warmUpPartitions(instance1,instance2);     final String mapName=randomMapName();     final ReplicatedMap<String,String> map1=instance1.getReplicatedMap(mapName);     final ReplicatedMap<String,String> map2=instance2.getReplicatedMap(mapName);     final int partitionCount=getPartitionService(instance1).getPartitionCount();     final Set<String> keys=generateRandomKeys(instance1,partitionCount);     for (    String key : keys) {       map1.put(key,"bar");     }     for (    String key : keys) {       map1.put(key,"bar");     }     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         for (        String key : keys) {           final ReplicatedRecord<String,String> record1=getReplicatedRecord(map1,key);           assertNotNull(record1);           assertEquals(1,record1.getHits());           final ReplicatedRecord<String,String> record2=getReplicatedRecord(map2,key);           assertNotNull(record2);           assertEquals(0,record2.getHits());         }       }     } );   } } 
config.trustStoreLocation == null
this == OTI_ONLY
protected BasicFontMetrics fontMetrics; 
view.getMode()
Gson.class
LOG.debug("Getting synchronous method stub from channel")
stat.st_ctim.tv_nsec.longValue()
Collector.<T,ImmutableSet.Builder<T>,ImmutableSet<T>>of(ImmutableSet.Builder::new,ImmutableSet.Builder::add,(ImmutableSet.Builder<T> left,ImmutableSet.Builder<T> right) -> {   left.addAll(right.build());   return left; } ,ImmutableSet.Builder::build,Collector.Characteristics.UNORDERED)
executor.scheduleAtFixedRate(this,period,period,unit)
isDirect=false
sessionConf != null && sessionConf.get("tez.queue.name") != null
this.connectTo(vertex,null,null,indexOfOutputGate,indexOfInputGate,DistributionPattern.BIPARTITE,true)
Assert.assertEquals(new InetSocketAddress(defaultHostname,10001),workerAddress)
children == null
/**   * This is the primary connection pool class that provides the basic pooling behavior for HikariCP.  * @author Brett Wooldridge  */ public abstract class BaseHikariPool implements HikariPoolMXBean, IBagStateListener {   protected final Logger LOGGER=LoggerFactory.getLogger(getClass());   private static final long ALIVE_BYPASS_WINDOW=Long.getLong("com.zaxxer.hikari.aliveBypassWindow",1000L);   protected static final int POOL_RUNNING=0;   protected static final int POOL_SUSPENDED=1;   protected static final int POOL_SHUTDOWN=2;   public final String catalog;   public final boolean isReadOnly;   public final boolean isAutoCommit;   public int transactionIsolation;   protected final PoolUtilities poolUtils;   protected final HikariConfig configuration;   protected final AtomicInteger totalConnections;   protected final ConcurrentBag<PoolBagEntry> connectionBag;   protected final ThreadPoolExecutor addConnectionExecutor;   protected final ThreadPoolExecutor closeConnectionExecutor;   protected final ScheduledThreadPoolExecutor houseKeepingExecutorService;   protected final boolean isUseJdbc4Validation;   protected final boolean isIsolateInternalQueries;   protected volatile int poolState;   protected volatile long connectionTimeout;   protected volatile long validationTimeout;   private final LeakTask leakTask;   private final DataSource dataSource;   private final GlobalPoolLock suspendResumeLock;   private final IConnectionCustomizer connectionCustomizer;   private final AtomicReference<Throwable> lastConnectionFailure;   private final String username;   private final String password;   private volatile MetricsTracker metricsTracker;   private volatile boolean isRecordMetrics;   /**   * Construct a HikariPool with the specified configuration.  * @param configuration a HikariConfig instance  */   public BaseHikariPool(  HikariConfig configuration){     this(configuration,configuration.getUsername(),configuration.getPassword());   }   /**   * Construct a HikariPool with the specified configuration.  We cache lots of configuration items in class-local final members for speed.  * @param configuration a HikariConfig instance  * @param username authentication username  * @param password authentication password  */   public BaseHikariPool(  HikariConfig configuration,  String username,  String password){     this.username=username;     this.password=password;     this.configuration=configuration;     this.poolUtils=new PoolUtilities(configuration);     this.connectionBag=createConcurrentBag(this);     this.totalConnections=new AtomicInteger();     this.connectionTimeout=configuration.getConnectionTimeout();     this.validationTimeout=configuration.getValidationTimeout();     this.lastConnectionFailure=new AtomicReference<Throwable>();     this.isReadOnly=configuration.isReadOnly();     this.isAutoCommit=configuration.isAutoCommit();     this.suspendResumeLock=configuration.isAllowPoolSuspension() ? new GlobalPoolLock(true) : GlobalPoolLock.FAUX_LOCK;     this.catalog=configuration.getCatalog();     this.connectionCustomizer=initializeCustomizer();     this.transactionIsolation=getTransactionIsolation(configuration.getTransactionIsolation());     this.isIsolateInternalQueries=configuration.isIsolateInternalQueries();     this.isUseJdbc4Validation=configuration.getConnectionTestQuery() == null;     setMetricRegistry(configuration.getMetricRegistry());     setHealthCheckRegistry(configuration.getHealthCheckRegistry());     this.dataSource=poolUtils.initializeDataSource(configuration.getDataSourceClassName(),configuration.getDataSource(),configuration.getDataSourceProperties(),configuration.getDriverClassName(),configuration.getJdbcUrl(),username,password);     this.addConnectionExecutor=createThreadPoolExecutor(configuration.getMaximumPoolSize(),"HikariCP connection filler (pool " + configuration.getPoolName() + ")",configuration.getThreadFactory(),new ThreadPoolExecutor.DiscardPolicy());     this.closeConnectionExecutor=createThreadPoolExecutor(4,"HikariCP connection closer (pool " + configuration.getPoolName() + ")",configuration.getThreadFactory(),new ThreadPoolExecutor.CallerRunsPolicy());     long delayPeriod=Long.getLong("com.zaxxer.hikari.housekeeping.periodMs",TimeUnit.SECONDS.toMillis(30L));     ThreadFactory threadFactory=configuration.getThreadFactory() != null ? configuration.getThreadFactory() : new DefaultThreadFactory("Hikari Housekeeping Timer (pool " + configuration.getPoolName() + ")",true);     this.houseKeepingExecutorService=new ScheduledThreadPoolExecutor(1,threadFactory,new ThreadPoolExecutor.DiscardPolicy());     this.houseKeepingExecutorService.scheduleAtFixedRate(getHouseKeeper(),delayPeriod,delayPeriod,TimeUnit.MILLISECONDS);     this.houseKeepingExecutorService.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);     this.leakTask=(configuration.getLeakDetectionThreshold() == 0) ? LeakTask.NO_LEAK : new LeakTask(configuration.getLeakDetectionThreshold(),houseKeepingExecutorService);     setRemoveOnCancelPolicy(houseKeepingExecutorService);     poolUtils.setLoginTimeout(dataSource,connectionTimeout);     registerMBeans(configuration,this);     initializeConnections();   }   /**   * Get a connection from the pool, or timeout after connectionTimeout milliseconds.  * @return a java.sql.Connection instance  * @throws SQLException thrown if a timeout occurs trying to obtain a connection  */   public final Connection getConnection() throws SQLException {     return getConnection(connectionTimeout);   }   /**   * Get a connection from the pool, or timeout after the specified number of milliseconds.  * @param hardTimeout the maximum time to wait for a connection from the pool  * @return a java.sql.Connection instance  * @throws SQLException thrown if a timeout occurs trying to obtain a connection  */   public final Connection getConnection(  final long hardTimeout) throws SQLException {     suspendResumeLock.acquire();     long timeout=hardTimeout;     final long start=System.currentTimeMillis();     final MetricsContext metricsContext=(isRecordMetrics ? metricsTracker.recordConnectionRequest(start) : MetricsTracker.NO_CONTEXT);     try {       do {         final PoolBagEntry bagEntry=connectionBag.borrow(timeout,TimeUnit.MILLISECONDS);         if (bagEntry == null) {           break;         }         final long now=System.currentTimeMillis();         if (bagEntry.evicted || (now - bagEntry.lastAccess > ALIVE_BYPASS_WINDOW && !isConnectionAlive(bagEntry.connection))) {           closeConnection(bagEntry,"(connection evicted or dead)");           timeout=hardTimeout - elapsedTimeMs(start);         }  else {           metricsContext.setConnectionLastOpen(bagEntry,now);           metricsContext.stop();           return ProxyFactory.getProxyConnection((HikariPool)this,bagEntry,leakTask.start(bagEntry));         }       }  while (timeout > 0L);     }  catch (    InterruptedException e) {       throw new SQLException("Interrupted during connection acquisition",e);     }  finally {       suspendResumeLock.release();     }     logPoolState("Timeout failure ");     throw new SQLTimeoutException(String.format("Timeout after %dms of waiting for a connection.",elapsedTimeMs(start)),lastConnectionFailure.getAndSet(null));   }   /**   * Release a connection back to the pool, or permanently close it if it is broken.  * @param bagEntry the PoolBagEntry to release back to the pool  */   public final void releaseConnection(  final PoolBagEntry bagEntry){     metricsTracker.recordConnectionUsage(bagEntry);     if (bagEntry.evicted) {       LOGGER.debug("Connection returned to pool {} is broken or evicted.  Closing connection.",configuration.getPoolName());       closeConnection(bagEntry,"(connection broken or evicted)");     }  else {       connectionBag.requite(bagEntry);     }   }   /**   * Shutdown the pool, closing all idle connections and aborting or closing active connections.  * @throws InterruptedException thrown if the thread is interrupted during shutdown  */   public final void shutdown() throws InterruptedException {     if (poolState != POOL_SHUTDOWN) {       poolState=POOL_SHUTDOWN;       LOGGER.info("HikariCP pool {} is shutting down.",configuration.getPoolName());       logPoolState("Before shutdown ");       connectionBag.close();       softEvictConnections();       houseKeepingExecutorService.shutdown();       addConnectionExecutor.shutdownNow();       houseKeepingExecutorService.awaitTermination(5L,TimeUnit.SECONDS);       addConnectionExecutor.awaitTermination(5L,TimeUnit.SECONDS);       final ExecutorService assassinExecutor=createThreadPoolExecutor(configuration.getMaximumPoolSize(),"HikariCP connection assassin",configuration.getThreadFactory(),new ThreadPoolExecutor.CallerRunsPolicy());       final long start=System.currentTimeMillis();       do {         softEvictConnections();         abortActiveConnections(assassinExecutor);       }  while (getTotalConnections() > 0 && elapsedTimeMs(start) < TimeUnit.SECONDS.toMillis(5));       assassinExecutor.shutdown();       assassinExecutor.awaitTermination(5L,TimeUnit.SECONDS);       closeConnectionExecutor.shutdown();       closeConnectionExecutor.awaitTermination(5L,TimeUnit.SECONDS);       logPoolState("After shutdown ");       unregisterMBeans(configuration,this);       metricsTracker.close();     }   }   /**   * Evict a connection from the pool.  * @param proxyConnection the connection to evict  */   public final void evictConnection(  IHikariConnectionProxy proxyConnection){     closeConnection(proxyConnection.getPoolBagEntry(),"(connection evicted by user)");   }   /**   * Get the wrapped DataSource.  * @return the wrapped DataSource  */   public final DataSource getDataSource(){     return dataSource;   }   /**   * Get the pool configuration object.  * @return the {@link HikariConfig} for this pool  */   public final HikariConfig getConfiguration(){     return configuration;   }   @Override public String toString(){     return configuration.getPoolName();   }   /**   * {@inheritDoc}   */   @Override public final int getActiveConnections(){     return connectionBag.getCount(STATE_IN_USE);   }   /**   * {@inheritDoc}   */   @Override public final int getIdleConnections(){     return connectionBag.getCount(STATE_NOT_IN_USE);   }   /**   * {@inheritDoc}   */   @Override public final int getTotalConnections(){     return connectionBag.size() - connectionBag.getCount(STATE_REMOVED);   }   /**   * {@inheritDoc}   */   @Override public final int getThreadsAwaitingConnection(){     return connectionBag.getPendingQueue();   }   /**   * {@inheritDoc}   */   @Override public final void suspendPool(){     if (suspendResumeLock == GlobalPoolLock.FAUX_LOCK) {       throw new IllegalStateException("Pool " + configuration.getPoolName() + " is not suspendable");     }  else     if (poolState != POOL_SUSPENDED) {       suspendResumeLock.suspend();       poolState=POOL_SUSPENDED;     }   }   /**   * {@inheritDoc}   */   @Override public final void resumePool(){     if (poolState == POOL_SUSPENDED) {       poolState=POOL_RUNNING;       addBagItem();       suspendResumeLock.resume();     }   }   public void setMetricRegistry(  Object metricRegistry){     this.isRecordMetrics=metricRegistry != null;     if (isRecordMetrics) {       this.metricsTracker=new CodaHaleMetricsTracker(this,(MetricRegistry)metricRegistry);     }  else {       this.metricsTracker=new MetricsTracker(this);     }   }   public void setHealthCheckRegistry(  Object healthCheckRegistry){     if (healthCheckRegistry != null) {       CodahaleHealthChecker.registerHealthChecks(this,(HealthCheckRegistry)healthCheckRegistry);     }   }   /**   * {@inheritDoc}   */   @Override public Future<Boolean> addBagItem(){     FutureTask<Boolean> future=new FutureTask<Boolean>(new Runnable(){       public void run(){         long sleepBackoff=200L;         final int minimumIdle=configuration.getMinimumIdle();         final int maxPoolSize=configuration.getMaximumPoolSize();         while (poolState == POOL_RUNNING && totalConnections.get() < maxPoolSize && getIdleConnections() <= minimumIdle && !addConnection()) {           quietlySleep(sleepBackoff);           sleepBackoff=Math.min(connectionTimeout / 2,(long)((double)sleepBackoff * 1.5));         }       }     } ,true);     addConnectionExecutor.execute(future);     return future;   }   /**   * Create and add a single connection to the pool.  */   protected final boolean addConnection(){     if (totalConnections.incrementAndGet() <= configuration.getMaximumPoolSize()) {       Connection connection=null;       try {         connection=(username == null && password == null) ? dataSource.getConnection() : dataSource.getConnection(username,password);         if (isUseJdbc4Validation && !poolUtils.isJdbc4ValidationSupported(connection)) {           throw new SQLException("JDBC4 Connection.isValid() method not supported, connection test query must be configured");         }         final int originalTimeout=poolUtils.getAndSetNetworkTimeout(connection,connectionTimeout);         transactionIsolation=(transactionIsolation < 0 ? connection.getTransactionIsolation() : transactionIsolation);         poolUtils.setupConnection(connection,isAutoCommit,isReadOnly,transactionIsolation,catalog);         connectionCustomizer.customize(connection);         poolUtils.executeSql(connection,configuration.getConnectionInitSql(),isAutoCommit);         poolUtils.setNetworkTimeout(connection,originalTimeout);         connectionBag.add(new PoolBagEntry(connection,this));         lastConnectionFailure.set(null);         return true;       }  catch (      Exception e) {         lastConnectionFailure.set(e);         if (poolState == POOL_RUNNING) {           LOGGER.debug("Connection attempt to database {} failed: {}",configuration.getPoolName(),e.getMessage(),e);         }         poolUtils.quietlyCloseConnection(connection,"(exception during connection creation)");       }     }     totalConnections.decrementAndGet();     return false;   }   /**   * Fill pool up from current idle connections (as they are perceived at the point of execution) to minimumIdle connections.  */   protected void fillPool(){     final int connectionsToAdd=configuration.getMinimumIdle() - getIdleConnections();     for (int i=0; i < connectionsToAdd; i++) {       addBagItem();     }     if (connectionsToAdd > 0 && LOGGER.isDebugEnabled()) {       addConnectionExecutor.execute(new Runnable(){         public void run(){           logPoolState("After fill ");         }       } );     }   }   /**   * Permanently close the real (underlying) connection (eat any exception).  * @param connectionProxy the connection to actually close  */   protected abstract void closeConnection(  final PoolBagEntry bagEntry,  final String closureReason);   /**   * Check whether the connection is alive or not.  * @param connection the connection to test  * @return true if the connection is alive, false if it is not alive or we timed out  */   protected abstract boolean isConnectionAlive(  final Connection connection);   /**   * Attempt to abort() active connections on Java7+, or close() them on Java6.  * @param assassinExecutor   * @throws InterruptedException   */   protected abstract void abortActiveConnections(  final ExecutorService assassinExecutor) throws InterruptedException ;   /**   * Create the JVM version-specific ConcurrentBag instance used by the pool.  * @param listener the IBagStateListener instance  * @return a ConcurrentBag instance  */   protected abstract ConcurrentBag<PoolBagEntry> createConcurrentBag(  IBagStateListener listener);   /**   * Create the JVM version-specific Housekeeping runnable instance used by the pool.  * @return the HouseKeeper instance  */   protected abstract Runnable getHouseKeeper();   /**   * Fill the pool up to the minimum size.  */   private void initializeConnections(){     if (configuration.isInitializationFailFast()) {       try {         try {           if (!addConnection()) {             shutdown();             throw new PoolInitializationException(lastConnectionFailure.getAndSet(null));           }           ConnectionProxy connection=(ConnectionProxy)getConnection();           connection.getPoolBagEntry().evicted=(configuration.getMinimumIdle() == 0);           connection.close();         }  catch (        SQLException e) {           shutdown();           throw new PoolInitializationException(e);         }       }  catch (      InterruptedException ie) {         throw new PoolInitializationException(ie);       }     }     fillPool();   }   /**   * Construct the user's connection customizer, if specified.  * @return an IConnectionCustomizer instance  */   @SuppressWarnings("deprecation") private IConnectionCustomizer initializeCustomizer(){     if (configuration.getConnectionCustomizerClassName() != null) {       return createInstance(configuration.getConnectionCustomizerClassName(),IConnectionCustomizer.class);     }     return configuration.getConnectionCustomizer();   }   public final void logPoolState(  String... prefix){     if (LOGGER.isDebugEnabled()) {       LOGGER.debug("{}pool stats {} (total={}, inUse={}, avail={}, waiting={})",(prefix.length > 0 ? prefix[0] : ""),configuration.getPoolName(),getTotalConnections(),getActiveConnections(),getIdleConnections(),getThreadsAwaitingConnection());     }   } } 
"Deleting existing file: " + target
edgeData.getAttributes() != null
JSError.make(getName(),-1,-1,ModuleLoader.MODULE_CONFLICT,getName())
assertClusterSizeEventually(2,data2,data3)
new MapStoreWithStoreCount(expectedStoreCount,300,50)
count < 0
StringByteIterator.putAllAsByteIterators(result,jedis.hgetAll(key))
serverSocket.setReuseAddress(true)
executor.execute(new NamedRunnable("OkHttp Window Update %s stream %d",hostName,streamId){   @Override public void execute(){     try {       frameWriter.windowUpdate(streamId,unacknowledgedBytesRead);     }  catch (    IOException ignored) {     }   } } )
returnValue
renderer.rect(x + rect.x + settings.paddingX,y + rect.y + settings.paddingY,rect.width - settings.paddingX,rect.height - settings.paddingY)
activeCount >= maxActive
logger.warn("InfluxDB is not yet connected")
ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor())
MANAGEMENT_API_MICRO_VERSION=1
new ValidationException("Unable to deserialize string '" + base64String + "' of base class '"+ baseClass.getName()+ "'.",e)
promise.setFailure(new ClosedChannelException())
null != rootCause && rootCause.getCause() != null
start.set(Calendar.DAY_OF_MONTH,startDay)
DirectMessage.createDirectMessageList(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/direct_messages.json"))
System.arraycopy(value,0,chars,length,value.length)
new AndroidFiles(this.getService().getAssets(),this.getService().getFilesDir().getAbsolutePath())
Assert.assertTrue(mFileSystem.getStatus(uri).getInMemoryPercentage() == 100)
mock.expectedBodiesReceivedInAnyOrder("Hello World 3")
ExceptionUtils.getStackTrace(th)
clientInvocation.invokeUrgent().andThen(new ExecutionCallback<ClientMessage>(){   @Override public void onResponse(  ClientMessage response){     if (connection.isAlive()) {       connection.onHeartbeatReceived();     }   }   @Override public void onFailure(  Throwable t){     if (connection.isAlive()) {       logger.warning("Error receiving heartbeat for connection: " + connection,t);     }   } } ,executionService.getInternalExecutor())
actor.addListener(listener)
heatpumpValues[66]
tableLayoutHandle.getPartitions().isPresent()
id=10998
private final ExecutionHandler executionHandler; 
Arrays.asList("spring-boot-starter-tomcat-","tomcat-embed-core-","tomcat-embed-el-","tomcat-embed-websocket-")
StringBuilder sb=new StringBuilder(); 
c > ic
NbBundle.getMessage(DesktopImportControllerUI.class,"DesktopImportControllerUI.spigot.ui.dialog.title",ui.getDisplayName())
annotatorImplementation.custom(inputProps,property)
Preconditions.checkNotNull(manager,"manager")
GL20.glGetUniformfv(program,location,params)
EXTFramebufferObject.glGetRenderbufferParameterivEXT(target,pname,params)
simple.getFromReceivedDate()
new CustomChangeException("Failed to insert one or more concept map types",be)
CassandraSplitManager.class
lockForRescale()
Thread.sleep(4000)
before == after
retries == 0 && totalConnections.incrementAndGet() > configuration.getMaximumPoolSize()
Iterable<String>
new RuntimeException("Could not create TypeInformation for type " + type.getName() + "; please specify the TypeInformation manually via "+ "ExecutionEnvironment#fromElements(Collection, TypeInformation)",e)
stat.st_mode.intValue()
config.getMaxQueryMemoryPerNode().toBytes() <= maxMemory.toBytes()
@Override
MongoConnection.getInstance().connect(null,null,"localhost","graylog2test",Integer.valueOf(27017),"false",null)
!unsafeBuffers.contains(buffer,true)
ObjectStreamClass.lookup(clazz)
!handle.parent().exists()
assertEquals(11,events.size())
new URI(parentUri.getScheme(),parentUri.getAuthority(),parentUri.getPath() + SEPARATOR,null,null)
assertEquals(SIZE * COUNTDOWN,c1.counts + c2.counts)
progress.start(0.29f)
expiresOn.getTime()
!((ExchangeIdempotentRepository<String>)idempotentRepository).contains(exchange,messageId)
theClass.getConstructor()
new Path(testBucket.getParent(),".test-2.inprogress").getPath()
data.position()
HornetQEmbeddedConfigurationFactory.class
assertEquals(response.getStatusCode(),200)
assertEquals(2,this.context.getBean(FilterChainProxy.class).getFilterChains().size())
conf.unset("tez.queue.name")
new StringBuilder(560)
LOG.error("Failed to shut down ActorSystem",t)
jmsTemplate.setPubSubDomain(true)
JSError.make(n,Es6ToEs3Converter.CANNOT_CONVERT,"Undecomposable expression")
typeName != null
NodeUtil.getFunctionNameNode(fn)
cache5.setColors(red)
testOffset=4875454L
9f / 10f
SimpleAttributeDefinitionBuilder.create(ModelDescriptionConstants.ANY_IPV6_ADDRESS,ModelType.BOOLEAN).setAllowExpression(false).setAllowNull(true)
cr.session_timeout_ms != null && cr.session_timeout_ms != 0
lookup="java:comp/ds"
twitter1.getRetweeterIds(1021608606934822912L,-1)
LOG.debug("Creating short circuit output stream for block {} @ {}",blockId,address)
@Override public ExtendedCell deepClone(){   throw new UnsupportedOperationException(); } 
new IllegalStateException("Unexpected rule: " + ruleStr)
ssl.hasDefined(CommonAttributes.CERTIFICATE_KEY_FILE)
m_data.getFixString((int)m_length,charsetName)
assertEquals(3,historyService.createHistoricActivityInstanceQuery().processInstanceId(processInstance.getId()).list().size())
edge.setDirection(EdgeDirection.UNDIRECTED)
/**   * The package controller for the current file. Used for performance optimisation.  */ private ImportControl currentLeaf; 
id=10870
setUnknownLabels(collapsedUnary,mainLabel)
new Duration(TimeUnit.MILLISECONDS,CREATED_EXPIRY_TIME_IN_MSEC)
basicInvocation.potentialResponse != null
initialCapacity <= capacity
lookup="org.jboss.as.test.integration.ee.datasourcedefinition.DataSourceBean/dataSource3"
conceptToValidate.getUuid()
!findClass
log.infof("started ResourceAdapterService %s",context.getController().getName())
final StringBuilder result=new StringBuilder(20); 
ImmutableList<ConformanceConfig>
pushExecutor.execute(new NamedRunnable("OkHttp %s Push Headers[%s]",hostName,streamId){   @Override public void execute(){     boolean cancel=pushObserver.onHeaders(streamId,requestHeaders,inFinished);     try {       if (cancel)       frameWriter.rstStream(streamId,ErrorCode.CANCEL);       if (cancel || inFinished) { synchronized (SpdyConnection.this) {           currentPushRequests.remove(streamId);         }       }     }  catch (    IOException ignored) {     }   } } )
javaBeanSerializer.getFieldValues(javaObject,json)
new DataSegment("test",new Interval("2012-02-01/2012-02-02"),new DateTime().toString(),Maps.<String,Object>newHashMap(),Lists.<String>newArrayList(),Lists.<String>newArrayList(),new NoneShardSpec(),1,0)
/**   * Returns messages older than the message ID specified as a numeric string. This is useful for paginating messages. For example, if you're currently viewing 20 messages and the oldest is number 2912, you could append "?olderThan=2912 to your request to get the 20 messages prior to those you're seeing.  */ private Long olderThan=-1L; 
CellUtil.estimatedHeapSizeOfWithoutTags(c)
logger.info("{} exists but cannot be executed even when execute permissions set; " + "check volume for \"noexec\" flag; use -Dio.netty.native.workdir=[path] " + "to set native working directory separately.",tmpFile.getPath(),"io.netty.native.workdir")
uncompressedProto.length < 2550000
event.getChangeColumns()
new GenericAggregationFunction(NAME,inputTypes,intermediateType,BIGINT,true,false,factory)
300 * Constants.SECOND_MS
assertEquals(303,t.request().get().getStatus())
config.setClientMappingCache(model.get(EJB3SubsystemModel.CLIENT_MAPPINGS_CACHE).asString())
oldestUnflushedStoreSequenceIds.putIfAbsent(encodedRegionName,oldestUnflushedStoreSequenceIdsOfRegion)
offset * 6
GL20.glGetVertexAttribiv(index,pname,params)
NSNumber.numberWithLongLong(val)
@InputIntMethodAnnotation(value=-45)
new CsvFilter(lines)
new ResourceProfile(Double.MAX_VALUE,Integer.MAX_VALUE,Integer.MAX_VALUE,Integer.MAX_VALUE,Integer.MAX_VALUE,managedMemoryPerSlotMB,Collections.emptyMap())
IntrospectionSupport.setProperties(exchange.getContext().getTypeConverter(),jpa,options)
mock.expectedMessageCount(1)
new HashMap<>(queryMemoryRevocableReservations)
ImmutableSortedSet.of("a","abbr","acronym","address","area","b","bdo","big","blockquote","br","caption","cite","code","colgroup","dd","del","div","dfn","dl","dt","em","fieldset","font","h1","h2","h3","h4","h5","h6","hr","i","img","ins","kbd","li","ol","p","pre","q","samp","small","span","strong","style","sub","sup","table","tbody","td","tfoot","th","thead","tr","tt","u","ul")
from("direct:b").delay(1000)
10 * 1000000L
end + " End Message Interceptor"
Assert.assertTrue(rule.appliesTo(builder.interval(new Interval(now.minusDays(1),now.plusDays(1))).build(),now))
g.tool.errMgr.grammarError(ErrorType.EMPTY_STRINGS_AND_SETS_NOT_ALLOWED,g.fileName,tree.token,"''")
getWrappedEngine().release(decrement)
doubleValue != 0
primitiveType != null || arrayComponentType != null
!exclude
new RMNodeImpl(nodeId,rmContext,null,0,0,null,null)
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
UriBuilder.fromResource(AlarmCallbackResource.class).path("{alarmCallbackId}").build(streamid,id)
/**   * {@code "x-frame-options"}  */ public static final AsciiString X_FRAME_OPTIONS=new AsciiString("x-frame-options"); 
assertEquals(3,data.size())
Logger.getLogger(loggerName).getEffectiveLevel()
block.useSourceInfoIfMissingFromForTree(exprRoot)
public class XpathRegressionNestedForDepthTest extends XpathTestSupport {   @Test public void testCorrect() throws Exception {     final String checkName=NestedForDepthCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionNestedForDepth.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(NestedForDepthCheck.class);     final String[] expectedViolation={"7:17: " + getCheckMessage(NestedForDepthCheck.class,NestedForDepthCheck.MSG_KEY,2,1)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionNestedForDepth']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_FOR/SLIST/LITERAL_FOR/SLIST/LITERAL_FOR");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
twitter4j.List.createListList(get(getApiBaseURL() + V1 + user+ "/lists/subscriptions.json?cursor="+ cursor,true))
7 * Bytes.SIZEOF_LONG
new NativeCodeGenerator().generate("src","bin:../../gdx/bin","jni")
String.format("Starting audit...%n" + expectedPath + ":3:14: "+ "warning: Name 'InputMain' must match pattern '^[a-z0-9]*$'.%n"+ expectedPath+ ":5:7: "+ "warning: Name 'InputMainInner' must match pattern '^[a-z0-9]*$'.%n"+ "Audit done.%n",expectedPath)
req.getPathInfo()
newCount <= reservoirSize
instance.managementService.destroy()
new InstrumentedTimingCollector(Metrics.defaultRegistry())
id=10831
Assert.assertEquals(3,visitor.getConditions().size())
/**   * @return the root {@link PkgControl} object loaded.  */ private ImportControl getRoot(){   return stack.peek(); } 
public class XpathRegressionExplicitInitializationTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=ExplicitInitializationCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ExplicitInitializationCheck.class);     final String[] expectedViolation={"4:17: " + getCheckMessage(ExplicitInitializationCheck.class,ExplicitInitializationCheck.MSG_KEY,"a",0)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitOne']" + "/OBJBLOCK/VARIABLE_DEF[@text='a']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=ExplicitInitializationCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ExplicitInitializationCheck.class);     final String[] expectedViolation={"6:20: " + getCheckMessage(ExplicitInitializationCheck.class,ExplicitInitializationCheck.MSG_KEY,"bar","null")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitTwo']/OBJBLOCK" + "/VARIABLE_DEF[@text='bar']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
stackTrace.length <= depth
/**   */ class SctpServerPipelineSink extends AbstractSctpChannelSink {   static final InternalLogger logger=InternalLoggerFactory.getInstance(SctpServerPipelineSink.class);   private final SctpWorker[] workers;   private final AtomicInteger workerIndex=new AtomicInteger();   SctpServerPipelineSink(  Executor workerExecutor,  int workerCount){     workers=new SctpWorker[workerCount];     for (int i=0; i < workers.length; i++) {       workers[i]=new SctpWorker(workerExecutor);     }   }   @Override public void eventSunk(  ChannelPipeline pipeline,  ChannelEvent e) throws Exception {     Channel channel=e.getChannel();     if (channel instanceof SctpServerChannelImpl) {       handleServerSocket(e);     }  else     if (channel instanceof SctpChannelImpl) {       handleAcceptedSocket(e);     }   }   private void handleServerSocket(  ChannelEvent e){     if (!(e instanceof ChannelStateEvent)) {       return;     }     ChannelStateEvent event=(ChannelStateEvent)e;     SctpServerChannelImpl channel=(SctpServerChannelImpl)event.getChannel();     ChannelFuture future=event.getFuture();     ChannelState state=event.getState();     Object value=event.getValue(); switch (state) { case OPEN:       if (Boolean.FALSE.equals(value)) {         close(channel,future);       }     break; case BOUND:   if (value != null) {     bind(channel,future,(SocketAddress)value);   }  else {     close(channel,future);   } case INTEREST_OPS: if (event instanceof SctpBindAddressEvent) {   SctpBindAddressEvent bindAddressEvent=(SctpBindAddressEvent)event;   bindAddress(channel,bindAddressEvent.getFuture(),bindAddressEvent.getValue()); } if (event instanceof SctpUnbindAddressEvent) { SctpUnbindAddressEvent unbindAddressEvent=(SctpUnbindAddressEvent)event; unbindAddress(channel,unbindAddressEvent.getFuture(),unbindAddressEvent.getValue()); } break; } } private void handleAcceptedSocket(ChannelEvent e){ if (e instanceof ChannelStateEvent) { ChannelStateEvent event=(ChannelStateEvent)e; SctpChannelImpl channel=(SctpChannelImpl)event.getChannel(); ChannelFuture future=event.getFuture(); ChannelState state=event.getState(); Object value=event.getValue(); switch (state) { case OPEN: if (Boolean.FALSE.equals(value)) { channel.worker.close(channel,future); } break; case BOUND: case CONNECTED: if (value == null) { channel.worker.close(channel,future); } break; case INTEREST_OPS: channel.worker.setInterestOps(channel,future,(Integer)value); break; } }  else if (e instanceof MessageEvent) { MessageEvent event=(MessageEvent)e; SctpChannelImpl channel=(SctpChannelImpl)event.getChannel(); boolean offered=channel.writeBuffer.offer(event); assert offered; channel.worker.writeFromUserCode(channel); } } private void bind(SctpServerChannelImpl channel,ChannelFuture future,SocketAddress localAddress){ boolean bound=false; boolean bossStarted=false; try { channel.serverChannel.bind(localAddress,channel.getConfig().getBacklog()); bound=true; channel.setBound(); future.setSuccess(); fireChannelBound(channel,channel.getLocalAddress()); Executor bossExecutor=((SctpServerSocketChannelFactory)channel.getFactory()).bossExecutor; DeadLockProofWorker.start(bossExecutor,new Boss(channel)); bossStarted=true; }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); }  finally { if (!bossStarted && bound) { close(channel,future); } } } private void bindAddress(SctpServerChannelImpl channel,ChannelFuture future,InetAddress localAddress){ try { channel.serverChannel.bindAddress(localAddress); future.setSuccess(); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void unbindAddress(SctpServerChannelImpl channel,ChannelFuture future,InetAddress localAddress){ try { channel.serverChannel.unbindAddress(localAddress); future.setSuccess(); }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } private void close(SctpServerChannelImpl channel,ChannelFuture future){ boolean bound=channel.isBound(); try { if (channel.serverChannel.isOpen()) { channel.serverChannel.close(); Selector selector=channel.selector; if (selector != null) { selector.wakeup(); } } channel.shutdownLock.lock(); try { if (channel.setClosed()) { future.setSuccess(); if (bound) { fireChannelUnbound(channel); } fireChannelClosed(channel); }  else { future.setSuccess(); } }   finally { channel.shutdownLock.unlock(); } }  catch (Throwable t) { future.setFailure(t); fireExceptionCaught(channel,t); } } SctpWorker nextWorker(){ return workers[Math.abs(workerIndex.getAndIncrement() % workers.length)]; } private final class Boss implements Runnable { private final Selector selector; private final SctpServerChannelImpl channel; Boss(SctpServerChannelImpl channel) throws IOException { this.channel=channel; selector=Selector.open(); boolean registered=false; try { channel.serverChannel.register(selector,SelectionKey.OP_ACCEPT); registered=true; }   finally { if (!registered) { closeSelector(); } } channel.selector=selector; } @Override public void run(){ final Thread currentThread=Thread.currentThread(); channel.shutdownLock.lock(); try { for (; ; ) { try { if (selector.select(500) > 0) { selector.selectedKeys().clear(); } SctpChannel acceptedSocket=channel.serverChannel.accept(); if (acceptedSocket != null) { registerAcceptedChannel(acceptedSocket,currentThread); } }  catch (SocketTimeoutException e) { } catch (CancelledKeyException e) { } catch (ClosedSelectorException e) { } catch (ClosedChannelException e) { break; } catch (Throwable e) { if (logger.isWarnEnabled()) { logger.warn("Failed to accept a connection.",e); } try { Thread.sleep(1000); }  catch (InterruptedException e1) { } } } }   finally { channel.shutdownLock.unlock(); closeSelector(); } } private void registerAcceptedChannel(SctpChannel acceptedSocket,Thread currentThread){ try { ChannelPipeline pipeline=channel.getConfig().getPipelineFactory().getPipeline(); SctpWorker worker=nextWorker(); worker.register(new SctpAcceptedChannel(channel.getFactory(),pipeline,channel,SctpServerPipelineSink.this,acceptedSocket,worker,currentThread),null); }  catch (Exception e) { if (logger.isWarnEnabled()) { logger.warn("Failed to initialize an accepted socket.",e); } try { acceptedSocket.close(); }  catch (IOException e2) { if (logger.isWarnEnabled()) { logger.warn("Failed to close a partially accepted socket.",e2); } } } } private void closeSelector(){ channel.selector=null; try { selector.close(); }  catch (Exception e) { if (logger.isWarnEnabled()) { logger.warn("Failed to close a selector.",e); } } } } } 
registrar.checkExisting(added)
TIMEOUT=30000
logger.warn("Invalid state {}",r)
seenVertices.contains(endAncestor)
id=12
id=10838
i >= BY_DYE_DATA.length
cSet.setConceptSet(this)
autoCommit != null && autoCommit != conn.getAutoCommit()
new SSL((short)MIN_SSL_OPTIONS,(short)0,(short)sslPort)
public Builder setRealmUsePreemptiveAuth(boolean usePreemptiveAuth){   realm().setUsePreemptiveAuth(usePreemptiveAuth);   return this; } 
assertEquals("Unable to open ''.",iter.next().getMessage())
jsonHotRestartState != null
new CreateTable(temporaryTableName,ImmutableList.of(new LikeClause(originalTableName,Optional.of(INCLUDING))),false,tablePropertyOverrides,Optional.empty())
AsyncHttpClientConfig.class
@UriParam
return areaWidth; 
plugin != null && plugin.canServeUri(uri,homeDir)
Pattern.compile(CURRENT_DIR,Pattern.LITERAL)
assertEquals(1234,deserialized.getOwnedEntryMemoryCost())
clazz.getInterfaces().length == 0
gen.get().document("target/testdocs","testsection")
LOGGER.log(Level.SEVERE,LocalizationMessages.ERROR_COMMITTING_OUTPUT_STREAM(),e)
ch == '?' && JdbcConstants.POSTGRESQL.equals(dbType)
this.conf.addResource(coreSiteXMLInputStream,YarnConfiguration.CORE_SITE_CONFIGURATION_FILE)
Float[]
route.setDelay(6000)
numMessages=200
configList == null || configList.size() == 0
ctx.writeAndFlush("Welcome to " + InetAddress.getLocalHost().getHostName() + " secure chat service!\n")
lockForRescale()
!Boolean.parseBoolean(ac)
return worldVertices; 
assertEquals(504,cause.getStatusCode())
new StringBuilder(28)
editor.apply()
indexFile.isFile()
@UriParam(label="producer",defaultValue="1") private String requestRequiredAcks="1"; 
if (mAllowUndeclaredRTE) {   final ClassResolver cr=new ClassResolver(getClassLoader(),mPackageFullIdent.getText(),mImports);   try {     final Class clazz=cr.resolve(tag.getArg1());     reqd=!RuntimeException.class.isAssignableFrom(clazz) && !Error.class.isAssignableFrom(clazz);   }  catch (  ClassNotFoundException e) {     log(tag.getLineNo(),"javadoc.classInfo","@throws",tag.getArg1());   } } 
wrapper.joinWithTimeout()
proxyServer != null && !isSecure(uri)
Status.createStatuseList(get(getBaseURL() + "favorites.json",new PostParameter[0],true))
!condition.isEmpty()
factory.get(mResponseWildcard,NO_ANNOTATIONS,retrofit)
codingSystem == null || HL7Constants.HL7_LOCAL_CONCEPT.equals(codingSystem)
@InputIntMethodAnnotation(-44)
result.expectedMinimumMessageCount(1)
processSelectedKeys()
this.r != null && r != null
AbstractStoreHandler<DelayedEntry>
left.getFieldName().equalsIgnoreCase(right.getFieldName())
GL20.glUniform2fv(location,v)
page.getLogicalSizeInBytes()
timeout=1800000
logger.trace("myq ReturnCode: {}",returnCode)
@RunWith(HazelcastParallelClassRunner.class) @Category(value={QuickTest.class,ParallelTest.class}) public class ReplicatedMapAntiEntropyTest extends ReplicatedMapAbstractTest {   @After public void cleanup(){     System.clearProperty("hazelcast.serialization.custom.override");   }   @Test public void testMapConvergesToSameValueWhenMissingReplicationUpdate() throws Exception {     Config config=new Config();     SerializationConfig serializationConfig=new SerializationConfig();     SerializerConfig serializerConfig=new SerializerConfig();     serializerConfig.setTypeClassName(PutOperation.class.getName());     serializerConfig.setImplementation(new PutOperationWithNoReplicationSerializer());     serializationConfig.addSerializerConfig(serializerConfig);     config.setSerializationConfig(serializationConfig);     System.setProperty("hazelcast.serialization.custom.override","true");     String mapName=randomMapName();     TestHazelcastInstanceFactory factory=createHazelcastInstanceFactory();     HazelcastInstance instance1=factory.newHazelcastInstance(config);     HazelcastInstance instance2=factory.newHazelcastInstance(config);     HazelcastInstance instance3=factory.newHazelcastInstance(config);     final ReplicatedMap<Object,Object> map1=instance1.getReplicatedMap(mapName);     final ReplicatedMap<Object,Object> map2=instance2.getReplicatedMap(mapName);     final ReplicatedMap<Object,Object> map3=instance3.getReplicatedMap(mapName);     final String key=generateKeyOwnedBy(instance2);     final String value=randomString();     map1.put(key,value);     assertEquals(value,map1.get(key));     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(value,map2.get(key));         assertEquals(value,map3.get(key));       }     } );   } public class PutOperationWithNoReplicationSerializer implements StreamSerializer<PutOperation> {     @Override public void write(    ObjectDataOutput out,    PutOperation object) throws IOException {       object.writeData(out);     }     @Override public PutOperation read(    ObjectDataInput in) throws IOException {       final PutOperationWithNoReplication operation=new PutOperationWithNoReplication();       operation.readData(in);       return operation;     }     @Override public int getTypeId(){       return 8778;     }     @Override public void destroy(){     }   } class PutOperationWithNoReplication extends PutOperation {     public PutOperationWithNoReplication(){     }     @Override protected Collection<Address> getMemberAddresses(){       return Collections.emptyList();     }   } } 
new FilterConfiguration(filterClass,filterParams)
new ClientBuilderImpl().serviceUrl(getPulsarBrokerUrl()).ioThreads(5)
sctpChannelClass.getMethod("open")
public class Arial extends BasicFontMetrics { {     maxCharHeight=781;     widths[32]=277;     widths[33]=277;     widths[34]=354;     widths[35]=556;     widths[36]=556;     widths[37]=889;     widths[38]=666;     widths[39]=190;     widths[40]=333;     widths[41]=333;     widths[42]=389;     widths[43]=583;     widths[44]=277;     widths[45]=333;     widths[46]=277;     widths[47]=277;     widths[48]=556;     widths[49]=556;     widths[50]=556;     widths[51]=556;     widths[52]=556;     widths[53]=556;     widths[54]=556;     widths[55]=556;     widths[56]=556;     widths[57]=556;     widths[58]=277;     widths[59]=277;     widths[60]=583;     widths[61]=583;     widths[62]=583;     widths[63]=556;     widths[64]=1015;     widths[65]=666;     widths[66]=666;     widths[67]=722;     widths[68]=722;     widths[69]=666;     widths[70]=610;     widths[71]=777;     widths[72]=722;     widths[73]=277;     widths[74]=500;     widths[75]=666;     widths[76]=556;     widths[77]=833;     widths[78]=722;     widths[79]=777;     widths[80]=666;     widths[81]=777;     widths[82]=722;     widths[83]=666;     widths[84]=610;     widths[85]=722;     widths[86]=666;     widths[87]=943;     widths[88]=666;     widths[89]=666;     widths[90]=610;     widths[91]=277;     widths[92]=277;     widths[93]=277;     widths[94]=469;     widths[95]=556;     widths[96]=333;     widths[97]=556;     widths[98]=556;     widths[99]=500;     widths[100]=556;     widths[101]=556;     widths[102]=277;     widths[103]=556;     widths[104]=556;     widths[105]=222;     widths[106]=222;     widths[107]=500;     widths[108]=222;     widths[109]=833;     widths[110]=556;     widths[111]=556;     widths[112]=556;     widths[113]=556;     widths[114]=333;     widths[115]=500;     widths[116]=277;     widths[117]=556;     widths[118]=500;     widths[119]=722;     widths[120]=500;     widths[121]=500;     widths[122]=500;     widths[123]=333;     widths[124]=259;     widths[125]=333;     widths[126]=583;   } } 
registration.registerOperationHandler(CommonAttributes.DISABLE_CONTEXT,ModClusterDisableContext.INSTANCE,disableContext,false,runtimeOnlyFlags)
minIdle < 0 || minIdle > maxPoolSize
List<String>
ImmutableSortedSet.of("br","li","dt","dd","hr","img","p","td","tr","th")
ImmutableSortedSet.of("a","abbr","acronym","address","area","b","bdo","big","blockquote","br","caption","cite","code","colgroup","dd","del","div","dfn","dl","dt","em","fieldset","font","h1","h2","h3","h4","h5","h6","hr","i","img","ins","kbd","li","ol","p","pre","q","samp","small","span","strong","style","sub","sup","table","tbody","td","tfoot","th","thead","tr","tt","ul")
Arrays.asList("onContextStart","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onServiceAdd","onComponentAdd","onEndpointAdd","onComponentRemove","onContextStop")
!query.getDimensionSpec().preservesOrdering()
logger.info("Illegal argument in chart: {}",e)
K key
ConfigAssertions.recordDefaults(FeaturesConfig.class).setExperimentalSyntaxEnabled(false).setDistributedIndexJoinsEnabled(false).setDistributedJoinsEnabled(true).setRedistributeWrites(true).setOptimizeMetadataQueries(false).setOptimizeHashGeneration(true).setOptimizeSingleDistinct(true).setPushTableWriteThroughUnion(true)
lexer.token() == (Token.SELECT) || lexer.token() == (Token.SEL)
factory.get(mBodyClass,NO_ANNOTATIONS,retrofit)
items[21]
!this.mrwork.getHadoopSupportsSplittable()
Assert.assertEquals(0,fastJsonConfig.getFeatures().length)
postAgg.getName().equalsIgnoreCase(metricName)
id=44
waitYieldLatch.await(1000,TimeUnit.MILLISECONDS)
arrayName=options.get(ARRAY_NAME)
customResourceLocator(url)
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class,CoreAnnotations.TokenBeginAnnotation.class,CoreAnnotations.TokenEndAnnotation.class,CoreAnnotations.OriginalTextAnnotation.class)
qp.isExclusiveMinimum()
BlockWorkerUtils.getWorkerAddress(mTachyonConf).getAddress().getHostAddress()
containedToken.endPosition()
getDatabaseCatalog() != null && getDatabaseCatalog().length() > 0
injectionConfiguration.getSource().getResourceValue(resolutionContext,serviceBuilder,context,managedReferenceFactoryValue)
createOrcWriterOptions(oi,conf,cacheWriter,allocSize)
Arrays.asList("spring-boot-starter-jetty-","jetty-continuation","jetty-util-","javax.servlet-","jetty-io-","jetty-http-","jetty-server-","jetty-security-","jetty-servlet-","jetty-servlets","jetty-webapp-","websocket-api","javax.annotation-api","jetty-plus","javax-websocket-server-impl-","apache-el","asm-","javax.websocket-api-","asm-tree-","asm-commons-","websocket-common-","jetty-annotations-","javax-websocket-client-impl-","websocket-client-","websocket-server-","jetty-xml-","websocket-servlet-")
new StringBuilder(238)
gradHidden[nodeIndex]
Integer.parseInt(quantifier)
new EntryEvent(packet.getName(),null,(int)packet.getLongValue(),toObject(packet.getKey()),toObject(packet.getValue()))
new NagiosNscaStub(25669,"password")
((Number)s.first()).floatValue()
timeout=60_000L
fieldNameNode.getCharno()
ProcessorDefinition<ExpressionNode>
exchange.setRequestHeader(HttpHeaders.AUTHORIZATION,"OAuth " + currentToken)
logger.trace("Trying to map {} to {}",t,path)
LinkageError ex
gen.generateParser(false)
startOffset >= pages.size()
buildPages.getTypesWithoutHash()
logPageUrl != null && logPageUrl.length() > 0
b.getTypeByte()
TreeSet<String>
ExecuteJobsRunnable.class
id=10871
LOG.debug("Processing changes for pool " + poolName + ": "+ pools.get(poolName))
TimeUnit.SECONDS.toMillis(4)
getPath("checks/javadoc/Input_02.java")
twitter1.getRetweets(1021608606934822912L)
out.writeBytes(mask)
Float.parseFloat(value.toString())
new File(value).toPath()
methodName.equalsIgnoreCase("scan")
client.srandmember(key,count)
GL.glDeleteTextures(n,textures,Memory.getPosition(textures))
items[19]
(Relationship)container
timeOut=240_000
DefaultAlluxioWorker.class
row(null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null)
new PrestoException(INVALID_CAST_ARGUMENT,"Value cannot be cast to timestamp with time zone: " + value.toStringUtf8(),e)
calendar.get(HOUR_OF_DAY)
CachePutAllCodec.encodeRequest(nameWithPrefix,entries,expiryPolicyData,completionId)
assertTrue(model.getUniqueItems())
propResource.get(BOOT_TIME).asBoolean(false)
value & 0xff
buffer.remaining()
InetAddress.getByName("0.0.0.0")
Namespace.CURRENT.getUriString()
GL20.glUniformMatrix2fv(location,transpose,value)
log.debug("Performing lookup: %s --> %s",nodeIds,retVal)
processEngineConfiguration.getExpressionManager() == null && applicationContext != null
jtaEnvironmentBean.getValue().getPerformImmediateCleanupOfCommitMarkableResourceBranchesMap().remove(jndiName)
lookup=Resources.REQUEST_QUEUE
session.getMachineIdentifier().startsWith(config.getMachineIdentifier())
new JedisClusterCommand<Set<String>>(connectionHandler,maxRedirections){   @Override public Set<String> execute(  Jedis connection){     return connection.spop(key,count);   } } 
mAbsListView.getPositionForView(childView) == position && childView.getTag() instanceof ViewHolder
log.debug("Checking bounds [{}, {}) (expect {} keys)",new Object[]{startCol,endCol,expected.size()})
DiagnosticType.disabled("JSC_TOO_MANY_TEMPLATE_PARAMS","{0}")
record.getId() != 0 && record.getLength() > store.getRecordSize() - store.getRecordHeaderSize()
BIG_ENOUGH_INT + 0.99999999
512 * 1024 * 1024
!fadeScrollBars && scrollbarsOnTop && scrollX
gran.next(input)
String.format("Starting audit...%n" + expectedPath + ":3:14: "+ "Name 'InputMain' must match pattern '^[a-z0-9]*$'.%n"+ expectedPath+ ":5:7: "+ "Name 'InputMainInner' must match pattern '^[a-z0-9]*$'.%n"+ "Audit done.%n"+ "Checkstyle ends with 2 errors.%n",expectedPath)
messageHandler.serverResponder()
@Override public ExtendedCell deepClone(){   byte[] copy=Bytes.copy(this.bytes,this.offset,this.length);   KeyValue kv=new KeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } 
GL.glPolygonOffset(factor,units)
http2c.setInitialStreamRecvWindow(initialStreamSendWindow)
toObject(dataValue)
LOG.debug("Retrieving location for state={} of job={} from the key-value state location oracle.",queryableStateName,jobId)
id=10845
public Integer getPort(){   return this.port; } 
POLL_PERIOD=1000L
PORT=6336
(getSource().y() + getTarget().y()) / 3f
assertEquals(12,events.size())
numConnections=20
Arrays.asList("bash",command)
getPreferences().save(fos,"")
PathUtils.concatPath(dst,child)
getExpressionTypesFromInput(session,metadata,SQL_PARSER,INPUT_TYPES,ImmutableList.of(translatedProjection),ImmutableList.of())
logger.trace("rapidRefreshFuture scheduleing for {} millis",millis)
type.createBlockBuilder(new BlockBuilderStatus(),4)
LOG.warn("Failed to look for classes in " + jarFileName + ": "+ ioEx)
http2.setInitialStreamRecvWindow(initialStreamSendWindow)
IntrospectionSupport.setProperty(exchange.getContext().getTypeConverter(),jpa,"timestamp",msg.getTimestamp())
createMessageConsumer(session,destinationName,null,false,null)
jniGetLocalAnchorB(addr,tmp)
isTestOnReturn()
WORKER_SESSION_TIMEOUT_MS(Name.WORKER_SESSION_TIMEOUT_MS,60000)
90
LOG.error("discarding {} messages because the Netty client to {} is being closed",numMessages,dstAddressPrefixedName)
Arrays.asList(TYPE,SUBSCRIBE_URL,MESSAGE,TIMESTAMP,SIGNATURE,SIGNATURE_VERSION,MESSAGE_ID,SUBJECT,TOPIC,TOKEN)
dimensionsSpec.getDimensionNames()
5 * Bytes.SIZEOF_BOOLEAN
new ThreadPoolExecutor(5,Integer.MAX_VALUE,60L,TimeUnit.SECONDS,new SynchronousQueue(),new ExecutorThreadFactory(node.threadGroup,node.getThreadPoolNamePrefix("cached"),classLoader),new RejectionHandler()){   protected void beforeExecute(  Thread t,  Runnable r){     threadPoolBeforeExecute(t,r);   } } 
final ImportControl root=ImportControlLoader.load(new File(getPath("import-control_WithNewElement.xml")).toURI()); 
new ChronicleEngineEndpoint(uri,this,configuration)
NoResolvedType noResolvedType=new NoResolvedType(this); 
new StringTypeHandler()
supportSession=false
ImmutableList.copyOf(result)
BaseBulletTest.init()
scaleX == 1
fields[i] >= 0 && in2 != null
Character.toUpperCase(ch)
@RunWith(HazelcastParallelClassRunner.class) @Category(value={QuickTest.class,ParallelTest.class}) public class ReplicatedMapReadYourWritesTest extends ReplicatedMapAbstractTest {   @Test public void testReadYourWritesBySize() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     HazelcastInstance instance2=nodeFactory.newHazelcastInstance();     final ReplicatedMap<Integer,Integer> map1=instance1.getReplicatedMap("default");     final ReplicatedMap<Integer,Integer> map2=instance2.getReplicatedMap("default");     HashMap<Integer,Integer> map=new HashMap<Integer,Integer>();     final int count=100;     for (int i=0; i < count; i++) {       map.put(i,i);     }     map1.putAll(map);     assertTrueEventually(new AssertTask(){       @Override public void run() throws Exception {         assertEquals(count,map1.size());         assertEquals(count,map2.size());       }     } );   }   @Test public void testReadYourWritesByGet() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     HazelcastInstance instance2=nodeFactory.newHazelcastInstance();     ReplicatedMap<String,Integer> map1=instance1.getReplicatedMap("default");     ReplicatedMap<String,Integer> map2=instance2.getReplicatedMap("default");     for (int i=0; i < 1000; i++) {       assertReadYourWriteByGet(instance2,map1,i);       assertReadYourWriteByGet(instance1,map2,i);     }   }   @Test public void testReadYourWritesByContainsKey() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     HazelcastInstance instance2=nodeFactory.newHazelcastInstance();     ReplicatedMap<String,Integer> map1=instance1.getReplicatedMap("default");     ReplicatedMap<String,Integer> map2=instance2.getReplicatedMap("default");     for (int i=0; i < 1000; i++) {       assertReadYourWriteByContainsKey(instance2,map1,i);       assertReadYourWriteByContainsKey(instance1,map2,i);     }   }   @Test public void testReadYourWritesByContainsValue() throws Exception {     TestHazelcastInstanceFactory nodeFactory=createHazelcastInstanceFactory();     HazelcastInstance instance1=nodeFactory.newHazelcastInstance();     HazelcastInstance instance2=nodeFactory.newHazelcastInstance();     ReplicatedMap<String,Integer> map1=instance1.getReplicatedMap("default");     ReplicatedMap<String,Integer> map2=instance2.getReplicatedMap("default");     for (int i=0; i < 1000; i++) {       assertReadYourWriteByContainsValue(instance2,map1,i);       assertReadYourWriteByContainsValue(instance1,map2,i);     }   }   private void assertReadYourWriteByGet(  HazelcastInstance instance,  ReplicatedMap<String,Integer> map,  int value){     String key=generateKeyAndPutValue(instance,map,value);     assertEquals(value,(int)map.get(key));   }   private void assertReadYourWriteByContainsKey(  HazelcastInstance instance,  ReplicatedMap<String,Integer> map,  int value){     String key=generateKeyAndPutValue(instance,map,value);     assertTrue(map.containsKey(key));   }   private void assertReadYourWriteByContainsValue(  HazelcastInstance instance,  ReplicatedMap<String,Integer> map,  int value){     generateKeyAndPutValue(instance,map,value);     assertTrue(map.containsValue(value));   }   private String generateKeyAndPutValue(  HazelcastInstance instance,  ReplicatedMap<String,Integer> map,  int value){     String key=generateKeyOwnedBy(instance);     map.put(key,value);     return key;   } } 
unlockForRescale()
Primitive.longObjectMap(8)
TEST_UTIL.waitUntilAllRegionsAssigned(tableName)
initial=100
synchronized (references) {   if (transformed == null) {     transformed=initializer.initializeBroadcastVariable(data);     data=null;   }   return transformed; } 
(System.currentTimeMillis() - this.lastAccessedTime.getTime()) >= maxInactiveInterval
t.report(n,REFERENCE_TO_SHORT_IMPORT_BY_LONG_NAME,n.getQualifiedName())
callTimeout=10000
ImmutableList<ObjectType>
getSessionTimeout().getSeconds()
Arrays.asList(STANFORD_TOKENIZE,STANFORD_SSPLIT,STANFORD_POS,STANFORD_LEMMA,STANFORD_NER,STANFORD_DEPENDENCIES)
ImmutableMap.<String,Type>of(StandardTypes.BOOLEAN,BOOLEAN,StandardTypes.BIGINT,BIGINT,StandardTypes.DOUBLE,DOUBLE,StandardTypes.VARCHAR,VARCHAR)
target == null || target.getNumFields() < this.mappings.size() + 1
!status.isDir()
conn.getResponseCode() == 200
width - originX
logger.trace("AtmosphereResource {} is resuming",uuid())
@UriParam(label="producer",defaultValue="true")
Calendar.getInstance(timeIsGivenInThisTimeZone)
new StringBuilder(726)
from(Constants.PARALLEL_LOANBROKER_URI).process(new CreditScoreProcessor(Constants.CREDITAGENCY_ADDRESS)).multicast(new BankResponseAggregationStrategy()).parallelProcessing(true)
assertEquals(3L,countDownLatch.getCount())
"value".equals(key) || "weight".equals(key)
log.warn("You did not add unauthenticated() nor session() but also don't have a current user. You probably meant unauthenticated(). This is a bug!",new Throwable())
outputDirectory="."
contentType != null && charset == null
event.isResuming() || event.isCancelled()
urlToNotify.openConnection(proxyToUse)
id=16504
callTimeoutMillis=6000
new Jackson2HalModule.HalHandlerInstantiator(HalObjectMapperConfiguration.this.relProvider,HalObjectMapperConfiguration.this.curieProvider,null)
ImmutableList.of(sourceNode)
@Override public Response description(String description){   this.setDescription(description);   return this; } 
FiltersTopComponent.findInstance().getUiModel().getSelectedRoot()
Utils.getInt(storm_conf.get(Config.TOPOLOGY_WORKERS),1)
i > 0 && glyphPositions[i] - x <= x - glyphPositions[i - 1]
setLowHighExpected(lowResults,highResults,expectedResults,MUC_TP,5965,5970,5965)
new DropTableEvent(tbl,success,deleteData,this)
setLowHighExpected(lowResults,highResults,expectedResults,CONLL_SCORE,53.75,54.10,54.01)
ids.getIDs().length > 50
value.equals("")
Byte.parseByte(value.toString())
quoteMatcher.group(1)
(xmin > x && xmin < x + width) && (xmax > x && xmax < x + width)
TestUtils.randomByte() + 128
new byte[18]
incomingMessage.getMessagePayloadByte(0)
Arrays.asList("abstract","continue","for","new","switch","assert","default","if","package","synchronized","boolean","do","goto","private","this","break","double","implements","protected","throw","byte","else","import","public","throws","case","enum","instanceof","return","transient","catch","extends","int","short","try","char","final","interface","static","void","class","finally","long","strictfp","volatile","const","float","native","super","while","type")
TupleDomain.all()
new IllegalStateException("Result is already complete: failed")
Thread.sleep(2000)
T deserialize(byte[] b); 
new ModelNode().set(240000L)
element.getLocalName()
clazz.isPrimitive() || clazz.isArray() || desc.getSerialVersionUID() == 0
case BALD: 
args.length != 3
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
logger.debug("The GENA Subscription for serviceID {} is established for device {}",sub.getService().getServiceId(),sub.getService().getDevice())
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.SentencesAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.BeforeAnnotation.class,CoreAnnotations.AfterAnnotation.class,CoreAnnotations.TokenBeginAnnotation.class,CoreAnnotations.TokenEndAnnotation.class,CoreAnnotations.IndexAnnotation.class,CoreAnnotations.OriginalTextAnnotation.class,CoreAnnotations.SentenceIndexAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class,CoreAnnotations.TokenIndexAnnotation.class)
address.getHost()
deployment.addServletContainerInitializer(new ServletContainerInitializerInfo(Initializer.class,new ImmediateInstanceFactory<ServletContainerInitializer>(initializer),NO_CLASSES))
ErrorHandlerBuilder builder=(ErrorHandlerBuilder)routeContext.getRoute().getErrorHandlerBuilder(); 
handleSecurityPermissionActions(child,permConfig)
n >= 0 && n < count(coll)
new TypeException("TypeHandler '" + getClass() + "' extends TypeReference but misses the type parameter. "+ "Remove the extension or add a type parameter to it.")
AtmosphereResourceImpl.class.cast(resource)
t.report(n,UNUSED_PRIVATE_PROPERTY,propName)
superClass == Object.class || superClass == null
MESSAGES.pathEntryNotFound(relativeTo)
new EnumValidator<TransactionMode>(TransactionMode.class,true,true)
Thread.sleep(3000)
assertThat(response).isEqualTo("Woop woop. yay\n")
assertClusterSizeEventually(2,h2)
new BufferedImage(region.width,region.height,page.getType())
renderUpdate(errorChannel,results)
AlluxioLogServerProcess.class
setComplete(mLength)
LOGGER.debug("no property for " + type + ", "+ format)
assertFalse(model.getUniqueItems())
assertEquals("There should be no files",0,files.length)
this.thrown.expectMessage("File must exist")
GL20.glUniform4iv(location,toIntBuffer(v,offset,count << 2))
Iterable<? extends IJsonNode>
MathUtils.PI * (this.width * this.height) / 4
new DataSize(40,Unit.MEGABYTE)
exportStatusCounts(exporter)
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
ImmutableMap.of(storeName,mutations)
!patient.isVoided() && patient.getIdentifiers().size() == 1
/**   * The resource.   */ private R mResource; 
TimeUnit.SECONDS.toMillis(5)
new StringBuilder(253)
chain.filter(exchange).transformDeferred((call) -> filter(exchange,call))
Utilities.getInputPaths(jobConf,mapWork,emptyScratchDir,ctx,false)
recordDefaults(HiveS3Config.class).setS3AwsAccessKey(null).setS3AwsSecretKey(null).setS3Endpoint(null).setS3SignerType(null).setS3PathStyleAccess(false).setS3UseInstanceCredentials(true).setS3SslEnabled(true).setS3SseEnabled(false).setS3SseType(PrestoS3SseType.S3).setS3SseKmsKeyId(null).setS3KmsKeyId(null).setS3EncryptionMaterialsProvider(null).setS3MaxClientRetries(5).setS3MaxErrorRetries(10).setS3MaxBackoffTime(new Duration(10,TimeUnit.MINUTES)).setS3MaxRetryTime(new Duration(10,TimeUnit.MINUTES)).setS3ConnectTimeout(new Duration(5,TimeUnit.SECONDS)).setS3SocketTimeout(new Duration(5,TimeUnit.SECONDS)).setS3MultipartMinFileSize(new DataSize(16,Unit.MEGABYTE)).setS3MultipartMinPartSize(new DataSize(5,Unit.MEGABYTE)).setS3MaxConnections(500).setS3StagingDirectory(new File(StandardSystemProperty.JAVA_IO_TMPDIR.value())).setPinS3ClientToCurrentRegion(false).setS3UserAgentPrefix("").setS3AclType(PrestoS3AclType.PRIVATE).setSkipGlacierObjects(false)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class RingbufferBasicLocalTest extends RingbufferAbstractTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(1).newInstances(config);   } } 
registry.bind("connectionFactoryMock",connectionFactoryMock)
logger.warn("",ex)
view == null
logger.warn("Configuration for influxdb not yet loaded or broken.")
taskService.createTaskQuery().orderByExecutionId()
Runnable t=new RunAfterTester(new DisconnectionBehavior(h2,h1),new QueueCallBuilder(h2)); 
testError("class Foo extends BaseFoo { method() { Foo.base(this, 'method'); } }",BASE_CLASS_ERROR)
WebAppUtils.getResolvedRMWebAppURLWithScheme(new Configuration())
mock.expectedMessageCount(3)
OptionalIdentifiedDefinition<RoutesDefinition>
new BroadcastAction(message)
DEFAULT_DATA_SIZE_PER_COLUMN=50
DEFAULT_NUMBER_OF_WRITE_BUFFERS=256
Optional.absent()
ProxyHelper.createProxy(endpoint,false,ISay.class)
servletPath.equals("/") || servletPath.equals("/*")
endFunction("write_column_statistics: ",ret != false,null)
xtw.writeCData(customProperty.getSimpleValue())
SimpleAttributeDefinitionBuilder.create("min-level",ModelType.STRING,true)
new InputStreamReader(localStream,StandardCharsets.UTF_8)
GL20.glUniform3fv(location,v)
!Arrays.equals(oldVal,val)
"Can't have more than 32767 vertices per batch: " + maxVertices
method.invoke(checksum,ByteBuffer.allocate(1))
unitOfWork != null && onCompletions != null
ResponseBody.create(new byte[0],MediaType.get("text/plain"))
totalBytesOnTiers.containsKey(tierAlias) && totalBytesOnTiers.get(tierAlias) > 0
testError("class Foo extends BaseFoo { constructor() { Foo.base(this); } }",BASE_CLASS_ERROR)
readLock()
Ints.min(completedSplits.get(),startedSplits.get(),splits)
dstPath.toString()
privObj.getObjectName().equals("masking_test_subq") || privObj.getObjectName().startsWith("masking_test_subq_n")
assertOpenEventually(latch)
i < 100
new IOException("should execute connector.connect() first")
lock.unlock()
STANDALONE
new ZipAggregationStrategy(true,true)
/**   * TreeTableCellEditor implementation. Component returned is the JTree.  */ private class TreeTableCellEditor extends BaseCellEditor implements TableCellEditor {   @Override public Component getTableCellEditorComponent(  JTable table,  Object value,  boolean isSelected,  int row,  int column){     return tree;   }   /**   * Overridden to return false, and if the event is a mouse event it is forwarded to the tree. <p>The behavior for this is debatable, and should really be offered as a property. By returning false, all keyboard actions are implemented in terms of the table. By returning true, the tree would get a chance to do something with the keyboard events. For the most part this is ok. But for certain keys, such as left/right, the tree will expand/collapse where as the table focus should really move to a different column. Page up/down should also be implemented in terms of the table. By returning false this also has the added benefit that clicking outside of the bounds of the tree node, but still in the tree column will select the row, whereas if this returned true that wouldn't be the case. <p>By returning false we are also enforcing the policy that the tree will never be editable (at least by a key sequence).  * @see TableCellEditor  */   @Override public boolean isCellEditable(  EventObject e){     if (e instanceof MouseEvent) {       for (int counter=getColumnCount() - 1; counter >= 0; counter--) {         if (getColumnClass(counter) == TreeTableModel.class) {           final MouseEvent me=(MouseEvent)e;           final MouseEvent newME=new MouseEvent(tree,me.getID(),me.getWhen(),me.getModifiers(),me.getX() - getCellRect(0,counter,true).x,me.getY(),me.getClickCount(),me.isPopupTrigger());           tree.dispatchEvent(newME);           break;         }       }     }     return false;   } } 
retries=1
LOG.error("Fail to set owner for {} with user: {}, group: {}",path,user,group)
analysis.getType(windowFunction)
executionJobVertex.getMaxParallelism()
new JmxEndpointProperties()
out.writeData(function)
tempBlock.getPath()
t=b.getBroadcasterConfig().applyFilters(r,t)
Status.createStatuseList(get(getBaseURL() + "statuses/retweeted_to_me.json",null,paging.asPostParameterList(),true))
transitiveClosure.setNumberOfPartitions(3)
logger.error("NODE {}: DeleteReturnRoute command failed.",nodeId)
Preconditions.checkNotNull(worker,"worker")
i >= BY_WOOL_DATA.length
queryPurger.scheduleWithFixedDelay(new PurgeQueriesRunnable(queries.keySet(),queryManager),200,200,TimeUnit.MILLISECONDS)
Time.currentTimeMillis()
new Texture(file,format,TextureFilter.isMipMap(min) || TextureFilter.isMipMap(max) ? true : false)
LOG.warn("Failed to freeSpace: No StorageDirView has enough capacity of {} bytes",availableBytes)
reducerCount=1
new IllegalStateException("Test IllegalStateException")
entityLabelProbVals.containsKey(label) && labelProbsForToken.get(label) < entityLabelProbVals.get(label)
(getSource().z() + getTarget().z()) / 3f
props.getProperty("exporter","com.yahoo.ycsb.measurements.exporter.TextMeasurementsExporter")
getTypeDeclaration(swaggerModel.getAdditionalProperties())
ctx.nextInboundMessageBuffer()
newPacked[j]
sentences.size() > 0 && sentences.get(0).entityMentions() != null
Arrays.asList("Int","Float","Double","Bool","Void","String","Character","AnyObject")
bufferSize < minAllocSize
d.setDefaultEncoding(mergedMetaData.getDefaultEncoding())
id=79
frustum.update(invProjectionView)
OpenmrsProfileWithoutMissingModule.class
new ClassicTableTypeMapping()
scanFeatures(getCamelKarafFeatureUrl(),"xml-specs-api","camel-core","camel-spring","camel-test")
new RetryDriver(maxAttempts,minSleepTime,maxSleepTime,scaleFactor,maxRetryTime,exceptions)
heartBeatTimerTask != null && heartBeatTimerTask instanceof MysqlDetectingTimeTask
testModules("var foo = function () {if (true) var module = {};" + "module.exports = {};};" + "module.exports = foo;","goog.provide('module$test');" + "var foo$$module$test=function(){if(true)var module={};" + "module.exports={}};"+ "var module$test=foo$$module$test")
items[23]
Thread.sleep(2000)
mavenBundle("info.cukes","cucumber-jvm-deps")
public class ArialBlack extends BasicFontMetrics { {     maxCharHeight=770;     widths[32]=333;     widths[33]=333;     widths[34]=500;     widths[35]=660;     widths[36]=666;     widths[37]=1000;     widths[38]=889;     widths[39]=277;     widths[40]=389;     widths[41]=389;     widths[42]=556;     widths[43]=660;     widths[44]=333;     widths[45]=333;     widths[46]=333;     widths[47]=277;     widths[48]=666;     widths[49]=666;     widths[50]=666;     widths[51]=666;     widths[52]=666;     widths[53]=666;     widths[54]=666;     widths[55]=666;     widths[56]=666;     widths[57]=666;     widths[58]=333;     widths[59]=333;     widths[60]=660;     widths[61]=660;     widths[62]=660;     widths[63]=610;     widths[64]=740;     widths[65]=777;     widths[66]=777;     widths[67]=777;     widths[68]=777;     widths[69]=722;     widths[70]=666;     widths[71]=833;     widths[72]=833;     widths[73]=389;     widths[74]=666;     widths[75]=833;     widths[76]=666;     widths[77]=943;     widths[78]=833;     widths[79]=833;     widths[80]=722;     widths[81]=833;     widths[82]=777;     widths[83]=722;     widths[84]=722;     widths[85]=833;     widths[86]=777;     widths[87]=1000;     widths[88]=777;     widths[89]=777;     widths[90]=722;     widths[91]=389;     widths[92]=277;     widths[93]=389;     widths[94]=660;     widths[95]=500;     widths[96]=333;     widths[97]=666;     widths[98]=666;     widths[99]=666;     widths[100]=666;     widths[101]=666;     widths[102]=389;     widths[103]=666;     widths[104]=666;     widths[105]=333;     widths[106]=333;     widths[107]=666;     widths[108]=333;     widths[109]=1000;     widths[110]=666;     widths[111]=666;     widths[112]=666;     widths[113]=666;     widths[114]=443;     widths[115]=610;     widths[116]=443;     widths[117]=666;     widths[118]=610;     widths[119]=943;     widths[120]=666;     widths[121]=610;     widths[122]=556;     widths[123]=389;     widths[124]=277;     widths[125]=389;     widths[126]=660;   } } 
case 2: 
new StringBuilder(246)
Nd4j.getAffinityManager().getDeviceForCurrentThread()
privObj.getObjectName().equals("masking_test_view") || privObj.getObjectName().startsWith("masking_test_view_n")
items[29]
MetricMonitorValues.getMetric(metrics,TRANSACTION_UNSAMPLED_CONTINUATION,UNSUPPORTED_GAUGE)
Math.abs(diff - maxAge) <= 2
lookup="java:/topic/myAwesomeTopic"
new HttpDigestAuthFilter(DIGEST_TEST_LOGIN,DIGEST_TEST_PASS)
new GenerationException("Couldn't parse type: " + typeDefinition,e)
DEFAULT_SHUFFLE_PORT=11000
Cli.<Runnable>builder("presto")
latch.await(5,TimeUnit.MINUTES)
topicRegistrations == null || topicRegistrations.isEmpty()
GL20.glUniform2iv(location,toIntBuffer(v,offset,count << 1))
contentLength >= 0
@Override DiscardMessageOutput create(Stream stream,Configuration configuration); 
Mockito.doNothing().when(mFileSystemMasterClient).rename(src,dst,renameOptions)
AstUtils.hasAtLeastOneAnnotation(classNode,"Controller","EnableWebMvc")
id=15
testClass.getMethod(SUITE_METHODNAME)
Arrays.asList(STANFORD_TOKENIZE,STANFORD_SSPLIT,STANFORD_POS,STANFORD_LEMMA,STANFORD_NER)
assertSizeEventually(COUNT,map,180)
!regex.equals(lastRegex) || p == null
log.error("Failed to transfer file from TaskExecutor {}.",taskManagerId,throwable)
TimeUnit.SECONDS.toMillis(timeoutSeconds)
page=DATABASE_TABLES_AND_USER
reg.getTimers(transformFilter(filter))
final AuditEventFormatter formatter=new AuditEventDefaultFormatter(); 
Optional<RemoteInterfaceType>
node1.isEquivalentToTyped(node2)
Status.createStatuseList(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/statuses/public_timeline.json"))
resultEndpoint.expectedBodiesReceivedInAnyOrder("one","three")
logger.trace("Mapped {} to {}",t,e.getValue())
DUPLICATE_OPS_TOLERANCE=10
nodeData.getAttributes() != null
mock.expectedMinimumMessageCount(2)
Optional<ImmutableZkWorker>
Assert.assertTrue(rule.appliesTo(builder.interval(new Interval("0500-01-01/2100-12-31")).build(),now))
is.read(buffer)
logger.trace("Removing: {}",r)
executeCommand("EXPLAIN OPTIONAL MATCH (n) RETURN n;","No data returned")
executionListenerContextCloseListener.addCloseFailedExecutionListener(executionListener,execution,executionVariablesToUse,customPropertiesMapToUse)
Assert.assertFalse(provider.checkValid("SELECT * FROM T WHERE FID = 40 OR EXTRACTVALUE(4484,CONCAT(0x5c,0x7163646371,(SELECT (CASE WHEN (4484=4484) THEN 1 ELSE 0 END)),0x7165767271))"))
public String getRequestRequiredAcks(){   return requestRequiredAcks; } 
new Duration(30,SECONDS)
assertThat(configs.get(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG)).isEqualTo(123)
Arrays.asList(STANFORD_TOKENIZE,STANFORD_SSPLIT,STANFORD_POS)
result.expectedBodiesReceivedInAnyOrder("A+C+E+G+I","B+D+F+H+J")
Float.parseFloat(encoding.substring(equalsPos + 1))
getConcept() != null && getConcept().getDescription() != null
intbuf.get(0)
this.categoryWithApiModel=category
configElements[0]
AbstractFilterRegistrationBean.class
logger.fine("Skipped renaming " + instancesSkipped + " invalidated "+ "properties, "+ propsSkipped+ " instances of properties "+ "that were skipped for specific types and "+ singleTypeProps+ " properties that were referenced from only one type.")
new IOException("test exception")
public Integer getAutoCommitInterval(){   return this.autoCommitInterval; } 
assertEquals(3,historyService.createHistoricActivityInstanceQuery().finished().list().size())
writtenIntermediatePhysicalDataSize+=stageStats.getPhysicalWrittenDataSize().toBytes()
invoke(agentInfoList,payload,DEFAULT_FUTURE_TIMEOUT)
builder.add(new ImplementSampleAsFilter(),new SimplifyExpressions(metadata),new UnaliasSymbolReferences(),new PruneRedundantProjections(),new SetFlatteningOptimizer(),new LimitPushDown(),new PredicatePushDown(metadata,splitManager),new PredicatePushDown(metadata,splitManager),new MergeProjections(),new SimplifyExpressions(metadata),new UnaliasSymbolReferences(),new PruneUnreferencedOutputs(),new PruneRedundantProjections())
FileSystemMaster.class
strategiesBuilder::customMessageReader
queryParams != null && !queryParams.isEmpty()
articleMgmtService.addArticle(article)
id=30
GL.glBindTexture(target,texture)
super(RowResolver.getCombinedRR(leftRR,rightRR),true,false,false,false,false,false,false,false,true,false); 
i <= getATN().maxTokenType
new CamelExchangeException("JettyClient failed with state " + exchangeState,exchange,exchange.getException())
flushIntervalSecs == 0
8 * Constants.MB
r.getResponse().sendError(503,"Remotely closed")
isDoubleA && isIntB
public LocalQueryRunner printPlan(){   printPlan=true;   return this; } 
Utilities.LOG14535.info("creating new paths " + System.identityHashCode(fsp2) + " for "+ dirName+ ", childSpec "+ unionPath+ ": tmpPath "+ fsp2.getTmpPath()+ ", task path "+ fsp2.getTaskOutputTempPath())
getJSDocType(cp)
new IntRangeValidator(0,true,true)
StringUtils.isEmpty(finalFormKey)
imageUrl.length() > MAX_FILE_NAME_LENGTH
PropertyValuesAnimationAdapter<T>
type.getName()
UfsUtils.loadUfs(new AlluxioURI(AlluxioURI.SEPARATOR),new AlluxioURI(mUfsRoot + AlluxioURI.SEPARATOR),new PrefixList("alluxio;exclusions",";"),mLocalAlluxioClusterResource.get().getMasterConf())
p.getFileSystem(conf).delete(p,true)
maxPendingPersists <= 0
location.equals(BlockStoreLocation.anyDirInTier(tierAlias))
log.info(message,exception)
i < 100
assertThat(getField(graphite,"port")).isEqualTo(2003)
DynamicAttributeRanking.refreshMinMax(this,graph)
LOG.warn("Block of ID " + getCurrentBlockId() + " could not be cached into Tachyon")
executeConnectAsync=true
LOG.warn("Error invoking metrics timer",e)
broadcasterFactoryClassName != null && broadcasterFactory == null
/**   * Telnet port.  */ private Integer port=5000; 
public class DefaultDynamicTransformerRegistry implements DynamicTransformerRegistry {   private final Logger logger=LoggerFactory.getLogger(this.getClass());   private final ConcurrentMap<TransformerKey,ClassFileTransformer> transformerMap=new ConcurrentHashMap<TransformerKey,ClassFileTransformer>();   @Override public void onRetransformRequest(  Class<?> target,  final ClassFileTransformer transformer){     add(target.getClassLoader(),target.getName(),transformer);     if (logger.isInfoEnabled()) {       logger.info("added retransformer classLoader: {}, class: {}, registry size: {}",target.getClassLoader(),target.getName(),transformerMap.size());     }   }   @Override public void onTransformRequest(  ClassLoader classLoader,  String targetClassName,  ClassFileTransformer transformer){     add(classLoader,targetClassName,transformer);     if (logger.isInfoEnabled()) {       logger.info("added dynamic transformer classLoader: {}, className: {}, registry size: {}",classLoader,targetClassName,transformerMap.size());     }   }   private void add(  ClassLoader classLoader,  String targetClassName,  ClassFileTransformer transformer){     ClassFileTransformer prev=transformerMap.putIfAbsent(new TransformerKey(classLoader,targetClassName.replace('.','/')),transformer);     if (prev != null) {       throw new ProfilerException("Transformer already exists. classLoader: " + classLoader + ", target: "+ targetClassName+ ", transformer: "+ prev);     }   }   @Override public ClassFileTransformer getTransformer(  ClassLoader classLoader,  String targetClassName){     if (transformerMap.isEmpty()) {       return null;     }     ClassFileTransformer transformer=transformerMap.remove(new TransformerKey(classLoader,targetClassName));     if (logger.isDebugEnabled()) {       logger.info("removed dynamic transformer classLoader: {}, className: {}, registry size: {}",classLoader,targetClassName,transformerMap.size());     }     return transformer;   } private static final class TransformerKey {     private final ClassLoader classLoader;     private final String targetClassName;     public TransformerKey(    ClassLoader classLoader,    String targetClassName){       this.classLoader=classLoader;       this.targetClassName=targetClassName;     }     @Override public int hashCode(){       return classLoader.hashCode() * 31 + targetClassName.hashCode();     }     @Override public boolean equals(    Object obj){       TransformerKey other=(TransformerKey)obj;       return this.classLoader.equals(other.classLoader) && this.targetClassName.equals(other.targetClassName);     }   } } 
LOG.debug("Failed to get mount information: {}",e.getMessage())
Thread.sleep(1500)
Assert.assertEquals("Wrong messages count: " + messages.size(),1,messages.size())
MESSAGES.persistenceUnitNotFound(absolutePath,puName,current)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class ListBasicDistributedTest extends ListAbstractTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(2).newInstances(config);   } } 
args == null || args.length == 0
logger.fine("Computing Control Flow Graph")
ctClass.toClass(clazz.getClassLoader(),null)
ImmutableBiMap<Integer,String>
new PriorityTieredBrokerSelectorStrategy(1,1)
this.addUnsafeEnchantments(stack.getEnchantments())
logger.trace("Retreiveing door data")
c.admin().indices().aliasesExist(new IndicesGetAliasesRequest(alias))
(int)timeoutMs / 1000
path(14)
ALIASES.addResourceAttributeDescription(resources,keyPrefix,container)
processDefinition.getTenantId() == null || ProcessEngineConfiguration.NO_TENANT_ID.equals(processDefinition.getTenantId())
conf.setInt("hbase.hregion.memstore.block.multiplier",100)
ImmutableSet<String>
Exception.class
url.getServiceKey()
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class AtomicLongBasicDistributedTest extends AtomicLongAbstractTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(2).newInstances();   } } 
getMemberships().stream().filter(m -> m.isActive() && m.getPatientId().equals(patient.getPatientId())).findFirst()
status.isDir()
routeList == null || routeList.isEmpty()
StringUtils.hasLength(secretQuestion) && StringUtils.hasLength(secretAnswer)
public Builder setRealmEnconding(String enc){   realm().setEnconding(enc);   return this; } 
ast != null && ast.getNextSibling() != null
NettyUtils.isDomainSocketSupported(dataSource)
new ObjectRecordWithStats(key,value)
maxRowsPerFrame=5000
-Float.parseFloat(position.getChildByName("Y").getText())
R
id=20
runtime.minus(provided)
@GET @Path("/{petId}") @ApiOperation(value="Find pet by ID",notes="Returns a pet when ID < 10.  ID > 10 or nonintegers will simulate API error conditions",response=Pet.class) @ApiResponses(value={@ApiResponse(code=400,message="Invalid ID supplied"),@ApiResponse(code=404,message="Pet not found")}) public Pet getPetById(@ApiParam(value="ID of pet that needs to be fetched",allowableValues="range[1,5]",required=true) @PathParam("petId") String petId) throws NotFoundException {   Pet pet=petData.getPetbyId(ru.getLong(0,100000,0,petId));   if (null != pet) {     return Response.ok().entity(pet).build();   }  else {     throw new NotFoundException(404,"Pet not found");   } } 
n.floatValue()
GL11.glGetFloatv(pname,params)
c.getPath() == null && getPath() != null
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class QueueBasicLocalTest extends QueueAbstractTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(1).newInstances(config);   } } 
mpline.substring(0,p).trim().toLowerCase(Locale.US)
LOG.error(e.getMessage(),e)
model.getNodeTextColumns() == null || model.getNodeTextColumns().length == 0
configuration.addViewInterceptor(method,factory,InterceptorOrder.View.COMPONENT_DISPATCHER)
new ArrayList<FileInputSplit>()
String... pathParams
checkArgument(keyGroupRange.contains(keyGroup),"%s does not contain key group %s",keyGroupRange,keyGroup)
views.html.search.noresults.render(currentUser(),q,searchResult,stream)
op.get("address").add("host",host)
PojoUtils.realize(list.toArray(),invokeMethod.getParameterTypes(),invokeMethod.getGenericParameterTypes())
assertEquals(1,conceptStopWords.size())
domainModel.execute(ExecutionContextBuilder.Factory.create(update).build(),resultHandler)
assertEquals(6358482l,received.get(0)[1])
assertResultExchange(result.getExchanges().get(0),true)
"simple".equalsIgnoreCase(language) && expression.indexOf("${") >= 0
Mockito.doThrow(EXCEPTION).when(mFileSystemMasterClient).rename(src,dst,renameOptions)
p == null || t < -1
return loadBefore; 
locations.isDefined()
registration.registerOperationHandler(CommonAttributes.ENABLE,ModClusterEnable.INSTANCE,enable,false,runtimeOnlyFlags)
VertexAttribute.ColorUnpacked()
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
isTop() || isUnknown() || objs == null && typeVar == null
defaultRowFlushBoundary == null ? 75000 : defaultRowFlushBoundary
(outputFolder + File.separator + apiFolder).replace("/",File.separator)
LOG.warn("Failed to delete path from UFS: {}",e.getMessage())
multiValueRow.get(0)
map.set(keyValue.getKeyData(),value)
globalExecutionStats.getStartedSplits()
AbstractBootstrap<ServerBootstrap,Channel>
Ordered.HIGHEST_PRECEDENCE + 20
StringBuilder pattern=new StringBuilder(this.prefix); 
new MidPartLongRange(mPos,endPos)
sendCommand(CLIENT,Keyword.LIST.raw)
assertEquals(5,lm.getFields().size())
getMockEndpoint("mock:" + i).expectedMessageCount(200)
getTupledSet()
partitionKey.getType().getName()
new LocalAlluxioClusterResource(1000,Constants.GB,Constants.SECURITY_AUTHENTICATION_TYPE,AuthType.SIMPLE.getAuthName(),Constants.SECURITY_AUTHORIZATION_PERMISSION_ENABLED,"true")
buffer.rewind().forward((int)n).getFixString((int)str_len,charsetName)
(outputFolder + File.separator + modelFolder).replace("/",File.separator)
SimpleAttributeDefinitionBuilder.create(ModelDescriptionConstants.ANY_ADDRESS,ModelType.BOOLEAN).setAllowExpression(false).setAllowNull(true)
!JedisClusterHashTagUtil.isClusterCompliantMatchPattern(matchPattern)
int retries() default 2; 
registry.bind("eventBus",new EventBus())
IOException e
ServiceHelper.startService(answer)
assertEquals(2,historyServer.getServices().size())
JsonNode::isNumber
new GetExecutionVariableInstancesCmd(executionId,variableNames,true)
internalExecutor.submit(futureTask)
logger.debug("Error connecting to Plex",e)
id=19905
connection.local().createStream(toStreamId(i),false)
id=47
index >= templateTypes.size()
Size.kilobytes(16)
new DynamicAwareEntry("http://localhost:80/test",null,null,null)
from("jms:queue:order").to("bean:validateOrder").to("mock:validate").threads(20).unmarshal(mySecureDataFormat).delay(500)
@ConditionalOnEnabledHealthIndicator("redis")
Expression.eq("searchable",searchable)
from("direct:tap").delay(1000)
public class XpathRegressionJavadocVariableTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=JavadocVariableCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionJavadocVariableOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(JavadocVariableCheck.class);     final String[] expectedViolation={"5:5: " + getCheckMessage(JavadocVariableCheck.class,JavadocVariableCheck.MSG_JAVADOC_MISSING)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='age']","/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='age']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableOne']/OBJBLOCK" + "/VARIABLE_DEF[@text='age']/MODIFIERS/LITERAL_PRIVATE");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=JavadocVariableCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionJavadocVariableTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(JavadocVariableCheck.class);     final String[] expectedViolation={"6:9: " + getCheckMessage(JavadocVariableCheck.class,JavadocVariableCheck.MSG_JAVADOC_MISSING)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableTwo']/OBJBLOCK" + "/CLASS_DEF[@text='InnerInner2']/OBJBLOCK/VARIABLE_DEF[@text='fData']","/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableTwo']/OBJBLOCK" + "/CLASS_DEF[@text='InnerInner2']/OBJBLOCK/VARIABLE_DEF[@text='fData']/MODIFIERS","/CLASS_DEF[@text='SuppressionXpathRegressionJavadocVariableTwo']/OBJBLOCK" + "/CLASS_DEF[@text='InnerInner2']/OBJBLOCK/VARIABLE_DEF[@text='fData']/MODIFIERS" + "/LITERAL_PUBLIC");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
keySet.isEmpty()
DatabaseDescriptor.getListenAddress().getHostAddress()
IRON_SWORD(267,1,250)
new CsvFilter("")
putBytes(v)
UnderFileSystemUtils.deleteFileIfExists(mUfs,mTempCheckpointPath)
"unable to parse " + optionStr
expected.getType().equalsIgnoreCase(actual.getType().toString())
/**   * Change the permission of a file or directory specified by args recursively.  */ public final class ChmodRecursiveCommand extends AbstractAclCommand {   public ChmodRecursiveCommand(  TachyonConf conf,  TachyonFileSystem tfs){     super(conf,tfs);   }   @Override public String getCommandName(){     return "chmodr";   }   @Override protected int getNumOfArgs(){     return 2;   }   @Override public void run(  String... args) throws IOException {     String modeStr=args[0];     TachyonURI path=new TachyonURI(args[1]);     chmod(path,modeStr,true);   }   @Override public String getUsage(){     return "chmodr <mode> <path>";   } } 
testSame("yz();","function yz() {}",VarCheck.NAME_REFERENCE_IN_EXTERNS_ERROR)
assertEquals(3,historyService.createHistoricActivityInstanceQuery().finished().list().size())
new MainMenu(Gdx.app)
filters={StringFilterAggregator.class}
Server server
ImmutableSortedSet.of("a","abbr","acronym","address","area","b","bdo","big","blockquote","br","caption","cite","code","colgroup","dd","del","div","dfn","dl","dt","em","fieldset","h1","h2","h3","h4","h5","h6","hr","i","img","ins","kbd","li","ol","p","pre","q","samp","small","span","strong","style","sub","sup","table","tbody","td","tfoot","th","thead","tr","tt","ul")
new Box2DTestCollection()
size=100
oldModel.getVendorExtensions().get("x-className") != null
bucketerContext.update(context.timestamp(),context.currentWatermark(),currentProcessingTime)
CellUtil.estimatedHeapSizeOfWithoutTags(cell)
verifyViewMethodsNotDeclaredFinal(sessionBeanClass,localBusinessInterfaces)
registry.bind("sessionStateListener",new SessionStateListener(){   @Override public void onStateChange(  SessionState arg0,  SessionState arg1,  Session arg2){   } } )
GL20.glVertexAttribPointer(indx,size,type,normalized,stride,(FloatBuffer)buffer)
Math.max(clientCount,1)
/**   * {@inheritDoc}  */ @Override public Broadcaster removeAtmosphereResource(AtmosphereResource r){   if (destroyed.get()) {     logger.debug(DESTROYED,getID(),"removeAtmosphereResource(AtmosphereResource r)");     return r;   }   if (!resources.contains(r)) {     return null;   }   boolean removed=resources.remove(r);   if (removed) {     if (resources.isEmpty()) {       notifyEmptyListener();       if (scope != SCOPE.REQUEST && lifeCyclePolicy.getLifeCyclePolicy() == EMPTY) {         releaseExternalResources();       }  else       if (scope == SCOPE.REQUEST || lifeCyclePolicy.getLifeCyclePolicy() == EMPTY_DESTROY) {         BroadcasterFactory.getDefault().remove(this,name);         destroy();       }     }   }   return r; } 
testSame(js)
el.classNames()
DeleteOptions.defaults().setRecursive(true).setAlluxioOnly(false).setUnchecked(true)
public static ScaleTo $(float scaleX,float scaleY,float duration){   ScaleTo action=pool.obtain();   action.scaleX=scaleX;   action.scaleY=scaleY;   action.duration=duration;   action.invDuration=1 / duration;   return action; } 
servers == null || servers.isEmpty()
DataFormat.PAYLOAD == message.get(DataFormat.class) && params[0] instanceof CxfPayload
from("direct:b").delay(4000)
setInternal(mapService.getMapServiceContext().toData(entry.getKey(),partitionStrategy),mapService.getMapServiceContext().toData(entry.getValue()),-1,TimeUnit.MILLISECONDS)
Database.builder(database)
RadioKafkaInput.class
realIndex < columns.size() && columns.get(realIndex).getColumn() != null
bytesRead == 0
0xffL << shift
E edge
minPriority == null ? 1 : minPriority
n.getNodeData().getId().toLowerCase().equals(str)
new GrammaticalRelation(Language.UniversalChinese,"amod:ordmod","ordinal numeric modifier",ADJECTIVAL_MODIFIER,"NP|QP",tregexCompiler,"NP < (QP=target < OD !< CLP)")
standardSearchRequest(query,IndexHelper.determineAffectedIndices(indexRangeService,deflector,range),range)
getConnectTimeout()
assertTrue(predicate.apply(pickleEvent))
CommandUtils.convertMsToDate(files[0].getCreationTimeMs())
public ReducedMetric registerMetric(String name,IReducer reducer,int timeBucketSizeInSecs){   return registerMetric(name,new ReducedMetric(reducer),timeBucketSizeInSecs); } 
String key
@ConditionalOnEnabledHealthIndicator("mail")
buf.discardReadBytes()
ImplementationMethodDescriptor methodDescriptor
expectedCountsForADoc(weights,e4Update,ind)
from("direct:a").delay(1000)
Threads.sleep(3000)
constructors[TXN_REMOVE_ALL_BACKUP]
type.isInterface()
callTimeout=5000
ChannelHandler handler=handler(); 
new ChannelInboundHandlerAdapter(){   @Override public void channelWritabilityChanged(  ChannelHandlerContext ctx) throws Exception {     buf.append(ctx.channel().isWritable());     buf.append(' ');   } } 
sname.getParent().getSimpleName().substring(8)
reportMissingOverride.isOn() && !declaredOverride && superClassHasDeclaredProperty&& declaredLocally&& !"__proto__".equals(propertyName)
portNum
id=10861
((ExecutorService)executor).isTerminated()
out.writeFloat((Float)obj)
Exception e
WebServicesTestUtils.checkStringEqual("hadoopBuildVersion",VersionInfo.getBuildVersion(),hadoopBuildVersion)
System.getProperty("RecoveryEnvironmentBean.expiryScannerClassNames") != null || System.getProperty("com.arjuna.ats.arjuna.common.RecoveryEnvironmentBean.expiryScannerClassNames") != null
instance.connect(null,null,"localhost","graylog2test",Integer.valueOf(27017),"false",null)
getConcept() != null && getConcept().getName() != null
id=10848
4 * Constants.KB
EnumMap<K,? extends V>
singletonComponentInstance == null
EmbeddedServerPortFileWriter.class
ElementsParser.isAlphaNumeric(ch2)
executeJobExecutorForTime(10000,200)
logger.fine("Expanding Jquery Aliases")
_availCPU + amount
app.getGraphics().newFont(app.getFiles().getInternalFileHandle("data/arial.ttf"),11,FontStyle.Plain,true)
public class XpathRegressionRightCurlyTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=RightCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRightCurlyOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RightCurlyCheck.class);     final String[] expectedViolation={"8:9: " + getCheckMessage(RightCurlyCheck.class,RightCurlyCheck.MSG_KEY_LINE_SAME,"}",9)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRightCurlyOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_IF/SLIST/RCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=RightCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRightCurlyTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RightCurlyCheck.class);     moduleConfig.addAttribute("option",RightCurlyOption.ALONE.toString());     final String[] expectedViolation={"9:15: " + getCheckMessage(RightCurlyCheck.class,RightCurlyCheck.MSG_KEY_LINE_NEW,"}",15)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRightCurlyTwo']/OBJBLOCK" + "/METHOD_DEF[@text='fooMethod']/SLIST/LITERAL_TRY/SLIST/RCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testThree() throws Exception {     final String checkName=RightCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRightCurlyThree.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RightCurlyCheck.class);     moduleConfig.addAttribute("option",RightCurlyOption.ALONE.toString());     final String[] expectedViolation={"5:72: " + getCheckMessage(RightCurlyCheck.class,RightCurlyCheck.MSG_KEY_LINE_ALONE,"}",72)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRightCurlyThree']/OBJBLOCK" + "/METHOD_DEF[@text='sample']/SLIST/LITERAL_IF/SLIST/RCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testFour() throws Exception {     final String checkName=RightCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionRightCurlyFour.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(RightCurlyCheck.class);     moduleConfig.addAttribute("option",RightCurlyOption.SAME.toString());     final String[] expectedViolation={"7:27: " + getCheckMessage(RightCurlyCheck.class,RightCurlyCheck.MSG_KEY_LINE_BREAK_BEFORE,"}",27)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionRightCurlyFour']/OBJBLOCK" + "/METHOD_DEF[@text='sample']/SLIST/LITERAL_IF/SLIST/RCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
mock2.expectedMinimumMessageCount(2)
Preconditions.checkNotNull(fileSystemMaster,"fileSystemMaster")
manager != null && manager.server != null
message.getFilteredFields()
this.uncollectedPointCreator
new IOException("Mocked failed close!")
id=16
items[31]
file.toURL()
List<String>
converterLookup.addCustomConverter(NUMBER_ITEM_NAME,IntegerDecimalConverter.class)
RestartStrategies.fixedDelayRestart(1,0)
eventListeners != null
FileSystem.getLocal(conf).delete(localScratchDir,true)
assertOpenEventually("responseLatch",responseLatch)
PartitionColumnsSeparator.class
Exception e
assertEquals(9,tokens.size())
!(!relaxLocality && (racks == null || racks.length == 0) && (nodes == null || nodes.length == 0))
modelNode.hasDefined(LOCAL)
new IllegalArgumentException("Cannot determine if commit is consistent")
sb.append(nc)
id=10863
Bytes.toString(tableName)
new Interval(startTime,endTime,ISOChronology.getInstanceUTC())
"Unsupported filesystem scheme found in the backup target url. Error Message: " + expMsg
e.toString()
getMockEndpoint("mock:test.after.1").expectedMessageCount(10)
log.debug("Received ping --> {}",payload)
testProviderConfig()
addListenerMethod2.addScopedInterceptor(NettyConstants.INTERCEPTOR_CHANNEL_PROMISE_ADD_LISTENER,NettyConstants.SCOPE,ExecutionPolicy.BOUNDARY)
super.getFamilyCellMap()
adapter.getCustomArgumentResolvers()
waitUntil(() -> noHandlersErrors.get() == (NODE_COUNT - 1) * ADDRESSES_COUNT,60_000)
/**   * Remove a  {@link AtmosphereResource} from the list of item to be notified whenthe  {@link Broadcaster#broadcast} is invoked.  * @param resource an {@link AtmosphereResource}  * @return {@link AtmosphereResource} if removed, or null if it was not.  */ Broadcaster removeAtmosphereResource(AtmosphereResource resource); 
id=10832
(BasicFontMetrics)c.newInstance()
AtmosphereRequest request
from("direct:c").delay(1000)
camelContext.getExecutorServiceManager().shutdown(timeoutCheckerExecutorService)
assertEquals(4,AccessControlClient.getUserPermissions(systemUserConnection,TEST_TABLE.toString()).size())
public Builder setRequestCompressionLevel(int requestCompressionLevel){   configBuilder.setRequestCompressionLevel(requestCompressionLevel);   return this; } 
i=2
Maps.newTreeMap()
details.setProperty(fileName,Long.toString(timestamp))
new HiveS3Config().setS3AwsAccessKey("abc123").setS3AwsSecretKey("secret").setS3Endpoint("endpoint.example.com").setS3SignerType(PrestoS3SignerType.S3SignerType).setS3PathStyleAccess(true).setS3UseInstanceCredentials(false).setS3SslEnabled(false).setS3SseEnabled(true).setS3SseType(PrestoS3SseType.KMS).setS3SseKmsKeyId("KMS_KEY_ID").setS3EncryptionMaterialsProvider("EMP_CLASS").setS3KmsKeyId("KEY_ID").setS3MaxClientRetries(9).setS3MaxErrorRetries(8).setS3MaxBackoffTime(new Duration(4,TimeUnit.MINUTES)).setS3MaxRetryTime(new Duration(20,TimeUnit.MINUTES)).setS3ConnectTimeout(new Duration(8,TimeUnit.SECONDS)).setS3SocketTimeout(new Duration(4,TimeUnit.MINUTES)).setS3MultipartMinFileSize(new DataSize(32,Unit.MEGABYTE)).setS3MultipartMinPartSize(new DataSize(15,Unit.MEGABYTE)).setS3MaxConnections(77).setS3StagingDirectory(new File("/s3-staging")).setPinS3ClientToCurrentRegion(true).setS3UserAgentPrefix("user-agent-prefix").setS3AclType(PrestoS3AclType.PUBLIC_READ).setSkipGlacierObjects(true)
ASYNC_PRODUCER_THREAD.getStackTrace()
LOCAL_OPTION.getLongOpt()
ttl >= 0
(DetailAST)child
modifiers.branchContains(TokenTypes.LITERAL_PRIVATE) || modifiers.branchContains(TokenTypes.ABSTRACT) || modifiers.branchContains(TokenTypes.FINAL)|| modifiers.branchContains(TokenTypes.LITERAL_STATIC)
new HttpClientCodec(4096,8192,true)
fragUtils.fragmentType()
idAnnotation != null && !method.isBridge()
InetAddress.getLocalHost()
new HashCollisionNode(edit,hash,count,array)
Assert.assertEquals(9300,Utils.calculateHeapSize(10000))
j.getConfiguration().get("pig.job.converted.fetch","").equals("") && j.getConfiguration().get("mapred.task.id","").equals("") && !("true".equals(j.getConfiguration().get("pig.illustrating")))
GL20.glGetUniformiv(program,location,params)
in.readLong()
resourceRegistration.registerAdditionalRuntimePackages(RuntimePackageDependency.optional("org.hibernate.search.orm"),RuntimePackageDependency.required("org.hibernate"),RuntimePackageDependency.optional("org.hibernate.envers"))
(byte)0xe2
new JobConf(config_,StreamJob.class)
List<Double>
LOG.warn("Failed to get next entry from " + jarFileName + ": "+ ioEx)
serialVersionUID=1975269372645791816L
ShrinkWrap.create(WebArchive.class).addClass(MyBatchlet.class).addAsWebInfResource(EmptyAsset.INSTANCE,ArchivePaths.create("beans.xml")).addAsResource("META-INF/batch-jobs/myJob.xml")
setBytes(index,data,0,length)
localInputFuture.cancel(mayInterruptIfRunning)
public class XpathRegressionDefaultComesLastTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=DefaultComesLastCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionDefaultComesLastOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(DefaultComesLastCheck.class);     final String[] expectedViolation={"8:13: " + getCheckMessage(DefaultComesLastCheck.class,DefaultComesLastCheck.MSG_KEY)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionDefaultComesLastOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP","/CLASS_DEF[@text='SuppressionXpathRegressionDefaultComesLastOne']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP" + "/LITERAL_DEFAULT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=DefaultComesLastCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionDefaultComesLastTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(DefaultComesLastCheck.class);     moduleConfig.addAttribute("skipIfLastAndSharedWithCase","true");     final String[] expectedViolation={"15:13: " + getCheckMessage(DefaultComesLastCheck.class,DefaultComesLastCheck.MSG_KEY_SKIP_IF_LAST_AND_SHARED_WITH_CASE)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionDefaultComesLastTwo']/OBJBLOCK" + "/METHOD_DEF[@text='test']/SLIST/LITERAL_SWITCH/CASE_GROUP/LITERAL_DEFAULT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
ImmutableList.of(new Identifier("a"),new Identifier("b"))
Status.createStatuseList(get(getBaseURL() + "statuses/user_timeline.json",null,paging.asPostParameterList(),true))
Configuration.getMs(PropertyKey.USER_FILE_WAITCOMPLETED_POLL_MS)
processEngineConfiguration.setEnableSafeBpmnXml(true)
GL20.glUniform1fv(location,toFloatBuffer(v,offset,count))
Site.me().setRetryTimes(3).setSleepTime(1000)
getExecutorService("hz.initialization")
beans.add(bean)
public Object getBean() throws NoBeanAvailableException {   Object value=lookupBean();   if (value == null) {     throw new NoBeanAvailableException(name);   }   if (value != bean) {     bean=value;     processor=null;     if (!ObjectHelper.equal(ObjectHelper.type(bean),ObjectHelper.type(value))) {       beanInfo=null;     }   }   return value; } 
twitter1.checkUserListSubscription(id1.screenName,userList.getId(),id2.id)
word=END_WORD
"Searching class for device type " + deviceType
DEFAULT_AKKA_LOG_LIFECYCLE_EVENTS=true
methodsToImplement(type,methods)
Exception ex
DEFAULT_OCTREE_WIDTH=50000
getMockEndpoint("mock:start").expectedMinimumMessageCount(5)
assertEquals(8,this.context.getBean(FilterChainProxy.class).getFilterChains().size())
new NotifyBuilder(context).whenDone(2)
serverService.getOutgoingInterceptors()
SSOTestBase.executeFormAuthSingleSignOnTest(baseURLNoAuth,baseURLNoAuth,log)
Preconditions.checkNotNull(blockIds,"blockIds")
RCFileMergeMapper.jobClose(outputPath,success,job,console)
id=10857
e instanceof MaybePrimitiveExpr && e.hasJavaClass() && ((MaybePrimitiveExpr)e).canEmitPrimitive()
Assert.assertEquals(expected,result)
Response schema(Property property); 
logger.warn("{} {}",errorCode,message)
timeoutMs=1000
public void testWithDFS() throws Exception {   MiniDFSCluster dfs=null;   MiniMRCluster mr=null;   FileSystem fileSys=null;   try {     final int taskTrackers=4;     Configuration conf=new Configuration();     dfs=new MiniDFSCluster(conf,4,true,null);     fileSys=dfs.getFileSystem();     JobConf jtConf=new JobConf();     jtConf.setInt(TTConfig.TT_MAP_SLOTS,1);     jtConf.setInt(TTConfig.TT_REDUCE_SLOTS,1);     jtConf.setLong(JTConfig.JT_TRACKER_EXPIRY_INTERVAL,10 * 1000);     mr=new MiniMRCluster(taskTrackers,fileSys.getUri().toString(),1,null,null,jtConf);     testFailCommitter(CommitterWithFailSetup.class,mr.createJobConf());     testFailCommitter(CommitterWithFailCommit.class,mr.createJobConf());     testSetupAndCleanupKill(mr,dfs,true);     fileSys.delete(setupSignalFile,true);     fileSys.delete(cleanupSignalFile,true);     testSetupAndCleanupKill(mr,dfs,false);   }   finally {     if (dfs != null) {       dfs.shutdown();     }     if (mr != null) {       mr.shutdown();     }   } } 
Exception e
implementationMethodDescriptors.build()
cursor.shouldRetry()
new MalformedException("Unused message placeholder: " + phName,node)
Optional.fromNullable(resourceManagementScheduler)
Long newerThan
assertEquals(1234,localReplicatedMapStats.getOwnedEntryMemoryCost())
type=200
decoder.readInbound()
table == null
operation.get(OPERATION_HEADERS,ALLOW_RESOURCE_SERVICE_RESTART).set(false)
options.setLanguageOut(LanguageMode.ECMASCRIPT5)
new Long(4)
new Color(pixels[i],true)
options.needsTranspilationFrom(ES8)
sentencesFile != null
row == null || row.size() == 0
lockMode == InodeTree.LockMode.READ
(ResourceAdapterXmlDeploymentService)controller.getService()
DiagnosticType.error("JSC_GOOG_MODULE_IN_NON_MODULE","goog.module() call must be the first statement in a module.")
/**   * Matches no characters.   */ public static final InputFastMatcher NONE=new InputFastMatcher(){   @Override public boolean matches(  char c){     return false;   }   @Override public String replaceFrom(  CharSequence sequence,  CharSequence replacement){     checkNotNull(replacement);     return sequence.toString();   }   private void checkNotNull(  CharSequence replacement){   }   @Override public String collapseFrom(  CharSequence sequence,  char replacement){     return sequence.toString();   }   @Override public String trimTrailingFrom(  CharSequence sequence){     return sequence.toString();   } } ; 
stat.st_size.longValue()
mMountTable.resolve(getPath(dir)).toString()
ImmutableMap<String,String>
ChannelBufferHolders.messageBuffer(queue)
CommandUtils.convertMsToDate(files[2].getCreationTimeMs())
inUseByte != Record.IN_USE.byteValue() && inUseByte != Record.NOT_IN_USE.byteValue()
Preconditions.checkNotNull(timer,"timer")
SSLContext.setCertificateChainFile(ctx,trustCertChainFile.getPath(),false)
batteryVp > full
Context.hasPrivilege(OpenmrsConstants.PRIV_EDIT_USERS)
new OptiqSemanticException(generateErrorMessage(tabref,"Schema of both sides of union should match: Column " + field + " is of type "+ lInfo.getType().getTypeName()+ " on first table and type "+ rInfo.getType().getTypeName()+ " on second table"))
resource() != null && resource().transport() != AtmosphereResource.TRANSPORT.WEBSOCKET
types.get(i)
overrideDeploymentConfig || (loginConfig == null)
newHighlyAvailableDatabaseBuilder(path)
buffer.readableBytes() < 8
newNode.makeNonIndexableRecursive()
new StringBuilder(740)
reg.bind(LDAP_CONN_NAME,getWiredConnection(ldapServer))
createRecord(value,now,expiryTime)
S3DataSegmentMover.class
!force && EventCacheBroadcasterCache.class.isAssignableFrom(broadcasterCache.getClass())
reportMissingOverride.isOn() && !declaredOverride && interfaceHasProperty&& !"__proto__".equals(propertyName)
complete.expectedBodiesReceivedInAnyOrder("finish","stop","faulted","except")
!sourceNodeTextData.getText().isEmpty()
1024 * 1024 * 15
(getSource().x() + getTarget().x()) / 3f
offset >= 0
annotations.remove(node)
GL15.glGetBufferParameteriv(target,pname,params)
logger.error("Item not found error while generating chart.",e)
id=10872
Preconditions.checkNotNull(blockWorker,"blockWorker")
parser.parse(INFO_OPTIONS,args,true)
request.getContentType().startsWith("application/x-www-form-urlencoded")
PositiveDurationValidator.class
OpenmrsProfileWithoutMissingModule bean=applicationContext.getBean(OpenmrsProfileWithoutMissingModule.class); 
new IllegalArgumentException("the annotation is null")
Response example(String type,Object example); 
setSunPosition(cal,latitude,longitude,sun)
System.nanoTime()
StringBuilder retval=new StringBuilder(); 
alluxioUriToLoad.getPath()
index < mInUseLocks.length()
GL20.glUniform3fv(location,toFloatBuffer(v,offset,count * 3))
client.getState().setProxyCredentials(new AuthScope(null,-1,AuthScope.ANY_REALM),defaultcreds)
new TableException(String.format("Unable to generate a string representation of the serializer snapshot of '%s' " + "describing the class '%s' for the ANY type.",serializer.getClass().getName(),clazz.toString()),e)
Gdx.input.getX(i)
SystemPropertyUtil.getBoolean("io.netty.noJdkZlibDecoder",true)
timelineObjectHolder.getObject().getChunk(0).getObject().getMetrics()
Subqueries.lt(0L,subquery)
i < 3
routes.SessionsController.index("")
retVal.setProperty(p.getKey(),p.getValue())
rejectRemoteInitiatedRenegotiation && !isDestroyed() && SSL.getHandshakeCount(ssl) > 1
new WebApplicationException(e,serverError(e))
mTestStream.getFlushedBytes()
visibleOnly=true
assertEquals(JavadocTagInfo.Type.BLOCK,JavadocTagInfo.VERSION.getType())
10 * 1024 * 1024
params.getInt("numPages",PageRankData.getNumberOfPages())
info.getRegionNameAsString()
namespaces.isDefined()
Assert.assertEquals(1061,details.get(0).getAbsolutePosition())
exchange.getIn()
new StoreFile(this.fs,linkFilePath,testConf,cacheConf,BloomType.NONE,NoOpDataBlockEncoder.INSTANCE)
BeanFactoryUtils.beanNamesForTypeIncludingAncestors(beanFactory,JwtAccessTokenConverter.class,false,false)
logger.error("Endpoint {} not found on node {}. Cannot set command classes.",endpointId,this.getNode().getNodeId())
assertEquals(row.getField(0),2L)
logError(lcurly,"lcurly",lcurlyPos,curlyIndent())
Assert.assertTrue("reload-required".equals(result.get(RESPONSE_HEADERS).get(PROCESS_STATE).asString()))
type == TokenTypes.CLASS_DEF || type == TokenTypes.ENUM_DEF || type == TokenTypes.INTERFACE_DEF
segments.add(segment)
websocketComponent.setMaxThreads(20)
conceptAnswer.getAnswerConcept()
ChronicleEngineEndpoint.class
new StringBuilder(120)
unkn_parts.addAll(Hive.get().getPartitions(tab))
id=13107
minSize(new Fixed(width),new Fixed(height))
id=10865
new RuntimeIOException("Error opening output file",e)
final String clientSecret="your client secret"; 
logger.debug("gave up waiting for query reply from device {}",m_address)
registration.registerOperationHandler(CommonAttributes.STOP,ModClusterStop.INSTANCE,stop,false,runtimeOnlyFlags)
mPreferredHost.equals("localhost")
ownedEntryCount == nearCacheSize
ImportAutoConfigurationWithItemsTwo.class
!r1
database.FindProduct(node.getManufacturer(),node.getDeviceType(),node.getDeviceId(),node.getApplicationVersion())
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
new SimpleAttributeDefinitionBuilder(CommonAttributes.NAME,ModelType.STRING,false).setXmlName(Attribute.NAME.getLocalName()).setAllowExpression(false)
GL20.glUniform4fv(location,toFloatBuffer(v,offset,count << 2))
lookup="java:/ConnectionFactory"
lDirAllocator.getLocalPathForWrite(ContainerLocalizer.USERCACHE + Path.SEPARATOR + user+ Path.SEPARATOR+ ContainerLocalizer.APPCACHE+ Path.SEPARATOR+ appIdStr+ Path.SEPARATOR+ containerIdStr,LocalDirAllocator.SIZE_UNKNOWN,this.conf,false)
Latkes.getStaticServePath()
Color.fromRGB(0x6689D3)
logger.info("Installing Filter {}",filterName)
stats.getLastAccessTime() >= lastAccessTime
latch.await(20,SECONDS)
MAX_ARITY=25
toByteBuffer(index,length)
abandonSegment(entry.getKey(),entry.getValue())
(Long)123L
ShrinkWrap.create(WebArchive.class).addClass(BatchTestHelper.class).addClass(MyInputRecord.class).addClass(MyItemProcessor.class).addClass(MyItemReader.class).addClass(MyItemWriter.class).addClass(MyOutputRecord.class).addAsWebInfResource(EmptyAsset.INSTANCE,ArchivePaths.create("beans.xml")).addAsResource("META-INF/batch-jobs/myJob.xml")
logger.trace("Invalid Account Credentials")
/**   * Loads the value of a given key. If distributed map doesn't contain the value for the given key then Hazelcast will call implementation's load (key) method to obtain the value. Implementation can use any means of loading the given key; such as an O/R mapping tool, simple SQL or reading a file etc.  * @param key  * @return value of the key  */ V load(K key); 
assertEquals(4,AccessControlLists.getTablePermissions(conf,TEST_TABLE).size())
region.getRegionHeight()
JSError.make(REPORT_PATH_IO_ERROR,reportPath,e.getMessage())
id=32
new HTable(TEST_UTIL.getConfiguration(),TABLE)
new Interval(timeList.get(0).getValue().getMinTime().getMillis(),timeList.get(0).getValue().getMaxTime().getMillis(),ISOChronology.getInstanceUTC())
DependencyFilterUtils.classpathFilter(JavaScopes.COMPILE,JavaScopes.RUNTIME)
DEFAULT_HEAP_LIMIT_CAP=700
LOG.info("Unable to unmarshall exception content",e)
source.getAddress()
invocation.logger.finest("'is-executing': " + executing + " -> "+ invocation)
/**   * {@inheritDoc}  */ @Override public Broadcaster addAtmosphereResource(AtmosphereResource r){   try {     if (destroyed.get()) {       logger.debug(DESTROYED,getID(),"addAtmosphereResource(AtmosphereResource<?, ?> r");       return r;     }     start();     if (scope == SCOPE.REQUEST && requestScoped.getAndSet(true)) {       throw new IllegalStateException("Broadcaster " + this + " cannot be used as its scope is set to REQUEST");     }     if (maxSuspendResource.get() > 0 && resources.size() >= maxSuspendResource.get()) {       if (policy == POLICY.FIFO) {         AtmosphereResource resource=resources.poll();         try {           logger.warn("Too many resource. Forcing resume of {} ",resource);           resource.resume();         }  catch (        Throwable t) {           logger.warn("failed to resume resource {} ",resource,t);         }       }  else       if (policy == POLICY.REJECT) {         throw new RejectedExecutionException(String.format("Maximum suspended AtmosphereResources %s",maxSuspendResource));       }     }     if (resources.contains(r)) {       return r;     } synchronized (concurrentSuspendBroadcast) {       if (resources.isEmpty()) {         BroadcasterFactory.getDefault().add(this,name);       }       checkCachedAndPush(r,r.getAtmosphereResourceEvent());       if (isAtmosphereResourceValid(r)) {         resources.add(r);       }     }   }   finally {     if (resources.size() > 0) { synchronized (awaitBarrier) {         awaitBarrier.notifyAll();       }     }   }   return r; } 
assertEquals("string",model.getProperties().get(NAME).getType())
new Tag(text,line,this)
mContext.getClass()
id=21
new StormClientErrorHandler(client.name())
Throwable exception
LOG.info("Unable to read HTTP response content",e)
logger.info(getName() + " has been started")
Mockito.any(ProducerRecord.class)
valueClass(NullWritable.class)
idGenerator.generateUuid()
value.longLongValue()
lowByte.equals("")
nlDataOutNodes != null && nlDataOutNodes.getLength() > 0
n.longValue()
logger.trace("Session created")
new StringBuilder(245)
callerPrincipalCallback != null
UndertowWebServer.class
!plugin.isEnabled()
routeController != null
!Iterables.isEmpty(batchServerInventoryView.getInventory()) && Iterables.get(batchServerInventoryView.getInventory(),0).getSegments().size() != testSegments.size()
file.getFileNameOnly()
Preconditions.checkNotNull(containerIdGenerator,"containerIdGenerator")
world.add("capsule",5f,3f,5f)
defaultCometSupport(defaultToBlocking)
logger.trace("myq securityToken: {}",securityToken)
ss.getAuthorizerV2().checkPrivileges(type,Arrays.asList(commandObj),null,null)
Integer autoCommitInterval
Object value=nsDictionary.get(convertKey(key)); 
XMLInputFactory.newInstance()
new IdentityHashMap<>()
System.currentTimeMillis() - start + 750
LOG.error(getName() + " caught: ",e)
mLocalWorkerAddress.getDataPort()
webSocketProcessor.close(webSocket,1000)
session == null
batteryVp > high
t.getCause()
modulePath.split(File.pathSeparator)[0]
chooser.showOpenDialog(null)
simple.getToSentDate()
new ChannelHandler(){   @Override public void userEventTriggered(  ChannelHandlerContext ctx,  Object evt) throws Exception {     if (evt instanceof WebSocketServerProtocolHandler.HandshakeComplete) {       assertNull(ctx.pipeline().context(WebSocketServerProtocolHandshakeHandler.class));     }   } } 
Integer id=Integer.parseInt(reader.getAttributeValue(null,"id")); 
assertThat(page2.pagination().getGlobalTotal()).isEqualTo(5)
(ZWaveWakeUpCommandClass)node.getCommandClass(CommandClass.WAKE_UP)
@Override public ExtendedCell deepClone(){   byte[] copy=Bytes.copy(this.bytes,this.offset,this.length);   KeyValue kv=new NoTagsKeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } 
longValue != 0
new DynamicAwareEntry("http://localhost/test",null,null,null)
maxSize(new Fixed(width),new Fixed(height))
"https".equals(protocol) || "wss".equals(protocol)
GL.glTexSubImage2D(target,level,xoffset,yoffset,width,height,format,type,pixels,Memory.getPosition(pixels))
column.createColumnObserver(false)
group != null && !"0".equals(group)
wrappedBuffer(Integer.MAX_VALUE,byteBuffer)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class TransactionalSetBasicLocalTest extends TransactionalSetAbstractTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(1).newInstances(config);   } } 
comparePartitionOwnership(false,localMember,partition)
GL20.glGetActiveUniform(program,index,256,size,typeTmp)
LOG.debug("Building gRPC server on <any address>" + ":" + configuration.getPort())
hasMatch=false
mRecomputeLauncherService.shutdown()
id=39
i < repeatCount
public Builder setCompressionEnabled(boolean compressionEnabled){   configBuilder.setCompressionEnabled(compressionEnabled);   return this; } 
new Server()
TypeUtils.getKoltinConstructor(constructors,paramNames)
private final ChannelPipeline pipeline; 
ReactiveHelper.scheduleSync(() -> processor.process(exchange,done -> {   if (exchange.getException() != null) {     getExceptionHandler().handleException("Error processing aggregated exchange",exchange,exchange.getException());   }  else {     log.trace("Processing aggregated exchange: {} complete.",exchange);   } } ),"sending aggregated exchange")
cached.get(group)
!entry.getKey().isEmpty()
Status.createStatuseList(get(getBaseURL() + "statuses/retweets_of_me.json",null,paging.asPostParameterList(),true))
connection.remote().incrementAndGetNextStreamId()
sequenceFileVersion != SEQUENCE_FILE_VERSION
/**   * Changes the group of a file or directory specified by args.  */ public final class ChgrpCommand extends AbstractAclCommand {   public ChgrpCommand(  TachyonConf conf,  TachyonFileSystem tfs){     super(conf,tfs);   }   @Override public String getCommandName(){     return "chgrp";   }   @Override protected int getNumOfArgs(){     return 2;   }   @Override public void run(  String... args) throws IOException {     String group=args[0];     TachyonURI path=new TachyonURI(args[1]);     chgrp(path,group,false);   }   @Override public String getUsage(){     return "chgrp <group> <path>";   } } 
public class XpathRegressionIllegalThrowsTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=IllegalThrowsCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionIllegalThrowsOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(IllegalThrowsCheck.class);     final String[] expectedViolation={"4:35: " + getCheckMessage(IllegalThrowsCheck.class,IllegalThrowsCheck.MSG_KEY,"RuntimeException")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionIllegalThrowsOne']/OBJBLOCK" + "/METHOD_DEF[@text='sayHello']/LITERAL_THROWS[@text='RuntimeException']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=IllegalThrowsCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionIllegalThrowsTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(IllegalThrowsCheck.class);     final String[] expectedViolation={"8:45: " + getCheckMessage(IllegalThrowsCheck.class,IllegalThrowsCheck.MSG_KEY,"java.lang.Error")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionIllegalThrowsTwo']/OBJBLOCK" + "/METHOD_DEF[@text='methodTwo']/LITERAL_THROWS/DOT[@text='Error']");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
@Override public ExtendedCell deepClone(){   byte[] copy=new byte[this.length];   ByteBufferUtils.copyFromBufferToArray(copy,this.buf,this.offset,0,this.length);   KeyValue kv=new KeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } 
nameDefinitionMultimap.keySet()
IS_EMPTY + 1
writeMethod2.addScopedInterceptor(NettyConstants.INTERCEPTOR_CHANNEL_PIPELINE_WRITE,NettyConstants.SCOPE_WRITE,ExecutionPolicy.BOUNDARY)
ImmutableSet<ImplementationMethodDescriptor>
ObjectHelper.isNotEmpty(configuration.getClusterService())
serversByLoad.firstKey()
id=22
ByteBuf line=buffer(64); 
methodName.startsWith("save") || methodName.startsWith("create") || methodName.startsWith("update")
new byte[14]
assertEquals(ChronicleEngineMapEventType.INSERT,mock.getExchanges().get(0).getIn().getHeader(ChronicleEngineConstants.MAP_EVENT_TYPE))
Y1
timer.isActive() || (!timer.isActive() && timer.getState() == TimerState.ACTIVE)
registry.bind("dummy",new ReactiveStreamsTestService("from-registry"))
LOG.isDebugEnabled()
Response header(String name,Property property); 
testWarning(LINE_JOINER.join("goog.module('m');","","var d = goog.require('a.b.d');","var c = goog.require('a.c');","","alert(1);"),REQUIRES_NOT_SORTED)
configureWebDotXmlAtmosphereHandler(scFacade)
public class XpathRegressionImportControlTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=ImportControlCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionImportControlOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ImportControlCheck.class);     moduleConfig.addAttribute("file",getPath(checkName,"SuppressionXpathRegressionImportControlOne.xml"));     final String[] expectedViolation={"3:1: " + getCheckMessage(ImportControlCheck.class,ImportControlCheck.MSG_DISALLOWED,"java.util.Scanner")};     final List<String> expectedXpathQueries=Collections.singletonList("/IMPORT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=ImportControlCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionImportControlTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ImportControlCheck.class);     moduleConfig.addAttribute("file",getPath(checkName,"SuppressionXpathRegressionImportControlTwo.xml"));     final String[] expectedViolation={"1:1: " + getCheckMessage(ImportControlCheck.class,ImportControlCheck.MSG_UNKNOWN_PKG)};     final List<String> expectedXpathQueries=Collections.singletonList("/PACKAGE_DEF");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testThree() throws Exception {     final String checkName=ImportControlCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionImportControlThree.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ImportControlCheck.class);     final String[] expectedViolation={"1:1: " + getCheckMessage(ImportControlCheck.class,ImportControlCheck.MSG_MISSING_FILE)};     final List<String> expectedXpathQueries=Collections.singletonList("/PACKAGE_DEF");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testFour() throws Exception {     final String checkName=ImportControlCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionImportControlFour.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(ImportControlCheck.class);     moduleConfig.addAttribute("file",getPath(checkName,"SuppressionXpathRegressionImportControlFour.xml"));     final String[] expectedViolation={"4:1: " + getCheckMessage(ImportControlCheck.class,ImportControlCheck.MSG_DISALLOWED,"java.util.Scanner")};     final List<String> expectedXpathQueries=Collections.singletonList("/IMPORT[./DOT[@text='Scanner']]");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
NettyConnectionsPool.class
@InputMagicNumberIntMethodAnnotation(42)
CliRealtimeExample.class
selectedFile != null && fileFilter != null
Configuration.getMs(PropertyKey.MASTER_TTL_CHECKER_INTERVAL_MS)
context.add("exceptionalMethod",123.0f)
LOG.warn("Cannot access storage directory " + rootPath,ex)
public class XpathRegressionHiddenFieldTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=HiddenFieldCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(HiddenFieldCheck.class);     final String[] expectedViolation={"10:34: " + getCheckMessage(HiddenFieldCheck.class,HiddenFieldCheck.MSG_KEY,"value")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitOne']/OBJBLOCK" + "/INSTANCE_INIT/SLIST/EXPR/METHOD_CALL/ELIST/LAMBDA/PARAMETERS" + "/PARAMETER_DEF[@text='value']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=HiddenFieldCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionExplicitTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(HiddenFieldCheck.class);     final String[] expectedViolation={"8:45: " + getCheckMessage(HiddenFieldCheck.class,HiddenFieldCheck.MSG_KEY,"other")};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionExplicitTwo']/OBJBLOCK" + "/METHOD_DEF[@text='method']/PARAMETERS/PARAMETER_DEF[@text='other']/IDENT");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
file.length() > Integer.MAX_VALUE
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
logger.debug("Cannot retrieve item {} for widget {}",itemName,w.eClass().getInstanceTypeName())
mock.expectedMinimumMessageCount(2)
getParser().parse(argsToUse)
ModuleReflectionUtils::isCheckstyleTreeWalkerCheck
Map<String,Object>
case PLAYER_QUIT: 
new IndexOutOfBoundsException(fieldNum + " for range [0.." + (this.numFields - 1)+ "]")
LOG.warn("Failed to find " + baseDirectory.getAbsolutePath())
LinkedHashMap<String,Operator<? extends Serializable>>
LOG.debug("EOL(end-of-line) defined for the CSV: {}",eol)
new DBException(String.format("Error while creating Aerospike " + "client for %s:%d.",host,port),e)
this.configuration.getMappedStatement(id,false)
lookupService.lookupPrincipalByName(user)
ObjectHelper.loadClass(name,loader)
size=1000
"Notes".equals(subSectionName) || "Rule Description".equals(subSectionName) || "Metadata".equals(subSectionName)
handles[count]
-29
o instanceof XidImpl
/**   * @author Eric Vergnaud  */ public class Python2Target extends AbstractPythonTarget {   protected static final String[] python2Keywords={"abs","all","any","apply","as","bin","bool","buffer","bytearray","callable","chr","classmethod","coerce","compile","complex","delattr","dict","dir","divmod","enumerate","eval","execfile","file","filter","float","format","frozenset","getattr","globals","hasattr","hash","help","hex","id","input","int","intern","isinstance","issubclass","iter","len","list","locals","map","max","min","next","memoryview","object","oct","open","ord","pow","print","property","range","raw_input","reduce","reload","repr","reversed","round","set","setattr","slice","sorted","staticmethod","str","sum","super","tuple","type","unichr","unicode","vars","with","xrange","zip","__import__","True","False","None"};   /**   * Avoid grammar symbols in this set to prevent conflicts in gen'd code.   */   protected final Set<String> badWords=new HashSet<String>();   public Python2Target(  CodeGenerator gen){     super(gen,"Python2");   }   @Override public String getVersion(){     return "4.4.0";   }   public Set<String> getBadWords(){     if (badWords.isEmpty()) {       addBadWords();     }     return badWords;   }   protected void addBadWords(){     badWords.addAll(Arrays.asList(python2Keywords));     badWords.add("rule");     badWords.add("parserRule");   } } 
type != EventType.QUERY && type != EventType.INSERT && type != EventType.UPDATE && type != EventType.DELETE
bc.getAsyncWriteService()
public Builder setScheduledExecutorService(ScheduledExecutorService reaper){   configBuilder.setScheduledExecutorService(reaper);   return this; } 
@Override public Response schema(Property property){   throw new RuntimeException("Not implemented"); } 
NetworkAddressUtils.assertValidPort(Preconditions.checkNotNull(address))
failure == null
analysis.getTypeWithCoercions(aggregate)
Boolean.getBoolean("java.awt.headless") || System.getProperty("os.name").startsWith("Mac OS") && System.getProperty("user.name").equals("cruise")
!argumentCount.isValidCount(actualCount)
hashSymbols.values()
sort.sort(inputRects.items,new Comparator<Rect>(){   public int compare(  Rect o1,  Rect o2){     int n1=o1.width > o1.height ? o1.width : o1.height;     int n2=o2.width > o2.height ? o2.width : o2.height;     return n2 - n1;   } } )
maxActiveSessions == null && servletContainerService != null
new Whitelist().addTags("a","b","blockquote","br","cite","code","dd","dl","dt","em","i","li","ol","p","pre","q","small","span","strike","strong","sub","sup","u","ul")
invocation.pendingResponse != null
public Long getNewerThan(){   return newerThan; } 
report(n,MISPLACED_ANNOTATION,"@abstract","constructors cannot be abstract")
estimatedLength < 0
that.getPath() == null && getPath() != null
MockReset.after()
Thread.sleep(300)
future1.get(2,TimeUnit.SECONDS)
ManifestUtils.getOrCreateManifest(archive)
this.connectTo(vertex,channelType,compressionLevel,indexOfOutputGate,indexOfInputGate,distributionPattern,true)
from("jms:queue2:parallelLoanRequestQueue").process(new CreditAgency()).multicast(new BankResponseAggregationStrategy().setAggregatingOutMessage(true)).parallelProcessing(true)
ImmutableSet.<String>builder().add(BUFFERS_READ,FIELDNAMES_READ,INDEXERCLUSTER_READ,INPUTS_READ,JOURNAL_READ,JVMSTATS_READ,MESSAGECOUNT_READ,MESSAGES_READ,METRICS_READ,SYSTEM_READ,THROUGHPUT_READ,SAVEDSEARCHES_CREATE,SAVEDSEARCHES_EDIT,SAVEDSEARCHES_READ,CLUSTER_CONFIG_ENTRY_READ)
Assert.assertEquals(3,propertyCategories.size())
context.createTaskContext().addPipelineContext(0,true,true,false)
JacksonMessageBodyProvider.class
OptionalIdentifiedDefinition<FromDefinition>
@InputMagicNumberIntMethodAnnotation(value=-45)
name.toString()
SLEEP_TIME=1500
incomingDir.mkdirs()
zwaveCommandClass.handleApplicationCommandRequest(serialMessage,offset + 2,0)
ImmutableSet.Builder<ImplementationMethodDescriptor>
GL20.glUniform4fv(location,v)
asList(4L)
first=word.substring(0,3)
assertEquals(conf,(Configuration)serializeDeserialize(conf))
@Override public ExtendedCell deepClone(){   return new KeyValue(this); } 
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class ReliableTopicBasicDistributedTest extends ReliableTopicAbstractTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(2).newInstances(config);   } } 
GL.glGenTextures(n,textures,Memory.getPosition(textures))
node.actor.getY() <= high && !selectedNodes.contains(node,true)
logger.fine("Normalizing")
(a & 0xe0) == 0xc0
channel.getPipeline().sendUpstreamLater(new DefaultExceptionEvent(channel,cause))
private final StringBuilder tmpSb=new StringBuilder(); 
System.out.println(hostResult)
scriptsToUpdate.add(n)
bulkInsertableMap.get(persistentObjectClass)
TransactionMetadata::setInactive
event.get(factory.getName())
container.getTimeFormat().equals(TimeFormat.DATE) || container.getTimeFormat().equals(TimeFormat.DATETIME)
environmentVariableMode=2
DataStreamSink<OUT>
ArrayUtils.subarray(args,3,args.length)
setop.getJavaName()
JSError.make(AbstractCompiler.READ_ERROR,sourceFile.getName(),e.getMessage())
stat.st_mtim.tv_nsec.longValue()
new EnumValidator(ParticipantStatus.class,true,false)
ssl.hasDefined(CommonAttributes.CA_REVOCATION_URL)
LOG.warn("I/O error when running rpc",e)
headerFilterStrategy.applyFilterToExternalHeaders(entry.getKey(),entry.getValue(),camelExchange)
/**   * Creates an exception indicating the transactional entity manager cannot be closed when it is managed by the container.  * @return an {@link IllegalStateException} for the error.  */ @Message(id=11424,value="Container managed entity manager can only be closed by the container " + "(auto-cleared at tx/invocation end and closed when owning component is closed.)") IllegalStateException cannotCloseTransactionContainerEntityManger(); 
public Builder setExecutorService(ExecutorService applicationThreadPool){   configBuilder.setExecutorService(applicationThreadPool);   return this; } 
/**   * Loads the import control file from a file.  * @param uri the uri of the file to load.  * @return the root {@link PkgControl} object.  * @throws CheckstyleException if an error occurs.  */ public static ImportControl load(final URI uri) throws CheckstyleException {   final InputStream inputStream;   try {     inputStream=uri.toURL().openStream();   }  catch (  final MalformedURLException ex) {     throw new CheckstyleException("syntax error in url " + uri,ex);   } catch (  final IOException ex) {     throw new CheckstyleException("unable to find " + uri,ex);   }   final InputSource source=new InputSource(inputStream);   return load(source,uri); } 
id=19
Ordered.LOWEST_PRECEDENCE - 5
config.getStrategyImpl()
!content.readable()
id=16512
ctx.sendUpstream(e)
id=17
getter.getType()
MessageOutput.Factory<DiscardMessageOutput>
InetAddress.getByName("127.0.0.1")
addResult.getNumRowsInSegment() >= tuningConfig.getMaxRowsPerSegment()
Arrays.asList("Java","CSharp","Python2","Python3","Node","Cpp")
Mockito.any(WorkerNetAddress.class)
HiveRexUtil.simplify(rexBuilder,node)
checkArgument(prestoTypeParameters.size() == fieldTypes.size(),"Schema mismatch, metastore schema for row column %s has %s fields but parquet schema has %s fields",columnName,prestoTypeParameters.size(),fieldTypes.size())
ugi.checkTGTAndReloginFromKeytab()
serverEnvironment.getLaunchType() != ServerEnvironment.LaunchType.DOMAIN
Throwable e
ssl.hasDefined(CommonAttributes.PROTOCOL)
yAmount != 0
stationItemName != null && openSprinkler != null
/**   * Tests for  {@link Es6SortedDependencies}  */ public class Es6SortedDependenciesTest extends SortedDependenciesTestHelper {   @Override public SortedDependencies<SimpleDependencyInfo> createSortedDependencies(  List<SimpleDependencyInfo> shuffled) throws CircularDependencyException {     return new Es6SortedDependencies<>(shuffled);   }   @Override public boolean handlesCycles(){     return true;   } } 
id=10806
level < RF_STATUS_MEDIUM_SIGNAL
IntrospectionSupport.getProperties(configuration,params,null,false)
size=500
IOException.class
new SimpleProxyPool(httpProxyList,false)
new JSONParseSpec(new TimestampSpec("timestamp","iso"),new DimensionsSpec(Arrays.asList(DIMENSIONS),Arrays.<String>asList(),null))
Preconditions.checkState(n.isModuleBody() || scope.getParent() == null,"Expected %s to be a module body, or %s to be the global scope.",n,scope)
location.equals(BlockStoreLocation.anyTier())
LoadTask.class
planNode.getPlanNodeScheduledTime()
data + end
!undirected && vizConfig.isShowArrows() && !edge.isSelfLoop()&& edge.isDirected()
new HashSet<RecordReplicationInfo>(recordStore.size())
!isTrivial()
Throwable cause
14 * Bytes.SIZEOF_LONG
Reflection.methodHandle(type,"sizeOf")
pushExecutor.execute(new NamedRunnable("OkHttp %s Push Request[%s]",hostName,streamId){   @Override public void execute(){     boolean cancel=pushObserver.onRequest(streamId,requestHeaders);     try {       if (cancel) {         frameWriter.rstStream(streamId,ErrorCode.CANCEL); synchronized (SpdyConnection.this) {           currentPushRequests.remove(streamId);         }       }     }  catch (    IOException ignored) {     }   } } )
id=10847
getSslStoreProvider().getTrustStore()
mock.expectedMinimumMessageCount(10)
value.getType().getName()
assertEquals(156,map.getLocalMapStats().getHeapCost())
new DatabaseFormatterPostgres()
CsvReporter.forRegistry(registry).convertDurationsTo(getDurationUnit()).convertRatesTo(getRateUnit())
RevisionVersion=3
new ModelNode().set(60000L)
assertEquals(800d,fStopwatch.runtime(MILLISECONDS),250d)
List<DelayedEntry>
IntrospectionSupport.setProperties(config,componentProperties)
makeResponse(new AuthorizationException("UI request '" + op + "' for '"+ user+ "' user is not authorized"),containerRequestContext,403)
new SimpleCanalConnector(address,username,password,destination)
/**   * Call WebModuleUtil.startModule on each started module  * @param servletContext  * @throws ModuleMustStartException if the context cannot restart due to a{@link MandatoryModuleException} or {@link OpenmrsCoreModuleException}  */ public static void performWebStartOfModules(ServletContext servletContext) throws ModuleMustStartException, Exception {   Log log=LogFactory.getLog(Listener.class);   List<Module> startedModules=new ArrayList<Module>();   startedModules.addAll(ModuleFactory.getStartedModules());   boolean someModuleNeedsARefresh=false;   for (  Module mod : startedModules) {     try {       boolean thisModuleCausesRefresh=WebModuleUtil.startModule(mod,servletContext,true);       someModuleNeedsARefresh=someModuleNeedsARefresh || thisModuleCausesRefresh;     }  catch (    Exception e) {       mod.setStartupErrorMessage("Unable to start module",e);     }   }   if (someModuleNeedsARefresh) {     try {       WebModuleUtil.refreshWAC(servletContext,true,null);     }  catch (    ModuleMustStartException ex) {       throw ex;     } catch (    Exception e) {       Throwable rootCause=getActualRootCause(e,true);       if (rootCause != null) {         log.fatal("Unable to refresh the spring application context.  Root Cause was:",rootCause);       }  else {         log.fatal("Unable to refresh the spring application context. Unloading all modules,  Error was:",e);       }       try {         WebModuleUtil.shutdownModules(servletContext);         for (        Module mod : ModuleFactory.getLoadedModules()) {           if (!mod.isCoreModule() && !mod.isMandatory()) {             try {               ModuleFactory.stopModule(mod,true,true);             }  catch (            Throwable t3) {               log.trace("Unable to shutdown module:" + mod,t3);             }           }         }         WebModuleUtil.refreshWAC(servletContext,true,null);       }  catch (      MandatoryModuleException ex) {         throw new MandatoryModuleException(ex.getModuleId(),"Got an error while starting a mandatory module: " + e.getMessage() + ". Check the server logs for more information");       } catch (      Throwable t2) {         log.warn("caught another error: ",t2);         throw t2;       }     }   }   for (  Module mod : ModuleFactory.getStartedModules()) {     WebModuleUtil.loadServlets(mod,servletContext);     WebModuleUtil.loadFilters(mod,servletContext);   } } 
public class XpathRegressionOuterTypeNumberTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=OuterTypeNumberCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionOuterTypeNumber.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(OuterTypeNumberCheck.class);     moduleConfig.addAttribute("max","0");     final String[] expectedViolation={"1:1: " + getCheckMessage(OuterTypeNumberCheck.class,OuterTypeNumberCheck.MSG_KEY,3,0)};     final List<String> expectedXpathQueries=Collections.singletonList("/PACKAGE_DEF");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
child.getProperties().isStreamPartitionedOn(partitioningRequirement)
override.asString()
@ConditionalOnEnabledHealthIndicator("jms")
log.warn("Unable to provision more workers. Current workerCount[%d] maximum workerCount[%d].",currValidWorkers,maxWorkerCount)
assertTrueEventually(new AssertTask(){   @Override public void run() throws Exception {     assertFalse(lock.isLocked());   } } ,20)
RequestBody.create((File)bodyContents,mediaType)
eventJournalConfig.getCacheName()
assertEquals(6358481l,received.get(0)[1])
getMapNearCacheManager(nearCacheMember)
new AutoValue_ModuleFiles(chunks,jsFiles,cssFiles)
CHECK_TEXT.computeIfAbsent("Properties",unused -> "")
public ReducedMetric registerMetric(String name,IReducer reducer,int timeBucketSizeInSecs){   return _topoContext.registerMetric(name,new ReducedMetric(reducer),timeBucketSizeInSecs); } 
setAttributeInternal(tempInodePath,false,opTimeMs,options)
resource.terminate(input.getId(),extractorId)
/**   * Make sure we don't attempt to recover inline; if the parser successfully recovers, it won't throw an exception.  */ @Override public Symbol recoverInline(BaseRecognizer<Symbol> recognizer) throws RecognitionException {   throw new RuntimeException(new InputMismatchException(recognizer)); } 
war.setWebXML(SimpleWebTestCase.class.getPackage(),"web.xml")
(JobResponse)result
id=16505
dumpErrorCountThreshold=2
partSpec.size()
ImmutableList<String>
getIntProperty("tachyon.master.web.threads",9)
ps.setNString(i,parameter)
Arrays.asList("spring-boot-starter-tomcat-","tomcat-embed-core-","tomcat-embed-el-","tomcat-embed-logging-juli-","tomcat-embed-websocket-")
Files.deleteIfExists(dir.toPath())
ReferenceCountUtil.release(holder)
LOG.trace("The sequence id for {} is continuous, pass",entry)
new ContinueProcessOperation(commandContext,execution,true)
Arrays.asList("SuppressWithNearbyCommentFilter.fileContents","SuppressionCommentFilter.fileContents")
!isNodeHealing(node.getNodeId())
assertTrue("reuse-address",networkConfig.isReuseAddress())
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class SetBasicLocalTest extends SetAbstractTest {   @Override protected HazelcastInstance[] newInstances(  Config config){     return createHazelcastInstanceFactory(1).newInstances(config);   } } 
id=10995
AtmosphereRequest.newInstance()
identifier != null
id=10869
holder.addCallback(callback)
LOG.debug("Failed to send receipt of data to worker {} for request {}: {}.",mAddress,mReadRequest,e.getMessage())
ImmutableSet.of("testAutoIndexKeyDroppingWithPersistence","testReIndexingOfElements")
uri.toString().equals(future.getURI().toString())
System.identityHashCode(o)
controller != null && controller.getState() != ServiceController.State.UP
@QueryParam("interval")
i=0
AvailablePortFinder.getNextAvailable(4000)
/**   * Represents the formatter for log message which is used in UTs. Message format is: filePath:lineNo:columnNo: message.  * @author Andrei Selkin  */ public class AuditEventUtFormatter implements AuditEventFormatter {   /**   * Length of all separators.   */   private static final int LENGTH_OF_ALL_SEPARATORS=4;   @Override public String format(  AuditEvent event){     final String fileName=event.getFileName();     final String message=event.getMessage();     final int bufLen=event.getFileName().length() + event.getMessage().length() + LENGTH_OF_ALL_SEPARATORS;     final StringBuilder sb=new StringBuilder(bufLen);     sb.append(fileName).append(':').append(event.getLine());     if (event.getColumn() > 0) {       sb.append(':').append(event.getColumn());     }     sb.append(": ").append(message);     return sb.toString();   } } 
region == null
assertEquals(1,beanInfo.getOperations().length)
GL20.glUniform1iv(location,toIntBuffer(v,offset,count))
new DatagramDnsQuery(null,addr,1)
offset == 0 || millis % offset == 0
COUNT_DATABASE.put(key,newVal)
public class CourierNew extends BasicFontMetrics { {     maxCharHeight=678;     for (int i=0; i < 128; i++)     widths[i]=600;   } } 
lastFailureException instanceof SocketTimeoutException
Integer.getInteger("org.neo4j.io.pagecache.impl.muninn.MuninnPagedFile.stripeFactor",10)
getConfiguration().getOrCreateConnectionFactory()
toEventData(key)
Thread.sleep(500)
values[i] == value
context.getLogger().logAttributeWarning(address,MESSAGES.invalidJSFSlotValue(slot.asString()),SLOT_ATTRIBUTE_NAME)
Optional.fromNullable(resourceManagement.getStats())
assertThat(page1reverse.pagination().getGlobalTotal()).isEqualTo(5)
steps <= 0
transactionalMap.set(key,value)
!taskOutput.getState().isDone()
n.getNodeData().getLabel().toLowerCase().equals(str)
assertTrue("map size is : " + map.size(),latch.await(5,TimeUnit.MINUTES))
framework.getBroadcasterFactory().lookup(a.broadcaster(),a.path(),true)
new StringLengthValidator(1,Integer.MAX_VALUE,true,false)
Status.createStatuseList(get(getBaseURL() + "statuses/mentions.json",null,true))
ObjectTypeAttributeDefinition.Builder.of(ModelKeys.REMOTE_SERVER,OUTBOUND_SOCKET_BINDING).setAllowNull(false)
protected abstract Block getBlock(); 
this.createError != null
lookup="java:/TransactionManager"
mock.expectedMessageCount(2)
findModule(moduleName)
LOG.error("Cannot create writer for app " + this.applicationId + ". Skip log upload this time. ",e1)
index >= n
LOG.error("Couldn't upload logs for " + containerId + ". Skipping this container.",e)
new StringBuilder(1024)
!broadcasterClassName.equalsIgnoreCase(DefaultBroadcaster.class.getName())
RequestTokenFactory.createOAuth2Request(null,"foo",null,false,Collections.singleton("ns_admin:read"),null,null,null,null)
dests.size() == 1 && joinTree.getNoOuterJoin()
Status.createStatuseList(get(getBaseURL() + "favorites/" + id+ ".json",new PostParameter[0],true))
id=22
"ppc64".equals(arch) || "ppc64le".equals(arch) || "aarch64".equals(arch)
Exception t2
new CommandLineException("The result couldn't be retrieved (perhaps the task was cancelled",e)
Color.fromRGB(0xF0F0F0)
assertEquals(typeString,actual().toString())
authentication.has(USERS)
new BranchedDataException("Unable to perform a mandatory sanity check due to an IO error.",e)
id=9
Foundation.log("[error] " + tag + ": "+ message)
new DynamicAwareEntry("https://localhost:8443/test",null,null,null)
toBeRemovedKeys.removeAll(keysToDelete)
logger.info("defineClass pluginClass:{} cl:{}",className,classLoader)
endFunction("delete_column_statistics_by_table: ",ret != false,null)
conn.getResponseCode() == HttpURLConnection.HTTP_OK || conn.getResponseCode() == HttpURLConnection.HTTP_BAD_REQUEST
kryo.readObject(input,JobID.class)
DeletionRetentionStrategyConfig.class
optionsOverride.getLambdaRole()
target.addTaskAndWakeup(task)
@UnrelatedTwo
(System.currentTimeMillis() - lastAccessedTime.getTime()) >= timeout
file.getAbsolutePath()
logger.severe("Failed to process response: " + responsePacket + " on response thread:"+ getName(),e)
DiagnosticType.disabled("JSC_GOOG_MODULE_IN_NON_MODULE","goog.module() call must be the first statement in a module.")
Status.createStatuseList(get(getBaseURL() + "statuses/retweets_of_me.json",null,true))
new RMNodeStatusEvent(node.getNodeID(),status,new ArrayList<ContainerStatus>(),null,null)
node.getLocalName()
new FastPathBalancedQueueRpcExecutor("deafult.FPBQ",handlerCount,maxQueueLength,priority,conf,server)
LOG.warn("OpenTracing: Failed to capture tracing data",t)
filteredSearchRequest(query,filter,IndexHelper.determineAffectedIndices(indexRangeService,deflector,range),range)
!mTFS.exists(turi)
FISHING_ROD(346,1,64)
Arrays.toString(volumes.get())
IOException e
new S_Command("00FE30",1,20.0)
log.rollWriter(true)
"streams:" + streamId
doInvoke(args.first(),args.rest())
MESSAGES.unknownMessageListenerType(messageListenerInterface.getName(),resourceAdapterName)
LOG.warn("Unable to delete {} because listInternal returns null",path)
id=10843
Throwable e
isTouched(0.5f,1)
this.registry.getValue().removeXAResourceRecovery(recovery)
total=2000
System.err.format("Tier %d: Not enough space on %s. %n" + "Desired quota: %s%n" + "Used in tiered storage: %s%n"+ "Available: %s%n",level,storageEntry.getKey(),FormatUtils.getSizeFromBytes(quota),FormatUtils.getSizeFromBytes(used),FormatUtils.getSizeFromBytes(available),FormatUtils.getSizeFromBytes(quota - used - available))
bytesToString(data).split("&",-1)
size=500
new ModelNode().set(15000L)
body.transferTo(position,target)
LOG.error("Failed to transit standby cluster to " + SyncReplicationState.DOWNGRADE_ACTIVE,e)
targetCondn == null || (nodeCondn.size() != targetCondn.size())
new DynamicAwareEntry("https://localhost:443/test",null,null,null)
parent.decrementPrioritizableForTree0(amt)
getTaskWriterCount(session) > 1 && !node.getPartitioningScheme().isPresent()
GL20.glUniform3iv(location,toIntBuffer(v,offset,count * 3))
src[i]
logger.fine(sb.toString())
JSError.make(boundFunNode,GOOG_BIND_EXPECTS_FUNCTION,pair.type.toString())
new IncrementalIndexSegment(TestIndex.getIncrementalTestIndex(),null)
requestReceived.await(10,TimeUnit.SECONDS)
"Excluding secondary region " + bestRegionReplica + " - trying to find a different region to refresh files."
new IndexSizeExceededException("%s",getOutOfRowsReason())
payload.getBodySources() != null && payload.getBodySources().size() == 1
assertEquals(1,map.size())
mapper.writeValueAsBytes(segment)
60 * 1000
RemoteInterfaceType
catalog.validateLanguageExpression(null,"simple",detail.getSimple())
factory.getEmbeddedServletContainer(initializers[0],initializers[1])
config.setSslProtocol(ssl.get(CommonAttributes.PROTOCOL).asString())
Status.createStatuseList(get(getBaseURL() + "statuses/retweeted_by_me.json",null,true))
getCamelContext().getTypeConverter().convertTo(int.class,timeout)
SCHEMA(35,false)
Thread.sleep(5000)
mLocalAlluxioClusterResource.get().getWorker()
GL11.glGetTexParameteriv(target,pname,params)
traceIds.isEmpty()
disables.contains(a.getName())
new DashboardServiceImpl(mongoRule.getMongoConnection(),dashboardWidgetCreator)
expectedMapSize / HASHMAP_DEFAULT_LOAD_FACTOR
@InputMagicNumberIntMethodAnnotation(value=43)
new SslContextBuilder(false)
id=10809
id=40
Exception t
LOG.warn("Could not parse syslog message. Not further handling.",e)
log.error("Not updating metadata, existing state[%s] in metadata store doesn't match to the new start state[%s].",oldCommitMetadataFromDb,startMetadata)
_emittedToOffset=e.startOffset
Arrays.asList("/css/**","/js/**","/images/**","/webjars/**","/**/favicon.ico")
contact.getWorldManifold()
new IOException(ExceptionMessage.BLOCK_NOT_LOCALLY_AVAILABLE.getMessage(mBlockId),e)
new IllegalArgumentException("Could not parse '" + input + "'",e)
entry.getCreateStore()
exchange.getContext().getTypeConverter().mandatoryConvertTo(InputStream.class,exchange,graph)
assertEquals(2,props.getDisabledPlugins().length)
c.writeAndFlush("[" + ctx.channel().remoteAddress() + "] "+ msg+ '\n')
id=10836
LOG.debug("Building gRPC server on " + configuration.getHost() + ":"+ configuration.getPort())
rsWrap.getMobFileCacheMissCount()
context.var("double",2)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class CountDownLatchBasicDistributedTest extends CountDownLatchAbstractTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(2).newInstances();   } } 
file.name().endsWith(".etc1")
new Font(nodeFontName,nodeFontStyle,nodeFontSize)
FlatJoinFunction.class
progress.start(0.35f)
this.getNotEmptyWaitThreadCount()
boolean multiValueResponse() default false; 
new StreamTaskException(exceptionMessage,e)
gauge.getValue() instanceof Number
ShrinkWrap.create(JavaArchive.class).addClasses(EmployeeBean.class,Employee.class).addAsManifestResource("beans.xml")
final Exception ignored
prop.getParamValue()
"GET".equalsIgnoreCase(httpMethod)
new BlobLibraryCacheManager(blobServer,FlinkUserCodeClassLoaders.ResolveOrder.CHILD_FIRST,new String[0])
Wt.getSlice(slice).plus(Wt.getSlice(slice).transpose())
new UnsupportedOperationException("PLAIN doesn't support wrap or unwrap operation")
logger.trace("Creating Object {}",count.getAndIncrement())
address.getHostAddress()
mIsMessageReady
from("jms:queue:order").to("bean:validateOrder").to("mock:validate").threads(20).unmarshal(mySecureDataFormat).delay(1000)
AsyncResult<Void>
Status.createStatuseList(get(getBaseURL() + "favorites.json","page",String.valueOf(page),true))
setAttributeInternal(inodePath,false,opTimeMs,options)
!template.contains(PATH_AUTO_NODE_INDEX) && !template.contains(PATH_AUTO_RELATIONSHIP_INDEX) && !template.contains("_auto_")
processInstanceArray.size() == 0 && StringUtils.isNotEmpty(callActivityBehavior.getProcessDefinitonKey())
reg.bind("localhost:" + port,ctx)
historicState(item,timestamp,serviceName)
createMessageConsumer(session,destinationName,messageSelector,false,null)
assertTrueAllTheTime(() -> {   assertTrue(map.containsKey(0));   Collection<Employee> valuesNullCity=map.values(predicateCityNull);   assertEquals(2,valuesNullCity.size());   Collection<Employee> valuesNotNullCity=map.values(Predicates.equal("city","cityname"));   assertEquals(3,valuesNotNullCity.size()); } ,30)
HIVE_SERVER2_ASYNC_EXEC_SHUTDOWN_TIMEOUT("hive.server2.async.exec.shutdown.timeout",10)
new IOException(ExceptionMessage.BLOCK_UNAVAILABLE.getMessage(blockId),e)
from("direct:start").aggregator().header("id").batchTimeout(500L)
fMethodDescriptions.putIfAbsent(method,description)
HeadArraySchema schema=new HeadArraySchema(); 
return false; 
getPreferences().put(key,value)
handleSecurityPermissionEndpoints(child,permConfig)
factory.get(mResponseClass,NO_ANNOTATIONS,retrofit)
delegate.requireChild(element)
Response<RemoteCallResponseType>
endpoint.expectedMinimumMessageCount(1)
1
i < 10000
BatchServerInventoryViewProvider.class
getSession(true)
LOG.debug("Exception while fetching metrics.",e)
ConcurrentHashMap<String,Channel>
this.loggingSystem.initialize(this.initializationContext,null,null)
LOG.warn("Failed to write to TachyonStore stream, block " + getCurrentBlockId() + " will not be in TachyonStorage.")
logger.fine("Renamed " + instancesRenamed + " instances of "+ propsRenamed+ " properties.")
b.getAtmosphereResources().contains(r)
Bytes.toBytes(tableNameOrRegionName)
CAPACITY=6000L
report(n,MISPLACED_ANNOTATION,"@abstract","function with a non-empty body cannot be abstract")
BufferedReader is=IOUtils.readerFromString(languagePropertiesFile)
factory.get(mResultClass,NO_ANNOTATIONS,retrofit)
rSocketMessageHandler.serverResponder()
agg.setBatchTimeout(2000L)
assertTrue(dr.isFailure())
HashMap.class
deploymentUnit.getParent() != null
response.getResponseBody().equals("")
LOG.info("Unable to parse HTTP response content",e)
this.repositories.add(0,repository)
delegate.tokenize(token,regex,group)
ObjectConverter.toBool(scriptValue)
DefaultBroadcaster.class.cast(resource.getBroadcaster()).broadcasterCache.addToCache(resource.getBroadcaster().getID(),resource,msg)
url.toServiceStringWithoutResolving()
fileName.startsWith("/") || fileName.matches("^[A-z]:\\\\\\S+$")
LinkedHashMap<String,ASTNode>
Thread.sleep(500L)
input.mark(bufferSize)
!key.equals(OAuthConstants.SCOPE)
waitUntil(() -> pongsReceived.get() == ADDRESSES_COUNT,60_000)
public class XpathRegressionLeftCurlyTest extends XpathTestSupport {   @Test public void testOne() throws Exception {     final String checkName=LeftCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionLeftCurlyOne.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(LeftCurlyCheck.class);     final String[] expectedViolation={"4:1: " + getCheckMessage(LeftCurlyCheck.class,LeftCurlyCheck.MSG_KEY_LINE_PREVIOUS,"{",1)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyOne']/OBJBLOCK","/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyOne']/OBJBLOCK/LCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testTwo() throws Exception {     final String checkName=LeftCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionLeftCurlyTwo.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(LeftCurlyCheck.class);     moduleConfig.addAttribute("option",LeftCurlyOption.NL.toString());     final String[] expectedViolation={"3:53: " + getCheckMessage(LeftCurlyCheck.class,LeftCurlyCheck.MSG_KEY_LINE_NEW,"{",53)};     final List<String> expectedXpathQueries=Arrays.asList("/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyTwo']/OBJBLOCK","/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyTwo']/OBJBLOCK/LCURLY");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   }   @Test public void testThree() throws Exception {     final String checkName=LeftCurlyCheck.class.getSimpleName();     final File fileToProcess=new File(getPath(checkName,"SuppressionXpathRegressionLeftCurlyThree.java"));     final DefaultConfiguration moduleConfig=createModuleConfig(LeftCurlyCheck.class);     final String[] expectedViolation={"5:19: " + getCheckMessage(LeftCurlyCheck.class,LeftCurlyCheck.MSG_KEY_LINE_BREAK_AFTER,"{",19)};     final List<String> expectedXpathQueries=Collections.singletonList("/CLASS_DEF[@text='SuppressionXpathRegressionLeftCurlyThree']/OBJBLOCK" + "/METHOD_DEF[@text='sample']/SLIST/LITERAL_IF/SLIST");     runVerifications(moduleConfig,fileToProcess,expectedViolation,expectedXpathQueries);   } } 
waitUntil(() -> externalNodesStarted.get() == NODE_COUNT,60_000)
/**   * Tests setup and cleanup attempts getting killed from command-line  and lost tracker  * @param mr  * @param dfs  * @param commandLineKill if true, test with command-line killelse, test with lost tracker  * @throws IOException  */ private void testSetupAndCleanupKill(MiniMRCluster mr,MiniDFSCluster dfs,boolean commandLineKill) throws Exception {   RunningJob job=launchJobWithWaitingSetupAndCleanup(mr);   JobTracker jt=mr.getJobTrackerRunner().getJobTracker();   JobInProgress jip=jt.getJob(job.getID());   TaskAttemptID setupID=getRunningTaskID(jip.getTasks(TaskType.JOB_SETUP));   if (commandLineKill) {     killTaskFromCommandLine(job,setupID,jt);   }  else {     killTaskWithLostTracker(mr,setupID);   }   UtilsForTests.writeFile(dfs.getNameNode(),dfs.getFileSystem().getConf(),setupSignalFile,(short)3);   while (job.reduceProgress() != 1.0f) {     try {       Thread.sleep(100);     }  catch (    InterruptedException ie) {     }   }   TaskAttemptID cleanupID=getRunningTaskID(jip.getTasks(TaskType.JOB_CLEANUP));   if (commandLineKill) {     killTaskFromCommandLine(job,cleanupID,jt);   }  else {     killTaskWithLostTracker(mr,cleanupID);   }   UtilsForTests.writeFile(dfs.getNameNode(),dfs.getFileSystem().getConf(),cleanupSignalFile,(short)3);   job.waitForCompletion();   assertEquals(JobStatus.SUCCEEDED,job.getJobState());   assertEquals(TaskStatus.State.KILLED,jt.getTaskStatus(setupID).getRunState());   assertEquals(TaskStatus.State.KILLED,jt.getTaskStatus(cleanupID).getRunState()); } 
t.replace(R.id.frame,new SampleListFragment())
bindingGroup.hasDefined(PORT_OFFSET)
Assert.assertNotNull(s)
NoopChatHandlerProvider.class
