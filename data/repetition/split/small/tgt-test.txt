expectedValue.equals(oldObject)
obj.setContentType(Mimetypes.MIMETYPE_BINARY_OCTET_STREAM)
server.getState()
outputDirectory="."
factory.getEmbeddedServletContainer(exampleServletRegistration(),new FilterRegistrationBean(new ExampleFilter()))
"false".equals(showRelationships) || result.hasErrors()
reg.bind("localhost:" + port,env)
AsyncHttpClientConfig.class
/**   * This is the primary connection pool class that provides the basic pooling behavior for HikariCP.  * @author Brett Wooldridge  */ public abstract class BaseHikariPool implements HikariPoolMXBean, IBagStateListener {   protected final Logger LOGGER=LoggerFactory.getLogger(getClass());   private static final long ALIVE_BYPASS_WINDOW=Long.getLong("com.zaxxer.hikari.aliveBypassWindow",1000L);   protected static final int POOL_RUNNING=0;   protected static final int POOL_SUSPENDED=1;   protected static final int POOL_SHUTDOWN=2;   public final String catalog;   public final boolean isReadOnly;   public final boolean isAutoCommit;   public int transactionIsolation;   protected final PoolUtilities poolUtils;   protected final HikariConfig configuration;   protected final AtomicInteger totalConnections;   protected final ConcurrentBag<PoolBagEntry> connectionBag;   protected final ThreadPoolExecutor addConnectionExecutor;   protected final ThreadPoolExecutor closeConnectionExecutor;   protected final ScheduledThreadPoolExecutor houseKeepingExecutorService;   protected final boolean isUseJdbc4Validation;   protected final boolean isIsolateInternalQueries;   protected volatile int poolState;   protected volatile long connectionTimeout;   protected volatile long validationTimeout;   private final LeakTask leakTask;   private final DataSource dataSource;   private final GlobalPoolLock suspendResumeLock;   private final IConnectionCustomizer connectionCustomizer;   private final AtomicReference<Throwable> lastConnectionFailure;   private final String username;   private final String password;   private volatile MetricsTracker metricsTracker;   private volatile boolean isRecordMetrics;   /**   * Construct a HikariPool with the specified configuration.  * @param configuration a HikariConfig instance  */   public BaseHikariPool(  HikariConfig configuration){     this(configuration,configuration.getUsername(),configuration.getPassword());   }   /**   * Construct a HikariPool with the specified configuration.  We cache lots of configuration items in class-local final members for speed.  * @param configuration a HikariConfig instance  * @param username authentication username  * @param password authentication password  */   public BaseHikariPool(  HikariConfig configuration,  String username,  String password){     this.username=username;     this.password=password;     this.configuration=configuration;     this.poolUtils=new PoolUtilities(configuration);     this.connectionBag=createConcurrentBag(this);     this.totalConnections=new AtomicInteger();     this.connectionTimeout=configuration.getConnectionTimeout();     this.validationTimeout=configuration.getValidationTimeout();     this.lastConnectionFailure=new AtomicReference<Throwable>();     this.isReadOnly=configuration.isReadOnly();     this.isAutoCommit=configuration.isAutoCommit();     this.suspendResumeLock=configuration.isAllowPoolSuspension() ? new GlobalPoolLock(true) : GlobalPoolLock.FAUX_LOCK;     this.catalog=configuration.getCatalog();     this.connectionCustomizer=initializeCustomizer();     this.transactionIsolation=getTransactionIsolation(configuration.getTransactionIsolation());     this.isIsolateInternalQueries=configuration.isIsolateInternalQueries();     this.isUseJdbc4Validation=configuration.getConnectionTestQuery() == null;     setMetricRegistry(configuration.getMetricRegistry());     setHealthCheckRegistry(configuration.getHealthCheckRegistry());     this.dataSource=poolUtils.initializeDataSource(configuration.getDataSourceClassName(),configuration.getDataSource(),configuration.getDataSourceProperties(),configuration.getDriverClassName(),configuration.getJdbcUrl(),username,password);     this.addConnectionExecutor=createThreadPoolExecutor(configuration.getMaximumPoolSize(),"HikariCP connection filler (pool " + configuration.getPoolName() + ")",configuration.getThreadFactory(),new ThreadPoolExecutor.DiscardPolicy());     this.closeConnectionExecutor=createThreadPoolExecutor(4,"HikariCP connection closer (pool " + configuration.getPoolName() + ")",configuration.getThreadFactory(),new ThreadPoolExecutor.CallerRunsPolicy());     long delayPeriod=Long.getLong("com.zaxxer.hikari.housekeeping.periodMs",TimeUnit.SECONDS.toMillis(30L));     ThreadFactory threadFactory=configuration.getThreadFactory() != null ? configuration.getThreadFactory() : new DefaultThreadFactory("Hikari Housekeeping Timer (pool " + configuration.getPoolName() + ")",true);     this.houseKeepingExecutorService=new ScheduledThreadPoolExecutor(1,threadFactory,new ThreadPoolExecutor.DiscardPolicy());     this.houseKeepingExecutorService.scheduleAtFixedRate(getHouseKeeper(),delayPeriod,delayPeriod,TimeUnit.MILLISECONDS);     this.houseKeepingExecutorService.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);     this.leakTask=(configuration.getLeakDetectionThreshold() == 0) ? LeakTask.NO_LEAK : new LeakTask(configuration.getLeakDetectionThreshold(),houseKeepingExecutorService);     setRemoveOnCancelPolicy(houseKeepingExecutorService);     poolUtils.setLoginTimeout(dataSource,connectionTimeout);     registerMBeans(configuration,this);     initializeConnections();   }   /**   * Get a connection from the pool, or timeout after connectionTimeout milliseconds.  * @return a java.sql.Connection instance  * @throws SQLException thrown if a timeout occurs trying to obtain a connection  */   public final Connection getConnection() throws SQLException {     return getConnection(connectionTimeout);   }   /**   * Get a connection from the pool, or timeout after the specified number of milliseconds.  * @param hardTimeout the maximum time to wait for a connection from the pool  * @return a java.sql.Connection instance  * @throws SQLException thrown if a timeout occurs trying to obtain a connection  */   public final Connection getConnection(  final long hardTimeout) throws SQLException {     suspendResumeLock.acquire();     long timeout=hardTimeout;     final long start=System.currentTimeMillis();     final MetricsContext metricsContext=(isRecordMetrics ? metricsTracker.recordConnectionRequest(start) : MetricsTracker.NO_CONTEXT);     try {       do {         final PoolBagEntry bagEntry=connectionBag.borrow(timeout,TimeUnit.MILLISECONDS);         if (bagEntry == null) {           break;         }         final long now=System.currentTimeMillis();         if (bagEntry.evicted || (now - bagEntry.lastAccess > ALIVE_BYPASS_WINDOW && !isConnectionAlive(bagEntry.connection))) {           closeConnection(bagEntry,"(connection evicted or dead)");           timeout=hardTimeout - elapsedTimeMs(start);         }  else {           metricsContext.setConnectionLastOpen(bagEntry,now);           metricsContext.stop();           return ProxyFactory.getProxyConnection((HikariPool)this,bagEntry,leakTask.start(bagEntry));         }       }  while (timeout > 0L);     }  catch (    InterruptedException e) {       throw new SQLException("Interrupted during connection acquisition",e);     }  finally {       suspendResumeLock.release();     }     logPoolState("Timeout failure ");     throw new SQLTimeoutException(String.format("Timeout after %dms of waiting for a connection.",elapsedTimeMs(start)),lastConnectionFailure.getAndSet(null));   }   /**   * Release a connection back to the pool, or permanently close it if it is broken.  * @param bagEntry the PoolBagEntry to release back to the pool  */   public final void releaseConnection(  final PoolBagEntry bagEntry){     metricsTracker.recordConnectionUsage(bagEntry);     if (bagEntry.evicted) {       LOGGER.debug("Connection returned to pool {} is broken or evicted.  Closing connection.",configuration.getPoolName());       closeConnection(bagEntry,"(connection broken or evicted)");     }  else {       connectionBag.requite(bagEntry);     }   }   /**   * Shutdown the pool, closing all idle connections and aborting or closing active connections.  * @throws InterruptedException thrown if the thread is interrupted during shutdown  */   public final void shutdown() throws InterruptedException {     if (poolState != POOL_SHUTDOWN) {       poolState=POOL_SHUTDOWN;       LOGGER.info("HikariCP pool {} is shutting down.",configuration.getPoolName());       logPoolState("Before shutdown ");       connectionBag.close();       softEvictConnections();       houseKeepingExecutorService.shutdown();       addConnectionExecutor.shutdownNow();       houseKeepingExecutorService.awaitTermination(5L,TimeUnit.SECONDS);       addConnectionExecutor.awaitTermination(5L,TimeUnit.SECONDS);       final ExecutorService assassinExecutor=createThreadPoolExecutor(configuration.getMaximumPoolSize(),"HikariCP connection assassin",configuration.getThreadFactory(),new ThreadPoolExecutor.CallerRunsPolicy());       final long start=System.currentTimeMillis();       do {         softEvictConnections();         abortActiveConnections(assassinExecutor);       }  while (getTotalConnections() > 0 && elapsedTimeMs(start) < TimeUnit.SECONDS.toMillis(5));       assassinExecutor.shutdown();       assassinExecutor.awaitTermination(5L,TimeUnit.SECONDS);       closeConnectionExecutor.shutdown();       closeConnectionExecutor.awaitTermination(5L,TimeUnit.SECONDS);       logPoolState("After shutdown ");       unregisterMBeans(configuration,this);       metricsTracker.close();     }   }   /**   * Evict a connection from the pool.  * @param proxyConnection the connection to evict  */   public final void evictConnection(  IHikariConnectionProxy proxyConnection){     closeConnection(proxyConnection.getPoolBagEntry(),"(connection evicted by user)");   }   /**   * Get the wrapped DataSource.  * @return the wrapped DataSource  */   public final DataSource getDataSource(){     return dataSource;   }   /**   * Get the pool configuration object.  * @return the {@link HikariConfig} for this pool  */   public final HikariConfig getConfiguration(){     return configuration;   }   @Override public String toString(){     return configuration.getPoolName();   }   /**   * {@inheritDoc}   */   @Override public final int getActiveConnections(){     return connectionBag.getCount(STATE_IN_USE);   }   /**   * {@inheritDoc}   */   @Override public final int getIdleConnections(){     return connectionBag.getCount(STATE_NOT_IN_USE);   }   /**   * {@inheritDoc}   */   @Override public final int getTotalConnections(){     return connectionBag.size() - connectionBag.getCount(STATE_REMOVED);   }   /**   * {@inheritDoc}   */   @Override public final int getThreadsAwaitingConnection(){     return connectionBag.getPendingQueue();   }   /**   * {@inheritDoc}   */   @Override public final void suspendPool(){     if (suspendResumeLock == GlobalPoolLock.FAUX_LOCK) {       throw new IllegalStateException("Pool " + configuration.getPoolName() + " is not suspendable");     }  else     if (poolState != POOL_SUSPENDED) {       suspendResumeLock.suspend();       poolState=POOL_SUSPENDED;     }   }   /**   * {@inheritDoc}   */   @Override public final void resumePool(){     if (poolState == POOL_SUSPENDED) {       poolState=POOL_RUNNING;       addBagItem();       suspendResumeLock.resume();     }   }   public void setMetricRegistry(  Object metricRegistry){     this.isRecordMetrics=metricRegistry != null;     if (isRecordMetrics) {       this.metricsTracker=new CodaHaleMetricsTracker(this,(MetricRegistry)metricRegistry);     }  else {       this.metricsTracker=new MetricsTracker(this);     }   }   public void setHealthCheckRegistry(  Object healthCheckRegistry){     if (healthCheckRegistry != null) {       CodahaleHealthChecker.registerHealthChecks(this,(HealthCheckRegistry)healthCheckRegistry);     }   }   /**   * {@inheritDoc}   */   @Override public Future<Boolean> addBagItem(){     FutureTask<Boolean> future=new FutureTask<Boolean>(new Runnable(){       public void run(){         long sleepBackoff=200L;         final int minimumIdle=configuration.getMinimumIdle();         final int maxPoolSize=configuration.getMaximumPoolSize();         while (poolState == POOL_RUNNING && totalConnections.get() < maxPoolSize && getIdleConnections() <= minimumIdle && !addConnection()) {           quietlySleep(sleepBackoff);           sleepBackoff=Math.min(connectionTimeout / 2,(long)((double)sleepBackoff * 1.5));         }       }     } ,true);     addConnectionExecutor.execute(future);     return future;   }   /**   * Create and add a single connection to the pool.  */   protected final boolean addConnection(){     if (totalConnections.incrementAndGet() <= configuration.getMaximumPoolSize()) {       Connection connection=null;       try {         connection=(username == null && password == null) ? dataSource.getConnection() : dataSource.getConnection(username,password);         if (isUseJdbc4Validation && !poolUtils.isJdbc4ValidationSupported(connection)) {           throw new SQLException("JDBC4 Connection.isValid() method not supported, connection test query must be configured");         }         final int originalTimeout=poolUtils.getAndSetNetworkTimeout(connection,connectionTimeout);         transactionIsolation=(transactionIsolation < 0 ? connection.getTransactionIsolation() : transactionIsolation);         poolUtils.setupConnection(connection,isAutoCommit,isReadOnly,transactionIsolation,catalog);         connectionCustomizer.customize(connection);         poolUtils.executeSql(connection,configuration.getConnectionInitSql(),isAutoCommit);         poolUtils.setNetworkTimeout(connection,originalTimeout);         connectionBag.add(new PoolBagEntry(connection,this));         lastConnectionFailure.set(null);         return true;       }  catch (      Exception e) {         lastConnectionFailure.set(e);         if (poolState == POOL_RUNNING) {           LOGGER.debug("Connection attempt to database {} failed: {}",configuration.getPoolName(),e.getMessage(),e);         }         poolUtils.quietlyCloseConnection(connection,"(exception during connection creation)");       }     }     totalConnections.decrementAndGet();     return false;   }   /**   * Fill pool up from current idle connections (as they are perceived at the point of execution) to minimumIdle connections.  */   protected void fillPool(){     final int connectionsToAdd=configuration.getMinimumIdle() - getIdleConnections();     for (int i=0; i < connectionsToAdd; i++) {       addBagItem();     }     if (connectionsToAdd > 0 && LOGGER.isDebugEnabled()) {       addConnectionExecutor.execute(new Runnable(){         public void run(){           logPoolState("After fill ");         }       } );     }   }   /**   * Permanently close the real (underlying) connection (eat any exception).  * @param connectionProxy the connection to actually close  */   protected abstract void closeConnection(  final PoolBagEntry bagEntry,  final String closureReason);   /**   * Check whether the connection is alive or not.  * @param connection the connection to test  * @return true if the connection is alive, false if it is not alive or we timed out  */   protected abstract boolean isConnectionAlive(  final Connection connection);   /**   * Attempt to abort() active connections on Java7+, or close() them on Java6.  * @param assassinExecutor   * @throws InterruptedException   */   protected abstract void abortActiveConnections(  final ExecutorService assassinExecutor) throws InterruptedException ;   /**   * Create the JVM version-specific ConcurrentBag instance used by the pool.  * @param listener the IBagStateListener instance  * @return a ConcurrentBag instance  */   protected abstract ConcurrentBag<PoolBagEntry> createConcurrentBag(  IBagStateListener listener);   /**   * Create the JVM version-specific Housekeeping runnable instance used by the pool.  * @return the HouseKeeper instance  */   protected abstract Runnable getHouseKeeper();   /**   * Fill the pool up to the minimum size.  */   private void initializeConnections(){     if (configuration.isInitializationFailFast()) {       try {         try {           if (!addConnection()) {             shutdown();             throw new PoolInitializationException(lastConnectionFailure.getAndSet(null));           }           ConnectionProxy connection=(ConnectionProxy)getConnection();           connection.getPoolBagEntry().evicted=(configuration.getMinimumIdle() == 0);           connection.close();         }  catch (        SQLException e) {           shutdown();           throw new PoolInitializationException(e);         }       }  catch (      InterruptedException ie) {         throw new PoolInitializationException(ie);       }     }     fillPool();   }   /**   * Construct the user's connection customizer, if specified.  * @return an IConnectionCustomizer instance  */   @SuppressWarnings("deprecation") private IConnectionCustomizer initializeCustomizer(){     if (configuration.getConnectionCustomizerClassName() != null) {       return createInstance(configuration.getConnectionCustomizerClassName(),IConnectionCustomizer.class);     }     return configuration.getConnectionCustomizer();   }   public final void logPoolState(  String... prefix){     if (LOGGER.isDebugEnabled()) {       LOGGER.debug("{}pool stats {} (total={}, inUse={}, avail={}, waiting={})",(prefix.length > 0 ? prefix[0] : ""),configuration.getPoolName(),getTotalConnections(),getActiveConnections(),getIdleConnections(),getThreadsAwaitingConnection());     }   } } 
new S3DataSegmentMover(mockS3Client,new S3DataSegmentPusherConfig())
globalExecutionStats.getStartedSplits()
cached.get(group)
test(externs,js,(String)null,null,ConstCheck.CONST_REASSIGNED_VALUE_ERROR)
op.get("address").add("host",host)
mSizeOnTier.containsKey(tierAlias) ? mSizeOnTier.get(tierAlias) : 0L
new StringTypeHandler()
LOG.trace("Finding components in url: {}",url)
1
assertEquals(id1,new Twitter(id3,pass3).verifyCredentials().getName())
LOGGER.log(Level.SEVERE,LocalizationMessages.ERROR_COMMITTING_OUTPUT_STREAM(),e)
monochrome=true
return loadBefore; 
constructor.getParameterTypes()
assertThat(converter.getSupportedMediaTypes()).containsExactly(MediaTypes.HAL_JSON,MediaType.parseMediaType(MediaTypes.HAL_JSON_VALUE + ";charset=UTF-8"))
new ClientBuilderImpl().serviceUrl(getPulsarBrokerUrl()).ioThreads(5)
LinkedHashMap<String,ASTNode>
LOG.warn("Storage directory " + rootPath + " does not exist")
executeJobExecutorForTime(10000,200)
configuration.addViewInterceptor(method,factory,InterceptorOrder.View.COMPONENT_DISPATCHER)
IOConverter.toInputStream(s,null)
patientState.getState().getUuid()
analysis.getTypeWithCoercions(expression)
ssl.hasDefined(CommonAttributes.CA_CERTIFICATE_FILE)
Thread.sleep(100)
level < RF_STATUS_HIGH_SIGNAL
return true; 
"Stream " + importerName
camelContext.getComponent(component,false)
Thread.currentThread().interrupted()
return false; 
eventListeners != null
new Date(1)
LOG.error("Failed to transit standby cluster to " + SyncReplicationState.DOWNGRADE_ACTIVE,e)
Exception iae
new BadRequestException("Field " + field + " is not of a numeric type and the cardinality could not be calculated either.",e1)
assertEquals(conf,(Configuration)serializeDeserialize(conf))
new RuntimeException("Could not create TypeInformation for type " + data[0].getClass().getName() + "; please specify the TypeInformation manually via "+ "StreamExecutionEnvironment#fromElements(Collection, TypeInformation)",e)
request.getContentType().startsWith("application/x-www-form-urlencoded")
suiteMethod.invoke(null)
new FlinkRuntimeException("Unexpected list element deserialization failure",e)
view.getClusteredLayerDegree(absNode)
setNetworkTimeout(connection,originalTimeout)
database.FindProduct(node.getManufacturer(),node.getDeviceType(),node.getDeviceId(),node.getApplicationVersion())
id=19
mime == null || mime.value().length == 0
DynamicAttributeRanking.refreshMinMax(this,graph)
mock.expectedMinimumMessageCount(1)
jarName.endsWith(".jar") || jarName.endsWith(".war")
RawTCPInput.class
findDelegateForNewObject(name)
endFunction("write_column_statistics: ",ret != false,null)
RetryHandlingBlockMasterClient.class
new TelnetServerInitializer()
EnterpriseMapPublisherCreateWithValueCodec.decodeResponse(response).response
GL20.glGetUniformiv(program,location,params)
p.getFileSystem(conf).delete(p,true)
JavaConversions.asJavaIterable(logManager.allLogs())
findDelegateForNewObject(name)
RT.count(s)
assertEquals(800d,fStopwatch.runtime(MILLISECONDS),250d)
http2.setInitialStreamRecvWindow(initialStreamSendWindow)
mListView.getListChildAt(index)
Status.createStatuseList(get(getBaseURL() + "statuses/public_timeline.json",null,new Paging((long)sinceID).asPostParameterList(Paging.S),false))
element.getLocalName()
websocketComponent.setMaxThreads(20)
this.thrown.expectMessage("File must exist")
contentType != null && charset == null
Thread.sleep(5000)
HiveRexUtil.simplify(rexBuilder,node)
LOG.warn("OpenTracing: Failed to capture tracing data",t)
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class,CoreAnnotations.TokenBeginAnnotation.class,CoreAnnotations.TokenEndAnnotation.class,CoreAnnotations.OriginalTextAnnotation.class)
nlDataOutNodes != null && nlDataOutNodes.getLength() > 0
!fields.contains(name)
Throwable exception
this.comparatorIgnoringType
view.getMode()
getCurrCapacityUsed()
LOG.isDebugEnabled()
new JobConf(config_,StreamJob.class)
edge.setDirection(type)
factory.terminateAll()
mock.expectedBodiesReceivedInAnyOrder("Hello World 2")
GL20.glUniformMatrix3fv(location,transpose,value)
assertTrue("Exit Statuses are supposed to be in: " + exitStatuses + ", but the actual exit status code is: "+ status.getExitStatus(),exitStatuses.contains(status.getExitStatus()))
bindings.or(ImmutableMap.<ColumnHandle,Object>of())
testSame("asdf;","var asdf;",VarCheck.NAME_REFERENCE_IN_EXTERNS_ERROR)
expiresOn.getTime()
IOException e
chain.filter(exchange).transformDeferred((call) -> filter(exchange,call))
DEFAULT_ALLOW_SPILLING=true
Exception ex
c.writeAndFlush("[you] " + msg + '\n')
ps.saveRelationship(rel)
exchange.setRequestHeader(HttpHeaders.AUTHORIZATION,"OAuth " + currentToken)
addListenerMethod2.addScopedInterceptor(NettyConstants.INTERCEPTOR_CHANNEL_PROMISE_ADD_LISTENER,NettyConstants.SCOPE,ExecutionPolicy.BOUNDARY)
CHECK_TEXT.computeIfAbsent("Properties",unused -> "")
new StormClientErrorHandler(client.name())
exchange.getIn()
LOG.warn("Async Kafka commit failed.",cause)
Math.max(1000L,connectionTimeout)
Arrays.asList("spring-boot-starter-tomcat-","tomcat-embed-core-","tomcat-embed-el-","tomcat-embed-logging-juli-","tomcat-embed-websocket-")
LOG.debug("Exception while fetching metrics.",e)
createMessageConsumer(session,destinationName,messageSelector,topic,durableSubscriptionId,false)
StringBuffer pattern=new StringBuffer(this.prefix); 
ImmutableBiMap<Integer,String>
mLineageStore.reportLostFile(fileId)
Thread.sleep(300)
assertClusterSizeEventually(2,h2)
TimeUtils.millis()
new StringBuilder(246)
HttpURLConnection.setFollowRedirects(httpRequest.getFollowRedirects())
Long.valueOf(p.getProperty("numberid.id"))
OpenmrsProfileWithoutMissingModule bean=applicationContext.getBean(OpenmrsProfileWithoutMissingModule.class); 
server.getSegment(segment.getIdentifier()) != null || peon.getSegmentsToLoad().contains(segment)
(outputFolder + File.separator + modelFolder).replace("/",File.separator)
CsvReporter.forRegistry(registry).convertDurationsTo(getDurationUnit()).convertRatesTo(getRateUnit())
grammar.getTokenDisplayNames()
ReferenceCountUtil.release(holder)
ServiceAnnouncingChatHandlerProvider.class
Assert.assertEquals(1144,details.get(1).getAbsolutePosition())
returnValue
body.endsWith("6") || body.endsWith("10")
i >= 0
runningTasks.remove(assignedTask)
ImmutableList<String>
getRequestMethod != null
id=10863
markChannelNotReadable(channel.getPipeline().getContext(NettyAsyncHttpProvider.class))
Exception t
GL.glBindTexture(target,texture)
interceptors.addLast(newAInterceptor(a))
Configuration.getMs(PropertyKey.USER_NETWORK_NETTY_TIMEOUT_MS)
Arrays.asList("cmd","ls","pwd")
mTfs.delete(mTfs.open(path),true)
type == TokenTypes.CLASS_DEF || type == TokenTypes.ENUM_DEF || type == TokenTypes.INTERFACE_DEF
routeList == null || routeList.isEmpty()
UriBuilder.fromResource(StreamAlertConditionResource.class).path("{conditionId}").build(stream.getId(),alertCondition.getId())
context.revertReloadRequired()
typeName != null
new IllegalStateException(msg.getMessage())
this(type,1); 
synchronized (references) {   if (transformed == null) {     transformed=initializer.initializeBroadcastVariable(data);     data=null;   }   return transformed; } 
statistics.addGetTimeNanos(System.nanoTime() - start)
lookup="java:/ConnectionFactory"
Bytes.toBytes(tableNameOrRegionName)
String... pathParams
Throwable exception
Arrays.asList("abstract","continue","for","new","switch","assert","default","if","package","synchronized","boolean","do","goto","private","this","break","double","implements","protected","throw","byte","else","import","public","throws","case","enum","instanceof","return","transient","catch","extends","int","short","try","char","final","interface","static","void","class","finally","long","strictfp","volatile","const","float","native","super","while","type")
lockForRescale()
new StringBuilder(560)
!isNodeHealing(node.getNodeId())
Arrays.asList("Java","CSharp","Cpp")
getOrCreateContainer().forceUnlock(dataKey)
spanEvent.getNextSpanId() != -1
id=48
"unable to parse " + optionStr
minZ != 0f || maxZ != 0f
getConnectTimeout()
10 * 1024 * 1024
clearFromMember.join()
refreshableViewWrapper.addView(newEmptyView)
(DetailAST)child
new PoolBagEntry(null,0,pool)
new SimpleAttributeDefinition("ha",new ModelNode().set(HornetQClient.DEFAULT_HA),ModelType.BOOLEAN,true)
factory.get(mResultWildcard,NO_ANNOTATIONS,retrofit)
sendTo("direct:foo")
dstPath.toString()
start.expectedMessageCount(7)
CONCURRENT_THREAD_COUNT=30
User.createUsersList(http.get("http://yusuke.homeip.net/twitter4j/en/testcases/statuses/friends/T4J_hudson.json"))
tempBlock.getPath()
getOrCreateContainer().forceUnlock(dataKey)
ChannelBuffers.buffer(2)
Status.createStatuseList(get(getBaseURL() + "statuses/user_timeline/" + id+ ".json",null,paging.asPostParameterList(),http.isAuthenticationEnabled()))
status != null
from("jms:queue2:parallelLoanRequestQueue").process(new CreditAgency()).multicast(new BankResponseAggregationStrategy().setAggregatingOutMessage(true)).parallelProcessing(true)
logger.debug("Trying to map {} to {}",t,path)
ArrayList<>
out.writeBytes(mask)
size * 1.8f
view.getMode()
LinkedHashMap<String,LinkedHashMap<String,ASTNode>>
invocation.logger.finest("Asking if operation execution has been started: " + invocation)
Configuration.getMs(PropertyKey.USER_NETWORK_NETTY_TIMEOUT_MS)
new DefaultPropertyNamePatternsMatcher(delimiters,"aaa","bbbb","ccccc")
factory.get(mResponseWildcard,NO_ANNOTATIONS,retrofit)
Exception e
!transactional && this.referenceId == referenceId
getClientConnectionManager()
new DynamicAwareEntry("https://localhost/test",null,null,null)
julianDateFloor(range,(int)date + EPOCH_JULIAN,false)
mesh.getNumVertices() / 4
beansXml.getOrCreateAlternatives()
mTestStream.getFlushedBytes()
Math.min(retryIntervalMillis,timeout.timeLeft().toMillis())
isTestOnReturn()
mPersistedFiles.removeAll(persistedFiles)
lastFailureException instanceof SocketTimeoutException
count < 0
new ScheduledJob(job,jobName,delay,period)
assertPlanEquals(expectedPlan,actualPlan)
Arrays.asList(CoreAnnotations.TextAnnotation.class,CoreAnnotations.TokensAnnotation.class,CoreAnnotations.CharacterOffsetBeginAnnotation.class,CoreAnnotations.CharacterOffsetEndAnnotation.class,CoreAnnotations.BeforeAnnotation.class,CoreAnnotations.AfterAnnotation.class,CoreAnnotations.TokenBeginAnnotation.class,CoreAnnotations.TokenEndAnnotation.class,CoreAnnotations.PositionAnnotation.class,CoreAnnotations.IndexAnnotation.class,CoreAnnotations.OriginalTextAnnotation.class,CoreAnnotations.ValueAnnotation.class,CoreAnnotations.IsNewlineAnnotation.class)
!fadeScrollBars && scrollbarsOnTop && scrollX
streamTokenizer.ttype == StreamTokenizer.TT_WORD || streamTokenizer.ttype == '"'
cursor.shouldRetry()
lexer.token == Token.HINT && !lexer.isEnabled(SQLParserFeature.StrictForWall)
key == null
pieces.length <= tagColumn
AstUtils.hasAtLeastOneAnnotation(classNode,"MessageEndpoint","EnableIntegrationPatterns")
WeakSafeReadWriteLock strongReference
camelContext.getExecutorServiceManager().shutdown(timeoutCheckerExecutorService)
new VersionMismatchLogRequest()
out.writeData(entry.getValue())
assertEquals(3,data.size())
logger.error("NODE {}: DeleteReturnRoute command failed.",nodeId)
DEFAULT_LABEL_MIPMAP=false
HELSINKI{   @Override public ServiceNowProducer get(  ServiceNowEndpoint endpoint) throws Exception {     return new HelsinkiServiceNowProducer(endpoint);   } } 
path.getPath()
uri.toString().equals(future.getURI().toString())
boundary.endsWith("\"")
options.checkProvides.isOn() || options.enables(DiagnosticGroups.MISSING_PROVIDE)
Glue optionalGlue
c * c
out.writeData(function)
System.nanoTime()
!template.contains(PATH_AUTO_NODE_INDEX) && !template.contains(PATH_AUTO_RELATIONSHIP_INDEX) && !template.contains("_auto_")
lookup="java:/TransactionManager"
ALIASES.addResourceAttributeDescription(resources,keyPrefix,container)
client.getVertx().setTimer(1000,id -> checkExpired())
cacheConfig.isUseCache()
configList == null || configList.size() == 0
new DefaultMemoryManager(totalMemory,numSlots,pageSize,true)
elementClass != null && Modifier.isPublic(elementClass.getModifiers())
this.hostToId
assertPlanEquals(expectedPlan,actualPlan)
entries.remove(timeKey)
dir.isDirectory() && !"target".equals(dir.getName()) && !dir.getName().startsWith(".")
ctx.sendUpstream(e)
HttpRequest.post("http://localhost:8080/ejbws-example/SingletonEndpoint",message,10,SECONDS)
new CacheCreateConfigOperation(cacheConfig,createAlsoOnOthers,false)
hashFunction.newHasher().putBytes(bigEndian)
TIMEOUT=40000L
group.id()
UndertowWebServer.class
items[29]
serialVersionUID=1975269372645791816L
Gdx.input.getX(i)
StatBuckets.prettyUptimeStr(secs)
public abstract class AbstractHikariConfig implements HikariConfigMXBean {   private static final Logger LOGGER=LoggerFactory.getLogger(HikariConfig.class);   private static final long CONNECTION_TIMEOUT=TimeUnit.SECONDS.toMillis(30);   private static final long VALIDATION_TIMEOUT=TimeUnit.SECONDS.toMillis(5);   private static final long IDLE_TIMEOUT=TimeUnit.MINUTES.toMillis(10);   private static final long MAX_LIFETIME=TimeUnit.MINUTES.toMillis(30);   private static int poolNumber;   private static boolean unitTest;   private volatile long connectionTimeout;   private volatile long validationTimeout;   private volatile long idleTimeout;   private volatile long leakDetectionThreshold;   private volatile long maxLifetime;   private volatile int maxPoolSize;   private volatile int minIdle;   private String catalog;   private String connectionCustomizerClassName;   private String connectionInitSql;   private String connectionTestQuery;   private String dataSourceClassName;   private String dataSourceJndiName;   private String driverClassName;   private String jdbcUrl;   private String password;   private String poolName;   private String transactionIsolationName;   private String username;   private boolean isAutoCommit;   private boolean isReadOnly;   private boolean isInitializationFailFast;   private boolean isIsolateInternalQueries;   private boolean isRegisterMbeans;   private boolean isAllowPoolSuspension;   private DataSource dataSource;   private Properties dataSourceProperties;   private IConnectionCustomizer customizer;   private ThreadFactory threadFactory;   private Object metricRegistry;   private Object healthCheckRegistry;   private Properties healthCheckProperties;   /**   * Default constructor  */   public AbstractHikariConfig(){     dataSourceProperties=new Properties();     healthCheckProperties=new Properties();     connectionTimeout=CONNECTION_TIMEOUT;     validationTimeout=VALIDATION_TIMEOUT;     idleTimeout=IDLE_TIMEOUT;     isAutoCommit=true;     isInitializationFailFast=true;     minIdle=-1;     maxPoolSize=10;     maxLifetime=MAX_LIFETIME;     customizer=new IConnectionCustomizer(){       @Override public void customize(      Connection connection) throws SQLException {       }     } ;     String systemProp=System.getProperty("hikaricp.configurationFile");     if (systemProp != null) {       loadProperties(systemProp);     }   }   /**   * Construct a HikariConfig from the specified properties object.  * @param properties the name of the property file  */   public AbstractHikariConfig(  Properties properties){     this();     PropertyBeanSetter.setTargetFromProperties(this,properties);   }   /**   * Construct a HikariConfig from the specified property file name.  <code>propertyFileName</code> will first be treated as a path in the file-system, and if that fails the  ClassLoader.getResourceAsStream(propertyFileName) will be tried.  * @param propertyFileName the name of the property file  */   public AbstractHikariConfig(  String propertyFileName){     this();     loadProperties(propertyFileName);   }   /**   * Get the default catalog name to be set on connections.  * @return the default catalog name  */   public String getCatalog(){     return catalog;   }   /**   * Set the default catalog name to be set on connections.  * @param catalog the catalog name, or null  */   public void setCatalog(  String catalog){     this.catalog=catalog;   }   /**   * Get the name of the connection customizer class to instantiate and execute on all new connections.  * @return the name of the customizer class, or null  */   @Deprecated public String getConnectionCustomizerClassName(){     return connectionCustomizerClassName;   }   /**   * Set the name of the connection customizer class to instantiate and execute on all new connections.  * @param connectionCustomizerClassName the name of the customizer class  */   @Deprecated public void setConnectionCustomizerClassName(  String connectionCustomizerClassName){     this.connectionCustomizerClassName=connectionCustomizerClassName;     LOGGER.warn("The connectionCustomizerClassName property has been deprecated and may be removed in a future release");   }   /**   * Get the customizer instance specified by the user.  * @return an instance of IConnectionCustomizer  */   @Deprecated public IConnectionCustomizer getConnectionCustomizer(){     return customizer;   }   /**   * Set the connection customizer to be used by the pool.  * @param customizer an instance of IConnectionCustomizer  */   @Deprecated public void setConnectionCustomizer(  IConnectionCustomizer customizer){     this.customizer=customizer;     LOGGER.warn("The connectionCustomizer property has been deprecated and may be removed in a future release");   }   /**   * Get the SQL query to be executed to test the validity of connections.  * @return the SQL query string, or null   */   public String getConnectionTestQuery(){     return connectionTestQuery;   }   /**   * Set the SQL query to be executed to test the validity of connections. Using the JDBC4 <code>Connection.isValid()</code> method to test connection validity can be more efficient on some databases and is recommended.  See  {@link HikariConfig#setJdbc4ConnectionTest(boolean)}.  * @param connectionTestQuery a SQL query string  */   public void setConnectionTestQuery(  String connectionTestQuery){     this.connectionTestQuery=connectionTestQuery;   }   /**   * Get the SQL string that will be executed on all new connections when they are created, before they are added to the pool.  * @return the SQL to execute on new connections, or null  */   public String getConnectionInitSql(){     return connectionInitSql;   }   /**   * Set the SQL string that will be executed on all new connections when they are created, before they are added to the pool.  If this query fails, it will be treated as a failed connection attempt.  * @param connectionInitSql the SQL to execute on new connections  */   public void setConnectionInitSql(  String connectionInitSql){     this.connectionInitSql=connectionInitSql;   }   /**   * {@inheritDoc}   */   @Override public long getConnectionTimeout(){     return connectionTimeout;   }   /**   * {@inheritDoc}   */   @Override public void setConnectionTimeout(  long connectionTimeoutMs){     if (connectionTimeoutMs == 0) {       this.connectionTimeout=Integer.MAX_VALUE;     }  else     if (connectionTimeoutMs < 1000) {       throw new IllegalArgumentException("connectionTimeout cannot be less than 1000ms");     }  else {       this.connectionTimeout=connectionTimeoutMs;     }   }   /**   * {@inheritDoc}   */   @Override public long getValidationTimeout(){     return validationTimeout;   }   /**   * {@inheritDoc}   */   @Override public void setValidationTimeout(  long validationTimeoutMs){     if (validationTimeoutMs < 1000) {       throw new IllegalArgumentException("validationTimeout cannot be less than 1000ms");     }  else {       this.validationTimeout=validationTimeoutMs;     }   }   /**   * Get the  {@link DataSource} that has been explicitly specified to be wrapped by thepool.  * @return the {@link DataSource} instance, or null  */   public DataSource getDataSource(){     return dataSource;   }   /**   * Set a  {@link DataSource} for the pool to explicitly wrap.  This setter is notavailable through property file based initialization.  * @param dataSource a specific {@link DataSource} to be wrapped by the pool  */   public void setDataSource(  DataSource dataSource){     this.dataSource=dataSource;   }   public String getDataSourceClassName(){     return dataSourceClassName;   }   public void setDataSourceClassName(  String className){     this.dataSourceClassName=className;   }   public void addDataSourceProperty(  String propertyName,  Object value){     dataSourceProperties.put(propertyName,value);   }   public String getDataSourceJNDI(){     return this.dataSourceJndiName;   }   public void setDataSourceJNDI(  String jndiDataSource){     this.dataSourceJndiName=jndiDataSource;   }   public Properties getDataSourceProperties(){     return dataSourceProperties;   }   public void setDataSourceProperties(  Properties dsProperties){     dataSourceProperties.putAll(dsProperties);   }   public String getDriverClassName(){     return driverClassName;   }   public void setDriverClassName(  String driverClassName){     try {       Class<?> driverClass=this.getClass().getClassLoader().loadClass(driverClassName);       driverClass.newInstance();       this.driverClassName=driverClassName;     }  catch (    Exception e) {       throw new RuntimeException("driverClassName specified class '" + driverClassName + "' could not be loaded",e);     }   }   /**   * {@inheritDoc}   */   @Override public long getIdleTimeout(){     return idleTimeout;   }   /**   * {@inheritDoc}   */   @Override public void setIdleTimeout(  long idleTimeoutMs){     if (idleTimeoutMs < 0) {       throw new IllegalArgumentException("idleTimeout cannot be negative");     }     this.idleTimeout=idleTimeoutMs;   }   public String getJdbcUrl(){     return jdbcUrl;   }   public void setJdbcUrl(  String jdbcUrl){     this.jdbcUrl=jdbcUrl;   }   /**   * Get the default auto-commit behavior of connections in the pool.  * @return the default auto-commit behavior of connections  */   public boolean isAutoCommit(){     return isAutoCommit;   }   /**   * Set the default auto-commit behavior of connections in the pool.  * @param isAutoCommit the desired auto-commit default for connections  */   public void setAutoCommit(  boolean isAutoCommit){     this.isAutoCommit=isAutoCommit;   }   /**   * Get the pool suspension behavior (allowed or disallowed).  * @return the pool suspension behavior  */   public boolean isAllowPoolSuspension(){     return isAllowPoolSuspension;   }   /**   * Set whether or not pool suspension is allowed.  There is a performance impact when pool suspension is enabled.  Unless you need it (for a redundancy system for example) do not enable it.  * @param isAllowPoolSuspension the desired pool suspension allowance  */   public void setAllowPoolSuspension(  boolean isAllowPoolSuspension){     this.isAllowPoolSuspension=isAllowPoolSuspension;   }   /**   * Get whether or not the construction of the pool should throw an exception if the minimum number of connections cannot be created.  * @return whether or not initialization should fail on error immediately  */   public boolean isInitializationFailFast(){     return isInitializationFailFast;   }   /**   * Set whether or not the construction of the pool should throw an exception if the minimum number of connections cannot be created.  * @param failFast true if the pool should fail if the minimum connections cannot be created  */   public void setInitializationFailFast(  boolean failFast){     isInitializationFailFast=failFast;   }   public boolean isIsolateInternalQueries(){     return isIsolateInternalQueries;   }   public void setIsolateInternalQueries(  boolean isolate){     this.isIsolateInternalQueries=isolate;   }   @Deprecated public boolean isJdbc4ConnectionTest(){     return false;   }   @Deprecated public void setJdbc4ConnectionTest(  boolean useIsValid){     LOGGER.warn("The jdbcConnectionTest property is now deprecated, see the documentation for connectionTestQuery");   }   /**   * Get the Codahale MetricRegistry, could be null.  * @return the codahale MetricRegistry instance  */   public Object getMetricRegistry(){     return metricRegistry;   }   /**   * Set a Codahale MetricRegistry to use for HikariCP.  * @param metricRegistry the Codahale MetricRegistry to set  */   public void setMetricRegistry(  Object metricRegistry){     if (metricRegistry != null) {       if (metricRegistry instanceof String) {         try {           InitialContext initCtx=new InitialContext();           metricRegistry=(MetricRegistry)initCtx.lookup((String)metricRegistry);         }  catch (        NamingException e) {           throw new IllegalArgumentException(e);         }       }       if (!(metricRegistry instanceof MetricRegistry)) {         throw new IllegalArgumentException("Class must be an instance of com.codahale.metrics.MetricRegistry");       }     }     this.metricRegistry=metricRegistry;   }   /**   * Get the Codahale HealthCheckRegistry, could be null.  * @return the Codahale HealthCheckRegistry instance  */   public Object getHealthCheckRegistry(){     return healthCheckRegistry;   }   /**   * Set a Codahale HealthCheckRegistry to use for HikariCP.  * @param healthCheckRegistry the Codahale HealthCheckRegistry to set  */   public void setHealthCheckRegistry(  Object healthCheckRegistry){     if (healthCheckRegistry != null) {       if (healthCheckRegistry instanceof String) {         try {           InitialContext initCtx=new InitialContext();           healthCheckRegistry=(HealthCheckRegistry)initCtx.lookup((String)healthCheckRegistry);         }  catch (        NamingException e) {           throw new IllegalArgumentException(e);         }       }       if (!(healthCheckRegistry instanceof HealthCheckRegistry)) {         throw new IllegalArgumentException("Class must be an instance of com.codahale.metrics.health.HealthCheckRegistry");       }     }     this.healthCheckRegistry=healthCheckRegistry;   }   public Properties getHealthCheckProperties(){     return healthCheckProperties;   }   public void setHealthCheckProperties(  Properties healthCheckProperties){     this.healthCheckProperties.putAll(healthCheckProperties);   }   public void addHealthCheckProperty(  String key,  String value){     healthCheckProperties.setProperty(key,value);   }   public boolean isReadOnly(){     return isReadOnly;   }   public void setReadOnly(  boolean readOnly){     this.isReadOnly=readOnly;   }   public boolean isRegisterMbeans(){     return isRegisterMbeans;   }   public void setRegisterMbeans(  boolean register){     this.isRegisterMbeans=register;   }   /**   * {@inheritDoc}   */   @Override public long getLeakDetectionThreshold(){     return leakDetectionThreshold;   }   /**   * {@inheritDoc}   */   @Override public void setLeakDetectionThreshold(  long leakDetectionThresholdMs){     this.leakDetectionThreshold=leakDetectionThresholdMs;   }   /**   * {@inheritDoc}   */   @Override public long getMaxLifetime(){     return maxLifetime;   }   /**   * {@inheritDoc}   */   @Override public void setMaxLifetime(  long maxLifetimeMs){     this.maxLifetime=maxLifetimeMs;   }   /**   * {@inheritDoc}   */   @Override public int getMaximumPoolSize(){     return maxPoolSize;   }   /**   * {@inheritDoc}   */   @Override public void setMaximumPoolSize(  int maxPoolSize){     if (maxPoolSize < 1) {       throw new IllegalArgumentException("maxPoolSize cannot be less than 1");     }     this.maxPoolSize=maxPoolSize;   }   /**   * {@inheritDoc}   */   @Override public int getMinimumIdle(){     return minIdle;   }   /**   * {@inheritDoc}   */   @Override public void setMinimumIdle(  int minIdle){     if (minIdle < 0) {       throw new IllegalArgumentException("minimumIdle cannot be negative");     }     this.minIdle=minIdle;   }   /**   * Get the default password to use for DataSource.getConnection(username, password) calls.  * @return the password  */   public String getPassword(){     return password;   }   /**   * Set the default password to use for DataSource.getConnection(username, password) calls.  * @param password the password  */   public void setPassword(  String password){     this.password=password;   }   /**   * {@inheritDoc}   */   @Override public String getPoolName(){     return poolName;   }   /**   * Set the name of the connection pool.  This is primarily used for the MBean to uniquely identify the pool configuration.  * @param poolName the name of the connection pool to use  */   public void setPoolName(  String poolName){     this.poolName=poolName;   }   public String getTransactionIsolation(){     return transactionIsolationName;   }   /**   * Set the default transaction isolation level.  The specified value is the constant name from the <code>Connection</code> class, eg.  <code>TRANSACTION_REPEATABLE_READ</code>.  * @param isolationLevel the name of the isolation level  */   public void setTransactionIsolation(  String isolationLevel){     this.transactionIsolationName=isolationLevel;   }   /**   * Get the default username used for DataSource.getConnection(username, password) calls.  * @return the username  */   public String getUsername(){     return username;   }   /**   * Set the default username used for DataSource.getConnection(username, password) calls.  * @param username the username  */   public void setUsername(  String username){     this.username=username;   }   /**   * Get the thread factory used to create threads.  * @return the thread factory (may be null, in which case the default thread factory is used)  */   public ThreadFactory getThreadFactory(){     return threadFactory;   }   /**   * Set the thread factory to be used to create threads.  * @param threadFactory the thread factory (setting to null causes the default thread factory to be used)  */   public void setThreadFactory(  ThreadFactory threadFactory){     this.threadFactory=threadFactory;   }   public void validate(){     Logger logger=LoggerFactory.getLogger(getClass());     validateNumerics();     if (connectionCustomizerClassName != null) {       try {         getClass().getClassLoader().loadClass(connectionCustomizerClassName);       }  catch (      Exception e) {         logger.warn("connectionCustomizationClass specified class '" + connectionCustomizerClassName + "' could not be loaded",e);         connectionCustomizerClassName=null;       }     }     if (driverClassName != null && jdbcUrl == null) {       logger.error("when specifying driverClassName, jdbcUrl must also be specified");       throw new IllegalStateException("when specifying driverClassName, jdbcUrl must also be specified");     }  else     if (driverClassName != null && dataSourceClassName != null) {       logger.error("both driverClassName and dataSourceClassName are specified, one or the other should be used");       throw new IllegalStateException("both driverClassName and dataSourceClassName are specified, one or the other should be used");     }  else     if (jdbcUrl != null) {     }  else     if (dataSource == null && dataSourceClassName == null) {       logger.error("one of either dataSource, dataSourceClassName, or jdbcUrl and driverClassName must be specified");       throw new IllegalArgumentException("one of either dataSource or dataSourceClassName must be specified");     }  else     if (dataSource != null && dataSourceClassName != null) {       logger.warn("both dataSource and dataSourceClassName are specified, ignoring dataSourceClassName");     }     if (transactionIsolationName != null) {       UtilityElf.getTransactionIsolation(transactionIsolationName);     }     if (poolName == null) {       poolName="HikariPool-" + poolNumber++;     }     if (LOGGER.isDebugEnabled() || unitTest) {       logConfiguration();     }   }   private void validateNumerics(){     Logger logger=LoggerFactory.getLogger(getClass());     if (validationTimeout > connectionTimeout && connectionTimeout != 0) {       logger.warn("validationTimeout is greater than connectionTimeout, setting validationTimeout to connectionTimeout.");       validationTimeout=connectionTimeout;     }     if (minIdle < 0 || minIdle > maxPoolSize) {       minIdle=maxPoolSize;     }     if (maxLifetime < 0) {       logger.error("maxLifetime cannot be negative.");       throw new IllegalArgumentException("maxLifetime cannot be negative.");     }  else     if (maxLifetime > 0 && maxLifetime < TimeUnit.SECONDS.toMillis(30)) {       logger.warn("maxLifetime is less than 30000ms, using default {}ms.",MAX_LIFETIME);       maxLifetime=MAX_LIFETIME;     }     if (idleTimeout != 0 && idleTimeout < TimeUnit.SECONDS.toMillis(10)) {       logger.warn("idleTimeout is less than 10000ms, using default {}ms.",IDLE_TIMEOUT);       idleTimeout=IDLE_TIMEOUT;     }  else     if (idleTimeout > maxLifetime && maxLifetime > 0) {       logger.warn("idleTimeout is greater than maxLifetime, setting to maxLifetime.");       idleTimeout=maxLifetime;     }     if (leakDetectionThreshold != 0 && leakDetectionThreshold < TimeUnit.SECONDS.toMillis(2) && !unitTest) {       logger.warn("leakDetectionThreshold is less than 2000ms, setting to minimum 2000ms.");       leakDetectionThreshold=2000L;     }   }   private void logConfiguration(){     LOGGER.debug("HikariCP pool {} configuration:",poolName);     final Set<String> propertyNames=new TreeSet<String>(PropertyBeanSetter.getPropertyNames(HikariConfig.class));     for (    String prop : propertyNames) {       try {         Object value=PropertyBeanSetter.getProperty(prop,this);         if ("dataSourceProperties".equals(prop)) {           Properties dsProps=PropertyBeanSetter.copyProperties(dataSourceProperties);           dsProps.setProperty("password","<masked>");           value=dsProps;         }         value=(prop.contains("password") ? "<masked>" : value);         LOGGER.debug((prop + "................................................").substring(0,32) + (value != null ? value : ""));       }  catch (      Exception e) {         continue;       }     }   }   abstract protected void loadProperties(  String propertyFileName);   public void copyState(  AbstractHikariConfig other){     for (    Field field : AbstractHikariConfig.class.getDeclaredFields()) {       if (!Modifier.isFinal(field.getModifiers())) {         field.setAccessible(true);         try {           field.set(other,field.get(this));         }  catch (        Exception e) {           throw new RuntimeException("Exception copying HikariConfig state: " + e.getMessage(),e);         }       }     }   } } 
return true; 
this.getDefaultReadOnly()
SLEEP_TIME=1500
eventListeners != null
this.registry.getValue().removeXAResourceRecovery(recovery)
error.expectedMinimumMessageCount(2)
target.directory("zk" + id + "data",true)
readUnlock()
new JedisClusterCommand<Set<String>>(connectionHandler,maxRedirections){   @Override public Set<String> execute(  Jedis connection){     return connection.spop(key,count);   } } 
logger.fine("Normalizing")
lookupService.lookupPrincipalByName(user)
getFirstByType(type)
assertTrueEventually(new AssertTask(){   @Override public void run() throws Exception {     assertFalse(lock.isLocked());   } } ,20)
pId + BASE_FILE_NUMBER
Exception t2
implementationMethodDescriptors.build()
S3DataSegmentMover.class
m_data.getFixString((int)m_length,charsetName)
id=10873
mListView.getListChildAt(index)
Mockito.verify(mRMClient).stop()
id=21
@DELETE
LOG.debug("Processing changes for pool " + poolName + ": "+ pools.get(poolName))
id=40
(this.getExecContext().getLocalWork() != null && this.getExecContext().getLocalWork().getInputFileChangeSensitive()) && mapJoinTables != null
assertFalse(jmsTemplate.isPubSubDomain())
GL20.glGetUniformiv(program,location,params)
id=10872
children == null
new java.util.Date(System.currentTimeMillis() - 3600 * 24)
new StringBuilder(729)
d.setDefaultEncoding(servletContainer.getDefaultEncoding())
@Override public ExtendedCell deepClone(){   byte[] copy=Bytes.copy(this.bytes,this.offset,this.length);   KeyValue kv=new KeyValue(copy,0,copy.length);   kv.setSequenceId(this.getSequenceId());   return kv; } 
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
lookup="java:/ConnectionFactory"
reg.getMeters(transformFilter(filter))
cache.setColors(style.fontColor == null ? color : Color.tmp.set(color).mul(style.fontColor))
result.expectedBodiesReceivedInAnyOrder("A+C+E+G+I","B+D+F+H+J")
propEditor != null && !type.isArray()
60 * 1000
IllegalArgumentException ise
assertEquals(4,AccessControlLists.getTablePermissions(conf,TEST_TABLE).size())
assertPlanEquals(expectedPlan,actualPlan)
stopwatch.elapsed(MILLISECONDS)
request.getContextPath()
removeBlock(sessionId,blockId,BlockStoreLocation.anyTier())
Gauge<Integer>
new IntRangeValidator(0,true,true)
traceIds.isEmpty()
assertFalse(found)
inner.innerSetException(new TimeoutException(),false)
new SSL((short)MIN_SSL_OPTIONS,(short)0,(short)sslPort)
assertEquals(orig.getResponse(),expectedResponse)
bigEndian.order()
getBoolean(ASYNC_CLIENT + "acceptAnyCertificate",false)
E
getGlobalProperty(OpenmrsConstants.GLOBAL_PROPERTY_LOCALE_ALLOWED_LIST,"")
Character.toUpperCase(ch)
TestSuiteEnvironment.getHttpAddress()
oldOverride.addParameter("enabled","enabled")
Set<String>
ObjectHelper.isNotEmpty(configuration.getClusterService())
rj.reduceProgress()
@Deprecated
buf.discardReadBytes()
context.add("exceptionalMethod",123.0f)
logger.error("{} is already cancelled",impl.uuid())
Thread.sleep(500L)
configureWebDotXmlAtmosphereHandler(scFacade)
engine.execute(query).dumpToString()
assertOpenEventually("responseLatch",responseLatch)
new ASMClassLoader(ASMSerializerFactory.class.getClassLoader())
Mockito.any(ProducerRecord.class)
new ModelNode().set(15000L)
expiresOn.getTime()
new UnderFileStatus("dummy",0L,isDirectory,0L,"owner","group",(short)077)
DEFAULT_MAX=4096
c.getPath() == null && getPath() != null
LOGGER.debug("no property for " + type + ", "+ format)
logger.debug("gave up waiting for query reply from device {}",m_address)
stopwatch.elapsed(MILLISECONDS)
E edge
analysis.getTypeWithCoercions(aggregate)
assertTrue(user.isGeoEnabled())
field.set(instance,value)
assertClusterSizeEventually(2,nodes[0])
reg.getHistograms(transformFilter(filter))
sectionStartTagToken.word()
public Long getOlderThan(){   return olderThan; } 
in.readLong()
id=20
triggerManager.getRules(CHANGE,item,oldState,newState)
getLsResultStr("/testRoot/testDir",files[1].getCreationTimeMs(),1,LsCommand.STATE_FOLDER,testUser,testUser,files[1].getPermission(),files[1].isFolder())
acquiredChannelCount < maxConnections
test("var foo = function (a) {}; foo.call(this, 1);","var foo = function () {var a$jscomp$1 = 1;}; foo.call(this);")
result.expectedMinimumMessageCount(3)
id=16
0 - originX
@ConditionalOnEnabledHealthIndicator("mongo")
JavaConversions.asJavaIterable(kafkaLog.logSegments(committedOffset,Long.MAX_VALUE))
@InputIntMethodAnnotation(value=-45)
first
case REPLACE_IF_SAME: 
GatherGetterAndSetterProperties.gather(compiler,mainRoot)
log.debug("Checking bounds key:[{}, {}) & col:[{}, {}) (expect {} keys)",new Object[]{keyStart,keyEnd,startCol,endCol,expected.size()})
className.lastIndexOf("org.openmrs.")
request.getPathInfo()
visitor.visitTypeLiteral(this)
includedGroup == null
Gdx.files.internal(fileName).pathWithoutExtension()
logger.info("{} exists but cannot be executed even when execute permissions set; " + "check volume for \"noexec\" flag; use -Dio.netty.native.workdir=[path] " + "to set native working directory separately.",tmpFile.getPath(),"io.netty.native.workdir")
new RMNodeImpl(nodeId,rmContext,null,0,0,null,null)
mavenBundle("info.cukes","cucumber-jvm-deps")
booleanSessionProperty(LEGACY_ORDER_BY,"Use legacy rules for column resolution in ORDER BY clause",featuresConfig.isLegacyOrderBy(),false)
conf.getRestBaseURL()
logger.fine("Renamed " + instancesRenamed + " instances of "+ propsRenamed+ " properties.")
mapper.getFactory()
container.getTimeFormat().equals(TimeFormat.DATE) || container.getTimeFormat().equals(TimeFormat.DATETIME)
this.originY
group != null && !"0".equals(group)
new JSONParseSpec(timestampSpec,new DimensionsSpec(dimensions,dimensionExclusions,spatialDimensions))
value()
config.getBroadcasterFactory().lookup(a.broadcaster(),path,true)
assertEquals(9,tokens.size())
IllegalStateException nsee
new CompilerException(sourcePath,e.line,e.getCause())
result.expectedMinimumMessageCount(2)
new GenerationException("Couldn't parse type: " + typeDefinition,e)
QuotaCache.this.tableQuotaCache.containsKey(table)
LOG.debug("Getting synchronous method stub from channel")
activeCount >= maxActive
buffer.readableBytes() < 8
logger.fine("Strip code")
instance2.getLifecycleService().shutdown()
node.getLifecycleService().shutdown()
version == null || version.equals("")
websocketComponent.setMaxThreads(20)
id=10806
!StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"flush") && !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"grant") && !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"create user")&& !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"drop user")&& !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"create database")&& !StringUtils.startsWithIgnoreCase(StringUtils.trim(ddl),"drop database")
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
maxSize < (used / total)
public String getRequestRequiredAcks(){   return requestRequiredAcks; } 
LOGGER.warn("Unable to process JSON",exception)
stats.getLastUpdateTime() >= lastUpdateTime
id=10802
new UnsupportedOperationException(getClass().getName())
new HashMap<>(queryMemoryRevocableReservations)
T extends Model
undertowHost.getServer().getListeners().get(0).getBinding().getValue().getAbsolutePort()
putBytes(v)
{14,3.5f}
node1.isEquivalentToTyped(node2)
executeJobExecutorForTime(10000,200)
user.getSystemId() == null || user.getSystemId().equals("")
public final TFAgentStatMapper tFAgentStatMapper=new TFAgentStatMapper(); 
websocketComponent.setMaxThreads(20)
DEFAULT_USER_AS_DEFAULT_QUEUE=true
QuotaCache.this.tableQuotaCache.containsKey(table)
e.toString()
@Override public Response description(String description){   throw new RuntimeException("Not implemented"); } 
entry.getValue().getManagementInterfaceMicroVersion()
assertEquals(3,historyService.createHistoricActivityInstanceQuery().processDefinitionId(processInstance.getProcessDefinitionId()).list().size())
Foundation.log("[info] " + tag + ": "+ message)
RetriesExhaustedException.class
idGenerator.generateUuid()
registered.remove(objectName)
E edge
value()
logger.trace("Removing: {}",r)
mCurrentBlockLeftByte >= tLen
new S_Command("00FE30",1,20.0)
abandonSegment(entry.getKey(),entry.getValue())
CxfSpringEndpointBean.class
zkWorker2.getWorker()
@Override public Response header(String name,Property property){   addHeader(name,property);   return this; } 
result.expectedMinimumMessageCount(3)
PropertyValuesAnimationAdapter<T>
routes.ExtractorsResource().create(input.getId())
createMessageConsumer(session,destinationName,messageSelector,true,null)
maxPendingPersists <= 0
new GeneralDataCoding(false,true,MessageClass.CLASS1,Alphabet.ALPHA_DEFAULT)
assertEquals(3,historyService.createHistoricActivityInstanceQuery().finished().list().size())
rowsRet <= 0 || work.getLimit() == totalRows
entry.getName().equals(BOOT_INF_CLASSES)
@RunWith(HazelcastParallelClassRunner.class) @Category({QuickTest.class,ParallelTest.class}) public class IdGeneratorBasicDistributedTest extends IdGeneratorAbstractTest {   @Override protected HazelcastInstance[] newInstances(){     return createHazelcastInstanceFactory(2).newInstances();   } } 
assertPlanEquals(expectedPlan,actualPlan)
assertEquals(6,config.getMapConfigs().size())
getHandledPredicate()
System.currentTimeMillis()
Assert.assertTrue(Boolean.valueOf(response.getFirstHeader("serialized").getValue()))
node.getLocalName()
future.isDone()
stackTrace.length <= depth
Preconditions.checkNotNull(blockIds,"blockIds")
GatherGetterAndSetterProperties.update(compiler,externs,root)
Integer.parseInt(tokens[3])
Integer.MIN_VALUE + 9
timeout=30000
CompletableFuture<Void>
ast != null && ast.getNextSibling() != null
Preconditions.checkNotNull(mBlockIdsOnTiers,"mBlockIdsOnTiers")
RestartStrategies.fixedDelayRestart(1,0)
LOG.warn("Cannot resolve the host name for " + regionAddress + " because of "+ e)
dynamicState.changingBlobs.isEmpty()
this.getDefaultReadOnly()
assertPlanEquals(expectedPlan,actualPlan)
logger.trace("MyQ binding received command '{}' for item '{}'",command,itemName)
id=38
return false; 
logger.trace("AtmosphereResource {} is resuming",uuid())
NbPreferences.forModule(DataTableTopComponent.class).getBoolean(DATA_LABORATORY_ONLY_VISIBLE,true)
executor.scheduleAtFixedRate(this,period,period,unit)
groupingSets.isEmpty()
DataStreamSink<OUT>
GL20.glUniformMatrix2fv(location,transpose,toFloatBuffer(value,offset,count << 2))
Exception t
GatherGetterAndSetterProperties.update(compiler,externs,root)
1
expectQueryToFail("UserWith:Colon",ldapUserPassword,MALFORMED_CREDENTIALS_ERROR)
removeQuotes(timestring.trim())
RT.count(s)
DiagnosticGroups.registerGroup("functionParams",FunctionTypeBuilder.INEXISTENT_PARAM,FunctionTypeBuilder.OPTIONAL_ARG_AT_END)
messageHandler.serverResponder()
DbSegmentPublisher.class
mapContainer.getMapConfig().getTimeToLiveSeconds() * 1000L
services=9
TestSuiteEnvironment.getServerAddressNode1()
new NotSupportedException("getResultSetInfo() is not supported by this resource adapter as per spec 15.11.3")
callTimeoutMs=10000
GL11.glGetFloatv(pname,params)
lines("Function.prototype.inherits = function(parentCtor) {","  function tempCtor() {};","  tempCtor.prototype = parentCtor.prototype;","  this.superClass_ = parentCtor.prototype;","  this.prototype = new tempCtor();","  this.prototype.constructor = this;","};","/** @constructor */ function A() {}","/** @constructor */ function B() {}","B.inherits(A);","use(B.superClass_);")
DiagnosticType.error("JSC_GOOG_MODULE_IN_NON_MODULE","goog.module() call must be the first statement in a module.")
type == VertexDataType.VertexBufferObject || Mesh.forceVBO
300 * Constants.SECOND_MS
StringUtil.in(name,"base","basefont","bgsound","command","link","meta","noframes","script","style","title")
javaChannel().isOpen() && config().getSoLinger() > 0
new Notification(notification,nodeService)
!Context.getEncounterService().canViewAllEncounterTypes(Context.getAuthenticatedUser())
return maxPagePartitioningBufferSize; 
doInvoke(args.first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),(args=args.rest()).first(),args.rest())
Foundation.log("[error] " + tag + ": "+ message)
0xffL << shift
Status.createStatuseList(get(getBaseURL() + "statuses/friends_timeline.json",true))
detailNode != null && detailNode.getNodeType().equals(JsonNodeType.OBJECT)
dis.readFully(serializedData,0,length)
p == null || t < -1
connection.zrevrangeByLex(key,max,min)
getRequestParameters()
logger.trace("Removing: {}",r)
annotatorImplementation.custom(inputProps,property)
args.length != 3
new Entry[2048]
defaults.jackson2JsonEncoder(new Jackson2JsonEncoder(objectMapper,EMPTY_MIME_TYPES))
segments.add(segment)
Configuration.getMs(PropertyKey.USER_NETWORK_NETTY_TIMEOUT_MS)
new StringBuilder(253)
Foundation.log("[debug] " + tag + ": "+ message)
"LEVEL".equalsIgnoreCase(ident) || "CONNECT_BY_ISCYCLE".equalsIgnoreCase(ident)
closeCode < 1001
@InputIntMethodAnnotation(-44)
toEventData(key)
future1.get(2,TimeUnit.SECONDS)
connectPromise.tryFailure(t)
new IOException("should execute connector.connect() first")
(Relationship)container
IDAUTHORITY_RETRY_COUNT_DEFAULT=20
Assert.assertTrue(Boolean.valueOf(response.getFirstHeader("serialized").getValue()))
simple.getToReceivedDate()
id=10995
IRON_SWORD(267,1,250)
idAnnotation != null && !method.isBridge()
mTestStream.getFlushedBytes()
result.expectedMinimumMessageCount(2)
id=10842
Metric<Long>
GL20.glUniform2iv(location,toIntBuffer(v,offset,count << 1))
lineageInfo.getChildren()
type != EventType.QUERY && type != EventType.INSERT && type != EventType.UPDATE && type != EventType.DELETE
Calendar.getInstance(JSON.defaultTimeZone,JSON.defaultLocale)
Preconditions.checkNotNull(jobName,"Streaming Job name should not be null.")
id=10801
zController.enqueue(doRequestStop())
obj.getRequiredTokens()
!resource.getAtmosphereResourceEvent().isClosedByClient() && !resource.getAtmosphereResourceEvent().isClosedByApplication() && !resource.isCancelled()
ufsPath.toString()
/**   * Frequency in milliseconds that the consumer offsets are auto-committed to Kafka if 'enable.auto.commit' true.  */ private Integer autoCommitInterval; 
hazelcastFactory.newHazelcastClient(newClientConfig())
ProcedureTestingUtility.waitAllProcedures(master.getMasterProcedureExecutor())
grammar.getTokenDisplayNames()
@UriParam(label="producer",defaultValue="true")
sizeNeeded > items.length
new StringBuilder(238)
isFieldKept(input,uniqueField)
Integer.parseInt(tokens[3])
(outputFolder + File.separator + apiFolder).replace("/",File.separator)
ImmutableSet.of("testStringRepresentation","testDataTypeValidationOnProperties")
group.shutdownGracefully(0,10,TimeUnit.SECONDS)
address.getHostAddress()
clearFromMember.join()
this.getDefaultReadOnly()
SecurityAutoConfiguration.class
assertRemoveSubsystemResources(servicesB)
processInstanceArray.size() == 0 && StringUtils.isNotEmpty(callActivityBehavior.getProcessDefinitonKey())
getResponse("GET","/books/" + bookId,null)
len % (1024 * 1024) / 10000
NodeTraversal.traverseEs6(compiler,scriptRoot,this)
LOG.warn(rootPath + "is not a directory")
/**   * {@inheritDoc}  */ @Override public Broadcaster addAtmosphereResource(AtmosphereResource r){   try {     if (destroyed.get()) {       logger.debug(DESTROYED,getID(),"addAtmosphereResource(AtmosphereResource<?, ?> r");       return r;     }     start();     if (scope == SCOPE.REQUEST && requestScoped.getAndSet(true)) {       throw new IllegalStateException("Broadcaster " + this + " cannot be used as its scope is set to REQUEST");     }     if (maxSuspendResource.get() > 0 && resources.size() >= maxSuspendResource.get()) {       if (policy == POLICY.FIFO) {         AtmosphereResource resource=resources.poll();         try {           logger.warn("Too many resource. Forcing resume of {} ",resource);           resource.resume();         }  catch (        Throwable t) {           logger.warn("failed to resume resource {} ",resource,t);         }       }  else       if (policy == POLICY.REJECT) {         throw new RejectedExecutionException(String.format("Maximum suspended AtmosphereResources %s",maxSuspendResource));       }     }     if (resources.contains(r)) {       return r;     } synchronized (concurrentSuspendBroadcast) {       if (resources.isEmpty()) {         BroadcasterFactory.getDefault().add(this,name);       }       checkCachedAndPush(r,r.getAtmosphereResourceEvent());       if (isAtmosphereResourceValid(r)) {         resources.add(r);       }     }   }   finally {     if (resources.size() > 0) { synchronized (awaitBarrier) {         awaitBarrier.notifyAll();       }     }   }   return r; } 
location.equals(BlockStoreLocation.anyDirInTier(tierAlias))
subProperties.putIfAbsent(subName,value)
new StringBuilder(256)
v.executeBlocking(fut -> {   try {     v.simulateKill();     fut.complete();   }  catch (  Exception e) {     fut.fail(e);   } } ,false,ar -> {   if (!ar.succeeded()) {     fail(ar.cause());   } } )
endsWith("/home/source")
lock.unlock()
logger.info("Installing Filter {}",filterName)
LOG.debug("Creating short circuit output stream for block {} @ {}",blockId,address)
attribute.getDefinition().getMarshaller()
queueLength.asString()
sizeNeeded > items.length
completionLatch.await(2500,TimeUnit.MILLISECONDS)
Class.forName(mUfsClz).getConstructor(String.class,TachyonConf.class)
assertTrue(runtimeOptions.isMonochrome())
endpointA.expectedBodiesReceivedInAnyOrder("A blue car!","A blue car, again!")
from(Constants.PARALLEL_LOANBROKER_URI).process(new CreditScoreProcessor(Constants.CREDITAGENCY_ADDRESS)).multicast(new BankResponseAggregationStrategy()).parallelProcessing(true)
Status.createStatuseList(get(getBaseURL() + "statuses/retweets_of_me.json",null,true))
ImmutableSortedSet.of("br","li","dt","dd","hr","img","p","td","tr","th")
lockMode == InodeTree.LockMode.READ
IR.thisNode()
version == null || version.equals("")
new StringBuilder(245)
new GZIPOutputStream(outputStream)
LogUtils.initializeDefaultTestConsoleLogger()
FSImageFormatPBINode.class
assertClusterSizeEventually(2,h2)
conn.getResponseCode() == HttpURLConnection.HTTP_OK || conn.getResponseCode() == HttpURLConnection.HTTP_BAD_REQUEST
toEventData(key)
Assert.assertEquals(select.size(),0)
setPin(file,true)
Bukkit.getOperators()
quoteMatcher.group(1)
endFunction("get_column_statistics_by_partition: ",statsObj != null,null)
TestSuiteEnvironment.getServerAddressNode1()
JDKAsyncHttpProvider.class
time.put(current)
conf.getRestBaseURL()
environmentVariableMode=2
getPath("checks/javadoc/Input_01.java")
shift > 0 && newroot.length == 1
ImmutableSet.copyOf(modules)
1
responseCode < OK || MULTIPLE_CHOICES <= responseCode
executionStats.getStartedSplits()
DiagnosticType.warning("JSC_NAME_REFERENCE_IN_EXTERNS","accessing name {0} in externs has no effect")
getSslStoreProvider().getTrustStore()
new JmxEndpointProperties()
LOG.debug("Retrieving location for state={} of job={} from the cache.",queryableStateName,jobId)
ctx.alloc().buffer()
authentication.has(USERS)
Byte.parseByte(value.toString())
hz1.getLifecycleService().shutdown()
config.getInputShipStrategy(1)
stat.st_size.longValue()
WebSocketProtocolStream.class.isAssignableFrom(webSocketProtocol.getClass())
toEventData(key)
distinctValues.put(slice,distinct)
/**   * Gets the key of service port.  * @return key of service port  */ public PropertyKey getPortKey(){   return mPortKey; } 
MessageSerializer.serializeServerFailure(ctx.alloc(),new RuntimeException(msg))
assertEquals(1,conceptStopWords.size())
Assert.notNull(patterns,"Patterns must not be null")
row == null || row.size() == 0
binder.bindConstant().annotatedWith(Names.named("servicePort")).to(8089)
ImmutableSet<ImplementationMethodDescriptor>
LOG.warn("OpenTracing: Failed to capture tracing data",t)
return true; 
mock.expectedMinimumMessageCount(2)
getSsl(ClientAuth.NEED,"password","src/test/resources/test.jks","src/test/resources/test.jks")
patientExitObs != null && patientExitObs.size() > 0
compare(leftValue,rightValue) >= 0
twitter4j.List.createListList(get(getApiBaseURL() + V1 + user+ "/lists/memberships.json?cursor="+ cursor,true))
new StringBuilder(560)
writeDelaySeconds=10
VARBINARY.createBlockBuilder(new BlockBuilderStatus(),1)
new Date(1)
CamelContextHelper.parseInteger(getCamelContext(),maxQueueSize)
war.setWebXML(ClusteredWebTestCase.class.getPackage(),"web.xml")
factory.getEmbeddedServletContainer(exampleServletRegistration(),new FilterRegistrationBean(new ExampleFilter()))
public Builder setRealmPassword(String password){   realm().setPassword(password);   return this; } 
new HashSet<RecordReplicationInfo>(recordStore.size())
drawable != null
return 16; 
assertTrue(dr.isFailure())
NONCONFORMING_LR_RULE(169,"rule <arg> is left recursive but doesn't conform to a pattern ANTLR can handle",ErrorSeverity.ERROR)
endpoint.getBus().getInInterceptors().size() >= 1
other.getLimit()
!key.equals(OAuthConstants.SCOPE)
currentStage != NodeStage.DONE && sendMessage() == false
Assert.assertEquals(new InetSocketAddress("RemoteMaster1",10000),masterAddress)
pushExecutor.execute(new NamedRunnable("OkHttp %s Push Data[%s]",hostName,streamId){   @Override public void execute(){     try {       boolean cancel=pushObserver.onData(streamId,buffer,byteCount,inFinished);       if (cancel)       frameWriter.rstStream(streamId,ErrorCode.CANCEL);       if (cancel || inFinished) { synchronized (SpdyConnection.this) {           currentPushRequests.remove(streamId);         }       }     }  catch (    IOException ignored) {     }   } } )
TIMEOUT=30000
rsWrap.getMobFileCacheMissCount()
mock.expectedBodiesReceivedInAnyOrder("c","b","a")
{11,7.0f}
@Deprecated
new StringBuilder(560)
assertEquals(10,set.size())
connection.zrevrangeByLex(key,max,min)
getNonCompilablePath("InputPackageDeclarationDiffDirectoryAtSubpackage.java")
client.getStatusCodeReply()
@SuppressWarnings("unused") private final WeakSafeReadWriteLock strongReference; 
n <= k && i > 0
this.thrown.expectMessage("File must not be null")
checkpointPath.toString()
Math.max(clientCount,1)
"Using bind address: " + bindAddress
ShrinkWrap.create(JavaArchive.class).addAsManifestResource("beans.xml")
Utils.javaDeserialize(_boltSer,IBatchBolt.class)
deletionRetentionStrategyConfig == null
log.warn("Unexpected exception on closing transaction.  Cause: " + e)
document.tokens().get(9)
WebAppUtils.getResolvedRMWebAppURLWithScheme(conf)
builder(SingleSignOnDefinition.INSTANCE).addAttributes(SingleSignOnDefinition.DOMAIN,SingleSignOnDefinition.PATH,SingleSignOnDefinition.HTTP_ONLY,SingleSignOnDefinition.SECURE,SingleSignOnDefinition.COOKIE_NAME)
toBeRemovedKeys.removeAll(keysToDelete)
line.toString(charset)
addGroupedInterceptor(filter,interceptorClassName,null,group,executionPolicy)
log.debug("Error while closing command context",exception)
put.getWriteToWAL()
meta.setContentType(Mimetypes.MIMETYPE_OCTET_STREAM)
sname.getParent().getSimpleName().substring(8)
id=10844
page.getRetainedSizeInBytes()
z / vz
testError("class Foo extends BaseFoo { method() { Foo.base(this, 'method'); } }",BASE_CLASS_ERROR)
registry.bind("kinesisClient",amazonKinesisClient)
addKeys(externalClasses,DATE_TIME,"org.joda.time.DateTime","org.joda.time.ReadableDateTime","javax.xml.datatype.XMLGregorianCalendar","java.time.LocalDateTime")
tableLayoutHandle.getPartitions().isPresent()
executeJobExecutorForTime(10000,200)
connection.psubscribe(jedisPubSub,patterns)
cluster.getTypeFactory().createSqlType(SqlTypeName.DECIMAL,unscaled.toString().length(),bd.scale())
ReferenceCountUtil.release(holder)
val.get(k)
postAgg.getName().equalsIgnoreCase(metricName)
newId >= max
Status.createStatuseList(get(getBaseURL() + "statuses/mentions.json",null,true))
bits2[1] == true
assertThat(page1reverse.pagination().getGlobalTotal()).isEqualTo(5)
/**   * Make sure we don't attempt to recover inline; if the parser successfully recovers, it won't throw an exception.  */ @Override public Symbol recoverInline(BaseRecognizer<Symbol> recognizer) throws RecognitionException {   throw new RuntimeException(new InputMismatchException(recognizer)); } 
new DynamicAwareEntry("http://localhost:8080/test",null,null,null)
message.getFilteredFields()
LOG.warn("Promotion of block " + blockId + " failed.")
addKeys(externalClasses,DATE,"org.joda.time.LocalDate","java.time.LocalDate")
config.getBroadcasterFactory().lookup(m.broadcaster(),path,true)
autoCommit != null && autoCommit != conn.getAutoCommit()
getter.getType()
assertEquals("string",model.getProperties().get(NAME).getType())
enabled=true
ExprEval.ofLong(null)
queue.size() > 100000
endsWith("/home/source")
logger.debug("Receive queue TAKE: Length={}",recvQueue.size())
!this.fs.delete(filePath,false)
xtw.writeCData(customProperty.getSimpleValue())
new CamelExchangeException("JettyClient failed with state " + exchangeState,exchange,exchange.getException())
segments.add(segment)
waitUntil(() -> clusterManager.getNodes().size() == 2,60_000)
new ModelNode().set(17500L)
bar.setResultWaitTime(1000)
new IllegalArgumentException("'level' cannot be null")
Color.fromRGB(0xABABAB)
xAmount != 0
Assert.notNull(artifactId,"ArtifactId must not be null")
ConversionException e
LOG.debug("Terminating channel to the remote gRPC server")
getNonCompilablePath("InputPackageDeclarationDiffDirectoryAtParent.java")
testClass.getMethod(SUITE_METHODNAME)
Wt.getSlice(slice).plus(Wt.getSlice(slice).transpose())
Integer id=Integer.parseInt(reader.getAttributeValue(null,"id")); 
return 1; 
ImmutableList.copyOf(interceptors)
grammar.getTokenDisplayNames()
new PutBackupOperation(name,dataKey,dataValue,replicationInfo,true,false)
@DELETE
Assert.assertTrue(mFileSystem.getStatus(uri).getInMemoryPercentage() == 100)
start.set(Calendar.DAY_OF_MONTH,startDay)
CsvReporter.forRegistry(registry).convertDurationsTo(getDurationUnit()).convertRatesTo(getRateUnit())
Mono.just(entry.getKey()).zipWith(entry.getValue().health().compose(this.timeoutCompose))
{11,7.0f}
minZ != 0f || maxZ != 0f
i > 0
dstPath.toString()
STANDALONE
id=10841
Character.toUpperCase(ch)
visitStatement(node,context)
getMockEndpoint("mock:test.after.1").expectedMessageCount(10)
Color.rgba8888ToColor(color,colorInt)
-2
GL.glTexSubImage2D(target,level,xoffset,yoffset,width,height,format,type,pixels,Memory.getPosition(pixels))
engine.execute(cypher).dumpToString()
status().isFound()
final StringBuilder result=new StringBuilder(20); 
private CsvFilter filter; 
twitter1.getRetweets(1021608606934822912L)
size=250
executionJobVertex.getMaxParallelism()
typeSerializer.getDeserializedType()
prePassivates != null
hints.append(LocalizationMessages.HINT_MSG(error.getMessage()))
ctx.alloc().buffer()
member.getType()
Nd4j.getAffinityManager().getDeviceForCurrentThread()
DefaultChannelFuture.setUseDeadLockChecker(true)
pId + BASE_FILE_NUMBER
GL.glCopyTexSubImage2D(target,level,xoffset,yoffset,x,y,width,height)
ImmutableSet.Builder<ImplementationMethodDescriptor>
LOG.warn("Promotion of block " + blockId + " failed.")
id=10804
new byte[11]
LOG.debug("Failed to get mount information: {}",e.getMessage())
left.getRowLength()
clusterProperties.getMaxRedirects()
log.error("Error while closing command context",exception)
new StringInputRowParser(new JSONParseSpec(new TimestampSpec("timestamp","auto"),new DimensionsSpec(Arrays.asList("dim1","dim2"),null,null)),null,null,null,null)
32 << 10
ExprEval.ofDouble(null)
Status.createStatuseList(get(getBaseURL() + "statuses/user_timeline/" + id+ ".json",http.isAuthenticationEnabled()))
Status.createStatuseList(get(getBaseURL() + "statuses/retweeted_to_me.json",null,paging.asPostParameterList(),true))
registerConsumer(owner,newUUIDString(),newUUIDString(),attributes)
eventJournalConfig.getCacheName()
context.var("double",2)
Flux.create(camelSink::set,FluxSink.OverflowStrategy.IGNORE)
lookup="java:jboss/mail"
routes.ExtractorsResource().create(input.getId())
dbSqlSessionFactory.getDatabaseCatalog() != null && dbSqlSessionFactory.getDatabaseCatalog().length() > 0
workerCount--
ModuleFactory.stopModule(mod,true,true)
getTablename().getName()
logger.trace("Trying to map {} to {}",t,path)
endFunction("write_partition_column_statistics: ",ret != false,null)
pushExecutor.execute(new NamedRunnable("OkHttp %s Push Reset[%s]",hostName,streamId){   @Override public void execute(){     pushObserver.onReset(streamId,errorCode); synchronized (SpdyConnection.this) {       currentPushRequests.remove(streamId);     }   } } )
!active
Status.createStatuseList(get(getBaseURL() + "favorites/" + id+ ".json","page",String.valueOf(page),true))
getTaskWriterCount(session) > 1 && !node.getPartitioningScheme().isPresent()
event.getChangeColumns()
total=2000
AtmosphereInterceptorWriter.class
next.getField(1)
log.warn("Unable to provision more workers. Current workerCount[%d] maximum workerCount[%d].",currValidWorkers,maxWorkerCount)
stats.facetFilter(standardFilters(range,filter))
configuredScriptEngineNames == null || configuredScriptEngineNames.isEmpty()
logger.error("Invalid Atmosphere Version {}",javascriptVersion)
response.get(ROLLED_BACK)
DataStreamSink<OUT>
StringUtils.hasLength(secretQuestion) && StringUtils.hasLength(secretAnswer)
ConfigUtils.absoluteStormLocalDir(stormConf)
details.setProperty(CONFIG_HASH_KEY,currentConfigHash)
expectedMinimumCount == -1 && expectedCount <= 0
Assert.assertEquals(3,json.size())
Color.fromRGB(0x51301A)
assertTrue(runtimeOptions.isMonochrome())
sExecutorService.shutdownNow()
assertTrue("reuse-address",networkConfig.isReuseAddress())
remoteAddressAliases != null && returnValue
result.expectedMinimumMessageCount(3)
executor.scheduleAtFixedRate(this,period,period,unit)
standardSearchRequest(query,IndexHelper.determineAffectedIndices(indexRangeService,deflector,range),range)
scanFeatures(getCamelKarafFeatureUrl(),"xml-specs-api","camel-core","camel-spring","camel-test")
connections.get(target)
